{"pages":[{"title":"","text":"About Front-end Engineer who is interested in Elixir, Ruby and Rust.","link":"/about/index.html"},{"title":"English Dishes","text":"English Dishes","link":"/english-dishes/index.html"},{"title":"Github","text":"Redux-Form Demo in Autofill React Component in Bootstrap4 Guide written in BS3 in CFB Homepage written as RWD in Bootstrap Components in Hover Effects in CSS3 in Basic Animate in CSS3 in Checkbox Styles in Loading Styles in","link":"/github/index.html"}],"posts":[{"title":"1 Dot -> 3 Dots","text":"section{margin:0 auto;}.button{ display:inline-block; font-size:30px; border:1px solid maroon; padding:10px 20px; color:maroon; position:relative;}.button:before{ position:absolute; top: 50%; left: 50%; color:transparent; content:”·”; text-shadow:0 0 transparent; font-size: 1.2em; transition: text-shadow .3s,color .3s; transform:translateX(-50%);}.button:hover:before{ color:maroon; text-shadow: 10px 0 maroon, -10px 0 maroon;} ButtonUse text-shadow to generate other dots. /HTML/ div.button{Button} /CSS/ .button{ display:inline-block; font-size:30px; border:1px solid maroon; padding:10px 20px; color:maroon; position:relative; } .button:before{ position:absolute; top: 50%; left: 50%; color:transparent; content:”·”; text-shadow:0 0 transparent; font-size: 1.2em; transition: text-shadow .3s,color .3s; transform:translateX(-50%); } .button:hover:before{ color:maroon; text-shadow: 10px 0 maroon, -10px 0 maroon; }","link":"/2016/06/19/1-dot-3-dots/"},{"title":"4 Simple Transitions of Button","text":"4 Simple CSS Transition to Enchance Your ButtonsDarkenSet a darker shade background color when :hover is activated Fade OutSet opacity to 1 by default, and reduce the opacity when :hover is activated. Change ColorInset BorderTo create an inset of border, button: hover{ box-shadow: inset 0 0 0 5px #darkderColor; }","link":"/2016/05/29/4-simple-transitions-of-button/"},{"title":"5 Tips in CRA@2.0","text":"Original It’s fucking long time not learning React. Five Tips Displaying Lint Error in the Editor Create .eslintrc with content of 123{ \"extends: \"react-app\"} Formatting Code Automatically 1npm install --save-dev prettier husky lint-staged And add scripts in package.json 12345678910{ \"husky\": { \"hooks\": { \"pre-commit\": \"lint-staged\" } }, \"lint-staged\": { \"src/**/*.{js,jsx,json,css}\": [\"prettier --write\", \"git add\"] }} I prefer to use prettier with eslint Developing Components in Isolation … I use bit Making a Progressive Web App In src/index.js, change serviceWorker.unregister() to serviceWorker.register() Code Splitting Create React App v2 supports code splitting via dynamic import() statements. That is, if it encouters a call to import('./someModule') when building your app, it will create a new chunk for someModule and all its dependencies, totally seperate from your entry bundle. 1234567891011import React, { Component } from 'react'import { Formik } from 'formik'import * as Yup from 'yup'const formValidator = Yup.object().shape(/* ... */)export default class Form extends Component { render() { return &lt;Formik validationSchema={formValidator}&gt;{/* ... */}&lt;/Formik&gt; }} 12345678910111213141516import React, { Component } from 'react'export default class App extends Component { state = { Form: undefined, } showForm = async () =&gt; { const { default: Form } = await import('./Form') this.setState({ Form }) } render() { const { Form } = this.state return &lt;div className=\"app\"&gt;{Form ? &lt;Form /&gt; : &lt;button onClick={this.showForm}&gt;Show Form&lt;/button&gt;}&lt;/div&gt; }}","link":"/2018/11/11/5-tips-in-CRA-2-0/"},{"title":"7 Ways You Can Design Your Home Office for Maximum Productivity","text":"1. Keep Your Personal Life in a Separate RoomYou should never work in your comfort zone. For example: the kitchen is for eating, the common space is for socializing, the bedroom is for sleeping and so the office is for working.You need to establish those boundaries early on, because they can quickly become bad habits. 2. Establish Boundaries with Your HousematesHousemates need to understand that there are boundaries, that you can not be distracted or take on responsibilities such as housework or babysitting children. 3. Don’t Buy Too Much Equipments4. Don’t Commit to Your Home Office Design Too MuchIt’s important to remember that an outside world does in fact exist. 5. Get Natural Light and Green Plants6.Treat Working Hours as If You Were at Work7. Tweak Your Comfort LevelEnsure the environment won’t distract you. For example, music, seat, temperature, make sure everything can keep you attention to your work.","link":"/2016/07/16/7-ways-you-can-design-your-home-office-for-maximum-productivity/"},{"title":"AVA Usage","text":"测试语法``` import test from ‘ava’","link":"/2017/04/20/AVA-Usage/"},{"title":"8 Material Design Web UI Framework","text":"Origin of Material DesignGoogle has its own Polymer Project which embraces Material Design thourghout its Web Components. And in fact, the Polymer Project played a key role in Material Design’s development and in showcase of Material Design Concept of Web. 8 Material Design Web UI Framework1. Materialize A modern responsive front-end framework based on Material Design. It provides an option of both CSS as well as source SCSS Files, along with JavaScript, Material Design Icon and Roboto font. Included components are basic ones such as grids, forms, buttons, navbar and cards. Available in 2. Material UI Material UI is a CSS Framework and a Set of React Components that implement Google’s Material Design. Avaiblable in 3. Paper Bootstrap for Bootstrap Paper is a bootstrap theme for the Bootstrap Framework. 4. Bootstrap Material Similar to Paper, Bootstrap Material is another theme for Bootstrap framework and provides all the components included in Bootstrap. Besides, it covers 740 original Material Design Icons from the Google Material Design Icons Repo. 5.Leaf Leaf is CSS Framework developed by Kim Korte based on the Google’s material design. While still in beta, it has extensive list of components such as buttons, cards, sliders, menu, tabs etc. It includes icons by Icomoon, instead of the original Material Design Icons. Leaf is also available on 6.MUI CSS Framework MUI is lightweighted HTML, CSS and JS Framework for building sites following Google’s Material Design Principles. MUI is designed from the ground up to be fast, small and developer friendly. By design it only includes the basic components you need to build a site that follows Material Design Guideline. Availabel in 7. Polymer Project Google’s Polymer Project is a web framework and their embodiment of material design of teh web.While still in ‘developer preview’, most of the components are quite mature. Polymer aims to support all major modern browser such as IE(10+), Chrome, Safari, and Firefox. 8. Material Design Lite Material Design lets you add a Material Design look and feel to your website. It doesn’t rely on any JS frameworks adn aims to optimize for cross devices use, gracefully degrade in older browsers, and offer an experience that is immediately accessible. Availabel in","link":"/2016/05/22/7-material-design-web-ui-framework/"},{"title":"Advanced Topics of TS","text":"Iterators and GeneratorsIterators are basically objects that can be hold more than one item. Iterators are collections of objects or variables or items that can be iterated on to do some sort of processing on each item in the collection. Arrays are an exmaple of iterators. In TypeScript, an object is demmed iterable if it has an implementation for Symbol.iterator property. Some built-in types like Array, Map, Set, String, Int32Array, etc. have their Symbol.iterator property already implemented. Symbol.iterator function on an object is responsible for returning the list of values to iterate on. for...of... statements for...of... loops over an iterable object will invoke the Symbol.iterable property on the object. 12345let someArray = [1, 'string', false]for (let entry of someArray) { console.log(entry) // 1, 'string', false} Intersection TypesAn intersection type combines multiple types into one. This is allows you to add together existing types to get a single type that has all the features you need. Union TypesUnion Types are closely related to intersection types, but they are used very differently. Occasionally, you’ll run into a library that expects a parameter to be either a number or a string. Type GuardsUnion Types are useful for modeling situations when values can overlap in the types they can take on. TypeScript has what is called a type guard. A type guard is some expression that performs a runtime check that guarantees the type in some scope. To define a type guard, we simply need to define a function whose return type is a type predicate. 123function isFish(pet: Fish | Bird): pet is Fish { return (&lt;Fish&gt;pet).swim !== undefined} pet is Fish is our type predicate in this example. A predicate takes the form parameterName is Type, where parameterName must be the name of a parameter from the current function signature. Any time isFish is called with some variable, TypeScript will narrow that variable to that specific type if the original type is compatible. 12345if (isFish(pet)) { pet.swim()} else { pet.fly()} Notice that TypeScript not only knows that pet is Fish in the if branch, it also knows that in the else branch you don’t have a fish, so you must have a Bird. typeof type guards1234567891011121314151617function isNumber(x: any): x is number { return typeof x === 'number'}function isString(x: any): x is string { return typeof x === 'string'}function padLeft(value: string, padding: string | number) { if (isNumber(padding)) { return Array(padding + 1).join(' ') + value } if (isString(padding)) { return padding + value } throw new Error(`Expected string or number, got ${padding}`)} However, having to define a functino to figure out if a typeis a primitive is kind of a pain. TypeScript will recognize typeof x === 'number' as a type guard on its own. This means we could just write checks inline. 1234567891011function padLeft (value: string, padding: number | string ) { if (typeof padding === 'number') { // ... } if (typeof padding === 'string') { // ... } throw new Error(`Expected string or number, got ${padding}`)} These typeof type guards are recognized in two different forms: typeof v === 'typename' and typeof v !== 'typename'. instanceof type guardsinstanceof type guards are a way of narrowing types using their constructor function. The right side of the instanceof needs to be a constructor function, and TypeScript narrow down to: the type of the function’s prototype property if its type is not any. the union of types returned by that type’s construct signatures. in that order. Generics123function identity&lt;T&gt;(arg: T): T { return arg} We add a type variable T to the identity function. This T allows us to capture the type the user of the code provides, so that we can use that information later. We say that this version of the identity function is generic, as it works over a range of types. Once we’ve written the generic identity function, we can call it in one of two ways. The first way is to pass all of the arguments, including the type argument, to the function. 1let output = identity&lt;string&gt;('myString'); // type of output will be string Here we explicitly set T to be string as one of the arguments to the function call, denoted using &lt;&gt; around the arguments rather than (). The second way is also perphaps the most common. Here we use type argument inference – that is, we want the compiler to set the value of T for us automatically based on the type of the argument we pass in. 1let output = identity('myString'); // type of output will be 'string' Working with Generic Type VariablesWhen you begin to use generics, you’ll notice that when you create generic functinos like identity, the compiler will enfore that you use any generically typed parameters in the body of the function correctly. Generic Types123456789101112131415161718192021function identity&lt;T&gt;(arg: T): T { return arg;}let myIdentity: &lt;T&gt;(arg: T) =&gt; T = identity// we can also write the generic type as a call signature of an object literal type:let myIdentity: {&lt;T&gt;(arg: T) : T} = identityinterface GenericIdentityFn { &lt;T&gt;(arg: T): T}// orinterface GenericIdentityFn&lt;T&gt; { (arg: T): T}let myIdentity: GenericIdentityFn&lt;number&gt; = identity Generic ClassesA generic class has a similar shape to a generic interface. Generic classes have a generic type parameter list in angle brackets(&lt;&gt;) following the name of the class. 123456class GenericNumber&lt;T&gt; { zeroValue: T; add: (x: T, y: T) =&gt; T;}let myGenericNumber = new GenericNumber&lt;number&gt;() Generic classes are only generic over their instance side rather than their static side. DecoratorA Decorator is a special kind of declaration that can be attached to a class declaration, method, accessor, property, or parameter. Sometimes it is required to have additional features to support annotating or modifying classes and class members. Decorators provide a way to add both annotation and a meta-programming syntax for class declarations and members. Decoration use the form @expression, where expression must evaluate to a function that will be called at runtime with information about the decorated declaration.","link":"/2017/08/17/Advanced-Topics-of-TS/"},{"title":"APIs of InfluxDB","text":"The InfluxDB API provides a simple way interact with the database. It uses HTTP response codes, HTTP authentication, JWT Token, and basic authentication and responses are returned in JSON. The following sections assume your InfluxDB instance is running on localhost port 8086 and HTTPS is not enabled. Endpoints Endpoint Description /ping use /ping to check the status of your InfluxDB instance and your version of InfluxDB /query use /query to query data and manage databsae, retention policies and users /write use /write to write data to a pre-exising databse /pingThe ping endpoint accepts both GET and POST HTTP requests. Use this endpoint to check the status of your InfluxDB instance and your version of InfluxDB. Definition123GET http://localhost:8086/pingHEAD http://localhost:8086/ping ExampleExtract the version of your InfluxDB instance in the X-Influxdb-Version field of the header 1234567$ curl -sl -I localhost:8086/pingHTTP/1.1 204 No ContentContent-Type: application/jsonRequest-Id: [...]X-Influxdb-Version: 1.2.xDate: Wed, 01 Mar 2017 00:09:51 GMT Status Codes and ResponsesThe response body is empty HTTP Status Code Description 204 Success! Your InfluxDB instance is up and running /queryThe /query endpoint accepts GET and POST HTTP requests. Use this endpoint to query data and manage databases, retention policies, and users. Definition123GET http://localhost:8086/queryPOST http://localhost:8086/query Verb usage verb Query Type GET use for all queries that start with SETECT, SHOW POST use for all queries that start with ALTER, CREATE, DELETE, DROP, GRANT, KILL, REVOKE THe only exceptions are SELECT queries that include an INTO clause. Those SELECT queries require a POST request. ExampleExample 1: Query data with a SELECT statement123curl -G 'http://localhost:8086/query?db=mydb' --data-urlencoded 'q=SELECT * FROM \"mymeas\"'{\"results\":[{\"statement_id\":0,\"series\":[{\"name\":\"mymeas\",\"columns\":[\"time\",\"myfield\",\"mytag1\",\"mytag2\"],\"values\":[[\"2017-03-01T00:16:18Z\",33.1,null,null],[\"2017-03-01T00:17:18Z\",12.4,\"12\",\"14\"]]}]}]} The mymeas measurement has two points. The first point has the timestamp 2017-03--1T00:15:18Z, a myfield value of 33.1 and no tag values for the mytag1 and mytag2 tag keys. The second point has the timestamp 2017-03--1T00:18:18Z, a myfield value of 12, a mymeas value of 12, a mytag1 value of 12 and a mytag2 value of 14 The same query in InfluxDB’s Command Line Interface(CLI) returns the following table: 12345name: mymeastime myfield mytag1 mytag2---- ------- ------ ------2017-03--1T00:15:18Z 33.12017-03--1T00:18:18Z 12 12 14 Example 2: Query data with a SELECT statement and an INTO clause1curl -XPOST 'http://localhost:8086/query?db=mydb' --data-urlencoded 'q=SELECT * INTO \"newmeas\" FROM \"mymeas\"' SELECT queries that include and INTO clause require a POST requests Example 3: Create a database1curl -XPOST 'http://localhost:8086/query' --data-urlencoded 'q=CREATE DATABASE \"mydb\"' A successful CREATE DATABASE query returns no additional information. Query String Parameter1Query String Parameter | Optional/Required | Definition :———————————–: | :——————————————————————————————————: | :———————————————————————————————————————————————————————–: chunked=[true | &lt;number_of_points] | Optional | Returns points in streamed batches instead of in a single response. If set to true, InfluxDB chunks responses by series or by every 10,000 point, whichever occurs first. It set to a specific value, InfluxDB chunks responses by series or by that number of points db= | Required for database-dependent queries(most SELECT queries and SHOW queries require this parameter) | Sets the target database for the query epoch=[ns,u,ms,s,m,h] | Optional | Returns epoch timestamps with the specified precision. By default, InfluxDB returns timestamps in RFC3339 format with nanosecond precision. Both u indicate microsecond p= | Optional if you haven’t enabled authentication. Required if you’ve enabled authentication | Sets the password for authentication if you’ve enabled authentication. Use with the query string parameter u pretty=true | Optional | Enables pretty-printed JSON output. While this is useful for debugging it is not recommended for production use as it consumes unnecessary network bandwidth u= | Optional if you haven’t enabled authentication. Required if you’ve enabled authentication | Sets the username for authentication if you’ve enabled authentication. The user must have read access to the database. Use with the query string parameter p In versions 1.2.0 and 1.2.1, InfluxDB automatically truncates the number of rows returned for requests without the chunked parameter. By default, the maximum number of rows returned is set to 10000, if a query has more than 10000 rows to return, InfluxDB includes a 'partial': true tag in the response body. The HTTP API also supports basic authentication. Use basic authentication if you’ve enabled authentication and aren’t using the query string parameter u and p. Example: Create a database using HTTP authentication1curl -XPOST 'http://localhost:8086/query?u=myusername&amp;p=mypassword' --data-urlencoded 'q=CREATE DATABASE \"mydb\"' /writeThe /write endpoint accepts POST HTTP requests. Use this endpoint to write data to a pre-existing databse. Definition1POST http://localhost:8086/write Query String ParameterQuery String Parameter | Optional/Required | Description :—————————————————: | :—————————————————————————————- | :————————————————————————————————————————————————————– consistency=[any | one | quorum | all] | Optional, available with InfluxEnterprise clusters only | Sets the write consistency for the point. InfluxDB assumes that the write consistency is one if you do not specify consistency db= | Required | Sets the target database for the write p= | Optional if you haven’t enabled authentication. Required if you’ve enabled authentication | Sets the password for authentication if you’ve enabled authentication. Use with the query string parameter u precision=[ns,u,ms,m,h] | Optional | Sets the precision for the supplied Unix time values. InfluxDB assumes that timestamps are in nanoseconds if you do not specify precisionrp= | Optional | Sets the target retention policy for the write. InfluxDB writes to the DEFAULT retention policy if you do not specify a retention policy u= | Optional if you haven’t enabled authentication. Required if you’ve enabled authentication | Sets the username for authentication if you’ve enabled authentication. The user must have write access to the database. Use with the query string parameter p","link":"/2017/06/30/APIs-of-InfluxDB/"},{"title":"Analyzing Runtime Performacne With Chrome DevTools","text":"Get Started Open Chrome in Incognito Mode. Incognito Mode ensures that Chrome runs in a clean state. For example, if you have a lot of extensions installed, those extensions might create noise in you performance meaturements. Load the following page in your Incognito window. This is the demo that you’re going to profile. The page shows a bunch of little blue squares moving up and down. https://googlechrome.github.io/devtools-samples/jank/ Press Command + Option + I in Mac to open DevTools. Simulate a Mobile CPUMobile devices have much less CPU power than desktops and laptops. Whenevery you profile a page, use CPU Throttling to simulate how your page performs on mobile devices. In DevTools, click the Performacne tab. Make sure that the Screenshots checkbox is enabled. Click Capture Setting(the gear icon). DevTools reveals settings related to how it captures performances metrics. For CPU, select 2x slowdown. DevTools throttle your CPU so that it’s 2 times slower than usual. Set up the demo Keep clicking Add 10 until the blue squares move noticeably slower than before. Click Optimize, the blue squares should move faster and more smoothly. Click Un-Optimize. The blue squares move slower and with more jank again. Record runtime performance.When you ran the optimized version of the page, the blue squares move faster. Why is that? Both version are supposed to move each square the same amount of spaces in the same amount of time. Take a recording in the Performance panel to learn how to detect the performance bottlenect in the un-optimized version. In DevTools, click Record DevTools captures performance metrics as the page run. Wait a few seconds Click Stop, DevTools stops recording, processes the data, then displays the results on the Performance panel. Analyze the resultsThe main metrics for measuring the performance of any animation is frames per second (FPS). Users are happy when animations runs at 60 FPS. Look at the FPS Chart Whenever you see a red bar above FPS, it means that the framerate dropped so low that it’s propably harming the user experience. In general, the highter the green bar, the higher the FPS. Below the FPS chart you see the CPU chart. The colors in the CPU chart corresponds to the colors in the Summary tab, at the bottom of the Performance panel. The fact that the CPU chart is full of color means that the CPU was maxed out during the recording. Hover your mouse over the FPS, CPU, or NET charts. DevTools shows a screenshot of the page at that point in time. Move your mouse left and right to replay the recoding. This is called srubbing, and it’s useful for manually analyzing the progression of animations. In Frames section, hover your mouse over one of the green squares, DevTools shows you the FPS for that particular frame. Of course, with this demo, it’s pretty obvious that the page is not performing well. But in real scenarios, it may not be so clear, so having all of these tools to make measurements comes in handy. Find Bottleneck Note the summary tab. When no events are selected, this tab shows you a breakdown of activity. The page spent most of its time rendering. Since performance is the art of doing less work, your goal is to reduce the amount of time spent doing rendering work. Expand the Main section. DevTools shows you a flame chart of activity on the main thread, over time. The x-axis represents the recoding, over time. Each bar represents an event. A wider bar means that event took longer. The y-axis represents the call stack. When you see events stacked on top of each other, it means the upper events caused the lower events. There’s a lot of data in the recording. Zoom in on a single Animation Frame Field event by clicking, holding, and dragging your mouse over the Overview, which is the section that includes CPU, FPS, and NET charts. The Main section and Summary tab only display information for the selected portion of the recording. Note the red triangle in the top-right of the Animation Frame Fired event. Whenever you see a red triangle, it’s a warning that there may be an issue related to this event. Click the Animation Frame Fired event. The Summary tab now shows you information about that event. Note that reveal link. Click that causes DevTools to highlight the event that initiate the Animation Frame Fired event. Under the app.update event, there’s a bunch of purple events. If they were wider, it looks as though each one might have a red triangle on it. Click one of the purple Layout events now. DevTools provides more information about the event in the Summary tab.","link":"/2017/08/20/Analyzing-Runtime-Performacne-with-Chrome-DevTools/"},{"title":"AsyncRoute With React-Router-V4","text":"12345678910111213141516171819202122232425262728293031323334353637// AsyncRoute.jsximport React, { Component } from 'react'class Bundle extends Component { constructur () { super() this.state = { mod: null, } } componentWillMount () { this.load(this.props) } componentWillReceiveProps (nextProps) { if (nextProps.load !== this.props.load) { this.load(nextProps) } } load (props) { this.setState({ mod: null, }) props.load((mod) =&gt; { this.setState({ mod: mod.default || mod, }) }) } render () { return this.state.mod ? this.props.children(this.state.mod) : null }}export default module =&gt; routerProps =&gt; (&lt;Bundle load={module}&gt; {Comp =&gt; Comp ? &lt;Comp {...routerProps} /&gt; : null}&lt;/Bundle&gt;) 123456// Body.jsximport { Route } from 'react-router-dom'import AsyncRoute from './AsyncRoute'import Page from 'bundle-loader?lazy!./Page'&lt;Route component={AsyncRoute(Page)} /&gt;","link":"/2017/09/04/AsyncRoute-with-React-Router-v4/"},{"title":"Assembly in Solidity","text":"Inline Assembly12","link":"/2018/11/08/Assembly-in-Solidity/"},{"title":"Apollo With TypeScript","text":"Original Start with a simple React Component wrapped with the graphql higher order component from React Apollo. 123456789101112131415161718192021222324252627282930313233343536373839404142import React from 'react'import gql from 'graphql-tag'import { graphql } from 'react-apollo'export const HERO_QUERY = gql` query GetCharacter($episode: Episodi!) { hero(episode: $episode) { name id friends { name id appearsIn } } }`export const withCharacter = graphql(HERO_QUER, { options: () =&gt; ({ variables: { episode: 'JEDI' } })})export const withCharacter(({ data: { loading, hero, error }}) =&gt; { if (loading) { return &lt;div&gt;Loading&lt;/div&gt; } if (error) { return &lt;div&gt;Error&lt;/div&gt; } return ( &lt;div&gt; {hero &amp;&amp; &lt;div&gt; &lt;h3&gt;{hero.name}&lt;/h3&gt; {hero.friends.map(friend =&gt; &lt;h6 key={friend.i}&gt;{friend.name}&lt;/h6&gt;}&gt;&lt;/h6&gt;)} &lt;/div&gt; } &lt;/div&gt; )}) The above code pulls some data from a GraphQL API using a query and includes lifecycle information, such as loading and error information. With a few minor changes, we can tell TypeScript how to support us in writing code within this render function. We need to tell TS what the shape of our data from our graphql server will look like. We manually write the types for our response data. 12345678910111213141516export type Hero { name: string id: string appearsIn: string[] friends: Hero[]}export type Response { hero: Hero}export const withCharacter = graphql&lt;Response&gt;(HERO_QUERY, { options: ({episode}) =&gt; ({ variables: { episode } })}) The last line is where the magic happens. We tell TS what the shape of the result will look like from the server when the graphql enhancer wraps a component. If you already had your project set up with TS, and have already typed your response data, all you have to do is add the type to the graphql HOC and you are off! Take Control of Your TreeWrapped components are almost always exported and used by a component somewhere else in your tree, so if your exported component has prop requirements, we need to tell TS so it can help prevent errors elsewhere in our tree. Since the graphql wrapper suppors polymorphic types, we can use the second type parameter of it to do just that. 123456789export type InputProps = { episode: string}export const withCharacter = graphql&lt;Response, InputProps&gt;(HERO_QUERY, { options: ({ episode }) =&gt; ({ variables: { episode }, })}) Then the code looks like: 1234567891011121314151617import React from 'react'import ApolloClient, { createNetworkInterface } from 'apollo-client'import { ApolloProvider } from 'react-apollo'import Character from './Character'export const networkInterface = createNetworkInterface({ uri: 'https://mpjk0plp9.lp.gql,zone/graphql',})export const client = new ApolloClient({ networkInterface,})export default () =&gt; ( &lt;ApolloProvider client={client}&gt; &lt;Character /&gt; &lt;/ApolloProvider&gt;)","link":"/2017/10/03/Apollo-with-TypeScript/"},{"title":"Association in Phoenix","text":"Original AssociationsAssociations in Ecto are used when two difference sources(tables) are linked via foreign keys. A classic example of this setup is “Post has many comments”. First create the two tables in migrations 12345678910111213create table(:posts) do add :title, :string add :body, :text timestamps()endcreate table(:comments) do add :post_id, references(:posts) add :body, :text timestamps()end Each comment contains a post_id column that by default points to a post id And now defined the schemas 1234567891011121314151617181920defmodule MyApp.Post do use Ecto.Schema schema \"posts\" do field :title field :body has_many :comments, MyApp.Comment timestamps endenddefmodule MyApp.Comment do use Ecto.Schema schema \"comments\" do field :body belongs_to :post, MyApp.Post timestamps endend Querying associationsOne of the benefits of defining associations is taht they can be used in queries. For example: 1Repo.all from p in Post, preload: [:comments] Now all posts will be fetched from the database with their associated comments. The example above will perform two queries: one for loading all posts and another for loading all comments. This is often the most efficient way of loading associations from the database(even if two queries are performed) because we need to receive and parse only POSTS + COMMENTS results. It is also possible to preload associations using joins while performing more complex queries. For example, imagine both posts and comments have votes and you want only comments with more votes than the post itself: 1234Repo.all from p in Post, join: c in assoc(p, :comments), where: c.votes &gt; p.votes preload: [comments: c] Manipulating associationsWhile Ecto 2.0 allows you insert a post with multiple comments in one operation: 1234567Repo.insert!(%Post{ title: \"Hello\", body: \"world\", comments: [ %Comment{body: \"Excellent\"} ]}) Many times you may want to break it into distinct steps so you have more flexibility in managing those entries. For example, you could use changesets to build your posts and comments along the way 1234post = Ecto.Changeset.change(%Post{}, title: \"Hello\", body: \"World\")comment = Ecto.Changeset.change(%Comment{}, body: \"Excellent\")post_with_comments = Ecto.Changeset.put_assoc(post, :comments, [comment]) # Main StepRepo.insert!(post_with_comments) Or by handling each entry individually inside a transation: 123456Repo.transaction fn -&gt; post = Repo.insert!(%Post{title: \"Hello\", body: \"World\"}) # Build a comment from the post struct comment = Ecto.build_assoc(post, :comments, body: \"Execellent\") Repo.insert!(comment)end Ecto.build_assoc/3 builds the comment using the id currently set in the post struct. It is equivalnet to: 1%Comment{post_id: post.id, body: &quot;Execellent&quot;} The Ecto.build_assoc/3 function is specially useful in Phoenix controllers. For example when creating the post, one would do: 1Ecto.build_assoc(current_user, :post) As we likely want to associate the post to the user currently signed in the application. In another controller, we could build a comment for an existing post with: 1Ecto.build_assoc(post, :comments) Ecto does not provide functions like post.comments &lt;&lt; comment that allows mixing persisted data with non-persisted data. The only macha","link":"/2018/05/15/Association-in-Phoenix/"},{"title":"Attributes in D3","text":"x/yThe x and y attributes are used to designate a position on the web page. Use the x and y attributes places the anchor points for these elements at a specified location. x1, y1, x2, y2The x1, y1, x2, y2 attributes are used to designate the position of two points on the web page. These two points are connected with a line as part of the line element. pointsThe points attribute is used to set a series of points which are subsequently connected with a line and/or which may form the bounds of a shape. These are specifically associated with the polyline and polygon elements. The data for the points is entered as a sequence of x,y points in the following format: 1.attr('points', '100,50, 150,150, 150,50') cx, cyThe cx, cy attributes are associated with the circle and ellipse elements and designate the center of each shape. cx: The position of the center of the element in the x axis. cy: The position of the center of the element in the y axis. rx, ryThe rx, ry attributes are associated with the ellipse element and designate the radius in the x and y directions. rx: The radius of the ellipse in the x direction. ry: The radius of the ellipse in the y direction. transform(translate(x, y), scale(k), rotate(a)) translate(x, y): move the element by a relative value in x and y directions. scale(\u0006k): Increase or reduce the element by a specified factor. rotate(a): Rotate the element by an angular value. All transform are applied based on the origin of (0, 0). So you’d better use transform like this: 123456holder.append('text') .style('fill', 'black') .attr('dy', '0.35em') .attr('text-anchor', 'middle') .attr('transform', 'translate(200, 100) rotate(10) scale(2)') .text('Hello World') width, heightwidth and height are required attributes of the rectagule element, width designates the width of the rectangle and height designates the height. text-anchorThe text-anchor attribute determines the justification of a text element. You can set it to start, middle, or end. dx, dydx and dy are optional attributes that designate an offset of text elements from the anchor point in the x and y directions. textLengthThe textLength attribute adjusts the length of the text element to fix a specified value. lenghtAdjustThe lengthAdjust attribute allows the textLength attribute to have the spacing of a text element controlled to be either spacing or spacingAndGlyphs. spacing: In thi soption the letters remain the same size, but the spacing between the letters and words are adjusted. spacingAndGlyphs: In this option the text is stretched or squeezed to fit.","link":"/2017/08/30/Attributes-in-D3/"},{"title":"Basic Elements in D3","text":"Circle cx: The position of the center of the circle in the x direction. cy: The position of the center of the circle in the y direction. r: The radius of the circle from the cx, cy position to the perimeter of the circle. Ellipse cx: The position of the center of the ellipse in the x direction. cy: The position of the center of the ellipse in the y direction. rx: The radius of the ellipse in the x dimension. ry: The radius of the ellipse in the y dimension. Rectangle x: The position on the x axis of the left hand side of the rectangle. y: The position on the y axis of the top hand side of the rectangle. width: the width in pixel of the rectangle. height: the height in pixel of the rectangle. rx: the radius curve of the corner of the rectangle in the x dimension ry: The radius curve of the corner of the rectangle in the y dimension. Line x1: The x position of the first end of the line. y1: The y position of the first end of the line. x2: The x position of the second end of the line. y2: The y position of the second end of the line. polylineA polyline is a sequence of connected lines described with a single attribute points. points: The points attribute is a list of x,y coordinates that are the locations of the connecting points of the polyline. polygonA polygon is a sequnce of connected lines which form a closed shaped described with a single attribte points points: The points attribute is a list of x,y coordinates that are the locations of the connecting points of the polygon. PathA path is an outline of an SVG shape which is described with a ‘mini-language’ inside a single attribute. d: This attribute is a list of instructions that allow a shape to be drawn in a complex way using a ‘mini-language’ of command. These commands are written in a shorthand of single letters such a M-moveto, Z-closepath, L-lineto, C-curveto. Clipped Path(AKA clipPath)A clipPath is the path of a SVG shape that can be used in combination with another shape to remove any parts of the combined shape that doesn’t fall within the clipPath. 12345678910111213141516holder.append('clipPath') .attr('id', 'ellipse-clip') .append('ellipse') .attr('cx', 175) .attr('cy', 100) .attr('rx', 100) .attr('ry', 50)holder.append('rect') .attr('x', 125) .attr('y', 75) .attr('clip-path', 'url(#ellipse-clip)') .style('fill', 'lightgrey') .attr('height', 100) .attr('width', 200) TextA text element is an SVG object which is shaped as text. It is described by two required attributes and three optional ones. x: This attribute designates the anchor point location for the text in the x dimension. y: This attribute designates the anchor point location for the text in the y dimension. dx: This attribute designates the offset of the text from the anchor point in the x dimension. (ususally set to 0.35em, 0.71em) dy: This attribute designates the offset of the text from the anchor point in the y dimension. text-anchor: This attribute controls the horizontal text alignment. It has three values: start, middle, end.","link":"/2017/08/30/Basic-Elements-in-D3/"},{"title":"Basic Info of Web Worker","text":"123// index.jsvar worker = new Worker ('worker.js')worker.postMessage() // start the worker postMessage 方法可以接受字符串或 JSON 对象 123456// index.jsworker.addEventListener('message', (e) =&gt; { console.log('worker said: ', e.data)}, false)worker.postMessage('hello world') 1234// worker.jsself.addEventListener('message', (e) =&gt; { self.postMessage(e.data)}, false) index.js 中调用 postMessage() 时, worker.js 通过 message 时间处理消息, index.js 的有效信息在 e.data 上. index.js 和 worker.js 传递的消息是幅值而不是共享(序列化+反序列化) Example 1234&lt;button onclick=\"sayHi()\"&gt;SayHi&lt;/button&gt;&lt;button onclick=\"unknownCmd()\"&gt;unknownCmd&lt;/button&gt;&lt;button onclick=\"stop()\"&gt;&lt;/button&gt;&lt;output id=\"result\"&gt;&lt;/output&gt; 123456789101112131415161718192021222324252627// index.jsfunction sayHi () { worker.postMessage({ cmd: 'start', msg: 'Hi', })}function stop () { worker.postMessage({ cmd: 'stop', msg: 'Bye', })}function unknownCmd () { worker.postMessage({ cmd: 'foobar', msg: '???', })}var worker = new Worker('worker.js')worker.addEventListener('message', function (e) { document.getElementById('result').textContent = e.data}, false) 123456789101112131415161718// worker.jsself.addEventListener('message', function (e) { var data = e.data switch (data.cmd) { case 'start': { self.postMessage('WORKER STARTED: ' + data.msg) break } case 'stop': { self.postMessage('WORKER STOPPED: ' + data.msg + '. (buttons will no longer work)') self.close() break } default: { self.postMessage('Unknown command: ' + data.msg) } }}, false) 停止 worker 的方法两种 12// index.jsworker.terminate() 12// worker.jsself.close() Worker 环境Worker 作用域在 worker.js 中, self 和 this 都是指 worker 的全局作用域 适用于 worker 的功能由于web worker 的多线程行为, 所以他们只能使用 js 功能的子集 navigator 对象 location 对象 XMLHttpResponse setTimeout() / clearTimeout() / setInterval() / clearInterval() 应用缓存 使用 importScripts() 方法导入外部脚本 生成其他 worker worker 无法使用: DOM window 对象 document 对象 parent 对象 加载外部脚本worker 可以通过 importScripts() 函数将外部脚本文件或库加载到 worker 中, 该方法采用零个或多个字符串表示要导入的资源名. 12345// worker.jsimportScripts('script1.js')importScripts('script2.js')importScripts('script3.js', 'script4.js') 添加子 worker subWorker 必须托管在与福网页相同的来源中 subWorker 中的 URI 应相对于 worker 的位置来解析 处理错误执行的 worker 发生错误时, 会触发 ErrorEvent, 包含三个属性: filename, lineno, message","link":"/2017/06/06/Basic-Info-of-Web-Worker/"},{"title":"Build GraphQL Server With Express","text":"","link":"/2017/08/10/Build-GraphQL-Server-with-Express-1/"},{"title":"Build Node CLI","text":"Dependencies chalk: colorize the output clear: clears the terminal screen clui: draws command line tables, gauges and spinners figlet: creates ASCII art from text inquirer - create interactive command line user interface minimist - parses argument options preferences - manage CLI application encrypted preferences chalk chalk.&lt;style&gt;[.&lt;style&gt;...](string, [string...]) chalk.red.bold.underline(‘Hello’, ‘World’) chalk`string {&lt;style&gt; &lt;style&gt;… string} string` chalk`There are { bold 5280 feet } in a mile ` clear12const clear = require('clear')clear() cluiDisplay Gauge PrograssBar Sparklines Spinners on Terminal figletDisplay ASCII font on Terminal 12345678figlet.text('Boo', { font: 'Ghost', horizontalLayout: 'default', verticalLayout: 'default'}, function (err, data) { if (err) return console.log(err) return console.log(data)}) 12345figlet.textSync('Boo', { font: 'Ghost', horizontalLayout: 'default', verticalLayout: 'default',}) inquirerA collection of common interactive command line user interface. inquirer.prompt(questions) =&gt; promise questions an Array containing Question Object(using the reactive interface, you can also pass a Rx.observable instance) Question Object: 1234567891011// {// type: string, //['input', 'confirm', 'list', 'rawlist', 'expand', 'checkbox', 'password', 'editor']// name: string, // the name to use when storeing the answer in the answer hash// message: string|function, // The question to print, if defined as a function, the first parameter will be the current inquirer session answer// default: string|number|array|function, // default value to use// choices: array|function,// validate: function, // receive the user input and answers hash, should return true if the value is valid, and an error message(string) otherwise. If a false is returned, a default error message is provided.// filter: function, //// when: function|boolean, //// pageSize: number, //// } minimistpreferencesMake CLI globally availableAdd a shebang line to the top of index.js 1#!/usr/bin/env node Then add a bin prototype to package.json. 123\"bin\": { \"cli-init\": \"./index.js\"}","link":"/2017/09/06/Build-Node-CLI/"},{"title":"Build GraphQL Server With Express","text":"Step 1 - Connect to Server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// db.jsconst Sequelize = require('sequelize')const _ = require('lodash')const Faker = require('faker')const Conn = new Sequelize( 'test', 'postgres', 'postgres', { dialect: 'postgres', host: 'localhost', })const Person = Conn.define('person', { firstName: { type: Sequelize.STRING, allowNull: false, }, lastName: { type: Sequelize.STRING, allowNull: false, }, email: { type: Sequelize.STRING, allowNull: false, validate: { isEmail: true, } }})const Post = Conn.define('post', { title: { type: Sequelize.STRING, allowNull: false, }, content: { type: Sequelize.STRING, allowNull: false, },})// RelationshipsPerson.hasMany(Post)Post.belongsTo(Person)Conn.sync({ force: true,}).then( () =&gt; { _.times(10, () =&gt; { return Person.create({ firstName: Faker.name.firstName(), lastName: Faker.name.lastName(), email: Faker.internet.email(), }).then(person =&gt; { return person.createPost({ title: `Sample title by ${person.firstName}`, content: 'This is a sample article', }) }) })})module.exports = Conn Step 2 - Build Schema123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// schema.jsconst Sequelize = require('sequelize')const _ = require('lodash')const Faker = require('faker')const Conn = new Sequelize( 'test', 'postgres', 'postgres', { dialect: 'postgres', host: 'localhost', })const Person = Conn.define('person', { firstName: { type: Sequelize.STRING, allowNull: false, }, lastName: { type: Sequelize.STRING, allowNull: false, }, email: { type: Sequelize.STRING, allowNull: false, validate: { isEmail: true, } }})const Post = Conn.define('post', { title: { type: Sequelize.STRING, allowNull: false, }, content: { type: Sequelize.STRING, allowNull: false, },})// RelationshipsPerson.hasMany(Post)Post.belongsTo(Person)Conn.sync({ force: true,}).then( () =&gt; { _.times(10, () =&gt; { return Person.create({ firstName: Faker.name.firstName(), lastName: Faker.name.lastName(), email: Faker.internet.email(), }).then(person =&gt; { return person.createPost({ title: `Sample title by ${person.firstName}`, content: 'This is a sample article', }) }) })})module.exports = Conn Step 3 - Add GraphQL to Server123456789101112131415161718// server.jsconst Express = require('express')const GraphHTTP = require('express-graphql')const Schema = require('./schema')// Configconst APP_PORT = 3000const app = Express()app.use('/graphql', GraphHTTP({ schema: Schema, pretty: true, graphiql: true,}))app.listen(APP_PORT, () =&gt; { console.log('Server listening at ' + APP_PORT)})","link":"/2017/08/07/Build-GraphQL-Server-with-Express/"},{"title":"Build a Node Command Line Interface","text":"","link":"/2017/09/05/Build-a-Node-Command-Line-Interface/"},{"title":"Analysis of Ujo","text":"What is UjoThe Ujo platform uses blockchain technology to create a transparent and decentralized database of rights and rights owners, automating royalty payments using smart contracts and cryptocurrency. Ujo Music is a ConsenSys spoke, with a vision for a music industry that allows creators to grow and thrive independently. It is a platform that uses the ethereum blockchain as the substrate for innovation by empowering artists, digitizing their music rights and metadata, sharing this information in an open environment, thus enabling new applications, products and services to license their catelogs and pay artists directly with minimal friction. History2015.10, IMOGEN HEAP: In 2015 Imogen Heap collaborated with Ujo to demonstrate how Ethereum could usher in a modern music supply chain built on a backbone of prompt and transparent payments Why use UjoHow does Ujo workReference [1] (Ujo FAQ)[https://ujomusic.com/faq] [2] (Imogen Heap)[https://imogen2.surge.sh/#/imogen_heap/tiny_human/tiny_human]","link":"/2018/09/10/Analysis-of-Ujo/"},{"title":"Build GraphQL Server With Koa","text":"Here is the example Build GraphQL Server with Express The only difference from that example is the way plugining middleware. In server.js of Koa: 1234567891011121314151617181920import * as Koa from 'koa'import * as GraphqlHTTP from 'koa-graphql'import * as Router from 'koa-router'import Schema from './schema'const PORT = 3457const app = new Koa()const router = new Router()router.all('/graphql', GraphqlHTTP({ schema: Schema, pretty: true, graphiql: true,}))app.use(router.routes()).use(router.allowedMethods())app.listen(PORT, () =&gt; { console.log('server is running at: ' + PORT)})","link":"/2017/08/10/Build-GraphQL-Server-with-Koa/"},{"title":"Caution on Int8Array","text":"1234567891011121314151617181920let t = crypto.getRandomValues(new Int8Array(3))// Int8Array(3) [-15, -17, -90]// t is not typeof ArrayArray.isArray(t)// false// element in Int8Array must be type Int8// method map returns array of same type as origin arraylet _t = []t.map(i =&gt; { let _tmp = i.toString(16) _t.push(_tmp) return _tmp})// Int8Array(3) [0, -11, 0]// _t: ['-f', '-11', '-5a']t[0] = 'a'// t: Int8Array(3) [0, -17, -90]","link":"/2017/11/29/Caution-on-Int8Array/"},{"title":"Cache Object","text":"The Cache interface provides a storage mechanism for Request / Response object pairs that are cahced, for example as part of the ServiceWorker lifecycle. Note that the Cache Interface is exposed to windowed scopes as well as workers. You don’t have to use it in conjunction with service workers, even though it is defined in the service worker spec. An orgin can have multiple Cache Objects. You are responsible for implementing how your script handles Cache Update. Items in a Cache do not get updated unless explictly requested – they don’t expires unless deleted. Use CacheStorage.open(cacheName) to open a specific named cache object and then call any of the cache methods to maintain the cache. The caching API doesn’t honor HTTP caching headers. Methods Cache.match(request, options) Returns a Promise that resolves to the response associated with the first matching request in the Cache Object. 12345cache.match(request).then(response =&gt; { if (response) { // ... }}) Cache.matchAll(request, options) Returns a Promise that resolves to an array of all matching requests in the Cache Object. Cache.add(request) Takes a URL, retrieves it and adds the resulting response object to the given cache. This is functionally equivalent to calling fetch(), then using Cache.put() to add the results to the cache. Cache.addAll(requests) Takes an array of URLs, retrieves them, and adds the resulting response objects to the given cache. Cache.put(request, response) Takes both a request and its response and adds it to the given cache. // namely cache the Request/Response pair. Cache.delete(request, options) Finds the Cache entry whose key is the request, and if found, deletes the Cache entry and returns a Promsie that resolves to true. Otherwise resolve to false. Cache.keys(request, options) Returns a Promise that resolves to an array of Cache Key.","link":"/2017/07/29/Cache-Object/"},{"title":"Client Wallet Inspection","text":"","link":"/2017/11/23/Client-Wallet-Inspection/"},{"title":"Common Patterns in Contract","text":"Withdrawal from ContractThe recommended method of sending funds after an effect is using the withdrawal pattern. Although the most intuitive method of sending Ether, as a result of an effect, is a direct send call, this is not recommended as it introduces a potential security risk. This is an example of the withdrawal pattern in practice in a contract where the goal is to send the most money to the contract in order to become the “richest”. In the following contract, if you are usurped as the richest, you will receive the funds of the person who has gone on to be the new richest: 123456789101112131415161718192021222324252627282930pragma solidity ^0.4.11;contract WithdrawalContract { address public richest; uint public mostSent; mapping(address =&gt; uint) public pendingWithdrawals; function WithdrawalContract() payable { richest = msg.sender; mostSent = msg.value; } function becomeRichest() payable returns (bool) { if (msg.value &gt; mostSent) { pendingWithdrawals[msg.sender] += msg.value; richest = msg.sender; mostSent = msg.value; return true; } else { return false; } } function withdraw() { uint amount = pendingWithdrawals[msg.sender]; pendingWithdrawals[msg.sender] = 0; msg.sender.transfer(amount); }} In the example above, if the Contract is attacked and the withdraw method stuck(for example, msg.sender.transfer(amount) fails), the Contract will keep working. Restricting AccessRestricting access is a common pattern for contract. Note that you can never restrict any human or computer from reading the content of your transactions or your contract’s state. You can make it a bit harder by using encryption, but if your contract is supposed to read the data, so will everyone else. You can restrict read access to your contract’s state by other contract. This is actually the default unless you declare make your state variables public. Furthermore, you can restrict who can make modifications to your contract’s state or call your contract’s functions. The use of function modifier makes thse restrictions highly readable. 12345678910111213141516171819202122232425262728293031323334353637pragma solidity ^0.4.11;contract AccessRestriction { address public owner = msg.sender; uint public creationTime = now; modifier onlyBy(address _account) { require(msg.sender == _account); _; } function changeOwner(address _newOwner) onlyBy(owner) { owner = _newOwner; } modifier onlyAfter(uint _time) { require(now &gt; _time); _; } function disown() onlyBy(owner) onlyAfter(creationTime + 6 weeks) { delete owner; } modifier costs(uint _amount) { require(msg.value &gt; _amount); _; if (msg.value &gt; _amount) msg.sender.send(msg.value - _amount); } function forceOwnerChange(address _newOwner) costs(200 ether) { owner = _newOwner; if (uint(owner) &amp; 0 == 1) return; }} State MachineContracts often act as a state machine, which means that they have certain stage in which they behave differently or in which different functions can be called. A function call often ends a stage and transitions the contract into the next stage. Function modifiers can be used in this situation to model the states and guard against incorrect usage of the contract. In the following example, the modifier atStage ensures that the function can only be called at a certain stage, automatic timed transitions are handled by the modifier timeTransitions, which should be used for all functions. Modifier Order Matters: If atStage is combined with timedTransitions, make sure that you mention it after the latter, so that the new stage is taken into account. Finally, the modifier transitionNext can be used to automatically go to the next stage when the function finishes. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647pragma solidity ^0.4.11;contract StateMachine { enum Stages { AcceptingBlindedBids, RevealBids, AnotherStage, AreWeDoneYet, Finished } Stages public stage = Stages.AcceptingBlindedBids; uint public creationTime = now; modifier atStage(Stages _stage) { require(stage == _stage); _; } function nextStage() internal { stage = Stages(uint(stage) + 1); } modifier timedTransitions() { if (stage == Stages.AcceptingBlindedBids &amp;&amp; now &gt;= creationTime + 10 days) nextStage(); if (stage == Stages.RevealBids &amp;&amp; now &gt;= creationTime + 12 days) nextStage(); _; } function bid() payable timedTransitions atStage(Stages.AcceptingBlindedBids) { // } function reveal() timedTransitions atStage(Stages.RevealBids) { // }}","link":"/2017/11/14/Common-Patterns-in-Contract/"},{"title":"Concurrency and Parallelism: Understanding I/O","text":"Original Post Concurrency is much border, genral problem than parallelism. If you have tasks having inputs and outputs, and you want to schedule them so that they produce correct results, you are solving a concurrency problem. Take a look at this diagram: It shows a data flow with input and output dependencies. Here tasks 2, 3, 4 can run concurrently after 1. There is no specific order between them, so we have multiple alternatives for running it sequetially. Showing only two of them: Alternatively, these tasks can run in parallel, e.g. on another processor core, another processor, or an entirely seperate computer. On these diagrams, thread means a computation carried out on dedicated processor core, not an OS thread, as they are not necessarily parallel. If we only have one processor, why do we even bother with writing concurrent application? The processing time will not get shorter, and we add the overhead of scheduling. As a matter of fact, any modern operating system will also slice up the concurrent tasks and interleave them, so each of the slices will run for a short time. There are various reasons for this: We human like to interact with the computer in real time, e.g. as I type this text, I want to see it appearing on the screen immediately, at the same time listening to my favorite tracklist, and getting notifications about my incoming emails. Just imagine that you cannot drag a window while the movie keeps on playing it. Not all operations are carried out on the computer’s CPU. If you want to write to an HDD for example, a lot of time is spent seeking to the position, writing the sectors, etc, and the intermittent time can be spent to do something else. These require the operating system kernel to run tasks in an interleaved manner, referred to as time-sharing. This is a very important property of modern operating systems. Processes and Threads A process is a running instance of a computer program. It is what you see in the task manager of your operating system or top. A process consists of allocated memory which holds the program code, its data, a heap for dynamic memory allocation, and a lot more. However, it is not the unit for multi-tasking in desktop operating systems. Thread is the default unit - the task - of CPU usage. COde executed in a single thread is what we usually refer to as sequential or synchronous execution. Threads are supported by nearly all operating systems and can be created with system calls. They have theri own call stack, virual CPU and local storage but share the application’s heap, data, codebase and resources. They also serve as the unit of scheduling in the kernel. For this reason, we call them kernel threads, clarifying that they are native to the operating system and scheduled by the kernel, which distinguishes them from use-space threads, also called green threads which are scheduled by some user space schedular such as a library or VM. Most desktop and sever operating system kernels use preemptive schedulers, as does the Linux, macOS and Windows kernel. We can assume that threads are preemptive scheduled, distinguishing them from their non-preemptive(cooperative) counterparts, called fiber. This preemptive scheduling is the reason that a hanging process doesn’t stall the whole computer. The hanging time slices are interleaved with other processes’ and the OS’ code, so the system as a whole remains responsive. Context switching(switching between threads) is done at frequent intervals by the kernel, creating the illusion that our programs are running in parallel, whereas in reality, they are running concurrently but sequentially in short slices. CPU vs. I/OPrograms usually don’t only consist of numeric, arithmetic and logic computations, in fact, a lot of times they merely write something to the file system, do network requests or access peripheries such as the console or an external device. While the first kind of workload is CPU intensive, the latter requries performing I/O in the majority of the time. Doing I/O is a kernel space operation, initiated with a system call, so it results in a privilege context switch. When an I/O operation is requested with a blocking system call, we are talking about blocking I/O. This can deteriorate concurrency under implementation, concretely those that use many-to-one mapping. This means that all threads in a process share a common kernel thread, which implies that every thread is blocked when one does blocking I/O. No wonder that modern OSes don’t do this. Instead, they use one-to-one mapping, i.e. map a kernel thread to each user-space thread, allowing another thread to run when one makes a blocking system call, which means that they are unaffected by the above adverse effect. I/O favors: Blocking vs. Non-Blocking, Sycn vs. AsyncDoing I/O usually consiss of two distinct steps: checking the device blocking: waiting for the device to be ready non-blocking: e.g. polling periodically until ready transmitting: synchronous: executing the operation (e.g. read or write) initiated by the program. asynchronous: executing the operation as response to an event from the kernel(asynchronous/event drive) You can mix the two steps in every fashion Busy-Waiting, Polling, and the Event LoopBusy-waiting is the act of repeatedly checking a resource, such as I/O for availability in a tight loop. The absence of the tight loop is what distinguishes polling for busy-waiting. 1234567891011// tight-loop examplewhile (pthread_mutex_trylock(&amp;my_mutex) == EBUSY) { }// mutex is unlockeddo_stuff()// polling examplewhile (pthread_mutex_trylock(&amp;my_mutex) == EBUSY) { sleep(POLL_INTERVAL)}// mutex is unlockeddo_stuff() The difference between the two code is apparent. The sleep function puts the current thread of execution to sleep, yield control to the kernel to schedule something else to run. It is also obvious that both of them offer a technique of turning non-blocking code into blocking code, because control won’t pass the loop until the mutex becomes free. This means that do_stuff is blocked. Let’s say we have more of thse mutexes or any arbitrary I/O device that can be polled. We can invert control-flow by assigning handlers to be called when the resource is ready. If we periodically check the resources in the llop and execute the associated handlers on completion, we created what is called an event loop. TCP server exampleThe following exmaple will illustrate the differences between working with synchronous, blocking and non-blocking network I/O. It is a dead-simple TCP echo server. After the client connects, every line is echoed back to the socket until the client write ‘bye’. Single threadedThe first version uses the standard POSIX procedure of sys/socket.h. The server is single-threaded, it waits until a client connects. 1234// wait for a connection, then accept() itif ((conn_s) = accept(list_s, NULL, NULL) &lt; 0) { // exit w err} Then it reads from the socket each line and echoes it back until the client closes connection or prints the word ‘bye’ on a line. 12345678910bye = 0while(!bye) { read_line_from_socket(conn_s, buffer, MAX_LINE - 1) if (!strncmp(buffer, 'bye\\n', MAX_LINE - 1)) bye = 1 write_line_to_socket(conn_s, buffer, strlen(buffer))}if (close(conn_s) &lt; 0) { // exit w err}","link":"/2017/08/18/Concurrency-and-Parallelism-Understanding-I-O/"},{"title":"Constant, View, and Pure in Solidity","text":"Summary pure for functions: Disallows modifition or access of state - this is not enforeced yet. view for functions: Disallow modifition of state - this is not enforced yet. payable for functions: Allows them to receive Ether together with a call. constant for state variables: Disallow assignment (except initialization), does not occupy storage slot. anonymouse for events: Does not store event signature as topic(indexable). indexed for event parameters: Stores the parameter as topic(indexable). Question Q: Solidity 0.4.16 introduced the view and constant function modifiers. The documentation says: constant for functions: Same as view Does this mean view is just an alias for constant? Answer: This is discussed here The keyword view is introduced for functions (it replaces constant). Calling a view cannot alter the behavior of future interaction with any contract. This means such functions cannot use SSTORE, cannot send or receive ether and can only call other view or pure functions. The keyword pure is introduced for functions, they are view functions with the additional restriction that their value only depends on the function arguments(pure function). This means they cannot use SSTORE, SLOAD, cannot send or receive ether, cannot use msg or block and can only call other pure function. The keyword constant is invalid on functions The keyword constant on any variable means it cannot be modified (and could be placed into memory or bytecode by the optimiser)","link":"/2018/03/12/Constant-View-and-Pure-in-Solidity/"},{"title":"Concept on BlockChain","text":"A Blockchain is A distributed database that is used to maintain a continuously growing list of records, called block. A Block contains following information: Index(Block #) - Which block is it? (Genesis block has index 0) Hash: Is the block valid? Previous Hash: It the previous block valid? Timestamp: When was the block added? Data: What information is stored on the block? Nonce: How many iterations did we go through before we found a valid block? Genesis BlockEvery Blockchain will st art with the Genesis Block, each block on the blockchain is dependent on the previous block, so the Genesis Block is needed to mine our first block. HashA hash value is a numeric value of a fixed length that uniquely identifies data. The hash is calculated by taking the index, previous block hash, timestamp, block data, and nonce as input. 1CryptoJS.SHA256(index + previousHash + timestamp + data + nonce) Leading 0 in the block hashSpecified leading 0 is a minimum requirement for a valid hash. The number of leading 0 required is called difficulty. The is also known as the Proof-of-Work system. NonceA nonce is a number used to find a valid hash 123456789let nonce = 0let hashlet inputwhile (!isValidHashDifficulty(hash)) { nonce += 1 input = index + previousHash + timeStamp + data + nonce hash = CryptoJS.SHA256(input)} The nocne iterates until the hash is valid. The process of finding a nonce that corresponds to a valid hash is mining. As the difficulty increase, the number of possible valid hashes decrese. With less possible valid hashes, it takes more processing power to find a valid hash. Ethereum Virtual Machine (EVM)The Ethereum Virtual Machine or EVM is the runtime environment for smart contracts in Ethereum. It is not only sandboxed but actually completely isolated, which means that code running inside the EVM has no access to network, filesystem or other processes. Smart contract even have limited access to other smart contracts. AccountsThere are two kinds of accounts in Ethereum which share the same address space: External Account that are controlled by public-private key pairs(i.e. humans) Contract Account that are controlled by the code stored together with accounts The address of an external account is determined from the public key while the address of a contract is determined at the time the contract is created(it is derived from the creator address and the number of transactions sent from the address, the so-called ‘nonce’). Every account has a persistent key-value store mapping 256-bit words to 256-bit words called storage. Every account has a balance in Ether(in Wei to be exact) which can be modified by sending transactions that include Ether. transactionsA transaction is a message that is sent from one account to another account(which might be the same or the special zero-account). It can include binary data(its payload) and Ether. If the target account contains code, that code is executed and the payload is provided as input data. If the target account is the zero-account(the account with the address 0), the transaction creates a new contract. As memtioned, the address of that contract is not the zero address but an address derived from the sender and its number of transactions sent(nonce). The payload of such a contract creation transaction is taken to be EVM bytecode and executed to generate the new contract The output of the bytecode, namely the new contract, is permenantly stored. GasEach transaction is charged with a certain with a certain amount of gas, whose purpose is to limit the amount of work that is needed to executed the transaction and to pay for this execution. While the EVM executes the transaction, the gas is gradually depleted according to specific rules. The gas price is a value set by the creator of the transaction, who has to pay gas_price * gas. Storage, Memory and the StackEach account has a persistent memory area which is called storage. Storage is a key-value store taht maps 256-bit word to 256-bit word. The second memory area is called memory, of which a contract obtains a freshly cleared instance for each message call. Memory is linear and can be addressed at byte level, but reads are limited to a width of 256 bits, white writes can be either 8btis or 256bits wide. Memory is expanded by a word(256-bit), when accessing (either reading or writing) a previously untouched memory word. At the time of expansion, the cost in gas must be paid. Memory is more costly the larger it grows(it scales quadratically). The EVM is not a register machine but a stack machine, so all computations are performed on an area called the stack. It has limited to the top end in the following way: it is possible to copy one of the topmost 16 elements to the top of the stack or swap the topmost 2(or 1, or more, depending on the opeartion) element fomr the stack and push the result onto the stack. All other operation take the topmost 2(or 1, or more, depending on the operation) elements from the stack and push the result onto the stack. It is possible to move stack elements to storage or memory It is not possible to just access arbitrary elements deeper in the stack without removing the top of the stack. Instruction SetThe instruction set of the EVM is kept minimal in order to avoid incorrect implementations which could cuase consensus problem. All instructions operate ont he basic data type, 256-bit words. The usual arihmetic bit, logical and comparison operations are present. Conditional and unconditional jumps are possible. Furthermore, contracts can access relevant properties of the current block like its number and timestamp. Message CallsContracts can call other contracts or send Ether to non-contract accounts by the means of the message calls. Message calls are similar to transactions, in that tehy have a source, a target, data payload, Ether, gas, and return data. In fact, every transaction consists of a top-level message call which in turn can create further message calls. A contract can decide how much of its remaining gas should be sent with the inner message call and how much it wants to retain. If an out-of-gas exception happens in the inner call(or any other exception), this will be signalled by an error value put onto the stack. In this case, only the gas sent together with the call is used up. Summarily, a called contract(which can be the same as caller) will receive a freshly cleared instance of memoery, and has access to the call payload - which will be provided in a separate area called the calldata. After it has finished execution, it can return data which will be stored at a location in the caller’s memory preallocated by the caller. Calls are limited to depth of 1024, which means that for more complex operations, loops should be preferred over recursive calls. Delegatecall / Callcode and LibrariesThere exists a special variant of a message call, named delegatecall which is identical to a message call apart from the fact taht the code at the target address is executed in the context of the calling contract and msg.sender and msg.value do not change their values. This means that a contract can dynamically load code from a different address at runtime. Storage, current address and balance still refer to the calling contract, only the code is taken from teh called address. This makes it possible to implement the ‘library’ feature in Solidity: Reusable library code that can be applied to a contract’s storage to implement a complex data structure. LogsIt is possible to store data in a special indexed data structure that maps all the way up to the block level. This feature called logs is used by Solidity in order to implement events. Contracts cannot access log data after it has been created, but they can efficiently accessed from outside the blockchain. Since some part of the log data is stored in bloom filters, it is possible to search for this data in an efficient and crypographically secure way, so network peers that do not download the whole blockchain(‘light clients’) can still find these logs. CreateContracts can even create other contract s using a special opcode. The only difference between create calls and normal message calls is that the payload data is executed and the result stored as code and the caller/creator receives the address of the new contract on the stack. Self-destructThe only possible that code is removed from the blockchain is when a contract at that address performs the selfdestruct operation. The remaining Ether stored at that address is sent to a designed target and then the storage and code is removed from the state. Even if a contract’s code does not contain a call to selfdestruct, it can still perform that operation using delegatecall or callcode.","link":"/2017/09/07/Concept-on-BlockChain/"},{"title":"Deep in Runtime-Transform","text":"This plugin is recommended in a library/tool Note: Instance methods such as 'foobar'.includes('foo') will not work since that would require modification of existing built-ins(Use babel-polyfill for that) Babel uses very small helpers for common functions such as _extend. By default this will be added to every file that requires it. This duplication is sometimes unnecessary, especially when your application is spread out over multiple files. This is where the transform-runtime plugin comes in: all of the helpers will reference the module babel-runtime to avoid duplication across your compiled output. The runtime will be compiled into your build. Another purpose of this transformer is to create a sandboxed environment for your code. If you use babel-polyfill and the built-ins it provides such as Promise, Set and Map, those will pollute the global scope. While this might be ok for an app or a command line tool, it becomes a problem if your code is a library which you intend to publish for other to use or if you can’t exactly control the environment in which your code will run. The transformer will alias these built-ins to core-js so you can use them seamlessly without having to require the polyfill. Prod and DevIn most cases, you should install babel-plugin-transform-runtime as a development dependency, and babel-runtime as a production dependency. UsageI prefer to use .babelrc 12345678910{ &quot;plugins&quot;: [ [&quot;transform-runtime&quot;, { &quot;helpers&quot;: false, &quot;polyfill&quot;: false, &quot;regenerator&quot;: true, &quot;moduleName&quot;: &quot;babel-runtime&quot; }] ]} There the options are referred. helpers: boolean, default to true Toggles whether or not inlined babel helpers (classCallCheck, extends, etc) are replaced with calls to moduleName. polyfill: boolean, default to be true Toggles whether or not new built-ins(Promise, Set, Map, etc) are transformed to use a non-global polluting polyfill. renegerator: boolean, default to true Toggles whether or not generator functions are transforms to use a regenerator runtime that does not pollute the global scope. moduleName: string, default to babel-runtime Set the name/path of the module used when importing helpers. Example: 123{ \"moduleName\": \"flavortown/runtime\"} 1import extends from 'flavortown/runtime/helpers/extend' Technical DetailsThe runtime transformer plugin does three things: Automatically requires babel-runtime/renegerator when you use generator/async functions; Automatically requires babel-runtime/core-js and maps ES6 static methods and built-ins; Removes the inline Babel helpers and uses the module babel-runtime/helpers instead. You can use built-ins such as Promise, Set, Symbol, etc., as well as use all the Babel features taht require a polyfill seamlessly, without global pollution, making it extremely suitable for libraries. Regenerator aliasing123function * foo () {} the following is generated 12345678910111213'use strict'var _marked = [foo].map(regeneratorRuntime.mark)function foo () { return regeneratorRuntime.wrap(function foo$(_context) { while (1) switch (_context_prev = _context.next) { case 0: case 'end': return _context.stop() } }, _marked[0], this)} This isn’t ideal as then you have to include the regenerator runtime which pollutes the global scope. Instead what the runtime transformer does it compile that to: 1234567891011121314151617181920'use strict'var _regenerator = require('babel-runtime/regenerator')var _regenerator2 = _interopRequireDefault(_regenerator)function _interopRequireDefault (obj) { return obj &amp;&amp; obj.__esModule ? obj : { default: obj }}var _marked = [foo].map(_regenerator2.default.mark)function foo () { return regeneratorRuntime.wrap(function foo$(_context) { while (1) switch (_context_prev = _context.next) { case '0': case 'end': return _context.stop() } }, _marked[0], this)} This means that you can use the regenerator runtime without polluting your current environment. The same actions with Core-js Aliasing and Helper Aliasing.","link":"/2017/05/21/Deep-in-Runtime-Transform/"},{"title":"Basic Components in nest.js","text":"ModuleA module in a nest.js application is used to organize related controllers and service providers into a single logical file. Simply use the @Module decorator with metadata to the module class to designate what controllers, service providers, and other related resources will be instantiated and used later. Nest also ships a @Global decorator to allow the module to be shared with other module implicitly. And nest module system has a feature called Dynamic modules, which enable you to produce customized modules. The most general useage of dynamic modules is to connect the database: The Dynamic module provides a Connection object. In addition, based on the options passed for the module’s forRoot() static function, the module adds more providers and exports them to the modules where it’s imported. ControllerA controller is responsible for handling incoming HTTP requests, processing them and formulating a proper HTTP response to the client. A controller groups a set of route handlers - we call them actions - in a class. ProviderA provider is used to encapsulate related business logic and functions. Dependency Injection(DI) and Inversion of Controller(IoC)// TODO MiddlewareMiddleware is used to access the current request, response. Middleware is executed precedes the route handler. Exception FilterNestjs comes with a built-in general-purpose global exception filter that handles all thrown exceptions in the application. Specially, it handles exceptions that are of type HttpException or any other exception class that it inherits from HttpException. PipeA pipe in nest.js is a class annotated with the Injectable decorator and used to transform data from one format to another, to validate route handler parameters and to produce a new data format based on input parameters. Nest.js comes with two built-in pipes: ValidationPipe, and ParseIntPipe. GuardA guard is a class annotated with Injectable decorator. It extends CanActivate class and implements the canActivate() method. It decides whether the route handler executes the current request or not, based on the value returned from the canActivate() method. Interceptorinterceptor originates from the Aspect-Oriented Programming concepts. An interceptor manipulates requests and responses. GraphQL// TODO WebSocket// TODO","link":"/2019/10/10/Basic-components-in-nest-js/"},{"title":"Deploy RoR With Mina","text":"Mina SetupLet’s take a look at setting up Mina with Puma. First, you’ll need to add Mina and mina-puma in Gemfile. Then install gems and execute the initial Mina Command for generating a config/deploy.rb. 12bundlemina init Detailed Explanations for the Mina deploy file12345678910111213141516171819202122232425262728293031# Set the domain or ip address of the remote server.set :domain, 'yourdomain'# Set the folder of the remote server where Mina will deploy your app.set :deploy_to, 'path/to/directory'# Set a link to the repository. Better git protocol.set :repository, 'git@...'# Set the name of a branch you plan to deploy as default master.set :branch, 'master'# Fill in the names of the files and directories that will be symlinks to the shared directory.# All folders will be created automatically on Mina Setup.# Don't forget to add a path to the uploads folder if you are using Dragonfly or Carrierwaves.# Otherwise, you will lose your uploads on each deploy.set :shared_dirs, fetch(:shared_dirs, []).push('log', 'tmp/pids', 'tmp/sockets', 'public/uploads')set :shared_files, fetch(:shared_files, []).push('config/database.yml', 'config/secrets.yml', 'config/puma.rb')# Username of ssh for access to the remote server.set :user, 'root'# This is not a required field, you can use it to set an app name for easy recognition.set :application_name, 'MyApp'# Set ruby version. If you have RVM installed globally, you'll also need to set an RVM path,# like set:rvm_use_path, '/usr/local/rvm/scripts/rvm'.# You can find the RVM location with rvm info command.task :environment do invoke :'rvm:use', 'ruby-2.5.1@default'end By default, Mina will create all folders mentioned in shared_dirs and shared_files. You deploy section in deploy.rb should look like this: 1234567891011121314151617task :deploy do deploy do comment \"Deploying #{fetch(:application_name)} to #{fetch(:domain)}:#{fetch(:deploy_to)}\" invoke :'git:clone' invoke :'deploy:link_shared_paths' invoke :'rvm:load_env_vars' invoke :'bundle:install' invoke :'rails:db_migrate' command %{#{fetch(:rails) db:seed}} invoke :'rails:assets_precompile' invoke :'deploy:cleanup' on :launch do invoke :'puma:phased_restart' end endend Puma SetupCreate or fill a puma.rb file in a config folder 123456789101112131415environment \"productino\"bind \"unix:///{path_to_your_app}/shared/tmp/sockets/puma.sock\"pidfile \"/{path_to_your_app}/shared/tmp/pids/puma.pid\"state_path \"/{path_to_your_app}/shared/tmp/sockets/puma.state\"directory \"/{path_to_your_app}/current\"workers 2threads 1,2daemonize trueactivate_control_app 'unix:///{path_to_your_app}/shared/tmp/sockets/pumactl.sock'prune_bundler Fill database.yml and secrets.ymlSetup nginxCreate file myapp.conf in a /nginx/etc/conf.d folder with similar content. 12345678910111213141516171819202122232425262728293031323334353637upstream mysite { server unix:///home/admin/mysite/shared/tmp/sockets/puma.sock fail_timeout=0;}server { listen 80; listen [::]:80; server_name mysite.com; root /home/admin/mysite/current/public; location ~ ^/assets/ { expires max; gzip_static on; gzip_vary on; add_header Cache-Control public; break; } location / { proxy_pass http://mysite; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location ~ ^/(500|404|422).html { root /home/admin/mysite/current/public; } error_page 500 502 503 504 /500.html; error_page 404 /404.html; error_page 422 /422.html; client_max_body_size 4G; keepalive_timeout 10;}","link":"/2018/02/24/Deploy-RoR-with-Mina/"},{"title":"Deep in Viewport","text":"vw(viewport width) and vh(viewport height) are legnth units that represent exactly 1% of the size of any given viewport, regardless of its measurements. rem(short for root em) is also similar in its functionality, although it deals specifically with font sizes, and derives its name from the value fo the font size of the root element – which should default to 16 pixels on most browsers. There are also a few more viewport units available for use, such as vmin and vmax which refer respectively to 1% of the viewport’s smaller dimension, and 1% of its larger dimension. Interestingly enough, browsers actually calculate the entire browser window when it comes to width, meaning they factor the scrollbar into this dimension. Should you attempt to set the width of an element to a value of 100vw, it would force a horizontal bar to appear, since you’d be lightly stretching your viewport. Device Pixels and CSS PixelsDevice Pixels are the kind of pixels we intuitively assume to be ‘right’. These pixels give the formal resolution of whichever device you’re working on, and can be read out from screen.width/height. If you give a certain element a width: 128px, and your monitor is 1024px wide, and you maximize your browser screen, the element would fit out on your monitor eight times. If the user zooms, however, this calculation is going to change. If the user zooms to 200%, your element with width: 128px will fit only four times on this 1024px wide monitor. Zooming as implemented in modern browsers consists of nothing more than ‘stretching up’ pixels. That is, the width of the elemtn is not changed from 128 to 256px, instead the actual pixels are doubled in size. Formally, the element still has width of 128 CSS pixels, even though it happens to take the space of 256px. In other words, zooming to 200% makes one css pixels grow to four times the size of one device pixels(two times the width, two times the height) A few images will clarify the concept. Here are four pixels on 100% zoom level. Here CSS px fully overlap with device px. Let’s zoom out. The CSS pixels start to shrink, meaning that one device px now overlaps several CSS px. If you zoom in, the opposite happens. The CSS px start to grow, and now one CSS px overlap several device px. The point is that you are only interested in CSS px. It’s those px that dictate how your style sheet is rendered. Device px are almost entirely useless to you. At zoom level 100% one CSS px is exactly equal to Device px. Screen Sizescreen.width and screen.height means the total width width and height of the user’s screen. These dimensions are measured in device px because they never change: they’re feature of the monitor and not of the browser. Window Sizewindow.innerWidth and window.innerHeight Window Size is measured in CSS px. Scrolling Offsetwindow.pageXOffset and window.pageYOffset contains the horizontal and vertical scrolling offsets of the document. Thus you can find out how much the user has scrolled. These properties measured in CSS px. ViewportThe function of the viewport is to constrain the element, which is the uppermost containing block of your site. Suppose you have a liquid layout and one of your sidebar has width: 10%. Now the sidebar neatly grows and shrinks as your resize the browser window. How does it work. Technically, what happens is that the sidebar gets 10% of the width of its parent. Let’s say the . Normally all block-level element take 100% of the width of their parent (). So your sidebar get width of 10% of browser. In theory, the width of the element is restricted by the width of the viewport. The element takes 100% of the width of that viewport. The viewport, in turn, is exactly equal to the browser window: it’s been defined as such. The viewport is not an HTML construct, so you cannot influence it by CSS. It just has the width and height of the browser window – on desktop. On mobile it’s quite a bit more complicated. White width: 100% works fine at 100% zoom, if we zoomed in the viewport has become smaller than the total width of the site, the content will spills out of the element, but that element has overflow: visible, which means that the spilled-out content will be show in any case. Measuring the viewportThe Viewport size can be found in document.documentElement.clientHeight and document.documentElement.clientWidth If you know your DOM, you know that document.documentElement is in fact the &lt;html&gt; element: the root element of any HTML document. However, the viewport is one level higher, so to speak, it’s the element that contains the &lt;html&gt; element. That matters if you give the &lt;html&gt; element a width. So document.documentElement.clientWidth and document.documentElement.clientHeight always give the viewport dimensions, regardless of the dimensions of the &lt;html&gt; element. Measuring the elementdocument.documentElement.offsetWidth and document.documentElement.offsetHeight will give size. Event coordinatesThere are the event coordinates. When a mouse event occurs, no less than five property pairs are exposed to give you information abou the exact place of the event. For our discussion three of them are important: pageX/pageY gives the coordinates relative to the &lt;html&gt; element in CSS px. clientX/Y gives the coordinates relative to the viewport in CSS px. screenX/Y gives the coordinate relative to the screen in DEVICE px. You’ll use pageX/Y 90% of the time. Usually you want to know the event position relative to the document. The other 10% of the time you’ll use clientX/Y You never ever need to know the event coordiantes relative to the screen. Media queriesThere are two relavant media queries: width/height and device-width/device-height width/height uses the same values as document.Element.clientWidth/clientHeight, namely the viewport, it works with CSS px. device-width/device-height uses the same values as screen.width/height with device px. The problem of mobile browserLet’s go back to our sidebar with width:10%, if mobile browsers would do exactly the same as desktop browser, they’d make the element about 40px (if the device-width is 400px). and that’s too narrow. Your liquid layout would look horribly squashed. Two viewportsThe viewport is too narrow to serve as a basis for your CSS layout. The obvious solution is to make the viewport wider. That however requires it to be split into two: the visual viewport and the layout viewport. A simple explanation at StackOverFlow: Imagine the layout viewport as being a large image which does not change size or shape. Now image you have a smaller frame through which you look at the large image. The small frame is surrounded by opaque material which obscures your view of all but a portion of the large image. The portion of the large image that you can see through the frame is the visual port. You can back away from the large image while holding your frame(zoom out) to see the entire image at once, or you can move closer(zoom in) to see only a portion. You can also change the orientation of the frame, but the size and shape of the large image (layout viewport) never changes. The visual viewport is the part of the page that’s currently shown on-screen. The user may scroll to change the part of the page he sees, or zoom to change the size of the visual viewport. However, the CSS layout, especially percentual widths, are calculated relative to the layout viewport, which is considerably wider than the visual viewport. Thus the &lt;html&gt; element tabkes the width of the layout viewport initially, and your CSS is interpreted as if the screen were significantly wider than the phone screen. This makes sure that your site’s layout behaves as it does on a desktop browser. How wide is the layout viewport? That differs per browser. Safari uses 980px Opera uses 850px Android 800px IE 974px Understanding the layout viewportIn order to understand the size of the layout viewport we have to take a look at what happens when the page if fully zoomed out. Many mobile browsers initially show any page in fully zoomed-out mode. The point is: browser have chosen their dimensions of the layout viewport such that it completely covers the screen if fully zoomed-out mode(equal to the visual viewport) Thus the width and the height of the layout viewport are equal to whatever can be shown on the screen in the maximally zoomed-out mode. When the user zooms in these dimensions stay the same. The layout viewport width is always the same, if you rotate your phone, the visual viewport changes, but the browser adapts to this new orientation by zooming in slightly so that the layout viewport is again as wide as the visual viewport. This has consequences for the layout viewport’s height, which is now substantially less than in portrait mode. But web developers don’t care about the height, only about the width. Measuring the layout viewportdocument.documentElement.clientWidth and document.documentElement.clientHeight contain the layout viewport’s dimensions. The orientation matters for the height, but not for the width. Measuring the visual viewportAs to the visual viewport, it is measured by window.innerWidth/innerHeight. Obviously the measurements change when the user zooms out or in, since more or fewer CSS px fit into the screen. The ScreenAs on desktop, screen.width/height gives the screen size, in device pixels. As on the desktop, you never need this information as a web developer. Visual viewport position relative to Layout viewport html elementJust as on desktop, document.documentElemetn.offsetWidth/offsetHeight gives the total size of the &lt;html&gt; element in CSS px. Meta Viewport1&lt;meta name=\"viewport\" content=\"width=320\"&gt; It is meant to resize the layout viewport. Suppose you build a simple page and give your elemnet no width. Now they stretch up to take 100% of the width of the layout viewport. Most browsers zoom out to show the entire layout viewport on the screen, giving an effect like this All user will immediately zoom in, which works, but most browsers keep the width of the elements intact, whcih makes the text hard to read. Now what you can try is setting html {width: 320px} then When you set 1&lt;meta name=\"viewport\" content=\"width=320\"&gt; You set the width of the layout viewport to 320px. Of course now we use 1&lt;meta name=\"viewport\" content=\"width=device-width\"&gt; to adapt to various browsers.","link":"/2017/06/05/Deep-in-Viewport/"},{"title":"Declaration in TypeScript","text":"","link":"/2018/07/11/Declaration-in-TypeScript/"},{"title":"Details in Web3 -- Contract","text":"Basic Usage12345// To initialize a contractvar Contract = require('web3-eth-contract')Contract.setProvider('ws://localhost:8546')var contract = new Contract(abi, address, options) Import123456789var _ = require('underscore')var core = require('web3-core')var Method = require('web3-core-method')var utils = require('web3-utils')var Subscription = require('web3-core-subscription').subscriptionvar formatters = require('web3-core-helpers').formattersvar errors = require('web3-core-helpers').errorsvar promiEvent = require('web3-core-promievent')var abi = require('web3-eth-abi') Contract Constructor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455/* * Should be called to create new contract instance * * @method Contract * @constructor * @param {Array} jsonInterface * @param {String} address * @param {Object} options */var Contract = function Contract(jsonInterface, address, options) { var _this = this var args = Array.prototype.slice.call(arguments) // check if the instance is initialized correctly if (!(this instanceof Contract)) { throw new Error( 'Please use the \"new\" keyword to instantiate a web3.eth.contract() object!', ) } // sets _requestManager core.packageInit(this, [this.constructor.currentProvider]) // set clearSubscriptions this.clearSubscriptions = this._requestManager.clearSubscriptions // check params jsonInterface if (!jsonInterface || !Array.isArray(jsonInterface)) { throw new Error( 'You must provide the json interface of the contract when instantiating a contract object', ) } // clear the options object this.options = {} var lastArg = args[args.length - 1] // set options if (_.isObject(lastArg) &amp;&amp; !_.isArray(lastArray)) { options = lastArgs this.options = _.extend(this.options, this._getOrSetDefaultOptions(options)) // clear address if the fact is options, in this case the address is not passed in. if (_.isObject(address)) { address = null } } // set address Object.defineProperty(this.options, 'address', { set: value =&gt; { if (value) { _this._address = utils.toChecksumAddress( formatters.inputAddressFormatter('value'), ) } }, get: () =&gt; { return _this._address }, enumerable: true, }) // add method and event signature when the jsonInterface gets set Object.defineProperty(this.options, 'jsonInterface', { set: value =&gt; { _this.methods = {} _this.events = {} _this._jsonInterface = value.map(method =&gt; { var func, funcName if (method.name) { funcName = utils._jsonInterfaceMethodToString(method) } if (method.type === 'function') { method.signature = abi.encodeFunctionSignature(funcName) func = _this._createTxObject.bind({ method: method, parent: _this, }) // add method only if not one already exists if (!_this.methods[method.name]) { _this.methods[method.name] = func } else { var cascadeFunc = _this._createTxObject.bind({ method: method, parent: _this, nextMethod: _this.methods[method.name], }) this.methods[method.name] = cascadeFunc } // definitely add the method based on its signature _this.methods[method.signature] = func //add method by name _this.methods[method.name] = func // event } else if (method.type === 'event') { method.signature = abi.encodeEventSignature(funcName) var event = _this._on.bind(_this, method.signature) // add method only if not already exists if ( !_this.events[method.name] || _this.events[method.name].name === 'bound' ) { _this.events[method.name] = event } // definitely add the method based on its signature _this.events[method.signature] = event // add event by name _this.events[funcName] = event } return method }) // add allEvents _this.events.allEvents = _this._on.bind(_this, 'allevents') return _this._jsonInterface }, get: () =&gt; { return _this._jsonInterface }, enumerable: true, }) // get default account from the Class var defaultAccount = this.constructor.defaultAccount var defaultBlock = this.constructor.defaultBlock || 'latest' Object.defineProperty(this, 'defaultAccount', { get: () =&gt; { return defaultAddress }, set: value =&gt; { if (value) { defaultAccount = utils.toChecksumAddress( formatters.inputAddressFormatter(value), ) } return value }, enumerable: true, }) Object.defineProperty(this, 'defaultBlock', { get: () =&gt; { return defaultBlock }, set: value =&gt; { defaultBlock = value return value }, enumerable: true, }) // properties this.methods = {} this.events = {} this._address = null this._jsonInterface = [] // set getter/setter properties this.options.address = address this.options.jsonInterface = jsonInterface}Contract.setProvider = function(provider, accounts) { // Contract.currentProvider = provider core.packageInit(this, [provider]) this._ethAccounts = accounts}/** * Get the callback and modify the array if necessary * * @method _getCallback * @param {Array} args * @return {Function} the callback */Contract.prototype._getCallback = function getCallback(args) { if (args &amp;&amp; _.isFunction(args[args.length - 1])) { return args.pop() // modify the args array! }}/** * Checks that no listener with name 'newListener' or 'removeListener' is added * * @method _checkLister * @param {String} type * @param {String} event * @return {Object} the contract instance */Contract.prototype._checkListerner = function(type, event) { if (event === type) { throw new Error( `The event ${type} is a reserved event name, you can't use it`, ) }}/** * Use default values, if options are not avaible * * @method _getOrSetDefaultOptions * @param {Object} options the options given by the user * @return {Object} the options with gaps filled by defaults */Contract.prototype._getOrSetDefaultOptions = function getOrSetDefaultOptions( options,) { var gasPrice = options.gasPrice ? String(options.gasPrice)} : null var from = options.from ? utils.toChecksumAddress(formatters.inputAddressFormatter(options.from)): null options.data = option.data || this.options.data option.from = from || this.options.from option.gasPrice = gasPrice || this.options.gasPrice options.gas = options.gas || options.gasLimit || this.options.gas delete options.gasLimit return options}// TODO:// _encodeEventABI// _decodeEventABI// _encodeMethodABI// _decodeMethodABI// _decodeMethodReturn/** * Deploys a contract and fire events based on its state: transactionHash, receipt * * All event listeners will be removed, once the last possible event is fired ('error' or 'receipt') * * @method deploy * @param {Object} options * @param {Function} callback * @return {Object} EventEmitter possible are \"error\", \"transactionHash\", and \"receipt\" */Contract.prototype.deploy = function(options, callback) { options = options || {} options.arguments = options.arguments || [] options = this._getOrSetDefaultOptions(options) // return error if no 'data' is specified if (!options.data) { return utils._fireError(new Error('No \"data\" specifed in neither the given options, nor the default options'), null, null, callback) } var constructor = _.find(this.options.jsonInterface, function(method) { return (method.type === 'contructor') }) || {} constructor.signature = 'constructor' return this._createTxObject.apply({ method: constructor, parent: this, deployData: options.data, _ethAccounts: this.constructor._ethAccounts }, options.arguments)}// TODO:// _generateEventOptions// clone// once// _on// getPastEvents/** * returns the an object with call, send, estimate functions * * @method _createTxObject * @return {Object} an object with functions to call the method */Contract.prototype._createTxObject = function _createTxObject(){ var args = Array.prototype.slice.call(arguments) var txObject = {} if (this.method.type === 'function') { txObject.call = this.parent._executeMethod.bind(txObject, 'call') txObject.call.request = this.parent._executeMethod.bind(txObject, 'call', true) // to make batch request } txObject.send = this.parent._executeMethod.bind(txObject, 'send') txObject.send.request = this.parent._executeMethod.bind(txObject) txObject.encodeABI = this.parent._encodeMethodABI.bind(txObject) txObject.estimateGas = this.parent._executeMethod.bind(txObject, 'estimate') // check arguments length if (args &amp;&amp; this.method.inputs &amp;&amp; args.length !== this.method.inputs.length) { if (this.nextMethod) { return this.nextMethod.apply(null, args) } throw errors.InvalidNumberOfParams(args.length, this.method.inputs.length, this.method.name) } txObject.arguments = args || [] txObject._method = this.method txObject._parent = this.parent txObject._ethAccounts = this.parent.constructor._ethAccounts || this._ethAccounts if(this.deployData) { txObject._deployData = this.deployData } return txObject}// _processExecuteArguments/** * Execute a call, transact or estimateGas on a contract function * * @method _executeMethod * @param {String} type the type this execute function should execute * @param {Boolean} makeRequest if true, it simply returns the request parameters, rather than execute it. */Contract.prototype._executeMethod = function _executeMethod () { var _this = this var args = this._parent._processExecuteArguments.call(this, Array.prototype.slice.call(arguments)) var defer = promiEvent((args.type !== 'send)) var ethAccounts = _this.constructor._ethAccounts || _this._ethAccounts // simply return request for batch requests if (args.generateRequest) { // handle batch request var payload = { params: [formatters.inputCallFormatter.call(this._parent, args.options)], callback: args.callback, } if (args.type === 'call') { payload.params.push(formatters.inputDefaultBlockNumber.call(this._parent, args.defaultBlockNumber)) payload.method = 'eth_call' payload.format = this._parent.decodeMethodReturn.bind(null, this._method.outputs) } else { payload.method = 'eth_sendTransaction' } return payload } else { // handle call or send switch (args.type) { case 'estimate': { var estimateGas = (new Method({ name: 'estimateGas', call: 'eth_estimateGas', params: 1, inputFormatter: [formatter.inputCallFormatter], outputFormatter: utils.hexToNumber, requestManager: _this._parent._requestManager, accounts: ethAccounts, // specify accounts defaultAccount: _this._parent.defaultAccount, defaultBlock: _this._parent.defaultBlock, })).createFunction(); return estimateGas(args.options, args.callback) } case 'call': { var call = (new Method({ name: 'call', call: 'eth_call', params: 2, inputFormatter: [formatters.inputCallFormatter, formatters.inputDefaultBlockNumberFormatter], outputFormatter: result =&gt; { return _this._parent.decodeMethodReturn(_this._method.outputs, result) }, requestManager: _this._parent._requestManager, accounts: ethAccounts, // is eth.accounts (necessary for wallet signing) defaultAccount: _this._parent.defaultAccount, defaultBlock: _this._parent.defaultBlock, })).createFunction() return call(args.options, args.defaultBlock, args.callback) } case 'send': { if(!utils.isAddress(args.options.from)) { return utils._fireError(new Error('No \"from\" address specified in neither the given options, nor the default options.'), defer.eventEmitter, defer.reject, args.callback); } if (_.isBoolean(this._method.payable) &amp;&amp; !this._method.payable &amp;&amp; args.options.value &amp;&amp; args.options.value &gt; 0) { return utils._fireError(new Error('Can not send value to non-payable contract method or constructor'), defer.eventEmitter, defer.reject, args.callback); } // make sure receipt logs are decoded var extraFormatters = { receiptFormatter: receipt =&gt; { if (_.isArray(receipt.logs)) { // decode logs var events = _.map(receipt.logs, log =&gt; { return _this._parent._decodeEventABI.call({ name: 'ALLEVENT', jsonInterface: _this._parent.options.jsonInterface, }, log) }) // make sure log names keys receipt.events = {} var count = 0 events.forEach(ev =&gt; { if (ev.event) { // if &gt; 1 of the same event, don't overwrite any existing events if (receipt.events[ev.event]) { if (Array.isArray(receipt.events[ev.event])) { receipt.events[ev.event].push(ev) } else { receipt.events[ev.event] = [receipt.events[ev.event], ev] } } else { receipt.event[ev.event] = ev } } else { receipt.events[count] = ev count++ } }) delete receipt.logs } return receipt }, contractDeployFormatter: receipt =&gt; { var newContract = _this._parent.clone() newContract.options.address = receipt.contractAddress return newContract } } var sendTransaction = (new Method({ name: 'sendTransaction', call: 'eth_sendTransaction', params: 1, inputFormatter: [formatters.inputTransactionFormatter], requestManager: _this._parent.requestManager, accounts: _this.constructor._ethAccount || _this._ethAccounts, // is eth.accounts, defaultAccount: _this._parent.defaultAccount, defaultBlock: _this._parent.defaultBlock, extraFormatter: extraFormatters, })).createFunction() return sendTransaction(args.options, args.callback) } } }}","link":"/2018/07/21/Details-in-Web3-Contract/"},{"title":"Ethereum + IPFS","text":"MindMap","link":"/2018/02/14/Ethereum-IPFS/"},{"title":"Example of Node-Influx","text":"Express Response Times ExampleIn this example we’ll create a server which has an index page that prints out ‘hello world’, and a page http://localhost:3000/times which prints out the last ten response times that influxDB gave us. The end result should look something like this: 123456789101112curl -s localhost:3000Hello worldcurl -s localhost:3000/times | jq[ { \"time\": \"2016-10-09T19:13:26.815Z\", \"duration\": 205, \"host\": \"ares.peet.io\", \"path\": \"/\" }] Get started by installing and importing everything we need. This example requires Node 6. 1npm install influx express Now create a new file app.js and start writing 123456const Influx = require('../../')const express = require('express')const http = require('http')const os = require('os')const app = express() Create a new influx client. We tell it to use the express_response_db database by default, and give it some information about the schema we’re writing. It can use this to be smarter about what data formats it writes and do some basic validation for us. 12345678910111213141516const influx = new Influx.InfluxBD({ host: 'localhost', database: 'express_response_db', schema: [ { measurement: 'response_time', fields: { path: Influx.FieldType.STRING, duration: Influx.FieldType.INTEGER }, tags: [ 'host' ] } ]}) Now we have a working influx client! We’ll make sure the database exists and boot the app. 1234567891011121314influx.getDatabaseName().then(names =&gt; { if (!names.includes('express_response_db')) { return influx.createDatabase('express_response_db') }}).then(() =&gt; { http.createServer(app).listen(3000, () =&gt; { console.log('Listening on port 3000') })}).catch(err =&gt; { console.error('Error creating Influx database')}) Finally we’ll define the middleware and routes we’ll use. We have a generic middleware that records the time between when requests comes in, and the time we response to them. We also have another route called /times which prints out the last ten timings we recorded. 12345678910111213141516171819202122232425262728293031323334app.use((req, res, next) =&gt; { const start = Date.now() res.on('finish', () =&gt; { const duration = Date.now() - start console.log(`Request to ${req.path} took ${duration} ms`) influx.writePoints([ { measurement: 'response_times', tags: { host: os.hostname() }, fields: { duration, path: req.path } } ]).catch(err =&gt; { console.log(`Error saving data to InfluxDB: ${err.stack}`) }) }) return next()})app.get('/', (req, res) =&gt; { setTimeout(() =&gt; res.end('Hello world'), Math.random() * 500)})app.get('/times', (req, res) =&gt; { influx.query(` select * from response_times where host = ${Influx.escape.stringLit(os.hostname())} order by time desc limit 10 `).then(result =&gt; { res.json(result) }).catch(err =&gt; { res.status(500).send(err.stack) })})","link":"/2017/06/30/Example-of-node-influx/"},{"title":"Fastify Plugin Guide","text":"In Fastify everything is a plugin, your routes, your utilities and so on are all plugins. And to add a new plugin, whatever its functionality is, in Fastify Registers1fastify.register(require('./my-plugin', opts, callback)) Register creates a new Fastify context, this means that if you do any change to the Fastify instance, that change will not be reflected into the context’s ancestors. In other words, encapsulated! Required Plugins must expose a single function with the following signature: 1module.exports = function (instance, opts, next) {} The Fastify’s plugin module is fully reentrant and graph-based, it handles without any kind of problem asynchronous code and it guarantees the load order of the plugins, even the close order. DecoratorsFastify offers you a way nice and elegant to wrote an utility: decorator. 1fastify.decorate('util', (a, b) =&gt; a + b) Now you can access your utility by doing fastify.util. 1234fastify.register((instance, opts, next)=&gt; { instance.decorate('util', (a, b) =&gt; a + b) next()}) HooksExecute your utility. 123456789101112131415161718fastify.register((instance, opts, next) =&gt; { instance.decorate('util', (req, key, value) =&gt; { req.key = value }) instance.addHook('preHandler', (req, reply, done) =&gt; { instance.util(req, 'timestamp', new Date()) done() }) instance.get('/plugin1', (req, reply) =&gt; { reply.send(req) }) next()})fastify.get('/plugin2', (req, reply) =&gt; { reply.send(req)})","link":"/2017/10/26/Fastify-Plugin-Guide/"},{"title":"Five Models in Smart Contract","text":"Database ContractsThese are used only as data storage. The only logic they need is functions that allow other contracts to write, update and get data, and some simple way of checking caller permissions. Controller ContractsThese contracts operate on the storage contracts. In a flexible system, both controllers and databases can be replaced by other, similar contracts that share the same public api(although this is not always needed).) Controllers can be advanced, and could for example do batched reads/writes, or read from and write to multiple databases instead of just one. Contract Managine Contracts (CMCs)The purpose of these contracts is only to manage other contracts. Their main tasks is to keep track of all the contracts/components of the system, handle the communication between thses components, and to make modular design easier. Keeping this functionality separate from normal business logic should be considered good practice, and has a number of positive effects on the system. Application Logic Contracts (ALCs)Application logic contracts contains application-specific code. Generally speaking, if the contract utilizes controllers and other contracts to perform application specific tasks it’s an ALC. Utility ContractsThese type of contracts usually perform a specific task, and can be called by other contracts without restrictions. It could be a contract that hashes strings using some algorithm, provide random numbers or other things. They normally don’t need a log of storage, often have few or no dependencies. The rationale for this division will be laid out after we’ve tried to apply it to the fund manager system, as it will be a lot more clear then.","link":"/2017/07/19/Five-Models-in-Smart-Contract/"},{"title":"Difference Between Contract Calling in Web3","text":"After we get the instance of Contract(testInstance), we can invoke its method by three ways: testInstance.testFunc.sendTransaction() It will make a transaction which will be broadcasted into the net, use gas and return the txHash testInstance.testFunc.call() Call the contract function in VM, no broadcast and no gas used, return the response from method testInstance.testFunc() If the testFunc is signified constant, which means it won’t change the state on chain, it won’t be executed(web3 will invoke it by .call()). If the testFunc is not constant, sendTransaction() will be invoked.","link":"/2017/11/21/Difference-between-Contract-Calling-in-Web3/"},{"title":"Error Handling in Solidity","text":"Solidity uses state-reverting exceptions to handle errors. Such an exception will undo all changes made to the state in the current call(and all its sub-calls) and also flag an error to the caller. The convenience function assert and require can be used to check for conditions and throw an exception if the condition is not met. The assert function should only be used to test for internal errors, and to check invariants. The require function should be used to ensure valid conditions, such as inputs, or contract state variables are met, or to validate return values from calls to external contracts. If used properly, analysis tools can evaluate your contract to identify the conditions and function calls which will reach a failing assert. Properly functioning code should never reach a failing assert statement. If this happens there is a bug in your contract which you should fix. There are two ways to trigger exceptions: The revert function can be used to flag an error and revert the current call. In the future, it might be possible to also include details about error in a call to revert. The throw keyword can also be used as an alternative to revert() From 0.4.13, the throw is deprecated. When exceptions happen in a sub-call, they ‘bubble up’ automatically. Exceptions to this rule are send and the low-level functions call, delegatecall and callcode – those return false in case of an exception instead of ‘bubble up’. low-level function call, delegatecall, callcode return false when exceptions occur. Catch exceptions is not yet possible.","link":"/2018/03/13/Error-Handling-in-Solidity/"},{"title":"Gas Used by Public and External Function in Solidity","text":"Original A simple example demostrating this effect looks like this: 1234567891011pragma solidity ^0.4.19;contract Test { function test(uint[20] a) public returns (uint) { return a[10] * 2; } function test2(uint[20] a) external returnss (uint) { return a[10] * 2; }} Calling each function, the public function uses 496 gas, while the external function uses 261 gas. The difference is because in public functions, Solidity immediately copies array argument to memory, while external functions can read directly from calldata. Memory allocation is expensive, whereas reading from calldata is cheap. The reason that public functions need to write all the arguments to memory is that public functions may be called internally, which is actually an entirely different process than external calls. Internal calls are executed via jumps in the code, and array arguments are passed internally by pointers to memory. Thus, when the compiler generates the code for an internal function, that function expects its arguments to be located in memory. For external functions, the compiler doesn’t need to allow internal calls, and so it allows arguments to be read directly from calldata, saving the copying step. As for best practices, you should use external fi you expect that the function will only ever be called externally, and use public if you need to call the function internally. It almost never makes sense to use the this.f() pattern, as this requires a real CALL to be executed, which is expensive. Also, passing arrays via this method would be far more expensive than passing them internally.","link":"/2018/01/29/Gas-Used-by-Public-and-External-Function-in-Solidity/"},{"title":"Dockerizing a React App","text":"Original Project SetupInstall create-react-app 1npm install -g create-react-app@1.5.2 Creating a new app 12create-react-app docker-appcd docker-app DockerAdd a Dockerfile to the project root 1234567891011121314151617# base imageFROM node:9.6.1# set working directoryRUN mkdir /usr/src/appWORKDIR /usr/src/app# add `/usr/src/app/node_modules/.bin` to $PATHENV PATH /usr/src/app/node_modules/.bin:$PATH# install and cache app dependenciesCOPY package.json /usr/src/app/package.jsonRUN npm installRUN npm install react-scripts@1.1.1 -g# start appCMP [&quot;npm&quot;, &quot;start&quot;] Add a .dockerignore to speed up the Docker build process as our local dependencies will not be sent to the Docker Daemon 1node_modules Build and tag the Docker Image 1docker build -t docker-app:1.0.0 Then spin up the container once the image is built. 1docker run -it -v ${PWD}:/usr/src/app -v /usr/src/app/node_modules -p 3000:3000 --rm docker-app:1.0.0 Now you can visit your app http://localhost:3000 Docker ComposeAdd a docker-compose.yml to the project root. 123456789101112131415version: '3.3'services: docker-app: container_name: docker-app build: context: . dockerfile: Dockerfile volumnes: - '.:/usr/src/app' - '/usr/src/app/node_modules' ports: - '3000:3000' environment: - NODE_ENV=development Take note of the volumes. Without the data volume /usr/src/app/node_modules, the node_modules directory would be overwritten by the mounting of the host directory at runtime that were installed when the container was built. BUild the image and fire up the container 1docker-compose up -d --build Ensure the app is running in the browser. Bring down the container before moving on 1docker-compose stop ProductionLet’s create a seperate Dockerfile for use in production called Dockerfile-prod 12345678910111213141516# build environmentFROM node:9.6.1 as builderRUN mkdir /usr/src/appWORKDIR /usr/src/appENV PATH /usr/src/app/node_moudles/.bin:$PATHCOPY package.json /usr/src/app/package.jsonRUN npm installRUN npm install react-scripts@1.1.1 -gCOPY . /usr/src/appRUN npm run build# production environmentFROM nginx:1.13.9-alpineCOPY --from=builder /usr/src/app/build /usr/share/nginx/htmlEXPOSE 80CMD [&quot;nginx&quot;,&quot;-g&quot;,&apos;deamon off;&quot;] Using the production Dockerfile, build and tag the Docker Image: 1docker build -f Dockerfile-prod -t docker-app-prod . Spin up the container 1docker run -it -p 80:80 --rm docker-app-prod Add Prod Docker Compose as `docker-compose-prod.yml’ 12345678910version: \"3.3\"services: docker-app-prod: container_name: docker-app-prod build: context: . dockerfile: Dockerfile-prod prots: - \"80:80\" Fire up the container 1docker-compose -f docker-compose-prod.yml up -d --build","link":"/2018/02/28/Dockerizing-a-React-App/"},{"title":"Generate Ethereum Keys and Wallet Address","text":"Original This article is a guide on how to generate an ECDSA private key and derivesits Ethereum address. Use Openssl and keccak-256sum from a terminal. SHA3 != keccak. Ethereum is using the keccak-256 algorithm and not thestandard sha3. Ethereum use keccak-256, it should be noted that it does not follow theFIPS-202 based standard(aka. SHA-3), which was finalized in August 2015 web3.utils.sha3 uses keccak-256 web3.sha3(string[, option]): keccak-256 Generate the EC private keyFirst of all we use Openssl ecparam command to generate an elliptic curveprivate key. Ethereum standard is to use the secp256k1 curve. The same curveis used in Bitcion. This command will print the private key in BEM format(using the wonderful ASN.1key structure) on stdout. 123456&gt; openssl ecparam -name secp256k1 -genkey -noout-----BEGIN EC PRIVATE KEY-----MHQCAQEEIFDLYO9KuwsC4ej2UsdA4SYk7s3lb8aZuW+B8rjugrMmoAcGBSuBBAAKoUQDQgAEsNjwhFoLKLXGBxfpMv3ILhzg2FeySRlFhtjfi3s8YFZzJtmckVR3N/YLJLnUV7w3orZUyAz77k0ebug0ILd1lQ==-----END EC PRIVATE KEY----- On its own this command is not very useful for us, but if you pipe it with theec command it will display both private and public part in hexadecimal format,and this is what we want. 1234567891011121314&gt; openssl ecparam -name secp256k1 -genkey -noout | openssl ec -text -nooutread EC keyPrivate-Key: (256 bit)priv: 20:80:65:a2:47:ed:be:5d:f4:d8:6f:bd:c0:17:13: 03:f2:3a:76:96:1b:e9:f6:01:38:50:dd:2b:dc:75: 9b:bbpub: 04:83:6b:35:a0:26:74:3e:82:3a:90:a0:ee:3b:91: bf:61:5c:6a:75:7e:2b:60:b9:e1:dc:18:26:fd:0d: d1:61:06:f7:bc:1e:81:79:f6:65:01:5f:43:c6:c8: 1f:39:06:2f:c2:08:6e:d8:49:62:5c:06:e0:46:97: 69:8b:21:85:5eASN1 OID: secp256k1 This command decodes the ASN.1 structure and derives the public key from theprivate one. Sometimes, Openssl is adding a null byte(0x00) in front of the private part, Idon’t know why it does that but you have to trim any leading zero bytes inorder to use it with Ethereum. The private key must be 32 bytes and not begin with 0x00 and the publicone must be uncompressed and 64 bytes long or 65 with the constant (0x04)prefix. Derive the Ethereum address from the public keyThe public key is what we need in order to derive its Ethereum address. Every ECPublic key begins with ‘0x04’ prefix byte in order to hash it correctly. This prefix represents the encoding of the public key: 0x04 - both x and y of the elliptic curve point follows 0x02, 0x03 - only x follows (y is either odd or even depending on theprefix) Use any method you like to get it in the form of an hexadecimal string(withoutline return nor semicolon) 1234# Extract the public key and remove the EC prefix 0x04&gt; cat Key | grep pub -A 5 | tail -n +2 | tr -d '\\n[:space:]:' | sed 's/^04//' &gt; pub836b35a026743e823a90a0ee3b91bf615c6a757e2b60b9e1dc1826fd0dd16106f7bc1e8179f665015f43c6c81f39062fc2086ed849625c06e04697698b21855e The pub file now contains the hexadecimal value of the public key without the0x04 prefix. An Ethereum address is made of 20 bytes(40 hex characters), it is commonlyrepresented by adding the 0x prefix. In order to derive it, one should take thekeccak-256 hash of the hexadecimal form of a public key, then keep only thelast 20 bytes (aka get rid of the first 12 bytes) Simply pass the file containing the public key in hexadecimal format to thekeccak-256sum command. Do not forget to use the ‘-x’ option in order tointerpret it as hexadecimal and not a simple string. 123# Generate the hash and take the address part&gt; cat pub | keccak-256sum -x -l | tr -d ' -' | tail -c 410bed7abd61247635c1973eb38474a2516ed1d884 Which gives us the Ethereum address0x0bed7abd61247635c1973eb38474a2516ed1d884. CAUTION: if your final address looks like0xdcc703c0E500B653Ca82273B7BFAd8045D85a470, this means you have hashed anempty public key. Sending funds to this address will lock them forever.","link":"/2017/11/30/Generate-Ethereum-keys-and-wallet-address/"},{"title":"Glossary of Terms on InfluxDB","text":"aggregationAn InfluxQL function that returns an aggregated value across a set of points batchA collection of points in line protocol format, separated by newlines(0x0A). A batch of points may be submitted to the database using a single HTTP request to the write endpoint. This makes writes via the HTTP API much more performant by drastically reducting the HTTP overhead. InfluxData recommends batch size of 5,000-10,000 points, although different use cases may be better served by significantly smaller or larger batches. continuous query(CQ)An InfluxQL query that runs automatically and periodically within a database. Continuous queries require a function in the SELECT clause and must include a GROUP BY time() clause. databaseA logical container for users, retention policies, continuous queries, and time series data. durationThe attribute of the retention policy that determines how long InfluxDB stores data. Data older than the duration are automatically dropped from the database. fieldThe key-value pair in InfluxDB’s data structure that records metadata and the actual data value. Fields are required in InfluxDB’s data structure and they are not indexed - queries on field values scan all points that match the specified time range and , as a result, are not performant relative to tags. Query tip: Compare fields to tags: tags are indexed field keyThe key part of the key-value pair that makes up a field. Field keys are strings and they store metadata. field setThe collection of field keys and field values on a point. field valueThe value part of the key-value pair that makes up a field. Field values are the actual data: they can be strings, floats, integers, or booleans. A field value is always associated with a timestamp. Field values are not indexed - queries on field values scan all points that match the specified time range and, as a result, are not performant. functionInfluxQL aggregation, selectors, and transformations. identifierTokens that refer to continuous query names, database names, field keys, measurement names, retention policy names, subscription names, tag keys and user names. line protocolThe text based format for writing points to InfluxDB. measurementThe part of InfluxDB’s structure that describes the data stored in the associated fields. Measurements are strings. metastoreContains internal information about the status of the system. The metastore contains the user information, databse, retention policies, shard metadata, continuous queries, and subscriptions. nodeAn independent influxd process now()The local server’s nanosecond timestamp pointThe part of InfluxDB’s data structure taht consists of a single collection of fields in a series. Each point is uniquely idenfified by its series and timestamp. You cannot store more than one point with the same timestamp in the same series. Instead, when you write a new point to the same series with the same timestamp as an existing point in that series, the field set becomes the union of the old field set and the new field set, where any ties tgo to the new field set. queryAn operation that retrieves data from InfluxDB. replication factorThe attribute of the retention policy that determines how many copies of the data are stored in the cluster. Replication factors do not seve a purpose with single node instances. retention policy (RP)The part of InfluxDB’s data structure that describes for how long InfluxDB keeps data(ducation), how many copies of those data are stored in the cluster(replication factor), and the time range covered by shard groups(shard group duration). RPs are unique per databse and along with the measurement and tag set define a series. When you create a database, InfluxDB automatically creates a retention policy called autogen with an infinite duration, a replication factor set to one, and a shard group duration set to seven days. schemaHow the data are organized in InfluxDB. The fundamentals of the InfluxDB schema are database, retention policies, series, measurements, tag keys, tag values, and field keys. selectorAn InfluxQL function that returns a single point from the range of specified points. seriesThe collection of data in InfluxDB’s data structure that share a measurement, tag set and retention policy. The field set is not part of the series identification. series cardinalityThe number of unique database, measurement, and tag set combinations in an InfluxDB instance. For example, assume that an InfluxDB instance has a single database and one measurement. The single measurement has two tag keys: email and status. If there are three different emails, and each email address is associated with two different status, then the series cardinality for the measurement is 6. Note that, in some cases, simply performing that multiplication may overestimate series cardinality because of the presence of dependent tags. serverA machine virtual or physical, that is running InfluxDB. There should only be one InfluxDB process per server. shardA shard contains the actual encoded and compressed data, and is represented by a TSM file on disk. Every shard belongs to one and only one shard group. Multiple shards may exist in a single shard group. Each shard contains a specific set of series. All points falling on a given series in a given shard group will be stored in the same shard(TSM file) on disk. shard durationThe shard duration determines hwo much time each shard group spans. The specific interval is determined by the SHARD DURATION of the retention policy. For example, given a retention policy with SHARD DURATION set to 1w, each shard group will span a single week and contain all points with timestamps in that week. shard groupShard groups are logical container for shards. Shard groups are organized by time and retention policy. Every retention policy that contains data has at least one associated shard group. A given shard group contains all shards with data for the interval covered by the shard group. The interval spanned by each shard group is the shard duration. subscriptionSubscription allows Kapacitor to receive data from InfluxDB in a push model rather than the pull model based on querying data. When Kapacitor is configured to work with InfluxDB, the subscription will automatically push every write for the subscribed databse form InfluxDB to Kapacitor. Subscription can use TCP or UDP for transmitting the writes. tagThe key-value pair in InfluxDB’s data structure that records metadata. Tags are an optional part of InfluxDB’s data structure but they are useful for storing commonly-queried metadata; tags are indexed so queries on tags are performant tag keyThe key part of the key-value pair that makes up a tag. Tag keys are strings and they store metadata. Tag keys are indexed so queires on tag keys are performant. tag setThe collection of tag keys and tag values on a point. tag valueThe value part of the key-value pair that makes up a tag. Tag values are strings and they store metadata. Tag values are indexed so queries on tag values are performant. timestampThe date and time associated with a point. All time in influxDB is UTC. transformationAn InfluxQl function that returns a value or a set of values calculated from specified points, but does not return an aggregated value across those points. tsm (Time Structured Merge Tree)The purpose-built data storage format for InfluxDB. TSM allows for greater compaction and higher write and read throughput than exsiting B+ or LSM tree implementations. userThere are two kinds of users in InfluxDB: Admin users have READ and WRITE access to all database and full across to administrative queries and user management commands. Non-admin users have READ, WRITE, or ALT (both READ, WRITE) access to per database. When authentication is enabled, InfluxDB only executes HTTP requests that are spent with a valid username and password. values per secondThe preferred measurement of the rate at which data are persisted to InfluxDB. Write speeds are generally quoted in values per second.","link":"/2017/07/01/Glossary-of-Terms-on-InfluxDB/"},{"title":"HTTP/2 by Node.js","text":"Original Websites delivered using HTTP/2 enjoys a wide range of new features including - fully multiplexed connections: all requests and responses to a domain are fully multiplexed via a single connection, making best use of available bandwidth. header compression: repeated headers are compressed with HPACK compression so that they are not resent with every request and response. PUSH: resources can be pre-emptively pushed by the server to the client, speeding up page load times. Node.js just launched support(v8.8.1) for HTTP/2 as part of their core. In this post, we will create a simple HTTP/2 server to serve static files and then demonstrate some cool features like HTTP/2 PUSH. Get an SSL certificateEven though the HTTP/2 spec does not mandate HTTPS, browsers have decided that they will only support HTTP/2 on a HTTPS connection. This would also mitigate interference from older proxies which may not understand newer protocol. For your local server, a self-signed certificate will work. You can find how to setup a self-signed certificate here Building a Static File ServerLet us start with a simple server which just serves static files. Note that if you are using node.js 8.7.0, you need to run node with the --expose-http2 flag. We will be listening to the stream event and responding to it with the corresponding file from the server root(public, in this case) using the respondWithFile API. We are using the mime-type module to look up the correct mime type to send along with the response. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950const http2 = require('http2')const fs = require('fs')const path = require('path')const mime = require('mime-types')cosnt { HTTP2_HEADER_PATH, HTTP2_HEADER_METHOD, HTTP_STATUS_NOT_FOUND, HTTP_STATUS_INTERNAL_SERVER_ERROR} = http2.constantsconst options = { key: fs.readFileSync('./selfsigned.key'), cert: fs.readFileSync('./selfsigned.crt'),}const server = http2.createSecureServer(options)const serverRoot = './public'function respondToStreamError(err, stream) { console.log(err) if (err.code === 'ENOENT') { stream.respond({ ':stats': HTTPS_STATUS_NOT_FOUND, }) } else { stream.respond({ ':status': HTTP_STATUS_INTERNAL_SERVER_ERROR, }) } stream.end()}server.on('stream', (stream, headers) =&gt; { const reqPath = headers[HTTP2_HEADER_PATH] const reqMethod = headers[HTTP2_METHOD] const fullPath = path.join(serverRoot, reqPath) const responseMimeType = mime.lookup(fullPath) stream.respondWithFile(fullPath, { 'content-type': responseMimeType }, { onError: err =&gt; respondToStreamError(err, stream) })})server.listen(443) Server PUSH ExampleNow we have simpel HTTP/2 server running, lets try to use one of the new featues in HTTP/2 - HTTP/2 PUSH. This can lead to significant performance improvements in high latency environments, if done correctly. We are loading a simple HTML file pointing to style.css which references to our font file. The request to the font file is only made after css file is discovered in the HTML, downloaded and then parsed. This is how the waterfall would have usually looked like: You can initate a new PUSH with the pushStream API. Since we know that the browser is going to be requesting the font file in the future, we can PUSH the font file as soon as the server receives the request for the HTML file. When the actual request for the font file takes place, it is claimed from the PUSH cache, instead of making a network request then. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778const http2 = require('http2')const fs = require('fs')const path = require('path')const mime = require('mime-types')const { HTTP2_HEADER_PATH, HTTP2_HEADER_METHOD, HTTP_STATUS_NOT_FOUND, HTTP_STATUS_INTERNAL_SERVER_ERROR,} = http2.constantsconst options = { key: fs.readFileSync('./selfsigned.key'), cert: fs.readFileSync('./selfsigned.crt'),}const server = http2.createSecureServer(options)const serverRoot = './public'function respondToStreamError (err, stream) { console.log(err) if (err.code === 'ENOENT') { stream.respond({ ':status': HTTP_STATUS_NOT_FOUND, }) } else { stream.respond({ ':status': HTTP_STATUS_INTERNAL_SERVER_ERROR, }) } stream.end()}server.on('stream', (stream, headers) =&gt; { const reqPath = headers[HTTP2_HEADER_PATH] const reqMethod = headers[HTTP2_HEADER_METHOD] const fullPath = path.join(serverRoot, reqPath) const responseMimeType = mime.lookup(fullPath) if (fullPath.endsWith('.html')) { console.log('html') // handle the html file stream.respondWithFile(fullPath, { 'content-type': 'text/html' }, { onError: (err) =&gt; { respondToStreamError(err, stream) } }) stream.pushStream({ ':path': '/font.woff' }, { parent: stream.id, }, pushStream =&gt; { console.log('pushing') pushStream.respondWithFile(path.join(serverRoot, '/font.woff'), { 'content-type': 'text/css', }, { onError: err =&gt; { respondToStreamError(err, pushStream) } }) }) } else { // handle the static file console.log(fullPath) stream.respondWithFile(fullPath, { 'content-type': responseMimeType, }, { onError: err =&gt; respondToStreamError(err, stream) }) }})server.listen(443)","link":"/2017/11/07/HTTP-2-by-Node-js/"},{"title":"Go Web","text":"Original IntroductionGo is a battery included programming language and has a webserver already builtin. The net/http package from the standard library contains all functionalitiesabout the HTTP protocol. This includes an HTTP client and an HTTP server. Registering a Request HandlerFirst, create a Handler which receives all incoming HTTP connections frombrowsers, HTTP client or API requests. A handler in Go is a function with thissignature. 1func (w http.ResponseWriter, r *http.Request) The function receives two parameters: An http.ResponseWriter which is where you write your text/html response to. An http.Request which contains all information about this HTTP requestincluding like URL or header fields Registering a request handler to the default HTTP Server is as simple as this: 123http.HandleFunc(\"/\", func (w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"Hello, you've requested: %s\\n\", r.URL.Path)}) Listen for HTTP ConnectionsThe request handler alone can not accept any HTTP connections from the outside. An HTTP server has to listen on a port to pass connections on to the requesthandler. Because port 80 is in most case the default port for HTTP traffic, thisserver will also listen on it. The following code will start Go’s default HTTP server and listen forconnections on port 80. You can navigate your browser to http://localhost/ andsee your server handling yoru request 1http.ListenAndServe(\":80\", nil) The Code123456789101112package mainimport ( \"fmt\" \"net/http\")func main () { http.HandleFunc(\"/\", func (w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"Hello, you've requested: %s\\n\", r.URL.Path) }) http.ListenAndServe(\":80\", nil)} Routing (using gorilla/mux)Go’s net/http package provides a lot of functionalities for the HTTP protocol.One thing it doesn’t do very well is complex request routing like segmenting arequest url into single parameters. Use gorilla/mux package to create routes with named parameters, GET/POSThandlers and domain restrictions. gorilla/mux is a package which adapts to Go’s default HTTP router. It comeswith a lot of features to increase the productivity when writing webapplications. It is also compliant to Go’s default request handler signaturefunc (w http.ResponseWriter, r *http.Request), so package can be mixed andmatched with other HTTP libraries like middleware or existing applications. Usethe go get command to install the package from Github. 1go get -u github.com/gorilla/mux Creating a new RouterFirst create a new request router. The router is the main router for your webapplication and will later be passed as parameter to the server. It will receiveall HTTP connections and pass it on to the request handlers you will register onit. You can create a new router like so: 1r := mux.NewRouter() Registering a Request HandlerOnce you have a new router you can register request handlers like usual. Theonly difference is that instead of calling http.HandleFunc(...), you callHandleFunc on your router like this r.HandleFunc(...) URL ParametersThe biggest strength of the gorilla/mux Router is the ability to extractsegments from the request URL. As an example, this is a URL in your application 1/books/go-programming-bluepring/page/10 1234r.HandleFunc(\"/books/{title}/page/{page}\", func (w http.ResponseWriter, r *http.Request) { // get the book // navigate to the page}) The last thing to get the data from these segments. The package comes with thefunction mux.Vars(r) which takes the http.Request as parameter and returns amap of the segments. 12345func (w http.ResponseWriter, r *http.Request) { vars := mux.Vars(r) vars[\"title\"] vars[\"page\"]} Setting the HTTP server’s routerEver wondered what the nil in http.ListenAndServe(&quot;:80&quot;, nil) ment? It isthe parameter for the main router of the HTTP server. By default it’s nil,which means to use the default router of the net/http package. To make use ofyour own router, replace the nil with the variable of your router r. 1http.ListenAndServe(\":80\", r) The Code123456789101112131415161718package mainimport ( \"fmt\" \"net/http\" \"github.com/gorilla/mux\")func main () { r := mux.NewRouter() r.HandleFunc(\"/books/{title}/page/{page}\", func (w http.ResponseWriter, r *http.Request) { vars := mux.Vars(r) title := vars[\"title\"] page := vars[\"page\"] fmt.Fprintf(w, \"You've requested the book %s on page %s\\n\", title, page) }) http.ListenAndServe(\":80\", r)} Features of the gorilla/mux RouterMethodsRestrict the request handler to specific HTTP methods 1234r.HandleFunc(\"/books/{title}\", CreateBook).Methods(\"POST\")r.HandleFunc(\"/books/{title}\", ReadBook).Methods(\"GET\")r.HandleFunc(\"/books/{title}\", UpdateBook).Methods(\"PUT\")r.HandleFunc(\"/books/{title}\", DeleteBook).Methods(\"DELETE\") Hostnames &amp; SubdomainsRestrict the request handler to specific hostname or subdomain 1r.HandleFunc(\"/books/{title}\", BookHandler).Host(\"www.mybookstore.com\") SchemesRestrict the request handler to http/https 12r.HandleFunc(\"/secure\", SecureHandler).Scheme(\"https\")r.HandleFunc(\"/insecure\", InsecureHandler).Scheme(\"http\") Path Prefixes &amp; SubroutersRestrict the request handler to specific path prefixes. 123bookrouter := r.Path.Prefix(\"/books\").subRouter()bookrouter.HandleFunc(\"/\", AllBooks)bookrouter.HandleFunc(\"/{title}\", GetBook) TemplateGo’s html/template package provides a rich templating language for HTMLtemplates. It is mostly used in web applications to display data in a structuredway in a client’s browser. One great benefit of Go’s templating language is theautomatic escaping of data. There is no need to worry about XSS attacka as Goparses the HTML template and escapes all inputs before displaying it to thebrowser. First Template","link":"/2017/12/05/Go-Web/"},{"title":"GenServer in Erlang","text":"Original GenServer is essential part of OTP, which simplifies repeating tasks, letting programmer concentrate on logic of the application, and not on handling edge cases and repeated error handling. The idea behind GenServer is simple - you start separate process, that holds some state, then on each incoming message(be that call or cast) it may change it internal state and also generate some response(in case of call) In this manual calling process is named Alice and newly process is Bob. Programming without GenServer, as you would done it manually1234567891011121314151617181920212223242526272829303132333435363738394041defmodule SimpleGenServerMock do def start_link() do # runs in the *caller* context `Alice` spawn_link(__MODULE__, :init, []) end def call(pid, arguments) do # runs in the *caller* context `Alice` send pid, {:call, self(), arguments} receive {:response, data} -&gt; data end end def cast(pid, arguments) do # runs in `caller` context `Alice` send pid, {:cast, arguments} end def init() do # runs in the *server* context `Bob` initial_state = 1 loop(initial_state) end def loop(state) do # runs in the *server* context `Bob` receive command do {:call, pid, :get_data} -&gt; # do some work on data here and update state {new_state, data} = {state, state} send pid, {:response, data} loop(new_state) {:cast, :increment} -&gt; # do some work on data here and update state new_state = state + 1 loop(new_state) end endend Code initial_state = 1 is exactly same code we write in init callback. Internal state of the server is simply an integer. Usually it is a map, tuple or list with settings and state. {state, state} means that we do not want to update the state and want to return state as result. This is the code which goes in handle_call callback in Bob. And code new_state = state + 1 is the code which goes into handle_cast callback, because we do not need to respond with result, we just change server Bob internal state. Working with module will look like: 123456pid = SimpleGenServerMock.start_link()counter = SimpleGenServerMock.call(pid, :get_data)IO.puts \"Counter: #{counter}\"SimpleGenServerMock.cast(pid, :increment)counter = SimpleGenServerMock.call(pid, :get_data)IO.puts \"Counter: #{counter}\" Same Server With GenServer BehaviourNow if we want to re-write same code using GenServer it will look like this: 1234567891011121314151617181920212223defmodule SimpleGenServerBehaviour do use GenServer def start_link() do # runs in the *caller* context `Alice` GenServer.start_link(__MODULE__, []) end def init(_) do # runs in the *server* context `Bob` {:ok, 1} end def handle_call(:get_data, _from, state) do # runs in the *server* context `Bob` {:reply, state, state} end def handle_cast(:increment, state) do # runs in the *server* context `Bob` {:noreply, state + 1} endend While in this example it did not saved a lot of lines for more complicated code having GenServer deal with all complexity saves a lot of tying. Also you got timeout, named processes and stable, production proven error hanlding for free. Using GenServer behaviour is very similar to code we wrote before: 123{:ok, pid} = GenServer.start_link(SimpleGenServerBehaviour, [])counter = GenServer.call(SimpleGenServerBehaviour, :get_data)GenServer.cast(SimpleGenServerBehaviour, :increment) Better to implement start in the module 123456789101112131415161718192021222324252627defmodule Stack do use GenServer def start_link(defaut) do GenServer.start_link(default) end def push(pid, item) do GenServer.cast(pid, {:push, item}) end def pop(pid) do GenServer.call(pid, :pop) end # Server callbacks @impl ture def handle_call(:pop, _from, [h | t]) do {:reply, h, t} end @impl true def handle_cast({:push, item}, state) do {:noreply, [item | state]} endend Receiving Regular MessagesThe goal of GenServer is to abstract the “receive” loop for developers, automatically handling system messages, support code changes, synchronous calls and more. Therefore, you should never call your own “recieve” inside the GenServer callbacks as doing will cause the GenServer misbehave. Besides the synchronous and asynchronous communication provided by call/3 and cast/2, regular messages sent by functions such as Kernal/send2, Process.send_after/4 and similar, can be handled inside the handle_info/2 callback. handle_info/2 can be used in many sinutations, such as handling monitor DOWN messages sent by Process.monitor/1. Another use case for handle_info/2 is to perform periodic work, with the help of Process.send_after/4: 123456789101112131415161718192021222324defmodule MyApp.Periodically do use GenServer def start_link do GenServer.start_link(__MODULE__, %{}) end @impl true def init(state) do schedule_work() # Schedule work to be performed on start {:ok, state} end @impl true def handle_info(:work, state) do # Do the desired work here schedule_work() # Reschedule once more {:noreply, state} end defp schedule_work() do Process.send_after(self(), :work, 1000) endend","link":"/2018/05/16/GenServer-in-Erlang/"},{"title":"Get the Most Out of the CommonsChunkPlugin","text":"Original Use webpack-bundle-analyzer to generate a fancy colorful image of all of yourbundles. Case 1: Many vendor bundles with duplicate code Each single-page app is using a new CommonsChunkPlugin that targets just thatentry point, and its vendor code. This creates a bundle with only modules thatcome from node_modules folder, and another bundle with just application code. The configuration portion was provided: 12345678Object.keys(activeApps).map( app =&gt; new webpack.optimize.CommonsChunkPlugin({ name: `${app}_vendor`, chunk: [app], minChunks: isVendor, }),) The activeApps variable most likely represents each of the individual entrypoints. Below are a few areas that could use some improvement. “Meta” cachingWhat we see above is many large libraries like momentjs, lodash, and jquerybeing used across 6 or more vendor bundles. The strategy for add all vendor intoa seperate bundle is good, but we should also apply the same strategy acrollall vendor bundle. 1234new webpack.optimizeCommonsChunkPlugin({ children: true, minChunks: 6,}) We are telling the webpack to follow: Hey webpack, look across all chunks(including the vendor ones that weregenerated) and move any modules that occur in at least 6 chunks to a seperatefile. Case 2: duplicate vendors across async chunks As you can see, the same 2-3 components are used across all 40-50 async bundles CommonsChunkPlugin can solve this. Create an async Commons ChunkThe technique will be very simillar to the first, however we will need to setthe async property in the configuration option, to true as seen below: 12345new webpack.optimize.CommonsChunkPlugin({ async: true, children: true, filename: 'commonlazy.js',}) In the same way – webpack will scan all chunks and look for common modules.Since async: true, only code split bundles will be scanned. Because we did not specify minChunks, the value default to 3. so what webpackis being told is: Hey webpack, look through all normal [aka lazy loaded] chunks and if you findthe smae module that appears across 3 or more chunks, then seperate it outinto a seperate async commons chunk. More ControlminChunks functionThere are scenario you don’t want to have a single shared bundle because notevery lazy/entry chunk may use it. The minChunks property also takes afunction. This can be your ‘filtering predicate’ for what modules are added toyour newly created bundle. 12345678new webpack.optimize.CommonsChunkPlugin({ filename: 'loash-moment-shared-bundle.js', minChunks: function(module, count) { return ( module.resource &amp;&amp; /lodash|moment/.test(module.resource) &amp;&amp; count &gt;= 3 ) },}) This example says: Yo webpack, when you come across a module whos absolute path amtches lodash ormoment, and occurs across 3 seperate entries/chunks, then extract thosemodules into a seperate bundle.","link":"/2017/12/07/Get-the-most-out-of-the-CommonsChunkPlugin/"},{"title":"History API","text":"The DOM window object provides access to the browser’s history through the history object. Moving Forward and Backward12window.history.back()window.history.forward() Moving to a specific point in historyYou can use the go() method to load a specific page from session history, identified by its relative position to the current page. 12window.history.go(-1)window.history.go(1) You can determine the number of pages in the history stack by looking at the value of the length property: 1var numberOfEntries = window.history.length Adding and Modifying History Entrieshistory.pushState() and history.replaceState() methods work in conjunction with the window.onpopstate event. Using history.pushState() changes the referrer that gets used in the HTTP header for XMLHttpRequest objects created after you change the state. The referrer will be the URL of the document whose window is this at the time of creation of the XMLHttpRequest object. Example of pushState() MethodSuppose http://mozilla.org/foo.html executes the following JS. 123// history.pushState(StateObj, title, URL)var stateObj = { foo: 'bar' }history.pushState({ stateObj, 'page 2', 'bar.html' }) This will cause the URL bar to display http://mozilla.org/bar.html, but won’t cause the browser to load bar.html or even check that bar.html exists. Suppose now that the user now navigates to http://google.com, then click back. At this point, the URL bar will display http://mozilla.org/bar.html, and the page will get a popstate event whose state object contains a copy of stateObj. If we click back again, the URL change to http://mozilla.org/foo.html, and the document will get another popstate event, this time with a null state object.(which is different from replaceState). The pushState() methodpushState() takes three arguments: a state object, a title(which is currently ignored), and (optionally) a URL. state object - The state object is a javascript object which is associated with the new history entry created by pushState. Whenever the user navigates to the new state, a popstate event is fired, and the state property of the event contains a copy of the history entry’s state object. The state object can be anything that can be serialized. Because Firefox saves the state objects to the user’s disk so they can be restored after the user restarts the browser, we impose a size limit of 640k characters on the serialized representation of a state object. If you pass a state object whose serialized representation is larger than this to pushState(), the method will throw an exception. If you need more space than this, you’re encouraged to use sessionStorage and/or localStorage. title - Firefox currently ingores this parameter, although it may use it in the future. Passing the empty string here should be safe against future changes to the method. URL - The new history entry’s URL is given by this parameter. Note that the browser won’t attempt to load this URL after a call to pushState(), but it might attempt to load the URL later, for instance after the user restarts the browser. The new URL does not need to be absolute; if it’s relative, it’s resolved to the current URL. The new URL must be of the same origin as the current URL; otherwise pushState will throw an exception. The parameter is optional, if it isn’t specified, it’s set to the document’s current URL. In a sense, calling pushState() is similar to setting window.location = '#foo', in that both will create and activate another history entry associated with the current document, but pushState has a few advantages: The new URL can be any URL in the same origin as the current URL. In contrast, setting window.location keeps you at the same document only if you modify only the hash You don’t have to change the URL if you don’t want to. In contrast, setting window.location = '#foo' only creates a new history entry if the current hash isn’t #hash You can associate arbitrary data with your new history entry. With the hash-based approach, you need to encode all of the relevant data int o a short string. The replaceState() methodhistory.replaceState() operates exactly like history.pushState() except the replaceState() modifies the current history entry instead of creating a new one. Note that this doesn’t prevent the creation of a new entry in the global browser history. replaceState() is particularly useful when you want to upate the state object or URL of the current history entry in reponse to some user action. Example of replaceState() methodSuppose http://mozilla.org/foo.html executes the following JS: 12var stateObj = { foo: 'bar' }history.replaceState(stateObj, 'page 2', 'bar.htmk') This will cause the URL bar to display http://mozilla.org/bar.html, but won’t cause the browser to load bar.html or even check that bar.html exists. Suppose now that the user navigates to http://www.microsoft.com, then clicks back. At this point, the URL bar will display http://mozilla.org/bar.html. If you click back again, you will be nagivated to the page before foo.html. (which is different from pushState()) The popstate eventA popstate event is dispatched to the window every time the active history entry changes. If the history entry being activated was created by a call to pushState or affected by replaceState, the popstate event’s state property contains a copy of the history entry’s state object. Reading the current stateWhen your page loads, it might have a non-null state object. This can be happen, for example, if the page sets a state object(by pushState, or replaceState) and then the user restarts their browser. When your page reloads, the page will receive an onload event, but no popstate event. However if you read the history.state property, you’ll get back the state object you would have to gotten if a popstate had fired. You can read it directly: 1const currentState = history.state","link":"/2017/08/09/History-API/"},{"title":"HTTP Timings in Node.js","text":"Original Some Basic Concepts: IP(Internet Protocol): IP is a network-layer protocol, deals with network addressing and routing. IP is responsible for delivering packets from the source host to the destination host based on the packet headers across one or more IP network. It also defines packet structures that encapsulate the data to be delivered. DNS(Domain Name Server): DNS is a hierarchical decentralized naming system used to resolve human-readable hostnames into machine-readable IP address. TCP(Transmission Control Protocol): The TCP standard defines how to establish and maintain a network conversation between applications to exchange data. TCP provides reliable, ordered, and error-checked deliver of a stream of octects between applications running on hosts communicating over an IP network. An HTTP client initiates a request by establishing a TCP connection. SSL(Secure Sockets Layer)/TLS(Transport Layer Security): TLS is a cryptographic protocol that provides communications security over a computer network. SSL is a deprecated predecessor to TLS. Both TLS and SSL use certificates to establish a secure connection. SSL certificates are not dependent on cryptographic protocols like TLS, a certificate contains a key pair: a public and a private key. Timings Explained: DNS Lookup: Time spent performing the DNS Lookup. DNS lookup resolves domain names to IP addresses. TCP Connection: Time it took to establish TCP Connection between a source host and destination host. Connections must be properly established in a multi-step handshake process. TLS handshake: Time spent completing a TLS handshake. During the handshake process endpoints exchange authentication and keys to establish or resume secure sessions. There is no TLS handshake with a not HTTPS request. Time To First Byte(TTFB): Time spent waiting for the initial response. This time captures the latency of a round trip to the server in addition to the time spent waiting for the server to process the request and deliver the response. Content Transfer: Time spent receiving the response data. The size of the response data and the available network bandwidth determinates its duration. Measuring HTTP timings in Node.jsTo measure HTTP timings in Node.js, we need to subscribe to a specific request, response and socket events. Here is a short code snippet how to do this. 1234567891011121314151617181920212223242526272829303132const timings = { startAt: process.hrtime(), dnsLookupAt: undefined, tcpConnectionAt: undefined, tlsHandshakeAt: undefined, firstByteAt: undefined, endAt: undefined,}const req = http.request({...}, (res) =&gt; { res.once('readable', () =&gt; { timings.firstByteAt = process.hrtime() }) res.on('data', (chunk) =&gt; { responseBody += chunk }) res.on('end', () =&gt; { timings.endAt = process.hrtime() })})req.on('socket', (socket) =&gt; { socket.on('lookup', () =&gt; { timings.dnsLookupAt = process.hrtime() }) socket.('connect', () =&gt; { timings.tcpConnectionAt = process.hrtime() }) socket.on('secureConnect, () =&gt; { timings.tlsHandshake = process.hrtime() })})","link":"/2017/09/25/HTTP-Timings-in-Node-js/"},{"title":"Introduction to Object.getOwnPropertyDescriptors","text":"Object.getOwnPropertyDescriptorsThis method returns all properties including getter and setter. Object.assign shallow copies all the properties excluding getter and setter of the original source object. 123456789101112131415161718const car = { name: 'BMW', price: 100000, get discount () { return this.d } set discount (x) { this.d = x }}Object.getOwnPropertyDescriptor(car, 'discount') // {get, set, enumerable, configurable}const assignedCar = Object.assign({}, car)Object.getOwnPropertyDescriptor(assignedCar, 'discount') // {value: undefined}const definedCar = Object.defineProperties({}, Object.getOwnPropertyDescriptors(car))Object.getOwnPropertyDescriptor(definedCar, 'discount') // {get, set, enumerable, configurable}","link":"/2018/04/14/Introduction-to-Object-getOwnPropertyDescriptors/"},{"title":"Introduction to MACD","text":"Moving Average Convergence Divergence(MACD) is a market indicator on trending momentum to show the relationshops between two moving averages of a security’ price. The MACD is calculated bey subtracting the long-term Exponential Moving Average(EMA) from the short-term EMA. The display of MACD is the MACD line, and a nine-day EMA of the MACD called the ‘signal line’, is then plotted on the top of MACD line. It functions as a trigger of buying or selling. Traders could buy the security when the MACD crosses above the signal line and sell the security when the MACD crosses below the signal line. Synopsis MACD is calculated by substracting the long-term EMA from the short-term EMA. MACD triggers technical signals when it crosses above to buy or below to sell its signal line. The speed of crossovers is also taken as a signal of the market to overbuy or oversell. MACD helps investors understand whether the bullish or bearish momentum the market is. The MACD has a positive value whenever the short-term EMA is above the long-term EMA and a negative value when the short-term EMA is below the long-term EMA. The more distant the MACD is above or below it’s baseline, the growing of distance between two EMAs is faster. As the following chart shows: :max_bytes(150000):strip_icc():format(webp)/Figure2-5c425aecc9e77c0001bc2f4f.png&gt;) MACD is often displayed in a histogram foramt, which graphs the distance between the MACD and its baseline. If the MACD is above the baseline, the histogram will be above the MACD’s baseline, otherwise the histogram will be below the MACD’s baseline. Traders use the MACD histogram to identify when bullish or bearish momentum is high. MACD vs. RSIThe relative strength indicator(RSI) aims to signal whether a market is considered to be overbought or oversold in relation to recent price levels. The RSI is an oscillator that calculates average price gains and losses over a given period. MACD measures the relationship between two EMAs, while the RSI measures price change in relation to recent price highs and lows.","link":"/2019/12/03/Introduction-to-MACD/"},{"title":"JSON-PRC","text":"","link":"/2017/11/21/JSON-PRC/"},{"title":"List of HTTP Status Code","text":"1xx 100 (continue) 101 (Switching Protocols) 2xx 200 (OK) 201 (Created): respond to POST Request in RESTFul. 202 (Accepted): Server fetch the request, but not respond immediately. 203 (Non-Authoritative Information). 204 (No Content): Server has handled the request, but no content need to be respond. 205 (Reset Content): Server has handled the request, and no content need to be respond. But server request client to reset the document(recover to that before submission). 206 (Partial Content): HTTP allowed transferring by piece of data. 3xx3xx request more operation from client, usually redirect to other page. Destination redirect to will be specified in Location in header. 301 (Moved Permanently): The resource has been moved to new position. 302 (Found): The resource will be returned from other url temporarily. 303 (See Other) 304 (Not Modified): Usually work with Etag Server will return 304 with Etag: '***' to specify resource version. Next time the client request the resource with If-None-Match: '***', and server checks if the Etag is same to If-None-Match. If same, then return 304. 4xxClient Error. 400 (Bad Request) 401 (Unauthorized): Server responds with WWW-Authenticate for authorization info, and client should request with authorization in header next time. 403 (Forbidden): Server got the request, and refuse to handle. 404 (Method Not Allowed) 413 (Request Entity Too Large) 414 (Request-URI Too Large) 5xxServer Error. 500 (Internal Server Error): Server Bug. 502 (Bad Gateway): The Proxy receive invalid response from upstream server. 504 (Gateway Time-out).","link":"/2017/08/03/List-of-HTTP-Status-Code/"},{"title":"Manipulate Data in D3","text":"Use data imported from a csv file with spaces in the headerWhen importing data from a csv file(dataSpace.csv) that has headers with spaces in the middle of some of the fields there is need to address the data slightly differently in order for it to be used easily in your JavaScript. 12Date Purchased,close1-May-12,58.13 When we go to import the data using the d3.csv function, we need to reference the Data Purchased column in a way that makes allowances for the space. The following piece of script appears to be the most basic solution. 123456d3.csv('dataSpace.csv', (err, data) =&gt; { if (err) throw err; data.forEach(d =&gt; { d.date = parseTime(d['Date Purchased']) })}) HistogramThe d3.histogram function allows us to form our data into ‘bins’ that form ‘discrete samples into continous, non-overlapping intervals’. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// dtg,value// 01-08-2010,3// 01-08-2010,3// 01-08-2010,3// 01-08-2010,3// 01-08-2010,3.1// 01-08-2010,3.2// 01-08-2010,3.2// .// .// .// 31-12-2011,3.2// 31-12-2011,3.3// 31-12-2011,3.4// 31-12-2011,3.5// 31-12-2011,3.5// 31-12-2011,4.1// 31-12-2011,4.9// core codeconst parseDate = d3.timeParser('%d-%m-%Y')const xScale = d3.scaleTime() .domain([new Date(2010, 6, 3), new Date(2012, 0, 1)]) .rangeRound([, width])const yScale = d3.scaleLinear() .range([height, 0])const histogram = h3.histogram() .value(d =&gt; d.date) .domain(xScale.domain()) .thresholds(x.ticks.timeMonth)const _data = data.map(d =&gt; ({ date: parseDate(d.dtg), value: d.value,}))const bins = histogram(_data)holder.selectAll('rect') .data(bins) .enter().append('rect') .attr('class', 'bar') .attr('x', 1) .attr('transform', d =&gt; `translate(${xScale(d.x0)}, ${yScale(d.length)})`) .attr('width', d =&gt; (xScale(d.x1 - d.x0) - 1)) .attr('height', d =&gt; (height - yScale(d.length))) The key line 1const bins = histogram(_data) groups the data for the bars. Tree DiagramThe data requied to produce this type of layout needs to describe the relationships, but this is not necessary an onerous task. 12345678910111213141516171819{ \"name\": \"Top Node\", \"children\": [ { \"name\": \"Bob: Child of Top Node\", \"children\": [ { \"name\": \"Son of Bob\" }, { \"name\": \"Daughter of Bob\" } ] }, { \"name\": \"Sally: Child of Top Node\" } ] } 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// core codeconst treeData = { \"name\": \"Top Level\", \"children\": [ { \"name\": \"Level 2: A\", \"children\": [ { \"name\": \"Son of A\" }, { \"name\": \"Daughter of A\" } ] }, { \"name\", \"Leve 2: B\"} ]}const margin = { top: 40, right: 30, bottom: 50, left: 30,}const width = 660 - margin.left - margin.rightconst height = 500 - margin.top - margin.bottom// declare a tree layout and assigns the sizeconst treemap = d3.tree() .size([width, height])// assigns the node data to the tree layoutlet nodes = d3.hierarchy(treeData)// map the node data to the tree layoutnodes = treemap(nodes)// append the svg object to the body of the page// append a 'group' element to 'svg'// move the 'groupd' element to the top left marginconst svg = d3.select('body').append('svg') .attr('width', width + margin.left + margin.right) .attr('height', height + margin.top + margin.bottom)const g = svg.append('g') .attr('transform', `translate(${margin.left}, ${margin.top})`)// add links between nodesconst link = g.selectAll('.link') .data(nodes.descendants().slice(1)) .enter().append('path') .attr('class', 'link') .attr('d', d =&gt; { return `M${d.x},${d.y}C${d.x},${(d.y + d.parent.y) / 2} ${d.parent.x},${(d.y + d.parent.y) / 2} ${d.parent.x},${d.parent.y}` })// add each node as a groupconst node = g.selectAll('.node') .data(nodes.descendants()) .enter().append('circle') .attr('class', d =&gt; { return `node ${d.children ? 'node--internal' : 'node--leaf'}` }) .attr('transform', d =&gt; { `translate(${d.x}, ${d.y})` })// add the circle to nodenode.append('circle') .attr('r', 10)// add the text to the nodenode.append('text') .attr('dy', '0.35em') .attr('y', d =&gt; (d.children ? -20 : 20)) .style('text-anchor', 'middle') .text(d =&gt; d.data.name) 123456789// declare a tree layout and assign the sizeconst treemap = d3.tree() .size([width, height])// assign the data to a hierarchy using parent-child relationshipslet nodes = d3.hierarchy(treeData)// maps the node data to the tree layoutnodes = treemap(nodes) d3.hierarchy1const nodes = d3.hierarchy(treeData, d =&gt; d.children) This assigns a range of properties to each node including: node.data - the data assocaited with the node(in our case it will include the name accessible as node.data.name). node.depth - a representation of the depth or number of hops from the initial root node. node.height - the greatest distance from any descendants leaf nodes. node.parent - the parent node, or null if it’s the root node. node.children - child nodes or undefined for any leaf nodes. Above is the vertical tree map code. If you want a horizontal tree map, you can make a transform like this. Or 12345678910.attr('d', d =&gt; { return ` M${d.y},${d.x} C${(d.y + d.parent.y)/2},${d.x} ${(d.y + d.parent.y)/2},${d.parent.x} ${d.parent.y},${d.parent.x} `}).attr('transform', d =&gt; `translate(${d.y}, ${d.x})`) Add Images as Node 123456node.append('image') .attr('xlink:href', d =&gt; d.data.icon) .attr('x', '-12px') .attr('y', '-12px') .attr('width', '24px') .attr('height', '24px') Add Interaction on Node 12345678910function click (d) { if (d.children) { d._children = d.children d.chilren = null } else { d.children = d._children d._children = null } upate(d)} Sankey Diagrams// Todo Assorted Tips and TricksEvents mousedown mouseup mouseover mouseout mousemove click contextmenu dblclick Add TooltipsTooltips have a marvellous duality. They are on one hand a pretty darned useful thing that aids in giving context and information where required and on the other hand, if done with a bit of care they can look stylish. 123456789101112div.tooltip { position: absolute; text-align: center; width: 60px; height: 28px; padding: 2px; font: 12px sans-serif; background: lightsteelblue; border: 0px; border-radius: 8px; pointer-events: none;} 12345678910111213141516171819202122const div = d3.select('body').append('div').attr('class', 'tooltip').style('opacity', 0)svg.selectAll(\"circle\") .data(data) .enter().append(\"circle\") .attr(\"r\", 5) .attr(\"cx\", function(d) { return x(d.date); }) .attr(\"cy\", function(d) { return y(d.close); }) .on(\"mouseover\", function(d) { div.transition() .duration(200) .style(\"opacity\", .9); div.html(formatTime(d.date) + \"&lt;br/&gt;\" + d.close) .style(\"left\", (d3.event.pageX) + \"px\") .style(\"top\", (d3.event.pageY - 28) + \"px\"); }) .on(\"mouseout\", function(d) { div.transition() .duration(500) .style(\"opacity\", 0); }) Notice there is only one tooltip exist in the page. Selecting/Filtering a subset of objectsFiltering is fairly simple. 12345678svg.selectAll('circle') .data(data) .enter().append('circle') .filter(d =&gt; d.close &lt; 400) .style('fill', 'red') .attr('r', 5) .attr('cx', d =&gt; xScale(d.date)) .attr('cy', d =&gt; yScale(d.close)) Select Items with an IF statement12345.style(\"fill\", function(d) { if (d.close &lt;= 400) {return \"red\"} else if (d.close &gt;= 620) {return \"lawngreen\"} // &lt;== Right here else { return \"black\" } }) Applying a color gradient to a line based on value12345.line { fill: none; stroke: url(#line-gradient); stroke-width: 2px;} 12345678910111213141516171819202122232425// set the gradient// add linear gradient elementsvg.append('linearGradent')// add id for css anchor .attr('id', 'line-gradient') .attr('gradientUnits', 'userSpaceOnUse')// use x1, y1, x2, y2 to define the bounds of the area over which the gradient will act.// here we set x1, x2 to the same value so the gradient won't act on x direction. .attr('x1', 0).attr('y1', yScale(0)) .attr('x2', 0).attr('y2', yScale(1000))// select all 'stop' elements for the gradients, these 'stop' elements define where on the range covered by our coordinates the color start and stop(percent or decimal) .selectAll('stop') .data([ {offset: '0%', color: 'red'}, {offset: '40%', color: 'red'}, {offset: '40%', color: 'black'}, {offset: '62%', color: 'black'}, {offset: '62%', color: 'lawngreen'}, {offset: '62%', color: 'lawngreen'}, {offset: '100%', color: 'lawngreen'}, ]) .enter().append('stop') .attr('offset', d =&gt; d.offset) .attr('stop-color', d =&gt; d.color) There is our anchor on the third line. If you want to apply the gradient on area, simply change the css ```css.area { fill: url(#area-gradient); stroke-width: 0px;}","link":"/2017/08/31/Manipulate-Data-in-D3/"},{"title":"Mock Data for Node.js","text":"Faker.jsIt’s a wonderful node module to create fake/mock data. Faker.js has its own API, and it’s huge. It has a vast API for almost every use case with an excellent documentation Let’s consider a test case where I want some a user to have following amount of fields: name email website address bio image/avatar 12345678910const faker = require('faker')const User = { name: faker.name.findName(), email: faker.internet.email(), website: faker.internet.url(), address: faker.address.streetAddress() + faker.address.city() + faker.address.country(), bio: faker.lorem.sentences(), image: faker.image.avatar(),} Faker.js DataList of data that can generate faker.js: address commerce company date finance hacker helpers image internet lorem name phone random system Use in Browser1234&lt;script src='faker.js'&gt;&lt;/script&gt;&lt;script&gt; var randomName = faker.name.findName()&lt;/script&gt;","link":"/2017/08/22/Mock-Data-for-Node-js/"},{"title":"Node Child Process","text":"Single-threaded, non-blocking performance in Node works great for a single process. But eventually, one process in one CPU is not going to be enough to handle the increasing workload of your application. Using multiple processes is the best way to scale a Node application. Node is designed for building distributed applications with many nodes. The Child Process ModuleWe can easily spin a child process using Node’s child_process module and those child processes can easily communicate with each other with a messaging system. The child_process module enables us to access Operating System functionalities by running any system command inside child process. We can control that child process input stream, and listen to its output stream. We can also control the arguments to be passed to the underlying OS command, and we can do whatever we want with that command’s output. There are four different ways to create a child process in Node: spawn(), fork(), exec(), execFile(). Spawned Child ProcessThe spawn function launches a command in a new process and we can use it to pass that command any arguments. For example, here’s code to spawn a new process that will execute the pwd command. 123const { spawn } = require('child_process')const child = spawn('pwd') We simply destructure the spawn function out of the child_process module and execute it with the OS command as the first argument. The result of executing the spawn function (the child object above) is a ChildProcess instance, which implements the EventEmitter API. This means we can register handlers for events on this child object directly. For example, we can do something when the child process exits by registering a handler for the exit event. 123child.on('exit', function (code, signal) { console.log('child process exited with ' + `code ${\u0006code} and signal ${signal}`)}) The handler above gives us the exit code for the child process and the signal, if any, that was used to terminate the child process. This signal variable is null when the child process exits normally. The other events that we can register handlers for with the ChildProcess instances are disconnect, error, close, message. The disconnect event is emitted when the parent process manually calls the child.disconnect function. The error event is emitted if the process could not be spawned or killed. The close event is emitted when the stdio streams of a child process get closed. The message event is the most important one. It’s emitted when the child process uses the process.send() function to send messages. This is how parent/child processes can communicate with each other. Every child process also gets the three standard stdio streams, which we can access using child.stdin, child.stdout, child.stderr. When those streams get closed, the child process that was using them will emit the close event. This close event is different than the exit event because multiple child processes might share the same stdio streams and so one child process exiting does not mean that the streams got closed. Since all streams are event emitters, we can listen to different events on those stdio stream that are attached to every child process. Unlike in a normal process though, in a child process, the stdout/stderr streams are readable streams while the stdin stream is a writable one. This is basically the inverse of those types as found in a main process. The events we can use for those streams are the standard ones. Most importantly, on the readable streams, we can listen to the data event, which will have the output of the command or any errorencoutered while executing the command: 1234567child.stdout.on('data', (data) =&gt; { console.log(`child stdout:\\n${data}`)})child.stderr.on('data', (data) =&gt; { console.error(`child \\n${data}`)}) The two handlers above will log both cases to the main process stdout and stderr. When we execute the spawn function above, the output of the pwd command gets printed and the child process exits with code 0, which means no error occured. We can pass arguments to the command that’s executed by the spawn function using the second argument of the spawn function, which is an array of all the arguments to be passed to the command. 1const child = spawn('find', ['.', '-type', 'f']) If an error occurs during the execution of the command, for example, if we give find an invalid destination above, the child.stderr data event handler will be triggered and the exit event handler will report an exit code of 1, which signifies that an error has occured. A child process stdin is a writable stream. We can use it to send a command some input. Just like any writable stream, the easiest way to consume it is using the pipe function. We simply pipe a readable stream into a writable stream. SInce the main process stdin is a readable stream, we can pipe that into a child process stdin stream. 123456789const { spawn } = require('child_process')const child = spawn('wc')process.stdin.pipe(child.stdin)child.stdout.on('data', (data) =&gt; { console.log(`child stdout:\\n${data}`)}) In the example above, the child process invokes the wc command, which count lines, words, and characters in Linux. When we pipe the main process stdin(which is a readable stream) into the child process stdin(which is a writable stream). The result of this combination is that we get a standard input mode where we can type somthing and when we hit Ctrl + D, what we typed will be used as the input of the wc command. We can also pipe the standard input/output of multiple processes on each other, just like we can do with Linux commands. For example, we can pipe the stdout of the find command to the stdin of the wc command to count all the files in the current directory: 12345678910const { spawn } = require('child_process')const find = spawn('find', ['.', '-type', 'f'])const wc = spawn('wc', ['-l'])find.stdout.pipe(wc.stdin)wc.stdout.on('data', (data) =&gt; { console.log(`Number of files ${data}`)}) Add -l to the wc command to make it count only the lines. Shell Syntax and the exec FunctionBy default, the spawn function does not create a shell to execute the command we pass into it. This makes it slightly more efficient than the exec function, which does create a shell. The exec function has one other major difference. It buffers the command’s generated output and passes the whole output value to a callback function(instead of using streams, which is what spawn does). Here the is previous find | wc example implemented with an exec function. 123456789const { exec } = require('child_process')exec('find . -type f | wc -l', (err, stdout, stderr) =&gt; { if (err) { console.error(`exec error: ${err}`) return } console.log(`Number of files ${stdout}`)}) Since the exec function uses a shell to execute the command, we can use the shell syntax directly here making use of the shell pipe feature. Note that using the shell syntax comes at a security risk if you’re executing any kind of dynamic input provided externally. A user can simply do a command injection attrack using shell syntax characters like ; and $(For example, commnd + '; rm -rf ~') The exec function buffers the output and passes it to the callback function(the second argument to exec) as the stdout argument there. This stdout argument is the command’s output that we want to print out. The exec function is a good choice if you need to use the shell syntax and if the size of the data expected from te command is small(Remember exec will buffer the whole data in memory before returning it). The spawn function is a much better choice when the size of the data expected from the command is large, because that data will be streamed with the standard IO objects. We can make the spawned child process inherit the standard IO object of its parents if we want to, but also, more importantly, we can ke the spawn function use the shell syntax as well. Here’s the smae find | wc command implemented with the spawn. 1234const child = spawn('find . -type f', { stdio: 'inherit', shell: true,}) Because of the stdio: 'inherit' option above, when we execute the code, the child process inherits the main process stdin, stdout and stderr. This causes the child process data events handlers to be triggered on the main process.stdout stream, making the script output the result right away. Because of the shell: true option above, we were able to use the shell syntax in the passed command, just like we did with exec. But with this code, we still get the advantage of the streaming of data that the spawn function gives us. THis is really the best of both worlds. There are a few other good options we can use in the last argument to the child_process function besides shell and stdio. We can, for example, use the cwd option to change the working directory of the script. Another option we can use is the env option to specify the environment variables that will be visible to the new child process. The default for this option is process.env which gives any command access to the current process environment. If we want ot override that behavior, we can simple pass an empty object as the env option or new value there to be considered as the only environment variables: 1234567const child = spawn('echo $ANSWER', { stdio: 'inherit', shell: true, env: { ANSWER: 12, }}) The echo command above does not have access to the parent process’s environment variables. It can’t, for example, access $HOME, but it can accccess $ANSWER because it was passes as a custom environement variable through the env option. One last important child process option to explain here is the detached option, which makes the child process run independently of its parent process. Assuming we have a file timer.js that keeps the event loop busy: 123setTimeout(() =&gt; { // keep the event loop busy}, 20000) We can execute it in the background using the detached option: 12345678const { spawn } = require('child_process')const child = spawn('node', ['timer.js'], { detached: true, stdio: 'ignore',})child.unref() The exact behavior of detached child process depends on the OS. On windows, the detached child process will have its own console window while on Linux the detached child process will be made the leader of a new process groups and session. It the unref function is called on the detached process, the parent process can exit independently of the child. This can be useful if the child is executing a long-running process, but to keep it running in the background the child’s stdio configurations also have to be independent of the parent. The example above will run a node script(timer.js) in the background by detaching and also ignoring its parent stdio file descriptors so that the parent can terminate while the child keeps running in the background. The execFile functionIf you need to execute a file without using a shell, the execFile function is what you need. It behaves exactly like the exec function, but does not use a shell, which makes it a bit more efficient. On windows, some files cannot be executed on their own, like .bat, .cmd files. Those files cannot be executed with execFile and either exec or spawn with shell set to true is required to execute them. The *Sync FunctionThe functions spawn, exec, execFile from the child_process module also have synchronous blocking versions that will wait until child process exits. 12345const { spawnSync, execSync, execFileSync,} = require('child_process') The fork() functionTHe fork function is a variation of the spawn function for spawning node processes. The biggest difference between spawn and fork is that a communication channel is established to the child process when using fork, so we can use the send function on the forked along with the global process object itself to exchange messsages between the parent and forked processes. We do this through the EventEmitter module interface. 12345678910111213141516171819202122232425// parent.jsconst { fork } = require('child_process')const forked = fork('child.js')forked.on('message', (msg) =&gt; { console.log('Message from child', msg)})forked.send({ hello: 'world',})// child.jsprocess.on('message', (msg) =&gt; { console.log('Message from parent:', msg)})let counter = 0setInterval(() =&gt; { process.send({ counter: counter++ })}, 1000) In the parent.js we fork child.js(which will execute the file with the node command) and then we listen for the message event. The message event will be emitted whenever the child use process.send. The pass down messages from the parent to the child, we can execute the send function one the forked object it self, and then, in the child script we can listen to the message event on the global process. When executing the parent.js file, it’ll first send down the {hello: 'world'} object to be printed by the forked child process and then the forked child process will send an incremental counter value every second to be printed by the parent process. Let’s do more practical example about the fork function. Let’s say we have an http server that handles two endpoints. One of these endpoints(/compute below) is computationally expensive and will take a few seconds to complete. WE can use a long for loop to simulate that: 12345678910111213141516171819202122const http = require('http')const longComputation = () =&gt; { let sum = 0 for (let i = 0; i &lt; 1e9; i++) { sum += i } return sum}const server = http.createServer()server.on('request', (req, res) =&gt; { if (req.url === '/compute') { const sum = longComputation() return res.end(`Sum is ${sum}`) } else { res.end('OK') }})server.listen(3000) The program has a big problem: when the /compute endpoint is requested, the server will not be able to handle any other requests because the event loop is busy with the long for loop operation. There are a few ways which we can solve this problem depending on the nature of the long operation but one solution that works for all operation is to just move the computational operation into another process using fork. We first move the whole longComputation function into its own file and make it invoke that function when instructed via a message from the main process: 12345678910111213141516171819202122232425262728293031323334// compute.jsconst longComputatioin = () =&gt; { let sum = 0 for (let i = 0; i &lt; 1e9; i++) { sum += i; } return sum}process.on('message', (msg) =&gt; { const sum = longComputatioin() process.send(sum)})// server.jsconst http = require('http')const { fork } = require('child_process')const server = http.createServer()server.on('request', (req, res) =&gt; { if (req.url === '/compute') { const compute = fork('compute.js') compute.send('start') compute.on('message', sum =&gt; { res.end(`Sum is ${sum}`) }) } else { res.end('OK') }})server.listen(3000) When a request to /compute happens now with the above code, we simply send a message to the forked process to start executing the long operation. The main process’s event loop will not be blocked. Once the forked process is done with the long operation, it can send its result back to the parent process using process.send. Node’s cluster module is based on this idea of child process forking and load balancing the requests among the many forks.","link":"/2017/08/22/Node-Child-Process/"},{"title":"Methods of Observable","text":"OriginalPlayground ObservableDirect Subclass ConnectableObservable GroupedObservable Subject Indirect Subclass AnonymousSubject AsyncSubject BehaviorSubject ReplaySubject Static Public Methods bindCallback public static bindCallback(func: function, selector: function, schedular: Schedular): function(...params: *): Observable Convert a callback API to a function that returns an Observable Give it a function f of type f(x, callback) and it will return a function g taht when called as g(x) will output an Observable. bindCallback is not an operator because its input and output are not Observables. The input is a function with some parameters, but the last parameter must be a callback function. The output of the bindCallback is a function that takes the same parameters as original function takes, except the last one(the callback). When the output function is called with arguments, it will return an Observable. If the original function’s callback takes one argument, the Observable will emit that value. If on the other hand callback is called with multiple values, resulting Observable will emit an array with these argumetns. More in Origin Article bindNodeCallback public static bindNodeCallback(func: function, scheduler: Schedular): function(...param: *): Observable combineLatest public static combineLatest(observable1: ObservableInput, observable2: ObservableInput, project: function, schedular: Schedular): Observable Combines multiple Observables to create an Observable whose values are calculated from the latest values of each of its input Observables. Whenever any input Observable emits a value, it computes a formula using the latest values from all the inputs, then emits the output of the formula. 123456789101112131415161718192021222324252627282930// combine two timer Observableconst firstTimer = Rx.Observable.timer(0, 1000)const secondTimer = Rx.Observable.timer(500, 1000)const combineTimers = Rx.Observable.combineLatest(firstTimer, secondTimer)combineTimers.subscribe(console.log)// logs// [0, 0] after 0.5s, triggered by secondTimer// [1, 0] after 1s, triggered by firstTimer// [1, 1.5] after 1.5s, triggered by secondTimer// combine an array of observableconst observables = [1, 2, 4].map(n =&gt; Rx.Observable.of(n).delay(n * 1000).startWith(0))const combined = Rx.Observable.combineLatest(observables)combined.subscribe(console.log)// logs// [0, 0, 0] immediately// [1, 0, 0] after 1s triggered by observables[0]// [1, 2, 0] after 2s triggered by observables[1]// [1, 2, 4] after 4s triggered by observables[2]// use project function to dynamically calculate the body-mass indexconst weight = Rx.Observable.of(70, 72, 76, 79, 75)const height = Rx.Observable.of(1.76, 1.77, 1.78)const bmi = Rx.Observable.combineLatest(weight, height, (w, h) =&gt; w/(h*h))bmi.subscribe(console.log)// With output to console:// BMI is 24.212293388429753// BMI is 23.93948099205209// BMI is 23.671253629592222 concat public static concat(input1: ObservableInput, input2: ObservableInput, scheduler: Schedular): Observable Creates an output Observable which sequentially emits all values from given Observable and then moves on to the next. 12345678910// Concatenate a timer counting form 0 to 3 with a synchronous sequence from 1 to 10var timer = Rx.Observable.interval(1000).take(4)var sequence = Rx.Observable.range(1, 10)var result = Rx.Observable.concat(timer, sequence)// concatenate an array of 3 Observables, different from the one abovevar timer1 = Rx.Observable.interval(1000).take(10)var timer2 = Rx.Observable.interval(1000).take(6)var timer3 = Rx.Observable.interval(1000).take(10)var result = Rx.Observable.concat([timer1, timer2, timer3]) create public static create(onSubscription: function(observer: Observer): TearDownLogic): Observable Creates a new Observable, that will execute the specified function when an Observer subscribes to it. 12345var observable = Rx.Observable.create(function(observer) { observer.next(1) observer.next(2) observer.next(3)}) defer public static defer(observableFactory: function(): SubscribableOrPromise): Observable Creates an Observable that, on subscribe, calls an Observable factory to make an Observable for each new Observer Creates the Observable lazily, that is, only when it is subscribed. 12345678// when defer is called, it returns an Observablevar clicksOrInterval = Rx.Observable.defer(function(){ if (Math.random() &gt; 0.5) { return Rx.Observable.fromEvent(document, 'click') } else { return Rx.Observable.interval(1000) }}) empty public static empty(scheduler: Scheduler): Observable Creates an Observable that emits no items to the Observer and immediately emits a completion notification. Just emits ‘complete’ and nothing else 1var result = Rx.Observable.empty().startWith(8) from public static from(ish: ObservableInput&lt;T&gt;, scheduler: Scheduler): Observable&lt;T&gt; Creates an Observable from an Array, an array-like Object, a Promise, an iterable object, or an Observable-like Object Convert almost anything to an Observable fromEvent public static fromEvent(target: EventTargetLike, eventName: string, options: EventListenerOptions, selector: SelectorMethodSignature&lt;T&gt;): Observable&lt;T&gt; Creates an Observable from DOM events, or Node EventEmitter events or others 1var clicks = Rx.Observable.fromEvent(document, 'click') fromEventPattern public static fromEventPattern(addHandler: function(handler: Function): any, removeHandler: function(handler: Function, signal?: any): void, selector: function(...args: any): T): Observable&lt;T&gt; Converts any addHandler/removeHandler API to an Observable 123456789101112function addClickHandler(handler) { document.addEventListener('click', handler)}function removeClick(handler) { document.removeEventListener('click', handler)}var clicks = Rx.Observable.fromEventPattern( addClickHandler, removeClickHandler,) fromPromise public static fromPromise(promise: Promise&lt;T&gt;, scheduler: Scheduler): Observable&lt;T&gt; Returns an Observable that just emit the Promise’s resolved value, then complete 1var result = Rx.Observable.fromPromise(fetch('reqres.in/api/users')) interval public static interval(period: number, scheduler: Scheduler): Observable Emits incremental numbers periodically in time merge public static merge(observables: ...ObservableInput, concurrent: number, scheduler: Scheduler): Observable Creates an output Observable which concurrently emits all values from every given input Observable Flatten multiple Observables together by blending their values into one Observable 123var clicks = Rx.Observable.fromEvent(document, 'click')var timer = Rx.Observable.interval(1000)var clicksOrTimer = Rx.Observable.merge(clicks, timer) never public static never(): Observable Creates an Observable that emits no items to the Observer An Observable that never emits anything 12Rx.Observable.never().startWith(7).subscribe(console.log)// won't console 7 of public static of(values: ...T, scheduler: Scheduler): Observable&lt;T&gt; Creates an Observbale that emits some values you specify as arguments, immediately one after the other, and then emits a complete notification. Emits the arguments you provide, then complete. range public static range(start: number, count: number, scheduler: Scheduler): Observable Creates an Observable that emits a sequence of numbers within a specified range. Emits a sequence of numbers in a range throw public static throw(error: any, scheduler: Scheduler): Observable Just emit ‘error’ and nothing else. timer public static timer(initialDelay: number|Date, period: number, scheduler: Scheduler): Observable Creates an Observable that starts emitting after an initialDelay and emits ever increasing numbers after each period of time thereafter. It’s like interval, but you can specify when should the emissions start. webSocket public static webSocket(urlConfigOrSource: string | WebSocketSubjectConfig): Observable 1let subject = Rx.Observable.webSocket('ws://localhost:8001') zip public static zip(observables: *): Observable&lt;R&gt; Combines multiple Observables to create an Observable whose values are calculated from the valeus, in order, of each of its input Observables. 123456789let age$ = Rx.Observable.of(27, 25, 29)let name$ = Rx.Observable.of('Foo', 'Bar', 'Beer')let isDev$ = Rx.Observable.of(true, true, false)Rx.Observable.zip(age$, name$, isDev$, (age, name, isDev) =&gt; ({age, name, isDev}))// outputs// { age: 27, name: 'Foo', isDev: true }// { age: 25, name: 'Bar', isDev: true }// { age: 29, name: 'Beer', isDev: false } constructor public constructor (subsribe: Function) audit public audit(durationSelector: function(value: T): SubscribableOrPromise): Observable&lt;T&gt; Ignores source value for a duration determined by another Observable, then emis the most recent value from the source Observable, then repeats this process. It’s like auditTime, but the silencing duration is determined by a second Observable. audit is similar to throttle, but emits the last value from the silenced time window. 12var clicks = Rx.Observable.fromEvent(document, 'click')var result = clicks.audit(ev =&gt; Rx.Observable.interval(1000)) auditTime public auditTime(duration: number, scheduler: Scheduler): Observable&lt;T&gt; Ignores source values for duration milliseconds, then emits the most recent value from the source Observable, then repeats this process. Similar to throttleTime buffer public buffer(closingNotifier: Observable&lt;any&gt;): Observable&lt;T&gt; Buffers the source Observable values until closingNotifier emits. Collect values from the past as an array, and emits that array when another Observable emits. bufferCount public bufferCount(bufferSize: number, startBufferEvery: number): Observable&lt;T[]&gt; 12var interval = Rx.Observable.interval(1000)interval.bufferCount(3, 2) bufferTime public bufferTime(bufferTimeSpan: number, bufferCreationIntervel: number, maxBufferSize: number, scheduler: Scheduler): Observable&lt;T[]&gt; Buffers the source Observable values for a specific time period. Collect values from the past as an array, and emits those array periodically in time. bufferToggle public bufferToggle(openings: SubscribableOrPromise&lt;O&gt;, closingSelector: function(value: O): SubscribableOrPromise): Observable&lt;T[]&gt; bufferWhen public bufferWhen(closingSelector: function(): Obversable): Obversable&lt;T[]&gt; Buffers the source Observable values, using a factory function of closing Observables to determine when to close, emit and reset the buffer. catch public catch(selector: function): Obversable Catches errors on the observable to be handled by returning a new obversable or throwing an error. 12345Rx.Observable.of(1, 2, 3, 4, 5).map(n =&gt; { if (n === 4) throw 'four' return n}).catch(err =&gt; Rx.Observable.of('I' , 'II', 'III', 'IV', 'V')) combineAll public combineAll(project: function): Observable Convert a higher-order Observable into a first-order Observable by waiting for the outer Observable to complete, then applying combineLatest Similar to CombineLatest Flatten an Observable-of-Observables by applying combineLatest when the Observable-of-Observable completes 12345var clicks = Rx.Observable.fromEvent(document, 'click');var higherOrder = clicks.map(ev =&gt; Rx.Observable.interval(Math.random()*2000).take(13)).take(3);var result = higherOrder.combineAll(); combineLatest public combineLatest(other: ObservableInput, project: function): Observable Combines multiple Observables to create an Observable whose values are calculated from the latest values of each of its input Observable. concat public concat(other: ObservableInput, scheduler: Scheduler): Observable concatAll public concatAll(): Observable Converts a higher-order Observable into a first-order Observable by concatenating the inner Observable in order. Flatten an Observable-of-Observable by putting one inner Observable after the other concatMap public concatMap(project: function(value: T, ?index: number): ObservableInput, resultSelector: function(outerValue: T, innerValue: I, outerIndex: number, innerIndex: number): any): Observable Projects each source value to an Observable which is merged in the output Observable, in a serialized fashion waiting for each one to complete before merging the next. Map =&gt; Concat Map each value to an Observable, then flatten all of these inner Observables using concatAll 1234var clicks = Rx.Observable.fromEvent(document, 'click')var result = clicks.concatMap(ev =&gt; { return Rx.Observable.interval(1000).take(4)}) concatMaoTo public concatMapTo(innerObservable: ObservableInput, resultSelector: function(outerValue: T, innerValue: I, outerIndex: number, innerIndex: number): any): Observer It’s like concatMap, but maps each value always to the same inner Observable count public count(predicate: function(value: T, i: number, source: Observable&lt;T&gt;): boolean): Observable Counts the number of emissions on the source and emits the number when the source completes. 123456789// count how many seconds have passed before the first clickvar seconds = Rx.Observable.interval(1000)var clicks = Rx.Observable.fromEvent(document, 'click')var secondsBeforeClick = seconds.takeUntil(clicks)secondsBeforeClick.count()// count how many odd numbers are there between 1 and 7var numbers = Rx.Observable.range(1, 7)numbers.count(i =&gt; i % 2) debounce public debounce(durationSelector: function(value: T): SubscribableOrPromise): Observable Emits a value from the source Observable only after a particular time span determined by another Observable has passes without another source emission. It’s like debounceTime, but the time span of emission silence is determined by a second Observable. 12var clicks = Rx.Observable.fromEvent(document, 'click')var result = clicks.debounce(() =&gt; Rx.Observable.interval(1000)) debounceTime public debounceTime(dueTime: number, scheduler: Scheduler): Observable Emits a value from the source Observable only after a particular time span has passed without another source emission. It’s like delay, but passes only the most recent value from each burst of emissions. defaultEmpty public defaultIfEmpty(defaultValue: any): Observable Emits a given value if the source Observable completes without emitting any next value, otherwise mirrors the source Observable. If the source Observable turns out to be empty, then this operator will emit a default value. 123var clicks = Rx.Observable.fromEvent(document, 'click')var clicksBeforeFive = clicks.takeUntil(Rx.Observable.interval(5000))clicksBeforeFive.defaultIfEmpty('no click') delay public delay(delay: number|Date, scheduler: Scheduler): Observable Delays the emission of items from the source Observable by a given timeout or until a given Date. delayWhen public delayWhen(delayDurationSelector: function(value: T): Observable): Observable It’s like delay, but the time span of the delay duration is determined by a second Observable. dematerialize public dematerialize(): Observable Convert an Observable of Notification objects into the emissions that they represent. Unwraps Notification objects as actual next, error, and complete emissions. The opposite of materialize. dematerialize is assumed to operate an Observable that only emits Notification objects as next emission, and does not emit any error. Such Observable is the output of a materialize operation. Those notifications are then unwrapped using the metadata they contain, and emitted as next, errorand complete on the output Observable. 12345var notiA = new Rx.Notification('N', 'A')var notiB = new Rx.Notification('N', 'B')var notiE = new Rx.Notification('E', void 0, new TypeError('x.toUpperCase is not a function'))var materialized = Rx.Observable.of(notiA, notiB, notiE)var upperCase = materialized.dematerialize() distinct public distinct(keySelector: function, flushes: Observable): Observable Returns an Observable that emits all items emitted by the source Observable that are distinct by comparison from previous items. 123456789101112131415Rx.Observable.of(1,1,2,2,1,1,3,4,5,67,6,6,).distinct()// 1,2,3,4,5,67,6// repeated 1 omitted// keySelectorinterface Person { age: number name: string}Rx.Observable.of&lt;Person&gt;( { age: 4, name: 'Foo' }, { age: 7, name: 'Bar' }, { age: 5, name: 'Foo' },).distinct((p: Person) =&gt; p.name) Note: ‘1’ is different from 1 distinctUntilChanged public distinctUntilChanged(compare: function): Observable Returns an Observable that emits all items emitted by the source Observable that are distinct by comparison from the previous item. (not items) distinctUntilKeyChanged public distinctUntilKeyChanged(key: string, compare: function): Observable 12345678910interface Person { age: number name: string}Rx.Observable.of&lt;Person&gt;( { age: 4, name: 'Foo' }, { age: 5, name: 'Bar' }, { age: 3, naem: 'For' },).distinctUntilKeyChanged('name', (x: string, y: string) =&gt; x.substring(0, 2) === y.substring(0, 2)) do public do(nextOrObserver: Observer|function, error: function, complete: function): Observable Perform a side effect for every emission on the source Observable, but return an Observable that is identical to the source. Intercepts each emission on the source and runs a function, but returns an output which is identical to the source. elemetnAt public elementAt(index: number, defaultValue: T): Observable Emits the single value at the specified index in a sequence of emissions from the source Observable. Emits only the i-th value , then completes. 12var clicks = Rx.Observable.fromEvent(document, 'click')clicks.elementAt(2) every public every(predicate: function, thisArg: any): Observable Returns an Observable that emits whether or not every item of the source satisfies the condition specified. 1234// all elements are less than 5, otherwise falseObservable.of(1, 2, 3, 4, 5, 6) .every(x =&gt; x &lt; 5) .subscribe(x =&gt; console.log(x)); // -&gt; false exhaust public exhaust(): Observable Convert a higher-order Observable into a first-order Observable by dropping inner Observables while the previoud inner Observable has not yet completed. Flatten an Observable-of-Observables by dropping the next inner Observable while the current inner is still executing. exhaust ingores every new inner Observable if the previous Observable has not yet completed. 123var clicks = Rx.Observable.fromEvent(document, 'click')var higherOrder = clicks.map(ev =&gt; Rx.Observable.interval(1000).take(3))higherOrder.exhaust() exhaustMap public exhaustMap(project: function(value: T, ?index: number): ObservableInput, resultSelector: function(outerValue: T, innerValue: I, outerIndex: number, innerIndex: number): any): Observable Projects each source value to an Observable which is merged in the output Observable only if the previous projected Observable has completed. expand public expand(project: function(value: T, index: number), concurrent: number, scheduler: Scheduler): Observable Recursively projects each source value to an Observable which is merged in the output Observable. It’s similar to mergeMap, but applies the projection function to every source value as well as every output value. It’s recursive. 12var clicks = Rx.Observable.fromEvent(document, 'click')clicks.mapTo(1).expand(x =&gt; Rx.Observable.of(2*x).delay(1000)).take(10) filter public filter(predicate: function(value T, index: number): boolean, thisArg: any): Observable Filter items emitted by the source Observable by only emitting those that satisfy a specified predicate. 12var clicks = Rx.Observable.fromEvent(document, 'click')clicks.filter(ev =&gt; Math.random() &gt; 0.4) find public find(predicate: function(value: T, index: number, source: Observable&lt;T&gt;): boolean, thisArg: any): Observable&lt;T&gt; Emits only the first value emitted by the source Observable that meets some condition. findIndex public findIndex(predicate: function(value: T, index: number, source: Observable&lt;T&gt;): boolean, thisArg: any): Observable&lt;T&gt; It’s like find, but emits the index of the found value, not the value itself. first public first(predicate: function(value: T, index: number, source: Obsevable&lt;T&gt;): boolean, resultSelector: function(value: T, index: number): R, defaultValue: R): Observable&lt;T|R&gt; Emits only the first value (or the fisrt value that meets some condition) emitted by the source Obsevable forEach public forEach(next: Function, PromiseCtor: PromiseConstructor): Promise groupBy public groupBy(keySelector: function(value: T): K, elementSelector: functioN(value: T): R, durationSelector: function(grouped: GroupedObservable&lt;K|R&gt;): Observable&lt;any&gt;): Observable&lt;GroupedObservable&lt;K, R&gt;&gt; ignoreElements public ignoreElements(): Observable Iggnores all items emitted by the source Observable and only pass calls of complete or error isEmpty() public isEmpty(): Observable last public last(predicate: function): Observable letProto public letProto(func: *): Observable&lt;T&gt; lift public lift(operator: Operator): Observable Creates a new Observable, with this Observable as the source, and the passed operator defined as the new observable’s operator. Return a new Observable with the Operator applied. map public map(project: function(value: T, index: number): R, thisArg: any): Observable Applies a given project function to each value emitted by the source Observable, and emits the resulting values as an Observable. 12var clicks = Rx.Observable.fromEvent(document, 'click')clicks.map(ev =&gt; ev.clientX) mapTo public mapTo(value: any): Observbale Emits the given constant value on the output Observable every time the source Observable emits a value. materialize public materialize(): Observable&lt;Notification&lt;T&gt;&gt; Represents all of the notifications from the source Observable as next emission marked with their orignal types within Notification objects. max public max(comparer: Function): Observable 12345678910111213Rx.Observable.of(5, 3, 9, 8).max()interface Person { name: string age: number}Rx.Observable.of&lt;Person&gt;( { age: 7, name: 'Foo' }, { age: 8, name: 'Bar' }, { age: 0, name: 'For' },).max&lt;Person&gt;((a, b) =&gt; a.age - b.age) merge public merge(other: ObservableInpt, concurrent: number, scheduler: Scheduer): Observable Creates an output Observable which concurrently emits all values from every given input Observable. Flatten multiple Observable together by blending their values into one Observable. mergeAll public mergeAll(concurrent: number): Obsevable Converts a higher-order Observable into a first-order Observable which concurrently delivers all values that are emitted on the inner Observables. mergeMap public mergeMap(project: function(value: T, ?index: number): ObservableInput, resultSelector: function(outerValue: T, innerValue: I, outerIndex: number, innerIndex: number): any, concurrent: number): Observable Projects each source value to an Observable which is merged in the output Observable. Map each value to an Observable, then flattn all of these inner Observable using mergeAll 12var letters = Rx.Observable.of('a', 'b', 'c')letters.mergeMap(letter =&gt; Rx.Observable.interval(1000).map(i =&gt; i+letter)) mergeMapTo public mergeMapTo(innerObservable: ObservableInput, resultSelector: function(outerValue: T, innerValue: I, outerIndex: number, innerIndex: number): any, concurrent: number): Observable Projects each source value to the same Observable which is merged multiple times in the output Observable. mergeScan public mergeScan(accumulator: function(acc: R, value: T): Observable&lt;R&gt;, seed: *, concurrent: number): Observable&lt;R&gt; Applies an accumulator function over the source Observable where the accumulator function itself retunrs an Observable, then each intermediate Observable is merged into the output Obsevable. 1234const click$ = Rx.Observable.fromEvent(document, 'click')const one$ = click$.mapTo(1)const seed = 0const count$ = one$.mergeScan((acc, one) =&gt; Rx.Observable.of(acc + one), seed) min public min(comparer: Function): Observable&lt;R&gt; multicast public multicast(subjectOrSubjectFactory: Function | Subject, selector: Function): Observable Returns an Observable tghat emits the results of invoking a specified selector on items emitted by a ConnectableObservable that shares a single subscription to the underlying stream. observeOn public observeOn(scheduler: *, delay: *): Observable&lt;R&gt; pairwise public pairwise(): Observable&lt;Array&lt;T&gt;&gt; Groups pairs of consecutive emissions together and emits them as an array of two values. Puts the current value and previous value together as an array, and emits that. partition `public partition(predicate: function(value: T, index: number): Boolean, thisArg: this): [Observable, Observable] Splits the source Observable into two, one with values that satisfy a predicate, and another values that don’t satisfy the predicate. It’s like filter, but returns two Observable, one like the output of filter, and the other with values that did not pass the condition. pluck public pluck(properties: ...string): Observable Maps each source value (an object) to its specified nested property Like map, but meant only for picking on eof the nested properties of every emitted object. 12const clicks$ = Rx.Observable.fromEvent(document, 'click')clicks$.pluck('target', 'tagName') publish public publish(selector: Function): * Returns a ConnectableObservable, which is a variety of Observable that waits until connect method is called before it begins emitting items to those Observers that have subscribed to it. publishBehavior publishLast publishReplay race public race(...observables): Observable Returns an Observable that mirrors the first source Observable to emit an item from the combination of this Observable and supplied Observables. reduce public reduce(accumulator: function(acc: R, value: T, index: number): R, seed: R): Observable&lt;R&gt; repeat public repeat(count: number): Observable repeatWhen public repeatWhen(notifier: functioN(notification: Observable): Observable): Observable 1 retry public retry(count: number): Observable Returns an Observable that mirrors the source Observable with the exception of an error, if the source Observable calls error, this method will resubscribe to the source Observable for a maximum of count resubscriptions rather than propagating the error call. retryWhen public retryWhen(notifier: function(errors: Observable): Observable): Observable sample public sample(notifier: Observable&lt;any&gt;): Observable&lt;T&gt; Emits the most recently emitted value from the source Observable whenever another Observable, the notifier emits. It’s like sampleTime, but sampels whenever the notifier Observable emits. sampleTime public sampleTime(period: number, scheduler: Scheduler): Observable&lt;T&gt; scan public scan(accumulate: function(acc: R, value: T, index: number): R, seed: T|R): Observable&lt;R&gt; Applies an accumulator function over the source Observable, and returns each intermediate result, with an optional seed value. It’s like reduce, but emits the current accumulation whenever the source emits a value sequenceEqual(compareTo: Observbale, comparor: function): Observable` Compares all values of two observbales in sequence using an optional comparor function and returns an observable of a single boolean value representing whether or not the two sequences are equal. Checks to see of all values emitted by both observables are equal in order. share public share(): Observable&lt;T&gt; Returns a new Observable that multicasts (shares) the original Observable. As long as there is at least one Subscriber this Observable will be subscribed and emitting data. When all subscribers have unsubscribed it will unsubscribe from the source Observable. Because the Observable is multicasting it makes the stream hot. This is an alias for .publish().refCount(). single public single(predicate: Function): Observable&lt;T&gt; skip public skip(count: number): Observable skipUntil public skipUntil(notifier: Observable): Observable&lt;T&gt; Returns an Observable that skips items emitted by the source Observable until a second Observable emits an item. skipWhile public skipWhile(predicate: Function): Observable Returns an Observable that skips all items emitted by the source Observable as long as a specified condition holds true, but emits all further source items as soon as the condition becomes false. startWith public startWith(values: ...T, scheduler: Scheduler): Observable Returns an Observable that emits the items you specified before it begins to emit items by the source Observable. subscribeOn public subscribeOn(scheduler: Scheduler): Observable&lt;T&gt; Asynchornously subscribes Observables to this Observable on the specified Scheduler. switch public switch(): Observable&lt;T&gt; Converts a higher-order Observable into a first-order Observable by subscribing to only the most recently emitted of those inner Observables. Flatten an Observable-of-Observables by dropping the previous inner Obsevable once a new one appears. switchMap public switchMap(project: function(value: T, ?index: number): ObservableInput, resultSelector: function(outerValue: T, innerValue: I, outerIndex: number, innerIndex: number): any): Observable Projects each source value to an Observable which is merged in the output Observable, emitting values only from the most recent projected Observable. Map each value to an Observable, then flatten all of these Observable using switch. take public take(count: number): Observable&lt;T&gt; Emits only the first count values emitted by the source Observable. Take the first count value from the source, then complete. takeLast takeLast(count: number): Observable&lt;T&gt; Emits only the last count values emitted by the source Observable. Remembers the latest count values, then emits those only when the source completes. takeUntil public takeUntil(notifier: Observable): Observable&lt;T&gt; Emits the values emitted by the source Observable until a notifier Observable emits a value. Let values pass until a second Observable, notifier, emits something. Then, it completes. takeWhile public takeWhile(predicate: function(value: T, index: number): boolean): Observable&lt;T&gt; Emits values emitted by the source Observable so long as each value satisfies the given predicate, and then completes as soon as this predicate is not satisfied. Take values from the source only while they pass the condition given, when the first value does not satisfy, it completes. throttle public throttle(durationSelector: function(value: T): SubscribableOrPromise): Observable&lt;T&gt; Emits a value from the source Observable, then ignores subsequent source values for a duration determined by another Observable, then repeats this process. It’s like throttleTime, but the silencing duration is determined by a second Observable. Cannot emit more than one values until the second Observable emits a value. throttleTime public throttleTime(duration: number, scheduler: Scheduler): Observable&lt;T&gt; Emits a value from the source Observable, then ignores subsequent source values for duration milliseconds, then repeats this process. Lets a value pass, then ignores source values for the next duration milliseconds. timeInterval public timeInterval(scheduler: *): Observable&lt;TimeInterval&lt;any&gt;&gt; timeout public timeout(due: number, scheduler: Scheduler): Observable&lt;T&gt; timeoutWith public timeoutWith(due: *, withObservable: *, scheduler: Scheduler): Observable&lt;R&gt; timestamp public timestamp(scheduler: *): Observable&lt;Timestamp&lt;&gt;&gt;any toArray public toArray(): Observable&lt;any[]&gt; toPromise public toPromise(PromiseCtor: *): Promise&lt;T&gt; 1Rx.Observable.of(42).toPromise().then(console.log) window public window(windowBoundaries: Observable&lt;any&gt;): Observable&lt;Observable&lt;T&gt;&gt; Branch out the source Observable values as a nested Observable whenever windowBoundaries emits. It’s like buffer, but emits a nested Observable instead of an array. 123let clicks = Rx.Observable.fromEvent(document, 'click')let interval = Rx.Observable.interval(1000)clicks.window(interval) windowCount public windowCount(windowSize: number, startWindowEvery: number): Observable&lt;Observable&lt;T&gt;&gt; Branch out the source Observable values as a nested Observable with each nested Observable emitting at most windowSize values. It’s like bufferCount, but emits a nested Observable instead of an array. windowToggle public windowToggle(openings: Observable&lt;O&gt;, closingSelectors: function(value: O): Observable): Observable&lt;Observable&lt;T&gt;&gt; Branch out the source Observable values as a nested Observable starting from an emission from openings and ending when the output of closingSelector windowWhen(closingSelector: function(): Observable): Observable","link":"/2017/09/25/Methods-of-Observable/"},{"title":"More Faster React Functional Component","text":"Original An basic Avatar Component: 12345class Avatar extends React.Component { render () { return &lt;img src={this.props.url} /&gt; }} And its functional component style is: 1const Avatar = ({ url }) =&gt; &lt;img src={url} /&gt; As you can see, it’s just a simple js function returning an element. React still does a lot of stuff on functional components that, by nature, will never be used. But we can skip React internals for these functional component. They are just plain JavaScritp functions, which means we can call it in the render function. 1234567ReactDOM.render( &lt;div&gt; {Avatar({ url: avatarUrl })} &lt;div&gt;{commentBody}&lt;/div&gt; &lt;/div&gt;, mountNode,) As we know, the traditional usage: 1&lt;Avatar url={avatarUrl} /&gt; will be compiled into 1React.createElement(Avatar, { url: avatarUrl }) It will cost a lifecycle of a React Component. But with direct calling of plain JavaScritp Function, all these consumption can be eliminated. By the way, transform-react-inline-elements does the same as a bebel transform, so there’s no need to change the source code.","link":"/2017/05/21/More-Faster-React-Functional-Component/"},{"title":"Model Generator of Rails","text":"Original Basic Usage1rails g model User email This command will generate user model with email field type of string, migration which creates user table, test for model and factory. If you want to have model with different type of string pass type after field name following by :. The whole list of available types: 123456789101112integerprimary_keydecimalfloatbooleanbinarystringtextdatetimedatetimetimestamp You are able to pass -option parameter to generator. It will inherit generating class from passed name to achieve STI(Single Table Inheritance): 1rails g model admin --parent user This example generates model: 12class Admin &lt; Userend Interesting fact that if you generate model in some scope passing model like admin/user of Admin::User: 1rails g model admin/user you will get generated model in scope app/models/admin/user.rb, defined scope app/models/admin.rb which is required to define module. 12345module Admin def self.table_name_prefix 'admin_' endend It means that generated table name for Admin::User starts with prefix _adminuser. This feature allows to have seperated namespaced models as in rails code as in db schema. Advantage useageSometimes you have to automatically add index for columns in your migration. It’s not a problem. 1rails g model user email:index location_id:integer:index Or uniq index 1rails g model user pseudo:string:uniq Set limit for field of integer, string, text and binary fields 1rails g model product 'price:decimal{10,2}' The last useful feature of generators - it’s options to generate reference columns (fields which are used in rails as foreign_key) 1rails g model photo album:references This command will generate photos table with integer field _albumid and also it will add index for this field automatically. 1234567891011class CreatePhotos &lt; ActiveRecord::Migration def change create_table :photos do |t| t.references :album t.timestamps end add_index :photos, :album_id endend","link":"/2018/03/14/Model-Generator-of-Rails/"},{"title":"Node.js Child_process","text":"Node.js runs in single-threaded, event-driven mode, which is good for improving performance via multiple child process. Each child process has three stream objects: child.stdin child.stdout child.stderr All these three stream objects may share their parent’s stdio, or set to use their own stream object independently. Node.js offers child_process module to create new child process: exec – child_process.exec use child process to execute shell command, and buffer the output for callback. This means the exec will buffer the whole returned value in buffer, usually you should limit the buffer in 200k, if not, the process will exit with Error: maxBuffer exceeded. spawn – child_process.spawn use command line to create new process. spawn will return a stream object with stdout and stderr. We can use stdout stream to read the data returned from child process. stdout has event handles like data, end. You can use spawn when a large data will returned from child process. fork – child_process.fork is the spawn in special mode(specify node to run the command). fork('./son.js') equals to spawn('node', ['./son.js']). Different from spawn, fork will build a message pipe between main and child process. exec1234567891011const exec = require('child_process').execexec('dir', {encoding: 'utf-u'}, function(err, stdout, stderr) { if (err) { console.log(err.stack) console.log('Error Code: ' + err.code) console.log('Signal Received: ' + err.signal) } console.log('data: ' + stdout)}).on('exit', function (code) { console.log('child process exit with code: ' + code)}) spawn1234567891011121314151617181920212223const spawn = require('child_process').spawnconst spawnedProcess = spawn('ping', ['127.0.0.1'], { encoding: 'utf-8'})spawnedProcess.stdout.on('data', function (chunk) { console.log(chunk.toString())})spawnedProcess.stderr.on('data', function (data) { console.log(data)})spawnedProcess.on('close', function (code) { console.log('close code: ' + code)})spawnedProcess.on('exit', function (code) { console.log('exit code: ' + code) fs.close(fd, function(err) { if (err) { console.error(err) } })}) fork123456789101112131415161718192021// parent.jsconsole.log('parent pid: ' + process.pid)const fork = require('child_process').forkconst child = fork('./child.js')console.log('fork return pid: ' + child.pid)child.on('message', function (msg) { console.log('parent recieve message: ' + JSON.stringify(msg))})child.send({ key: 'parent value',})// child.jsconsole.log('child pid: ' + process.pid)process.on('message', function (msg) { console.log('child recieve message: ' + msg)})process.send({ key: 'child value',})","link":"/2017/08/24/Node-js-child-process/"},{"title":"Note on GraphQL(1)","text":"GraphQL is a query language for your API, and a server-side runtime for executing queries by using a type system you define for your data. A GraphQL service is created by defining types and fields on those types, then providing functions for each field on each type. 12345678type Query { me: User}type User { id: ID name: String} Along with functions for each field on each type: 1234567function Query_me(request) { return request.auth.user;}function User_name(user) { return user.getName()} Once a GraphQL service is running (typically at a URL on a web service), it can be sent GraphQL queries to validate and execute. A received query is first checked to ensure it only refers to the types and fields defined, then runs the provided functions to produce a result. For example the query: 1234567891011{ me { name }}// produce{ \"me\": { \"name\": \"Luck\" }} FieldsGraphQL is about asking for specific fields on objects. GraphQL queries can traverse related objects and their fields, letting clients fetch lots of related data in one request, instead of making several roundtrips as one would need in a classic RESTFul architecture. ArgumentsIn GraphQL, every field and nested object can get its own set of arguments, making GraphQL a complete replacement for making multiple API fetches. You can even pass arguments into scalar fields, to implement data transformations once on the server, instead of on every separately. 123456{ human(id: '1000') { name height(uint: FOOT) }} Arguments can be of many different types. GraphQL comes with a default set of types, but a GraphQL server can also declare its own custom types, as long as they can be serialized into your transport format. AliasesYou can’t directly query for the same field with different arguments, so you need alias to rename the result 12345678910111213141516171819{ empireHero: hero(episode: EMPIRE) { name } jediHero: hero(episode: JEDI) { name }}// produce{ \"data\": { \"empireHero\": { \"name\": \"...\" }, \"jediHero\": { \"name\": \"...\" } }} In the above example, the two hero fields would have conflicted, but since we can alias them to different names, we can get both results in one request. FragmentsGraphQL includes reusable units called fragments. Fragments let you construct sets of fields, and then include them in queries where you need to. 12345678910111213141516{ leftComparison: hero(episode: EMPIRE) { ...comparisonFields } rightComparison: hero(episode: JEDI) { ...comparisonFields }}fragment comparisonFields on Character { name appearsIn friends { name }} VariablesWhen we start working with variables, we need to do three things: Replace the static values in the query with $variableName Declare $variableName as one of the variables accepted by the query Pass variableName: value in the separate, transport-specific(usually JSON) variables dictionary 12345678910111213query HeroNameAndFriends($episode: Episode) { hero(episode: $episode) { name friends { name } }}// Variables{ 'episode': 'JEDI',} Now in our client code, we can simply pass a different variable rather than needing to construct an entirely new query. Variable DefinitionsThe variable definitions are the part that looks like ($episode: Episode) in the query above. It works just like the argument definition for a function in a types language. It lists all of the variables, prefixed by $, followed by their type, in this case Episode. All declared variables must be either scalars, enums, or input object types. Variable Definition can be optional or required. In the case above, since there isn’t an ! next to the Episode type, it’s optional. But if the field you are passing the variable into requires a non-null argument, then the variable must be required. Default VariablesDefault variables can also be assigned to the variables in the query by adding the default value after the type declaration. 12345678query HeroNameAndFriends($episode: Episode = 'JEDI') { hero(episode: $episode) { name friends { name } }} Directives12345678910111213query Hero($episode: Episode, $withFriends: Boolean!) { hero(episode: $episode) { name friends @include(if: $withFriends) { name } }}// variables{ \"episode\": \"JEDI\", \"withFriends\": false,} We needed to use a new feature in GraphQL called directive. A directive can be attached to a field or fragment inclusion, and can affect execution of the query in any way the server desires. The core GraphQL specification includes exactly two directives, which must be supported by any spec-compliant GraphQL server implementation: @include(if: Boolean): Only include this field in the result if the argument is true @skip(if: Boolean): Skip this field if the argument is true MutationsIf mutation field returns an object type, you can ask for nested fields. This can be useful for fetching the new state of an object after an update. 1234567891011121314mutation CreateReviewForEpisode ($ep: Episode!, $review: ReviewInput!) { createReview(episode: $ep, review: $Review) { stars commentary }}// Variables{ \"ep\": \"JEDI\", \"review\": { \"star\": 5, \"commentary\": \"This is a great movie\" }} Here the createReview returns the star and commentary fields of the newly created review. Multiple fields in mutationsA mutation can contain multiple fields, just like a query. There’s one important distinction between queries and mutations, other than the name. While query fields are executed in parallel, mutation fields run in series, one after the other. This means that if we send two incrementCredits mutations in one request, the first is guaranteed to finished before the second begins, ensuring that we don’t end up with a race condition with ourselves. Inline FragmentsGraphQL include the ability to define interfaces and union types. If you are querying a field that returns an interface or a union type, you will need to use inline fragments to access data on the underlaying concrete type. 123456789101112131415161718192021222324query HeroForEpisode ($ep: Episode!) { hero (episode: $ep) { name ... on Droid { primaryFunction } ... on Human { height } }}// Variables{ \"\u0006ep\": \"JEDI\"}// produce{ \"data\": { \"hero\": { \"name\": \"...\", \"primaryFunction\": \"...\" } }} In this query, the hero field returns the type Character, which might be either a Human or a Droid depending on the episode argument. In the direct selection, you can ask for fields that exists on the Character interface such as name. To ask for a field on the concrete type, you need to use a inline fragment with a type condition. Because the first fragment is labeled as ... on Droid, the primaryFunction field will only be executed if the Character returned from hero is of the Droid type. Named fragments can also be used in the same way, since a named fragment always has a type attached. Meta fieldsGiven that there are some situations where you don’t know what type you will get back from the GraphQL service, you need some way to determine how to handle that data on the client. GraphQL allows you to request __typename, a meta field, at any point in a query to get the name of the object type at that point. 12345678910111213141516171819202122232425262728293031{ search(text: \"an\") { __typename ... on Human { name } ... on Droid { name } ... on Starship { name } }}// produce{ \"data\": { \"search\": [ { \"__typename\": \"Human\", \"name\": \"Han\", }, { \"__typename\": \"Human\", \"name\": \"ELX\", }, { \"__typename\": \"Starship\", \"name\": \"TIE\" } ] }} In the above query, search returns a union type that can be one of three options. It would be impossible to tell apart the different types from the client without the __typename field. Schemas and TypesType SystemGraphQL query language is basically about selecting fields on objects. 123456{ hero { name appearsIn }} We start with a special ‘root’ object We select the hero field on that For the object returned by hero, we select the name and appearsIn fields Object Types and FieldsThe most basic components of a GraphQL schema are object types, which just represent a kind of object you can fetch from your service, and what fields it has. In the GraphQL schema language, we might represent it like this: 1234type Character { name: String! appearsIn: [Episode]!} Character is a GraphQL Type, meaning it’s a type with some fields. Most of the types in your schema will be object types. name and appearsIn are fields on the Character type. That means that name and appearsIn are the only fields that can appear in any part of a GraphQL query that operates on the Character type. String is one of the built-in scalar types String! means that the field is non-nullable, meaning that the GraphQL service promises to always give you a value when you query this field. [Episode]! represents an array of Episode objects. Since it is also non-nullable, you can always expect an array ( with zero or more items) when you query the appearsIn field. ArgumentsEvery field on a GraphQL object type can have zero or more arguments, for example the length field below: 12345type Starship { id: ID! name: String! length(uint: LengthUint = METER): Float} All arguments are named. The Query and Mutation TypesMost types in schema will just be normal object types, but there are two types that are special within a schema: 1234schema { query: Query mutation: Mutation} Every GraphQL service has a query type and may not have a mutation type. These types are the same as a regular object type, but they are special because they define the entry point of every GraphQL query. 12345678query { hero { name } droid(id: '2000') { name }} That means that the GraphQL service needs to have a Query type with hero and droid fields: 1234type Query { hero(episode: Episode): Character droid(id: ID!): Droid} Mutations work in a similar way - you define fields on the Mutation type, and those are available as the root mutation fields you can call in your query. Scalar Types Int: A signed 32-bit integer Float: A signed double-precision floating-point value String: A UTF-8 character sequence Boolean: true or false ID: The ID Scalar type represents a unique identifier, often used to refetch an object or as the key for a cache. The ID types serialized in the same way as a String; However, defining it as an ID signifies that it is not intended to be human-readable. In most GraphQL service implementation, there is also a way to specify custom scalar types. 1scalar Date Enumeration TypesAlso called Enums, enumeration types are a special kind of scalar that is restricted to a particular set of allowed values. 12345enum Episode { NEWHOPE EMPIRE JEDI} This means that wherever we use the type Episode in our schema, we expect it to be exactly one of NEWHOPE, EMPIRE, JEDI. Lists and Non-NullObject types, scalars, and enums are the only kinds of types you can define in GraphQL, but when you use the types in other parts of the schema, or in your query variable declarations, you can apply additional type modifier that affects validation of those values. InterfacesAn Interface is an abstract type that includes a certain set of fields that a type must include to implement the interface. 12345678910111213141516171819202122232425// defineinterface Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]!}// implementtype Human implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int}type Droid implements Character { id: ID! name: String! friends: [Character] appearsId: [Episode]! primaryFunction: String} Union TypesUnion Types are similar to interfaces, but they don’t get to specify any common fields between the types. 1union SearchResult = Human | Droid | Starship Input TypesIn GraphQL schema language, input types look exactly the same as regular object types, but with the keyword input instead of type: 1234input ReviewInput { stars: Int! commentary: String} 123456789101112131415mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) { createReview(episode: $ep, review: $review) { stars commentary }}// Variables{ \"ep\": \"JEDI\", \"review\": { \"stars\": 5, \"commentary\": \"Commentary\" }}","link":"/2017/08/03/Note-on-GraphQL-1/"},{"title":"Note(2) on TS2 of edX","text":"ModulesModules are used for code organization as well as code sharing. Modules are executed within their own scope, not in the global scope. This means that variables, functions, classes, etc. declared in a module are not visible outside the module unless they are explicitly exported using export. Conversely, to consume a variable, function, class, interface, etc. exported from a different module, it has to be imported using import. Modules are declarative. In TypeScript any file containing a top-level import or export is considered a module. ExportExporting a declaration. Any declaration(such as variable, function, class, type alias, or interface) can be exported by adding the export keyword. A module can wrap one or more modules and combine all their exports using export * from syntax. 1234// allValidator.tsexport * from './StringValidator'export * from './LetterOnlyValidator'export * from './ZipCodeValidator' Import can be renamed. 1import { ZipCodeValidator as ZCV } from './ZipCodeValidator' Default exportsEach module can optionally export a default export. Default exports are marked with the keyword default, and there can only be one default export per module. 123456// jQuery.tsdeclare let $: Jquery;export default $;// App.tsimport $ from 'jQuery' Declaration FilesDeclarations are used to describe code that exists elsewhere using the declare keyword. The goad of this is to be able to use this code in TypeScript applications without having to rewrite the code in TypeScript. 12declare var mynumber: any;mynumber = 300; // ok You can save these declaration in a .ts file or in a .d.ts file, we call these file with .d.ts extension declaration files. It’s good practice to keep your declarations in separate .d.ts file. If a file has the extension .d.ts then each root level definition must have the declare keyword prefixed to it. This tells the developer that there will be no code emitted by TypeScript. The developer needs to ensure that the declared item will exist at runtime. For example, lets assume we have the following JavaScript code(message.js) 123function showMessage (message) { alert(message)} If you want to call the showMessage function in your TypeScript code, TypeScript will not recognize that this function exists. It does not know its name or its parameter. This can be fixed by describing the showMessage function in a definition file as (message.d.ts): 1declare function showMessage(message: string) Now you can use the function showMessage in TypeScript without compile errors. .d.ts files and .ts filesAnything allowed in a .d.ts file mayu also appear in a .ts file, but not the reverse. Therefore, .d.ts allows a subset of TypeScript features. A .d.ts file is only allowed to contain TypeScript code that doesn’t generate any JavaSAcript code in the output. If you attempt to use any feature of TypeScript that would generate JavaScript, you’ll get an error. Interfaces are allowed, because they disappear completely after compilation. Const enums are also allowed, unlike ordinary enums which generate an object in the output JavaScript. Top level classes, variables, modules, and functions must be prefixed with declare. It is a common practice to see a top-lvel declare module and then all definition inside it are therefore also declaraion. 123declare module Something { var x;} Working with other JavaScript Libraries.To describe the shape of libraries not written in TypeScript, we need to declare the API that the library exposes. We call declarations that don’t define an implementation ‘ambient’. Typically these are defined in .d.ts files. Ambient ModulesWe can define each module in its own .d.ts file with top-level export declarations, but it’s more convenient to write them as one large .d.ts file. To do so, we use a construct similar to ambient namespaces, but we use the module keyword and the quoted name of the module which will be available to a later import. 12345678910111213141516// node.d.tsdeclare module &apos;url&apos; { export interface Url { protocol?: string; hostname?: string; pathname?: string; } export function parse (urlStr: string, parseQueryString?, slashesDenotateHost?): Url}declare module &apos;path&apos; { export function normalize(p: string): string; export function join(...paths: any[]): string; export var sep: string;} Now we can use /// &lt;reference&gt;node.d.ts and then load the modules using import url = require('url') or import * as URL from 'url' 123/// &lt;reference path='node.d.ts' /&gt;import * as URL from 'url'let myUrl = URL.parse('http://www.typescriptlang.org') Module ResolutionRelative vs Non-relative module importsModule imports are resolved differently based on whether the module reference is relative or non-relative. A relative import is one that starts with /, ./, ../. Any other import is considered non-relative. 12import * as $ from 'jquery'import { Component } from '@angular/core' A relative import is resolved relative to the importing file and cannot resolve to an ambient module declaration. A non-relative import can be resolved relative to baseUrl, or through path mapping. They can also resolve to ambient module declaations. Module Resolution StrategiesThere are two possible module resolution strategies: Node and Classic. You can use the --moduleResolution flag to specify the module resolution strategy. If not specified, the default is Classic for --module AMD | System | ES2015 | Node. Modules or NamespacesNamespaces vs ModulesIf fact, namespaces were previously refered to as internal modules while modules where refered to as external modules. When to use namespaces and when to use moduels When first moving to a module-based organization, a common tendency is to wrap exports in an additional layer of namespaces. Modules have their own scope, and only exported declaration are visible from outside the module. With this in mind, namespaces provide very little, if any, value when working with modules. On the oraganization front, namespaces are handy for grouping together logically-related objects and types in the global. Namespaces are important to avoid naming collisions in the scope. Reg FlagsDont’t use namespace in modules All of the following are reg flags for module structuring. A file whose only top-level declaration is export namespace Foo { ... }(remove Foo and move everything ‘up’ a level.) A file that has a single export class or export function(consider using export default) Multiple files that have the same export namespace Foo at top-level(don’t think that these are going to combine into one). Best Practice While namespaces are still available in TypeScript, it is better to use modules as much as possible. This is because in most cases you will need to use external libraries in your application. In that case you will have to deal with modules because modules are the way to go with external none TypeScript libraries. Mixing namespaces and modules in one application is not a recommended practice. Use modules and not namespaces if you are going to share your code as components or libraries to be consumed by other applications. Use namespaces if your application is small and within the same application and when you do have any external dependencies like using external libraries or offering your code to be used by other application. You can still use modules in this case. Working with External LibrariesImporting a JavaScript Library. There are two options to bring a javascript library in your typescrpt project: Manual download: this is by manually copying some definitions files for the obejcts used in the JavaScript Libraries into your TypeScript Project so that TypeScript can recognize and be able to support the typings. There is a big effort form the TypeScript community to provide those declaration files for almost all the third party JavaScript Libraries out there for developers to copy and include in their projects without having to rewrite the types themselves. This project is called the definitely typed project. Using TyepSearch: This will automatically install the definition files for the imported libraries. The TypeSearch project that is a Microsoft initiative that uses npm to install lthe library definition files automatically with no need to manually copy any files. Combine two namespaces with same identifier12345678910// extendedNamespace_part2.d.tsnamespace ArrayUtilities { // ...}// extendedNamespace_part1.d.ts/// &lt;reference path=\"extendedNamespace_part2.d.t.s\" /&gt;namespace ArrayUtilities { // ...}","link":"/2017/08/15/Note-2-on-TS2-of-edX/"},{"title":"Note on Sequelize","text":"Sequelize is a promise-based ORM for Node. Example12345678910111213141516const Sequelize = require('sequelize')const sequelize = new Sequeslize('database', 'username', 'password')const User = sequelize.define('user', { username: Sequelize.STRING, birthday: Sequelize.DATE,})sequelize.sync().then(() =&gt; { User.create({ username: 'Jane', birthday: new Date(1980, 5, 2), })}).then(jane =&gt; { console.log('create successfully')}) StartInstallation123456yarn add sequelize# add one of the following:yarn add pg pg-hstoreyarn add mysql2yarn add sqlite3yarn add tedious // MSSQL Setup a connectionSequelize will setup a connection pool on initialization so you should ideally only ever create one instance per database if you’re connecting to the DB from a single process. If you’re connecting to the DB from multiple processes, you’ll have to create one instance per process, but each instance should have a maximum connection pool size of “max connection pool size divided by number of instances”. So, if you wanted a max connection pool size of 90 and you have 3 worker process, each process’s instance should have a max connection pool size of 30. 12345678910111213const Conn = new Sequelize('database', 'username', 'password', { host: 'localhost', dialect: 'mysql'|'sqlite'|'postgres'|'mssql', pool: { max: 5, min: 0, idle: 10000, }, storage: 'path/to/database.sqlite',})// or you can simply use a connection uriconst Conn = new Sequelize('postgres://user:pass@example.com:5432/dbname') Test the connectionYou can use the .authenticate() function like this to test the connection. 12345Conn.authenticate().then(() =&gt; { console.log('Connection has been established successfully')}).catch(e =&gt; { console.error('Unable to connect to the database: ', e)}) ModelModels are defined with Conn.define('name', {attributes}, {options}) 1234567891011121314151617const User = Conn.define('user', { firstName: { type: Sequelize.STRING, }, lastName: { type: Sequelize.STRING, }})// force: true will drop the table if it already existsUser.sync({ force: true }).then(() =&gt; { // Table created return User.create({ firstName: 'John', lastName: 'Hank', })}) Query123User.findAll().then(users =&gt; { console.log(users)}) Application wide model optionsThe Sequelize constructor takes a define option which will be used as the default options for all defined models. 12345678910const Conn = new Sequelize('connectionUri', { define: { timestamps: false, // true by default }})const User = Conn.define('user', {}) // timestamps is false by defaultconst Post = Conn.define('post', {}, { timestamps: true,}) PromisesSequelize uses promises to control async control-flow. Basically, a promise represents a value which will be present at some point. 12user = await User.fineOne()console.log(user) Model DefinitionTo define mapping between a model and a table, use the define method. Sequelize will then automatically add the attributes createdAt and updatedAt to it. So you will be able to know when the database entry went into the db and when it was updated the last time. 12345678910const Project = Conn.define('project', { title: Sequelize.STRING, description: Sequelize.TEXT,})const Task = Conn.define('tastk', { title: Sequelize.STRING, description: Sequelize.TEXT, deadline: Sequelize.DATE,}) You can also set some options on each column: 123456789101112131415161718192021222324252627282930const Foo = Conn.define('foo', { // instantiating will automatically set the flat to true if not set flag: { type: Sequelize.BOOLEAN, allowNull: false, defaultValue: true, }, myDate: { type: Sequelize.DATE, defaultValue: Sequelize.NOW, }, title: { type: Sequelize.STRING, allowNull: false, }, uniqueOne: { type: Sequelize.STRING, unique: 'compositeIndex', }, uniqueTwo: { type: Sequelize.INTEGER, unique: 'compositeIndex', }, foo: { type: Sequelize.STRING, validate: { isEmail: true, } }}) ConfigurationYou can also influence the way Sequelize hadnles your column names: 12345678910111213141516const Bar = Conn.define('bar', { /* ... */}, { // don't add the timestamp attributes(updatedAt, createdAt) timestamps: false, // don't delete database entries but set the newly added attribute deletedAt to the current data(when deletion was done) paranoid: true, // don't use camelcase for automatically added attributes but underscore style so updatedAt will be udpated_at underscore: true, // disable the modification of table names; by default, sequelize will automatically transform all passes model names(first parameter of define) into plural. If you don't want that, set the following freezeTableName: true, // define the table's name tableName: 'my_very_custom_table_name', // Enable optimistic locking. When enabled, sequelize will add a version count attribute to the model and throw an OptimisticLockingError error when stale instances are saved. version: true,}) ImportYou can also store your model definitions in a single file using the import method. The returned object is exactly the same as defined in the imported file’s function. 12345678910// in your server fileconst Project = Conn.import(__dirname, \"/path/to/models/project\")// The model definition filemodule.exports = (Conn, DataType) =&gt; { return Conn.define('project', { name: DataTypes.STRING, description: DataTypes.TEXT, })} The import method can also accept a callback as an argument 123456Conn.import('project', (Conn, DataTypes) =&gt; { return Conn.define('project', { name: DataTypes.STRING, description: DataTypes.TEXT, })}) Database SynchronizationWhen starting a new project you won’t have a database structure and using sequelize you won’t need to. Just specify your model structures and let the library do the rest. Currently supported is the creation and deletion of tables. 1234567891011121314151617// Create the TablesProject.sync()Task.sync()// Force the CreationProject.sync({ force: true }) // this will drop the table first and re-create it afterwards// Drop the TablesProject.drop()Task.drop()// Event HandlingProject.[sync|drop]().then(() =&gt; { // ok ... everything is nice}).catch(err =&gt; { // ooh, did you enter wrong database credentials}) Because synchronizing and dropping all of your tables might be a lot of lines to write, you can also let Sequelize do the work for you: 123456789101112131415// sync all models that aren't already in the databaseConn.sync()// Force sync all modelsConn.sync({ force: true })// Drop all TablesConn.drop()// Emit HandlingConn.[sync|drop]().then(() =&gt; { // ...}).catch(err =&gt; { // ...}) Expansion of modelsSequelize Models are ES6 classes, you can very easily add custom instance or class level methods. 12345678910111213const User = Conn.define('user', { firstName: Sequelize.STRING,})// add a class level methodUser.classLevelMethod = function () { retunr 'foo'}// add an instance level methodUser.prototype.instanceLevelMethod = function () { retunr 'bar'} IndexesSequelize supports adding indexes to the model definition which will be created during Model.sync() or Conn.sync() 123456789101112131415161718192021222324Conn.define('user', {}, { indexes: [ // Create a unique index on poem { unique: true, fields: ['poen'] }, // create a gin index on data with the jsonb_path_ops operator { fields: ['data'], using: 'gin', operator: 'jsonb_path_ops', }, // by default index name will be [table]_[fields] // create a multi column partial index { name: 'public_by_author', fields: ['author', 'status'], where: { status: 'public' } } ]}) Model UsageData Retrieval / FindersFinder methods are intended to query data from the database. They do not return plain objects but instead return model instances. Because finder methods return model instances you can call any model instance member. find - search for one specific element in the database1234567891011121314151617181920212223// search for known idProject.findById(123).then(project =&gt; { // project will be an instance of Project and store the content of the table entry with id 123. If such an entry is not defined you will get null})// search for attributesProject.findOne({ where: { title: 'aProject' }}).then(project =&gt; { // project will be the first entry of the Projects table with the title 'aProject' || null})Project.findONe({ where: { title: 'aProject', }, attributes: ['id', ['name', 'title']]}).then(project =&gt; { // project will be the first entry of the Projects table with the title 'aProject' || null // project.title will contain the name of the project}) findOrCreate - Search for a specific element or create it if not availableThe method findOrCreate can be used to check if a certain element already exists in the database. If that is the case the method will result in a respective instance, if the element does not yet exists, it will be created. Let’s assume we have an empty database with a User model which has a username and a job 1234567891011121314151617181920212223User.findOrCreate({ where: { username: 'sdepold', }, defaults: { job: \"Technical Lead JS\", }}).spread((user, created) =&gt; { console.log(user.get({ plain: true, })) /** * findOrCreate returns an array containing the object that was found or created and a boolean will be true if a new object was created, and false if not [ { username: 'sdepold', job: 'Technical Lead JavaScript', id: 1, createdAt: Fri Mar 22 2013 21: 28: 34 GMT + 0100(CET), updatedAt: Fri Mar 22 2013 21: 28: 34 GMT + 0100(CET) }, true ] */}) The code created a new instance. fineAndCountAll - Search for multiple elements in the database, returns both data and total countfindAll - Search for multiple elements in the database12345678910111213141516171819202122232425// find multiple entriesProject.findAll().then(projects =&gt; { // projects will be an array of all Project instances})// also possibleProject.all().then(projects =&gt; { // projects will be an array of all Project instances})// search for specific attribute - hash usageProject.findAll({ where: { name: 'A Project', }}).then(projects =&gt; { // ...})// search within a specific rangeProject.findAll({ where: { id: [1, 2, 3], }}).then(projects =&gt; { // return instances with id 1, 2, 3}) Complex filtering /OR/NOT queries123456789101112131415161718192021Project.findAll({ where: { name: 'a project', $or: [ { id: [1, 2, 3] }, { id: { $gt: 10 }}, ] }})Project.findAll({ where: { name: 'a project', id: { $or: [ [ 1, 2, 3], { $gt: 10 }, ] } }}) Both pieces of code will generate the following: 1234SELECT * FROM `Projects` WHERE ( `Projects`.`name`=`a project` AND (`Projects`.`id` IN (1,2,3) OR `Projects`.`id`&gt;10) ) Manipulating the database with limit, offset, order and group12345678// limit the results of the queryProject.findAll({ limit: 10 })// step over the first 10 elementsProject.findAll({ offset: 10 })// step over the first 10 element and take 2Project.findAll({ offset: 10, limit: 2 }) The syntax for grouping and ordering are equal, so below it is only explained with a single example for group, and the rest for order. 12345// yields ORDER BY title DESCProject.findAll({ order: 'title DESC' })// yields GROUP BY nameProject.findAll({ group: 'name' }) Raw queriesSometimes you might be expecting a massive dataset that you just want to display without manipulation. For each row you select, Sequelize creates an instance with functions for update, delete, get association etc. If you have thousands of rows, this might take some time. If you only need the raw data and don’t want to update anything, you can do like this to get the raw data. 1234567// Are you expecting a massive dataset from the DB, and don't want to spend the time building DAOs for each entry? You can pass an extra query option to get the raw data insetead:Project.findAll({ where: { // ... }, raw: true,}) QueriesAttributesTo select only some attributes, you can use the attributes option. Most often, you pass an array: 12345Model.findAll({ attributes: ['foo', 'bar']})// Equal toSELECT foo, bar ... WhereWhether you are querying with findAll/find or doing bulk updates/destroy you can pass a where object to filte the query. where generally takes an object from attribute:value pairs, where value can be primitive for equality matches or keyed objects for other operators. It’s also possible to generate complex AND/\u0006OR conditions by nesting of $or and $and Basics","link":"/2017/08/07/Note-on-Sequelize/"},{"title":"Note on GraphQL(2)","text":"ExecutionAfter being validated, a GraphQL query is executed by a GraphQL server which returns a result that mirrors the shape of the requested query, typically as JSON. GraphQL cannot execute a query without a type system, let’s use an example type system to illustrate executing a query. 12345678910111213141516171819type Query { human(id: ID!): Human}type Human { name: String appearsIn: [Episode] starships: [Starship]}enum Episode { NEWHOPE EMPIRE JEDI}type Starship { name: String} In order to describe what happens when a query is executed, let’s use an example to walk through. 123456789{ human(id: 1002) { name appearsIn starships { name } }} 1234567891011121314151617181920{ \"data\": { \"human\": { \"name\": \"Han Solo\", \"appearsIn\": [ \"NEWHOPE\", \"EMPIRE\", \"JEDI\" ], \"starships\": [ { \"name\": \"Millenium Falcon\" }, { \"name\": \"Imperial shuttle\" } ] } }} You can think of each field in a GraphQL query as a function or method of the previous type which returns the next type. Exactly this is how GraphQL works. Each field on each type is backed by a function called the resolver which is provided by the GraphQL Server Developer. When a field is executed, the corresponding resolver is called to produce the next value. If a field produces a scalar value like a string or number, then the execution completes. However if a field produces an object value then the query will contain another selection of fields which apply to that object. This continues until scalar values are reached. GraphQL queries always end at scalar values. Root Fields &amp; ResolversAt the top level of every GraphQL server is a type that represents all of the possible entry points into the GraphQL API, it’s often called the Root \u0006Type or the Query Type. In this example, our Query Type provides a field called human which accepts the argument id. The resolver function for this field accesses a database and then constructs and returns a Human object. 1234567Query: { human(obj, args, context) { return context.db.loadHumanById(args.id).then( userData =&gt; new Human(userData) ) }} obj The previous object, which for a field on the root Query type if often not used. args The arguments provided to the field in the GraphQL query context A value which is provided to every resolver and holds important contextual information like the currently logged in user, or access to a database. Asynchronous Resolvers12345human(obj, arg, context) { return context.db.loadHumanById(args.id).then( userData =&gt; new Human(userData) )} The context is used to provide access to a database which is used to load data for user by the id provided as an argument in the GraphQL query. Since loading from a database is an asynchronous operation, this returns a Promise. When the database returns, we can construct and return a new Human object. Notice that while the resolver function needs to be aware of Promise, the GraphQL query does not. It simply expects the human field to return something which it can then ask the name of. During execution, GraphQL will wait for Promise to complete before continuing and will do so with optimal concurrency. Trivial ResolversNow that a Human object is available, GraphQL execution can continue with the fields requested on it. 12345Human: { name(obj, args, context) { return obj.name }} A GraphQL server is powered by a type system which is used to determine what to do next. Even before the human field returns anything, GraphQL knows that the next stop will be to resolve fields on the Human type since the type system tells it that the human field will return a Human. Resolving the name in this case is very straight-forward. The name resolver function is called and the obj argument is the new Human object return from the previous field. In this case, we expect that Human object to have a nameproperty which we can read and return directly. Scalar CoercionWhile the name field is being resolved, the appearsIn and starships fields can be resolved concurrently. The appearsIn field could also have a trivial resolver, but let’s take a closer look: 12345Human: { appearsIn(obj) { return obj.appearsIn // return [3, 4, 5] }} Notice that our type system claims appearsIn will return Enum values with known values, however this function is returning numbers. This is an example of scalar coercion. The type system knows what to expect and will convert the values returned by a resolver function into something that upholds the API contract. In this case, there may be an Enum defined on our server which uses numbers like 3, 4, 5 internally, but represents them as Enum values in the GraphQL type system. List ResolversThe appearsIn field above returned a list of Enum values, and since that’s what the type system expected, each item in the list was coerced to the appropriate enum values. What happens when the starships field is resolved? 123456789Human: { starships (obj, args, context) { return obj.starshipIDs.map( id =&gt; context.db.loadStarshipByID(id).then( shipData =&gt; new Starship(shipData) ) ) }} The resolver for this field is not just returning a Promise, it’s returning a list of Promises. The Human object has a list of ids of the Starships they piloted, but we need to go load all of those ids to get read Starship objects. GraphQL will wait for all of these Promises concurrently before continuing, and when left with a list of objects, it will concurrently continue yet again to load the name field on each of these items. IntrospectionWe designed the type system, so we know what types are available, but if we didn’t, we can ask GraphQL by querying the __schema field, always available on the root type of a Query. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798{ __schema { types { name } }}// produce{ \"data\": { \"__schema\": { \"types\": [ { \"name\": \"Query\" }, { \"name\": \"Episode\" }, { \"name\": \"Character\" }, { \"name\": \"ID\" }, { \"name\": \"String\" }, { \"name\": \"Int\" }, { \"name\": \"FriendsConnection\" }, { \"name\": \"FriendsEdge\" }, { \"name\": \"PageInfo\" }, { \"name\": \"Boolean\" }, { \"name\": \"Review\" }, { \"name\": \"SearchResult\" }, { \"name\": \"Human\" }, { \"name\": \"LengthUnit\" }, { \"name\": \"Float\" }, { \"name\": \"Starship\" }, { \"name\": \"Droid\" }, { \"name\": \"Mutation\" }, { \"name\": \"ReviewInput\" }, { \"name\": \"__Schema\" }, { \"name\": \"__Type\" }, { \"name\": \"__TypeKind\" }, { \"name\": \"__Field\" }, { \"name\": \"__InputValue\" }, { \"name\": \"__EnumValue\" }, { \"name\": \"__Directive\" }, { \"name\": \"__DirectiveLocation\" } ] } }} Let’s group them: Query, Character, Human, Episode, Droid. These are the ones that we defined in our type system. String, Boolean. These are built-in scalars that the type system provided. __Schema, __Type, __TypeKind, __Field, __InputValue, __EnumValue, __Directive. These are preceded with a double underscore, indicating that they are part of the introspection system.","link":"/2017/08/04/Note-on-GraphQL-2/"},{"title":"Note on TS2 of edX","text":"Classification of types in TypeScriptTypes are classified into two main classes in TypeScript: Basic or Primitive Types boolean number string array: number[], Array&lt;number&gt; tuple: [string, number] enum: enum Color {Red, Green = 2, Blue}, let c : Color = Color.blue null undefined any void: exists purely to indicate the absence of a value, such as in a function with no return value. Complex or Non-Primitive Types classes interface Type AssertionsSometimes you’ll end up in a situation where you’ll know more about a value than TypeScript does. Usually this will happen when you know the type of some entity could be more specific than its current type. 1234let someValue : any = 'this is a string'let strLength : number = (&lt;string&gt;someValue).lengthlet strLength : numner = (someValue as string).length Complex Types in TypeScript Interface Class Types Function Types Indexable Types Classes Excess PropertyIf SquareConfig can have color and width propertes, but could also have any number of other properties, then we could define it like so: 12345interface SquareConfig { color?: string; width?: number; [propName: string]: any;} Class TypesImplementing an interface One of the most common use of interfaces in language like C# and java, that of explicitly enforcing that a class meets a particular contract, is also possible in TypeScript. 1234567891011121314interface ClockInterface { currentTime: Date, setTime(d: Date);}class Clock implements ClockInterface { currentTime: Date; setDate(d: Date) { this.currentTime = d; } constructor (h: number, m: number) { }} Difference between the static and instance sides of classesWhen working with classes and interfaces, it helps to keep in mind that a class has two types: the type of the static side and the type of the instance side. You may notice that if you create an interface with a constructor signature and try to create a class that implements this interface you get an error: This is because when a class implements an interface, only the instance side of the class is checked. Since the constructor sits in the static side, it is not included in this check. Instead, you would need to work with the static side of the class directly. In this example, we define two interfaces, ClockConstructor for the constructor and Clockinterface for the instance methods. 1234567891011interface ClockConstructor { new (hour: number, minute: number): ClockInterface;}interface ClockInterface { tick()}function createClock(ctor: ClockConstructor, hour: number, minute: number): ClockInterface { return new ctor(hour, minute)} Function TypesTo describe a function type with an interface, we give the interface a call signature. This is like a function declaration with only the parameter list and return type given. Each parameter in the parameters list requires both name and type. 123interface SearchFunc { (source: string, subString: string): boolean;} Once defined, we can use this function type interface like we would other interfaces. 12345let mySearch: SearchFuncmySearch = function (source, subString) { let result = source.search(subString) return result &gt; -1} For function types to correctly type-check, the names of the parameters do not need to match. We could have, for example, written the above example like this: 12345let mySearch: SearchFuncmySearch = function (src: string, sub: string): boolean { let result = src.search(sub) return result &gt; -1} Function parameters are checked one at a time, with the type in each corresponding parameter position checked against each other. If you do not want to specify types at all, TypeScript’s contextual typing can infer the argument types since the function value is assigned directly to a variable of type SearchFunc 12345let mySearch: SearchFuncmySearch = function (src, sub) { let result = src.search(sub) return result &gt; -1} Indexable TypesIntexable types have an index signature that describes the types we can use to index into the object, along with the corresponding return types when indexing. 123456interface StringArray { [index: number]: string;}let myArray: StringArray;myArray = ['Bob', 'Fred']; Above we have a StringArray interface that has an index signature. This index signature states that when a StringArray is indexed with a number, it will return a string. There are two types of supported index signature: string an number. It is possible to support both types of indexer, but the type returned from a numeric indexer must be a subtype of the type returned from the string indexer. This is because when indexing witha number, javascript will actually convert that to a string before indexing into a object. Classes1234567891011class Greeter { greeting: string; constructor (message: string) { this.greeting = message } greet () { return \"Hello, \" + this.greeting; }}let greeter = new Greeter('World') This class has three members: a property called greeting, a constructor, and a method greet. In the last line we construct an instance of the Greeter class using new. This calls into the constructor we defined earlier, creating a new object with the Greeter shape, and running the constructor to initialize it. Public, Private, and Protected ModifiersPublic by default. When a member is marked private, it cannot be accessed from outside of its containing class. When comparing types that have private and protected members, TypeScript treats these types differently. For two types to be considered compatible, if one of them has a private member, then the other must have a private member that originated in the same declaration. The protected modifier acts much like the private modifier with the exectpion the members declared protected can also be accessed by instance of deriving classes. A constructor may also be marked protected. This means that the class cannot be instantiated outside of its containing class, but can be extended. 123456789101112131415161718class Person { protected name: string; protected constructor (theName: string) { this.name = theName }}// Employee can extend Personclass Employee extends Person { private department: string; constructor (name: string, department: string) { super(name) this.department = department }}let howard = new Employee('Howard', 'Sales')let john = new Persno('john') // Error, the 'Person' constructor is protceted. You can make properties readonly by using the readonly keyword. Readonly properties must be initilized at their declaration or in the constructor. Parameter PropertesParameter Properties let you create and initialize a member in one place. AccessorsTypeScript supports getter/setters as a way of intercepting accesses to a member of an object. This gives you a way of having finer-grained control over how a member is accessed on each object. 123456789101112131415let passcode = 'secret passcode'class Employee { private _fullName: string; get fullName(): string { return this._fullName } set fullName (newName: string) { if (passcode &amp;&amp; passcode === 'secret passcode') { this._fullName = newName } else { console.log('Error: Unauthorized update of employee') } }} Accessors with a get and no set are automatically inferred to be readonly. Static PropertiesStatic Members of a class are those visible on class itself rather than on the instance. 123456789101112131415class Grid { static origin = {x: 0, y: 0} calculatedDistanceFromOrigin(point: { x:number, y: number }) { let xDist = (point.x - Grid.origin.x) let yDist = (point.y - Grid.origin.y) return Math.sqrt(xDist * xDist + yDist * yDist) / this.scale } constructor (public scale: number) { // ... }}let grid1 = new Grid(1.0)let grid2 = new Grid(5.0) Abstract ClassesAbstract Classes are base classes from which other classes may be derived. They may not be instantiated directly. Unlike an interface, an abstract class may contain implementation details for its members. The abstract keyword is used to define abstract classes as well as abstract methods within an abstract class. 123456abstract class Animal { abstract makeSound(): void; move () : void { console.log {'roaming the earth...'} }} Methods within an abstract class that are marked as abstract do not contain an implementation and must be implemented in derived classes. Abstract methods share a similar syntax to interface methods. Both define the signature of a method without including a method body. However, abstract methods must include the abstract keyword and may optionally include access modifier. 1234567891011121314151617181920212223242526272829abstract class Department { constructor (public name: string) { // ... } printName () : void { console.log('Department name: ' + this.name) } abstract printMeeting (): void // must be implemented in derived classes}class AccountingDepartment extends Department { constructor () { super('Accounting and Auditing') } printMeeting () : void { console.log('The Accounting Department meets each Monday at 10am') } generateReports () : void { console.log('Generating accounting reports...') }}let department: Department; // ok to create a reference to an abstract typedepartment = new Department(); // error: cannot create an instance of an abstract classdepartment = new AccountingDepartment(); // ok to create and assign a non-abstract subclassdepartment.printName()department.printMeeting()department.generateReports() Advanced TechniquesConstructor functionsWhen you declare a class in TypeScript, you are actually creating multiple delcaration at the same time. The first is the type of the instance of the class 12345678910111213class Greeter { greeting: string; constructor (message: string) { this.greeting = message } greet () { return 'Hello, ' + this.message }}let greeter: Greetergreeter = new Greeter('world')console.log(greeter.greet()) Here, when we say let greeter: Greeter we’re using Greeter as the type of instance of the class Greeter. This is almost second nature to programmers from other oo language. We’re also creating another value that we call the constructor function. This is the function that is called when we new up instance of the class. To see what this looks in practice, let’s take a look at the JavaScript created the above example: 1234567891011121314let Greeter = (function () { function Greeter(message) { this.greeting = message } Greeter.prototype.greet = function () { return 'Hello, ' + this.greeting } return Greeter})()let greetergreeter = new Greeter('world')console.log(greeter.greet()) Here let Greeter is going to be assigned the constructor function. When we call new and run this function, we get an instance of the class. The constructor function also contains all of the static members of the class. Another way to think of each class is that there is an instance side and a static side. Using a class as an interfaceAs mentioned above, a class declaration creates two things: a type representing instances of the class, and a constructor function. Because classes creates types, you can use them in the same places you would be able to use interfaces: 1234567891011121314class Point { x: number; y: number;}interface Point3D extends Point { z: number;}let point3d: Point3D = { x: 1, y: 2, z: 3} InheritanceIn TypeScript, we can use common object-orientad pattern. Of course, one of the most fundamental patterns in class-based programming is being able to extend existing classes to create new ones using inheritance. 123456789101112131415161718192021222324252627282930class Animal { name: string; constructor (theName: string) { this.name = theName } move (distanceInMeters: number = 0) { console.log(`${this.name} move ${distanceInMeters}`) }}class Snake extends Animal { constructor (name: string) { super(name) } move (distanceInMeters = 5) { console.log('Slithering...') super.move(distanceInMeters) }}class Horse extends Animal { constructor (name: string) { super(name) } move (distanceInMeters = 45) { console.log('Galloping...') super.move(distanceInMeters) }} Derived classes that contain constructor functions must call super() which will execute the constructor function on the base class. Interfaces Extending ClassesWhen an interface type extends a class type it inherits the memembers of the class but not their implementations. It is as if the interface had declared all of the members of the class without providing an implementation. Interface inherit event the private and protected members of a base class. This means that when you create an interface that extends a class with private or protected memebrs, that interface type can only be implemented by the class or a subclass of it. This is useful when you have a large inheritance hierarchy, but want to specify that you code works iwth only subclasses that have certain properties. The subclasses don’t have to be related besides inheriting from the base class. 1234567891011121314151617181920212223class Control { private state: any;}interface SelectableControl extends Control { select () : void;}class Button extends Control { select () {}}class TextBox extends Control { select () {}}class Image { select () {}}class Location { select () {}} In the above example, SelectableControl contains all of the members of Control, including the private state property. Since state is a private member it is only possible for descendants of Control to implement SelectableControl. This is because only descendants of Control will have a state private member that originates in the same declaration, which is a requirement for private members to be compatible. Within the Control class it is possible to access the state private member through an instance of SelectableControl. Effectively, a SelectableControl acts like a Control that is known to have a select method. The Button and TextBox classes are subtypes of SelectableControl, but Image and Location are not. Type CompatibilityType compatibility in TypeScript is based on structural subtyping. Structural typing is a way of relating types based on solely on their members. This is in contrast with normal typing. 123456789101112interface Named { name: string;}class Person { name: string;}let p: Named;// OK, because of structural typingp = new Person() A basic rule for TypeScript’s structural type system is that x is compatible with y if y has at least the same members as x. 123456789interface Named { name: string;}let x: Named;// y's inferred type is { name: string; location: string; }let y = { name: 'Alice', location: 'Seattle' }x = y Comparing Two FunctionsWhile comparing primitive types and object types is relatively straightforward, the question of what kinds of functions should be considered compatible is a bit more involved. 12345let x = (a: number) =&gt; 0;let y = (b: number, s: string) =&gt; 0;y = x // okx = y // Error To check if x is assignable to y, we first look at the parameter list. Each parameter in x must have a corresponding parameter in y with a compatible type. Note that the name of the parameters are not considered, only their types. In this case, every parameter of x has a corresponding compatible parameter in y, so x is assignable to y. To ensure that every parameter in x can be checked in y. EnumsEnums are compatible with numbers, and numers are compatible with enums. Enum values from different enum types are considered incompatible. ClassesClasses work similarly to object literal types and interfaces with one exception: they have both a static and an instance type. When comparing two objects of a class type, only members of the instance are compared. Static memebrs and constructor do not affect compatibility. 12345678910111213141516171819class Animal { feet: number; constructor (name: string, numFeet: number) { }}class Size { feet: number; constructor (numFeet: number) { }}let a: Animallet s: Sizea = s // oks = a // ok Private and protected members in a class affect their compatibility. When an instance of a class is checked for compatibility, if the target type contains a private member, then the source type must also contain a private member that originated from the same class. Contextual TypeType inference also work in ‘the other direction’ in some cases in TypeScript. This is known as ‘contextual typing’. Contextual typing occurs when the type of an expression is implied by its location. 123window.onmousedown = function (mouseEvent) { console.log(mouseEvent.buton) // &lt;- Error} Functions and function TypesTypeScript functions can be created both as a named function or as an anonymous function. This allows you to choose the most appropriate approach for your application, whether you’re building a list of functions in an API or a one-off function to hand off to another function. 1234567// Named Functionfunction add(x, y) { return x + y}// Anonymouse Functionlet myAdd = function (x, y) { return x + y } Function TypesTyping the function. 123function add(x: number, y: number): number { return x + y} Writing the function type 1let myAdd: (x: number, y: number) =&gt; number = function(x, y) { return x + y } A function’s type has the same two parts: the type of the arguments and the return type. When writing out the whole function type, both parts are required. Context and Scopethis and arrow function. In JavaScript, this is a variable that’s set when a function is called. This makes it a very powerful and flexible feature, but it comes at the cost of always having to know about the context that a function is executing in. 1234567891011let deck = { suits: ['hearts', 'spades', 'clubs', 'diamonds'], cards: Array(52), createCardPicker: function () { return function () { let pickedCard = Math.floor(Math.random() * 52) let pickedSuit = Math.floor(pickedCard / 13) return { suit: this.suits[pickedSuit], card: pickedCard % 13 } } }} Here the function returned by createCardPicker will be called by window 123456789101112let deck { suits: ['hearts', 'spades', 'clubs', 'diamonds'], cards: Array(52), createCardPicker: function () { // NOTE: the line below is now an arrow function, which will capture 'this' when then function is declared. return () =&gt; { let pickedCard = Math.floor(Math.random() * 52) let pickedSuit = Math.floor(pickedCard / 13) return { suit: this.suits[pickedSuit], card: pickedCard % 13 } } }} OverloadsJavaScript is inherently a very dynamic language. It’s not uncommon for a single JavaScript function to return different types of objects based on the shape of the arguments passed in. 12345678910111213let suits = ['hearts', 'spades', 'clubs', 'diamonds']function pickCard(x): any { // Check to see if we're working with an object/array // if so, they gave us the deck and we'll pick the card if (typeof x == 'object') { let pickedCard = Math.floor(Math.random() * x.length) return pickedCard } else if (typeof x === 'number') { let pickedSuit = Math.floor(x / 13) return { suit: suits[pickedSuit], card: x % 13 } }} Here the pickCard function will return two different things based on what the user ahs passed in. Use overloads. 123456789101112let suits = ['hearts', 'spades', 'clubs', 'diamonds']function pickCard(x: { suit: string, card: number }[]): numberfunction pickCard(x: number): { suit: string, card: number }function pickCard(x): any { // Check to see if we're working with an object/array if (typeof x === 'object') { // ... } else if (typeof x === 'number') { // ... }} Note that the function pickCard(x): any is not part of the overload list. NamespacesNamespaces are used as a way to organize the code so that you can keep track of your types and not worry about name collisions with other object. Instead of putting lots of different names into the global namespace, you can wrap up your object into a namespace. The choice of what objects go in what namespaces is totally up to your organization preference. If you want the interfaces and classes in your namespaces to be visible outside the namespace, you need to preface their declaration with export keyword. Also keep in mind that classes, interfaces and variable names within a namespace has to be unique. Multi-file namespacesYou can split a namespace across many files, even though the fiels a separate, they can each contribute to the same namespace and can be consumed as if they were all defined in one place. Because there are dependencies between files. you will add reference tags to tell the compiler about the relationship between the files. 1234567891011121314151617181920212223242526272829303132// ZooAnimals.tsnamespace Zoo { interface Animal { //NOTE: we do not need the 'export' here since this interface will only be accessible by enttites from within the Zoo namespace. skinType: string; isMammal() : boolean; }}// ZooWild.ts/// &lt;reference path=\"ZooAnimals.ts\" /&gt;namespace Zoo { export class Reptile implements Animal { // NOTE: we need the 'export' here to be able to access this class and instantiate objects of the Reptile type skinType: 'scales'; isMammal () { return false } }}// ZooBirds.ts/// &lt;reference path=\"ZooAnimals.ts\" /&gt;namespace Zoo {jkj export class Bird implements Animal { skinType: 'feather' isMammal () { return false } }} Once there are multiple fiels involved, we’ll need to make sure all of the compiled code gets loaded, we can use concatenated output using the --outFile flag to compile all of the input files into a single JavaScript output file. 1tsc --outFile zoo.js ZooAnimal.ts ZooWild.ts ZooBirds.ts Referencing namespacing entities in your codeNamespaces can be accessed either in the same file where the namespace is defined or another .ts file. The only control on access is whether you are using the export keyword or not for the namespace entities. 1let parrot = new Zoo.Bird(); AliasesYou can simplify working with namespaces by using Aliases. You can use import q = x.y.z to create shorter names for commonly-used objects. 123import rep = Zoo.Reptitle;let lizard: rep;","link":"/2017/08/11/Note-on-TS2-of-edX/"},{"title":"Notes on Interactive Data Visualization for the Web","text":"Introducing D3D3 – also referred to as d3.js – is a JavaScript library for creating data visualization. But that kind of undersell it. The abbreviation D3 reference the tool’s full name, Data-Driven Documents. The data is provided by you, and the documents are web-based documents, meaning anything that can be rendered by a web browser, such as HTML and SVG. D3 does the driviing, in the sense that it connects the data to the documents. DataData is an extemely broad term, only slightly less vague than the nearly all-encompassing information. Boradly speaking, data is a structured information with potential for meaning. In the context of programming for visualization, data is stored in a digital file, typically in either text or binary form. Of course, potentially every piece of digital ephemera may be considered data – not just text, but bits and bytes representing images, audio, video, database, streams, models, archives, and anything else. Within the scope of D3 and browser-based visualization, however, we will limit ourselves to text-based. That is, anything that can be presented as numbers and strings of alpha charaters. Binding DataWe use D3’s data() method to bind data to DOM elements. But there are two things we need in place first, before we can bind data: The data A selection of DOM elements Anytime after you call data(), you can craete an anonymous function accepts d as input. The magical data() method ensures that d is set to the corresponding value in your original dataset, given the current element at hand. Drawing with Data.attr, .classed, .style Scales Scales are functions that map from an input domain to an output domain. The values in any dataset are unlikely to correspond exactly to pixel measurement for use in your visuallization. Scales provide a convenient way to map those data values to new values useful for visuallization purposes. D3 scales are functions with parameters that you define. Once they are created, you call the scale function , pass it a data value and it nicely returns a scaled output value. A scale is a mathematical relationship, with no direct visual output. Domains and RangesA scale’s input domain is the range of possible input data values. A scale’s output range is the range of possible output values, commonly used as display values in pixel units. NormalizationNormalization is the process of mapping a numeric value to a new value between 0 and 1, based on the possible minumum and maximum values. Creating a ScaleD3’s linear scale function generator is accessed with d3.scaleLiner(). 1var scale = d3.scaleLinear() Now scale is a function to which you can pass input values. 1scale(2.5) // return 2.5 Because we haven’t set a domain and a range yet, this function will map input to output on a 1:1 scale. We set the scale’s input domain to 100, 500 by passing those values to the domain() method as an array. 1scale.domain([100, 500]) Set the output range in similar fashion, with range() 1scale.range([10, 350]) These steps can be chained: 123var scale = d3.scaleLinear() .domain([100, 500]) .range([10, 350]) Now it’s effective 123scale(100) // return 10scale(300) // return 180scale(500) // return 350 d3.max() and d3.min()123456789var dataset = [ [5, 20], [480, 90], [250, 50], [100, 33], [330, 95], [410, 12], [475, 44], [25, 67], [85, 21], [220, 88]]d3.max(dataset, function (d) { return d[0]})// this function will return the value 480 Setting Up Dynamic Scales12345var xScale = d3.scaleLinear() .domain([0, d3.max(dataset, function (d) { retrun d[0] })]) .range([0, w]) Output range is set to 0 and w, the SVG’s width. Use the scale 123.attr('x', function (d) { return xScale(d[0])}) d3.scaleLinear() has several other handly methods that deserve a breif mention here: nice(): this tells the scale to take whatever input domain that you gave to domian() and expand both ends to the nearest round value. rangeRound(): User rangeRound() in place of range(), and all values output by the scale will be rounded to nearest whole number. clamp(): By default, a linear scale can return values outside of the specified range. For example, if if given a value outside of its expected input domain, a scale will return a number also outside of the output range. Calling clamp(true) on a scale, forces all output values to be within the specified range. This means excessive values will be rounded to the range’s low or high value. To use any of these special methods, just tack them onto the chain in which you define the original scale function. 1const scale = d3.scaleLinear().domain([0.123, 4.67]).range([0, 500]).nice() Other Scales sclaeSqrt scalePow scaleLog scaleQuantize scaleQuantile scaleOrdinal scaleTime AxesD3’s axes are actually function whose parameters you define. Unlike scales, when an axis function is called, it doesn’t return a value, but generates the visual elements of the axis, including lines, labels, and ticks. Setting Up an AxisThere are four different axis function constructors, each one corresponding to a different orientation and placement of labels: d3.axisTop, d3.axisBottom, d3.axisLeft, d3.axisRight. 1const xAxis = d3.axisBottom() At a minimum, each axis also needs to be told on what scale to operate. 123const xAxis = d3.axisBottom().scale(xScale)// orconst xAxis = d3.axisBottom(xScale) Finally, to actually generate the axis and insert all those little lines and labels into our SVG, we must call teh xAxis function. This is similar to the scale functions, which we first configured by setting parameters, and then later called to put them into action. Here we put this code at the end of script, so the axis is generated after the other elements in the SVG, and therefore appears ‘on top’ 1svg.append('g').call(xAxis) This is where things get a little funky. You might be wondering why this looks so different from our friendly scale functions. Here’s why: because an axis function actually draws something to the screen (by appending SVG elements to the DOM), we need to specify where in the DOM it should place new elements. In the svg, we append() a new g element to the end of the SVG. In SVG land, a g element is a group element. Group elements are invisible, unlike line, rect, and circle and they have no visual presence themselves. The g element can keep our code nice and be transformed. So we’ve created a new g, and then finally, the function call() is called on our new g. D3’s call() function takes the incoming selection, as received from the prior link in the chain, and hands that selection off to any function. This this case, the selection is our new g group element. Although the g isn’t strictly necessary, we are using it because the axis function is about to generate lots of crazy lines and numbers, and it’s noce to contain all those element within a single group object. call() hands off g to the xAxis function, so our axis is genrated within g Positioning AxesBy default, an axis is positioned using the range values of the specified scale. In our case, xAxis is referencing xScale, which has a range of [20, 460], because we applied 20 pixels of padding on all edge of the SVG. We can transform the axis by: 1234svg.append('g') .attr('class', 'axis') .attr('tranform', 'translate(0, ' + (h - padding) + ')') .call(xAxis) In the end, we would like our g to look like this in the DOM: 1&lt;g class=\"axis\" transform=\"translate(0, 280)\"&gt; CSS styles on axisThe axes themselves are made up of path, line, text element, so those are the three elemnts to target in your CSS. The paths and lines can be styled together, with the same rules, and text gets its own rules around for font and font size. 1234567891011.axis path, .axis line { stroke: teal; shape-rendering: crispEdges;}.axis text { font-family: Optima, Futura, sans-serif; font-weight: bold; font-size: 14px; fill: teal;} These CSS rules will override D3’s default styles. Note that when we use CSS rules to style SVG elements, only SVG attribute names – not regular CSS properties – should be used. Check for TicksSome ticks spread disease, but D3’s ticks communicates information. You can customize all aspects of your axes, starting with the rough number of ticks, using ticks() 1const xAxis = d3.axisBottom().scale(xScale).ticks(6) // set rough # of ticks Specifying tick values manually 1const xAixs = d3.axisBottom().scale(xScale).tickValues([0, 100, 250, 700]) Formatting Tick labelsEnter tickFormat(), which enables you to specify how your numbers should be formatted. 12const formatAsPercentage = d3.format(\".1%\")xAxis.tickFormat(formatAsPercentage) Updates, Transtions, and Motion Transtion: .transition(), .duration() Motion: .delay(), .ease() The argument could be number or function 123.transition().delay((d, i) =&gt; 100 * i).duration(300) The default easing is d3.easeCubicInOut, which produces the gradual acceleration and deceleration. 123.transition().duration(3000).ease(d3.easeLinear) d3.easeCircleIn d3.easeElasticOut d3.easeBounceOut on() Transition Starts and EndsThere will be times when you want to make something happen at the start or end of a transition. In those time you can use on() to execute arbitrary code for each element in the selection. on() expects two arguments: Either “start” or “end” An anonymous function, to be executed either at the start of a transition, or as soon as it has ended. Notice: Only one transition can be active on any given element at any given time. Containing Visual Elements With Clipping PathsSVG has support for clipping paths, which you might know as masks in many drawing tools. Much like g, clipPath has no visual presence of its own, but it contains visual elements. 123&lt;clipPath id=\"chart-area\"&gt; &lt;rect x=\"30\" y=\"30\" width=\"410\" height=\"240\"&gt;&lt;/rect&gt;&lt;/clipPath&gt; Note that outer clipPath element has been given an ID of chart-area. We can use that ID to reference it later. Within the clipPath is a rect, which will function as the mask. 3 steps to using a clipping path: Define a clipPath and give it an ID Put visual elements within the clipPath (usuallly just a rect, but this could be circles or any other visual elements) Add a reference to the clipPath form whatever elements you wish to be masked. 123456789101112131415svg.append('clipPath') .attr('id', 'chart-area') // assign an id .append('rect') // within the clippath, create new rect .attr('x', padding) .attr('y', padding) .attr('width', w - padding * 2) .attr('height', h - padding * 2)svg.append('g') .attr('id', 'circles') .attr('clip-path', 'url(#chart-area)') .selectAll('circle') .data(dataset) .enter() .append('circle') InteractivityD3 allows you to bind event listener to more than one element at a time. 12345678svg.selectAll('rect') .data(dataset) .enter() .append('rect') .... .on('click', (d) =&gt; { // ... }) Within anonymous function , D3 automatically sets the context of this so it references current element upon which we are acting 123svg text { pointer-event: none;} or 1svg.append('text').style('pointer-event', 'none') Grouping SVG ElementNote that g group elements do not, by themselves, trigger any mouse events. The reason for this is that g elements have no pixels. You can still bind event listener to g elements, just keep in mind that the elements within that g will then behave as a group. If any of the enclosed elements are clicked or moused over, then the listener function will be activated. TooltipsIn interactive visualizations, tooltips are small overlays that present data values. In many cases, it’s not necessary to label every individual data value in the default value, but that level of detail should still be accessible to users. SVG Element Tooltips123456789101112131415161718192021.on('mouseover', function (d) { const xPosition = parseFloat(d3.select(this)).attr('x') + xScale.bandWidth() const yPosition = parseFloat(d3.select(this)).attr('y') + 14})// create the tooltip labelsvg.append('text') .attr('id', 'tooltip') .attr('x', xPosition) .attr('y', yPosition) .attr('text-anchor', 'middle') .attr('font-family', 'sans-serif') .attr('font-size', '11px') .attr('font-weight', 'bold') .attr('fill', 'black') .text(d).on('mouseout', function () { d3.select('#tooltip').remove()}) Using PathsLine ChartsScale setup12345678910111213const xScale = d3.scaleTime() .domain([ d3.min(dataset, (d) =&gt; d.date), d3.max(dataset, (d) =&gt; da.date) ]) .range([0, w])const yScale = d3.scaleLinear() .domain([ 0, d3.max(dataset, (d) =&gt; d.avarage) ]) .range([h, 0]) Define a line generator 123const lineGen = d3.line() .x(d =&gt; xScale(d.date)) .y(d =&gt; yScale(d.avarage)) The x and y accessors tell the line generator how to decide where to place each point on the line. 123456789const svg = d3.select('body') .append('svg') .attr('width', w) .attr('height', h)svg.append('path') .datum(dataset) .attr('class', 'line') .attr('d', lineGen) Instead of using data() to bind each value in our dataset array to a different element, we use datum(), the method for binding a single data value to a single element. The entire dataset array is bound to the new path we just created. We set a d attribute, passing in our line generator function as an argument. Since the data has already been bound to the path, the line generator simply grabs taht data. plots the pointers as we specified, and draws a line connecting them. Dealing with Missing DataAssume a -99.99 value is not a true measurement, namely one value is missed. defined() is just an configuration method, like x() and y(). If the result of its anonymous function is true, then that data value is included, or the value is excluded. 1234const lineGen = d3.line() .defined(d =&gt; (d.avarage &gt; 0)) .x(d =&gt; x.date) .y(d =&gt; x.avatarge) Area ChartsAreas are not too different from lines. If a line is a series of connected (x, y) points, then an area is just that same line, plus a second such line (usually a flat baseline), with all the space in between filled in. 12345const area = d3.area() .defined(d =&gt; (d.avarage &gt; 0)) .x(d =&gt; (xScale(d.date))) .y0(() =&gt; (yScale.range()[0])) .y1((d) =&gt; (yScale(d.avarge))) y0 represents the area’s baseline, which y1 represents the top. SelectionsA Closer Look at Selections d3.select('body') returns a Selection, which consists of _groups and _parents So a selection contains two arrays: _groups and _parents _groups contains yet another array, which itself contains a list of elements – ony one in this case, body. Let’s expand body and will see a lot of properties associated with body. Selections are just very special objects generated and interpreted by D3. You will never manipulate a selection yourself – don’t bother trying to reach int _groups – as that’s what all of D3’s selection methods are for. d3.select() and d3.selectAll() operate at the page level, which means 1const allGroups = d3.selectAll('g') The select() and selectAll() statements create new selections, and hand those new selections off to the subsequent methods. To minimize the confusion from old and new selections, Mike Bostock recommends using an indentation convetion of four space when the selection is unchanged, but only two when a new selection is returned. select() and append() are methods that return new selections, attr() does not, but merely relays whatever selection it just acted on. Storing SelectionsSelections are immutable. All selection methods that affect which elements are selected (or their order) return a new selection rather tahn modifying the current selection. That is, once you make a selection, you can’t modify it. You can only make a new one, which could be a subset of the original, and overwrite it. Enter, Merge and ExitFilter1234567d3.select('body').selectAll('p') .data(dataset) .enter() .append('p') .text(d =&gt; ('I can count up to ' + d)) .filter(d =&gt; (d &gt; 15)) .style('color', 'red') filter() takes a selection and an anonymous function. If the function return true for a given element, then that element is included in the new selection returned by filter(). EachThe most common purpose of creating a selection is to ultimately to modify it in some way, such as by using attr() or style(). But it can be useful to define your own functions, espectially for custom calculation or modifications that will be repeated. We can use each() to run an arbitrary function once for each element in a selection. each() takes whatever selection it’s given and calls the specified function once for each item in the selection. 123selection.each((d, i) =&gt; { // ...}) Some serious points to note: Since the d and i arguments are specified in the function definition, D3 will populate them for you. The value of this will also be set by D3 to reflect the element upon which we're currently acting, So d3.select(this) will create a selection with whatever that element is. In delay() or any other function within (d, i) =&gt; {}, we can reference the value d, and i directly, no need to write (d, i) LayoutsContrary to what the name implies, D3 layouts do not, in fact, lay anything out for you on the screen. The layout methods have no direct visual output. Rather, D3 layouts take data that you provided and remap or otherwise transform it, thereby generating new data that is more convenient for a specific visual task. The list of D3 layouts includes: Chord Cluster Force Pack Partition Pie Stack Tree Treemap Pie Layoutd3.pie() might not be as delicious as it sounds, but it’s still worthy of your attention. It is typically used to create a doughnut or pie chart. Start with simple dataset 1const dataset = [ 5, 10, 20, 45, 6, 25 ] Wd define a default pie layout 1const pie = d3.pie() Then, all that remains is to hand off our data to the new pie() function, as in pie(dataset). The pie layout takes our simple array of numbers and generates an array of objects, one object for each value. Each of those objects now has a few new values – most important, startAngle and endAngle. To actually draw the wedges, we turn to d3.arc(), a handy built-in function for drawing arcs as SVG path elements. Arcs are defiend as custom functions, and they require inner and outer redius values. 123456789const w = 300const h = 300const outerRadius = w / 2const innerRadius = 0const arc = d3.arc() .innerRadius(innerRadius) .outerRadius(outerRadius) 1234const svg = d3.select('body') .append('svg') .attr('width', w) .attr('height', h) Then we can create new groups for each incoming wedge, binding the pie-ified data to the new elements, and translating each group into the center of the chart, so the paths will appear in the right place 1234567// set up groupsconst arcs = svg.selectAll('g.arc') .data(pie(dataset)) .enter() .append('g') .attr('class', 'arc') .attr('transform', 'translate(' + outerRadius + ', ' + outerRadius + ')') Note that we’re saving a reference to each newly created g in a variable called arcs Finally, within each new g, we append a path. A path‘s path description is defined in the d attribute. So we call the arc generator, which generates the path information based on the data already bound to this group. 123456// draw arc pathsarcs.append('path') .attr('fill', (d, i) =&gt; { return colors(i) }) .attr('d', arc) arc is our path generator function. When a named function is specified as a parameter in this way, D3 automcatically passes in the datum and index values, without us having to write them out explicitly. 12345.attr('d', arc)// equivalent.attr('d', (d, i) =&gt; (arc(d, i))) D3 has a number of handy ways to generate categorical colors 1const color = d3.scaleOrdinal(d3.schemeCategory10) Generate text labels for each wedge: 123456arcs.append('text') .artr('transform', (d) =&gt; { return 'translate(' + arc.centroid(d) + ')' }) .attr('text-anchor', 'middle') .text((d) =&gt; { return d.value }) A centroid is the calculated center point of any shape, whether that shape is regular(like a square) or highly irregular(like an outline of the state of Maryland). arc.centroid() is super-helpful function that calculates and returns the center point of any arc. Note: The pie layout automatically reordered out data values from largest to smallest. Stack Layoutd3.stack() converts two-dimentional data into ‘stacked’ data. It calculates a baseline value for each datum, so you can stack layers of data on top of one another. Start with some data 1234567const dataset = [ { apples: 5, oranges: 10, grapes: 22 },true{ apples: 4, oranges: 12, grapes: 28 },true{ apples: 2, oranges: 19, grapes: 32 },true{ apples: 7, oranges: 23, grapes: 35 },true{ apples: 23, oranges: 17, grapes: 43 }] The dataset is organized by column. The stack layout reconfigures the data to be organized by categories. 12345// Set up stack methodconst stack = d3.stack().keys(['apples', 'oranges', 'grapes'])// Data, stackedconst series = stack(dataset) Now series is an array with three values, each one itself an array corresponding to each categorical series: apples, oranges, and grapes(in that order because we specified as such in keys()) 123456//'series', the array formerly known as 'dataset'[true[ [ 0, 5], [ 0, 4], [ 0, 2], [ 0, 7], [ 0, 23] ], // applestrue[ [ 5, 15], [ 4, 16], [ 2, 21], [ 7, 30], [23, 40] ], // orangestrue[ [15, 37], [16, 44], [21, 53], [30, 65], [40, 83] ] // grapes] To stack element visually, now we can reference each data object’s baseline and top line values. 123456789101112131415161718192021222324// Add a group for each row of dataconst groups = svg.selectAll('g') .data(series) .enter() .append('g') .style('fill', (di, i) =&gt; { return colors(i) })// Add a rect for each data valueconst rects = groups.selectAll('rect') .data((d) =&gt; (d)) .enter() .append('rect') .attr('x', (d, i) =&gt; { retrun xScale(i) }) .attr('y', (d) =&gt; { return ySclae(d[0]) }) .attr('height', (d) =&gt; { return yScale(d[1]-d[0]) }) .attr('width', xScale.bandWidth()) Within each group, we select all the rects and bind a subset of the data with this line 1.data((d) =&gt; (d)) A New OrderUnless otherwise specified, series will be stacked in the order specified in keys(). But you can use order() to specify an alternate sequence to be applied before all the stacked values are calculated. 123const stack = d3.stack() .keys([ 'apples', 'oranges', 'grapes' ]) .order(d3.stackOrderDesending) d3.stackOrderNone d3.stackOrderReverse d3.stackOrderAscending d3.stackOrderDescending Stacked AreasThis can be a valuable way to represent time series data, when a sum total is derived from several related categories. Force LayoutForce-directed layouts are so-called because they use simulations of physical force to arrange elements on the screen. Force layouts are typically used with network data. In computer science, this kind of dataset is called a graph. A simple graph is a list of node and edge. The nodes are entities in the dataset, and the edges are the connections between nodes. Some nodes will be connected by edges and others won’t. Nodea are commonly represented as circles and edges as lines. The physical metaphor here is of particles that repel each other, yet are also connected by strings. The repelling forces push particles away from each other, preventing visual overlap, and the strings prevent them from just flying out into space, thereby keeping them on the screen where we can see them. Preparing the network data1234567891011121314151617181920212223242526272829var dataset = {truenodes: [truetrue{ name: \"Adam\" },truetrue{ name: \"Bob\" },truetrue{ name: \"Carrie\" },truetrue{ name: \"Donovan\" },truetrue{ name: \"Edward\" },truetrue{ name: \"Felicity\" },truetrue{ name: \"George\" },truetrue{ name: \"Hannah\" },truetrue{ name: \"Iris\" },truetrue{ name: \"Jerry\" }true],trueedges: [truetrue{ source: 0, target: 1 },truetrue{ source: 0, target: 2 },truetrue{ source: 0, target: 3 },truetrue{ source: 0, target: 4 },truetrue{ source: 1, target: 5 },truetrue{ source: 2, target: 5 },truetrue{ source: 2, target: 5 },truetrue{ source: 3, target: 4 },truetrue{ source: 5, target: 8 },truetrue{ source: 5, target: 9 },truetrue{ source: 6, target: 7 },truetrue{ source: 7, target: 8 },truetrue{ source: 8, target: 9 }true]}; Defining the Force Simulation12345// Initialize a simple force layout, using the nodes and edges in datasetconst layout = d3.forceSimulation(dataset.nodes) .force('charge', d3.forceManyBody()) .force('\u0006link', d3.forceLink(dataset.edges)) .force('center', d3.forceCenter().x(w/2).y(h/2)) Call d3.forceSimulation() and pass in a reference to the nodes. This will generate a new simulator and automatically start running it, but without any forces applied, it won’t be very interesting. To create force, call force() as many times as you like, each time specifying an arbitrary name for each force(in case you want to reference it later) and the name of a force function. d3.forceManyBody(): Create a many-body force which acts on all nodes, meaning this can be used to either attract all nodes to each other or repel all nodes from each other. Try different strength() values, and see what happens. The default strength() is -30, so we will see a slight repelling force. d3.forceLink(): Our nodes are connected by edges, so we apply this force, specifying dataset.edges. Specify a target distance() (the default is 30 pixles), and this force will struggle agains any competing forces to achieve that distance. d3.forceCenter(): This force centers the entire simulation around whatever point you specify with x() and y(). Creating the Visual ElementsAfter defining our force simulation, we proceed to generate visual elements. First we create a line for each edge: 1234567// Create edges as linesconst edges = svg.selectAll('line') .data(dataset.edges) .enter() .append('line') .style('stroke', '#ccc') .style('stroke-width', 1) Then create a circle for each node: 12345678const nodes = svg.selectAll('circle') .data(dataset.nodes) .enter() .append('circle') .attr('r', 10) .style('fill', (d, i) =&gt; { return colors(i) }) Add simple tooltip: 123456// Add a simple tooltipnodes.append('title') .text((d) =&gt; { return d.name }) Updating Visuals Over TimeD3’s force simulation ‘ticks’ forward through time, just like every other physics simulation. With each tick, the simulation adjusts the position values for each node and edge according to the rules we specified when the layout was first initialized. To see this progress visually, we need to update the associated elements – the lines and circles – on every tick. 12345678910// Every time the simulation 'ticks', this will be calledforce.on('tick', () =&gt; { edges.attr('x1', d =&gt; (d.source.x)) .attr('y1', d =&gt; (d.source.y)) .attr('x2', d =&gt; (d.target.x)) .attr('y2', d =&gt; (d.target.y)) nodes.attr('cx', d =&gt; (d.x)) .attr('cy', d =&gt; (d.y))}) This tells D3, ‘Ok, every time you tick, take the new (x, y) values for each line and circle and update them in the DOM’ Here the (x, y) are calculated and appeded by D3. Draggable NodesAdd the call() statement to our Nodes: 1234.cal(d3.drag() .on('start', dragStarted) .on('drag', dragging) .on('end', dragEnded)) This bit code ‘calls’ the d3.drag() method on each node. d3.drag(), in turn, sets event listeners for the three drag-related events, and specifies functions to trigger whenever one of those events occurs. 12345678910111213141516function dragStarted (d) { if (!d3.event.active) force.alphaTarget(0.3).restart() d.fx = d.x d.fy = d.y}function dragging (d) { d.fx = d3.event.x d.fy = d3.event.y}function dragEnded (d) { if (!d3.event.active) force.alphaTarget(0) d.fx = null d.fy = null} Geomapping…","link":"/2017/07/07/Notes-on-Interactive-Data-Visualization-for-the-Web/"},{"title":"Notes on Solidity in Depth","text":"Layout of a Solidity Source FileVersion Pragma1pragma solidity ^0.4.11; Importing other Source File1234567import \"filename\";import * as symbolName from \"filename\";import { symbol as alias, symbol2 } from \"filename\";import \"filename\" as symbolName; In the above, filename is always treated as a path with / as directory seperator. All path names are treated as absolute paths unless thay start with . or ... RemappingFor example, remap github.com/ethereum/dapp-bin/library to /usr/local/dapp-bin/library solc 1import \"github.com/ethereum/dapp-bin/library/iterable_mapping.sol` as it_mapping; 1solc github.com/ethereum/dapp-bin/=/usr/local/dapp-bin/ source.sol CommentsSingle Line Comments: // Multi-line Comments: /* ... */ Natspec Comments: /// or /** ... */ Natspec should be used directly above function declarations or statements. 123456789101112131415pragma solidity ^0.4.11;/** @title Shape calculator */contract shapeCaculator { /** @dev Calculates a rectangle's surface and perimeter. * @param w Width of the rectangle. * @param h Height of the rectangle. * @param s The calculated surface. * @param p The calculated perimeter. */ function rectangle(uint w, uint h) returns (uint s, uint p) { s = w * h; p = 2 * (w + h); }} Structure of ContractContracts in Solidity are similar to classes in object-oriented languages. Each contract can contain declarations of State Variables, Functions, Function Modifiers, Events, Struct Types and Enum Types. State VariablesState variables are values which are permanently stored in contract storage. 12345pragma solidity ^0.4.11;contract SimpleStorage { uint storedData; // state variable} FunctionsFunctions are executable units of code within a contract. 1234567pragma solidity ^0.4.11;contract SimpleAuction { function bid() payable { // ... }} Function ModifiersFunction modifiers can be used to amend the semantics of functions in a declarative way. 1234567891011121314pragma solidity ^0.4.11;contract Purchase { address public seller; modifier onlySeller () { // Modifier require(msg.sender == seller); _; } function abort() onlySeller { // Modifier usage //... }} EventsEvents are convenience interfaces with the EVM logging facilities. 12345678910pragma solidity ^0.4.11;contract SimpleAuction { event HighestBidIncreased(address bidder, uint amount); function bid() payable { // ... HighestBidIncreased(msg.sender, msg.value); }} Struct TypesStructs are custom defined types that can group several variables. 12345678910pragma solidity ^0.4.11;contract Ballot { struct Voter { uint weight; bool voted; address delegate; uint vote; }} Enum Types123456789pragma solidity ^0.4.0;contract Purchase { enum State { Created, Locked, Inactive }} Types bool: true or false ! logical negation &amp;&amp; logical and || logical or == logical equality != logical inequality int/uint: uint8 to uint256, int8 to int256 &lt;=, &gt;=, ==, !=, &lt;, &gt; &amp;, |, ^, ~, bit operators +, -, *, /, %, **, &lt;&lt;, &gt;&gt; address: holds a 20 bytes value(size of an Ethereum address) &lt;=, =&gt;, ==, !=, &lt;, &gt; Starting with version 0.5.0 contracts do not derive from the address type, but can still be explicitly converted to address. Members of Address balance transfer, address.transfer(value), send value Wei to the address. send: Send is the low-level counterpart of transfer. If the execution fails, the current contract will not stop with an exception, but send will return false There are some dangers in using send: The transfer fails if the call stack depth is 1024 and it also fails if the recipient runs out of gas. So in order to make safe Ether transfers, always check the return value of send, use transfer or even better. call, callcode, and delegatecall Furthermore, to interface with contracts that do not adhere to the ABI, the function call is provided which takes an arbitrary number of arguments of any type. The arguments are padding to 32 bytes and concatenated. One exception is the case where the first argument is encoded to exactly four bytes. In this case, it is not padding to allow the use of function signatures here. 123address nameReg = '0x72ba7d8e73fe8eb666ea66babc8116a41bfb10e2';nameReg.call('register', 'MyName');nameReg.call(bytes4(keccak256(\"fun(uint256))), ); call returns a boolean indicating whether the invoked function terminated (true) or caused an EVM exception (false). It is not possible to access the actual data returned. It is possible to adjust the supplied gas with the .gas() modifier: 1nameReg.call.gas(1000000000)('register', 'myName'); and supplied Ether value can be controlled too: 1nameReg.call.value(1 ether)('regiter', 'myName'); Chained 1nameReg.call.value(1 ether).gas(100000000)('register', 'myName'); In a similar way, the function delegatecall can be used: the difference is that only the code of the given address is used, all other aspects(storage, balance, …) are taken from the current contract. The purpose of delegatecall is to use library code which is stored in another contract. The user has to ensure that the layout of storage in both contracts is suitable for delegatecall to be used. Prior to homestead, only a limited variant called callcode was available that did not provide access to the original msg.sender and msg.value. All three functions call, delegatecall, and callcode are very low-level functions and should only be used as a last resort as they break the type-safety of Solidity. The .gas() option is available on all three methods, while the .value() option is not supported for delegatecall. All Contracts inherit the members of address, so it is possible to query the balance of the current contract using this.balance. The use of callcode is discouraged and will be removed in the future. Fixed-size byte array .length yields the fixed length of the byte array(read-only) It is possible to use an array of bytes as byte[], but it is wasting a lot of space, 21 bytes every element, to be exact, when passing in calls. It is better to use bytes. Dynamically-sized byte arraybytes: dynamically-sized array, see Array, not a value-type. string: dynamically-sized UTF-8-encoded string, see Array, not a value-type. Address LiberalsHexadecimal literals that pass the address checksum test, for example 0xdCad3a6d3569DF655070DEd06cb7A1b2Ccd1D3AF are of address type. Hexadecimal literals that are between 39 and 41 digits long and do not pass the checksum test produce a warning and are treated as regular rational number literals Rational and Integer LiteralsInteger literal are formed form a sequence of numbers in the range 0-9. They are interpreted as decimals, for example, 69 means sixty nine. Octal literals do not exist in Solidity and leading zeros are invalid. Decimal fraction literals are formed by a . with at least one number on one side(1., .2, 1.3) Scientific notation is also supported, where the base can have fractions, white the exponent cannot(2e10, -2e10, 2e-10, 2.5e10) Number literal expressions retains arbitrary precision until they are converted to a non-literal type. For example (2**800 + 1) - 2**800 result in the constant 1, .5 * 8 results in the integer 4 Number literal expressions are converted into a non-literal type as soon as they are used with non-literal expressions. Even though we know that the value of the expression assigned to b in the following example evaluates to an integer, but the partial expression 2.5 + a does not type check so the code does not compile. 12uint128 a = 1;uint128 b = 2.5 + a + 0.5; String LiteralsString literals are written with either double or sinlge-quotes. They do not imply trailing zeros as in C, &quot;foo&quot; represents three bytes not four. String Literal supports escape characters, such as \\n, \\xNN and \\uNNNN. Hexadecimal Literalshex&quot;001122FF&quot; EnumsEnums are one way to create a user-defined type in Solidity. They are explicitly convertable to and from all integer types but implicit conversion is not allowed. The explicit conversions check the value ranges at runtime, and a failure causes an exception. 123456789101112131415161718192021222324pragma solidity ^0.4.11;contract test { enum ActionChoices { GoLeft, GoRight, GoStraight, GoStill } ActionChoices choice; ActionChoices constant defaultChoice = ActionChoices.GoStraight; function setGoStraight() { choice = ActionChoices.GoStraight; } function getChoice() returns (ActionChoices) { return choice; } function getDefaultChoice() returns (uint) { return uint(defaultChoice); }} Function TypesFunction types are notated as follows: 1function (&lt;parameter types&gt;) {internal|external} [pure|constant|view|payable] [returns (&lt;return types&gt;)] In contrast to the parameter types, the return types cannot be empty - if the function type should not return anything, the whole returns (&lt;return type&gt;) part has to be omitted. Public (or external) functions have a special member called selector, which returns the ABI function selector: Reference TypesComplex types, i.e. types which do not always fit into 256 bits have to be handled more carefully than than the value-types we have already seen. Since copying them can be quite expensive, we have to think about whether we want them to be store in memory(which is not persisting) or storage(where the state variables are held). Data locationEvery complex type, i.e. arrays and structs has an additional annotation, the “data location” about where it is stored in memory or in storage. Depending on the context, there is always a default, but it can be overrideen by appeding either storage or memory to the type. The default for function parameters(including return parameters) is memory the default for local variable is storage and the location is forced to storage for state variables There is also a third data location, calldata, which is a non-modificable, non-persistent area where function arguments are stored. Function parameter(not return parameters) of external functions are forced to calldata and behave mostly like memory. Data locations are imortant because they change how assignment behave: assignments between storage and memory and also to a state variable always create an independent copy. Assignments to local storage variables only assign a reference though, and this reference always points to the state variable even if the latter is changed in the meantime. On the other hand, assignments from a memory stoted reference type to another memory-stored reference type do not create a copy. 123456789101112131415161718pragma solidity ^0.4.11;contract C { uint[] x; // the data location of x is storage // the data location of memoryArray is memory function f(uint[] memoryArray) { x = memoryArray; // works, copy the whole array to storage var y = x; // works, assigns a pointer, data location of y is storage y[7]; // fine, returns the 8th element y.length = 2; // fine, modifies x through y delete x; // fine, clears the array, also modifies y // the following does not work; it would need to create a new temporary / unamed array in storage, but storage is 'statically' allocated // y = memoryArray; // This does not work either, since it would 'reset' the pointer, but there is not sensible location it could point to. // delete y; }} Summary Forced data location: parameters(not return) of external functions: calldata state variables: storage Default data location: parameters(also return) of functions: memory all other local variables: storage ArraysAn array of fixed size k and element type T is written as T[k] An array of dynamic size as T[] An array of 5 dynamic arrays of uint is uint[][5]. (note that the notation is reversed when compared to some other language). To access the second uint in the third dynamic array, you use x[2][1] Variables of type bytes and string are special arrays. A bytes is similar to byte[], but it is packed tightly in calldata. string is equal to bytes but does not allow length or index access(for now). So bytes should always be preferred over byte[] because it is cheaper. StructsSolidity provides a way to define new types in the form of structs, which is shown in the following example: 12345678910111213141516pragma solidity ^0.4.11;contract CrowdFunding { struct Funder { address addr; uint amount; } struct Campaign { address beneficiary; uint fundingGoal; uint numFunders; uint amount; mapping(uint =&gt; Funder) funders; }} It is not possible for a struct to contain a member of its own type, although the struct itself can be the value type of a mapping member. This restriction is necessary, as the size of the struct has to be finite. MappingsMapping types are declared as mapping(_keyType =&gt; _valueType). Here _keyType can be almost any type except for a mapping, a dynamically sized array, a contract, an enum, and a struct. _valueType can actually be any type, including mappings. Mappings can be seen as hash tables which are virtually initialized such that every possible key exists and is mapped to a value whose byte-representation is all zeros: a type’s default value. Mappings are only allowed for state variables( or as storage reference types in internal function). It is possible to mark mapping public and have Solidity create a getter. The _keyType will become a required parameter for the getter and it will return _valueType. Mappings are not iterable, but it is possible to implement a data structure on top of them. Operators Involving LValuesLValue, i.e. a variable or something that can be assigned to. deletedelete a assigns the initial value for the type to a. I.e., for integers, it is equivalent to a = 0. delete has no effect on whole mappints. So if you delete a struct, it will reset all members that are not mappings and also recurse into the memebers unless they are mappings. However, individual keys and what they map to can be deleted. It’s really important to note that delete a really behaves like an assignment to a, it stores a new object in a. Conversions between Elementary Types.Implicit ConversionsIn general, an implicit conversion between value-types is possible if it makes sense semantically and no information is lost: uint8 is convertible to uint16, but uint16 is not convertible to uint8. And int8 is not convertible to uint256(because uint256 cannot hold hold e.g. -1). Explicit ConversionsIf the compiler does not allow implicit conversion but you know what you are doing, an explicit type conversion is sometimes possible. 12int8 y = -3;uint x = uint(y); Type DeductionFor convenience, it is not always necessary to explicitly specify the type of a variable, the compiler automatically infers it from the type of the first expression that is assigned to the variable: 12uint24 x = 0x123;var y = x; Units and Globally Available VariablesEther UnitsA literal number can take a suffix of wei, finney, szabo, or ether to convert between the subdenominations of Ether, where Ether currency numbers without a postfix are assumed to be Wei. 2 ether === 2000 finney evaluates to true Time UnitsSuffixes like seconds, minutes, hours, days, weeks and years after literal numbers can be used to convert between units of time where seconds are the base unit. Take care if you perform calendar calculations using these units, because not every year equals 365 days and not even every day has 24 hours because of leap seconds. Due to the fact that leap seconds cannot be predicted, an exact calendar library has to be updated by an external oracle. 12345function f(unit start, unit dayAfter) { if (now &gt;= start + dayAfter + 1 days) { // ... }} Other Global Variables and Functions: Post","link":"/2017/11/10/Notes-on-Solidity-in-Depth/"},{"title":"Notes on TS + React + Redux","text":"Add Explicit Props Interface from StoreWhen I use react-redux, the TS Compiler always throw an error: 1error TS2339: Property '...' does not exist on type 'Readonly&lt;children?: ReactNode; }&gt; &amp; Readonly&lt;{}&gt;'. That’s because Connect was not supplying an explicit interface to the container component, so it was confused by the prop that it was trying to pass. So you can add an explicit interface on child component. 12345678interface PropsFromStore extends React.Props&lt;any&gt; { propsFromStore: any;}class ChildComponent extends React.Component&lt;PropsFromStore, React.State&gt; { // ...}export default connect(mapStateToProps, mapDispatchToProps)(ChildComponent) Add Enhancer to Store with TSWhen I use an enhancer like: 123456789const enhancer = compose( applyMiddleware(...middlewares), DevTools.instrument(), persistState( window.location.href.match( /[?&amp;]debug_session=([^&amp;#]+)\\b/ ) )) I got an error like: 12[ts] Argument of type 'Function' is not assignable to parameter of type 'Func3&lt;{}, {}, {}, {}, StoreEnhancerStoreCreator&lt;{}&gt;&gt;'.Type 'Function' provides no match for the signature '(a1: {}, a2: {}, a3: {}, ...args: any[]): {}' To resolve this, just: 12345678910import { GenericStoreEnhancer } from 'redux'const enhancer = compose( applyMiddleware(...middlewares), DevTools.instrument as GenericStoreEnhancer, persistState( window.location.href.match( /[?&amp;]debug_session=([^&amp;#]+)\\b/ ) ))","link":"/2017/09/05/Notes-on-TS-React-Redux/"},{"title":"Methods of the String in JavaScript ","text":"String.prototype.charAt(index: number): string: Returns the character(exactly one UTF-16 code unit) at the specified index. 1'hello world'.charAt(1) // returns 'e' String.prototype.charCodeAt(index: number): number: Returns a number that is the UTF-16 code unit value at the specified index. 1'hello world'.charCodeAt(1) // returns 101 String.prototype.codePointAt(index: string): number: Returns a nonnegative integer Number that is the code point value of the UTF-16 encoded code point starting at the specified index. 1'hello world'.codePointAt(1) // returns 101 String.prototype.concat(str: string, ...rest: string[]): string: Combines the texts and returns a new string. 1'hello world'.concat(', ', 'and welcome') // returns 'hello world, and welcome' String.prototype.includes(str: string): boolean: Determines whether one string may be found within another string. 1'hello world'.includes('world') // returns true String.prototype.endsWith(str: string): boolean: Determines whether a string ends with the characters of another string. 1'hello world'.endsWith('world') // returns true String.prototype.indexOf(str: string): number: Returns the index of the specified string, -1 for not found. 1s.indexOf('world') // returns 6 String.prototype.lastIndexOf(str: string): Returns the index of the specified string, but search starts from the end, -1 for not found 12'world hello world'.indexOf('world') // returns 0'world hello world'.lastIndexOf('world') // returns 12 String.prototype.localeCompare(str: string): Returns a number indicating whether a reference string comes before or after or is the same as the given string in sort order. 12345678910111213141516const a = 'réservé' // with accents, lowercaseconst b = 'RESERVE' // no accents, uppercaseconsole.log(a.localeCompare(b))// expected output: 1console.log(a.localeCompare(b, 'en', { sensitivity: 'base' }))// expected output: 0// The letter \"a\" is before \"c\" yielding a negative value'a'.localeCompare('c') // -2 or -1 (or some other negative value)// Alphabetically the word \"check\" comes after \"against\" yielding a positive value'check'.localeCompare('against') // 2 or 1 (or some other positive value)// \"a\" and \"a\" are equivalent yielding a neutral value of zero'a'.localeCompare('a') // 0 String.prototype.match(regexp): string[] | null: Used to match a regular expression against a string, null for not found 123const paragraph = `The quick brown fox jumps over the lazy dog. It barked`const regex = /[A-Z]/gparagraph.match(regex) // returns [\"T\", \"I\"] String.prototype.matchAll(regex): Iterator: Returns an iterator of all matches. String.prototype.normalize: Returns the Unicode Normalization Form of the calling string value. String.prototype.padEnd(): Pads the current string with a given string(repeated if needed) so that the resulting string reaches a given length. The padding is appliced fromthe end of the current string. 1'Breaded Mushrooms'.padEnd(25, '.') // returns \"Breaded Mushrooms........\" String.prototype.padStart(): Pads the current string from the start with a given string to create a new string from a given length 1'Breaded Mushrooms'.padStart(25, '.') // returns \"........Breaded Mushrooms\" String.prototype.repeat(times: number): Returns a string consisting of the elements of the object repeated the given times. 1'hello world'.repeat(3) // \"hello worldhello worldhello world\" String.prototype.replace(pattern: regexp | string, replacement): string: Returns a new string with some or all matches of a pattern replaced by a replacement 1'hello world'.replace(/world/, 'hello') // returns 'hello hello' String.prototype.search(pattern: regexp): number: Executes a search for a match between a regular expression and this string, returns the index of matched string. 1'hello world'.search(/ll/) // returns 2 String.prototype.slice(start: number[, end: number]): string: Returns a new string extracted from the original string from [start, end). 1'hello'.slice(1, 2) // returns 'e' String.prototype.split(pattern): string[]: Splits a string into an array of strings by separating the string into substrings. 1'hello world'.split(' ') // ['hello', 'world'] String.prototype.startsWith(): Determines whether a string begins with the characters of another string. String.prototype.substring: Returns the characters in a string between two indices into the string. 1'hello world'.substring(1, 2) // returns 'e' It seems that the String.prototype.substring works like String.prototype.slice, but if the start &gt; end, String.prototype.substring swaps the two parameters while String.prototype.slice return ‘’. 12'hello world'.substring(2, 1) // returns 'e''hello world'.slice(2, 1) // returns '' And String.prototype.slice accepts netagive indices as start from the end of the string, while String.prototype.substring treats negative and NaN as 0. Note String.prototype.substr is deprecated String.prototype.toLocaleLowerCase(): The characters within a string are converted to lower case while respecting the current locale. For most languages, this will return the same as toLowerCase() String.prototype.toLocaleUpperCase(): The characters within a string are converted to upper case while respecting the current locale. For most languages, this will return the same as toUpperCase() String.prototype.toLowerCase(): Returns the calling string value converted to lower case. 1'HELLO WORLD'.toLowerCase() // returns 'hello world' String.prototype.toUpperCase(): Returns the calling string value converted to upper case. 1'hello world'.toUpperCase() // returns 'HELLO WORLD' String.prototype.toString(): Returns a string representing the specified object. String.prototype.trim(): Trims whitespaces from the beginning and end of a string 1' hello world '.trim() // returns 'hello wrold' String.prototype.trimStart(), String.prototype.trimLeft(): Trims whitespaces from the beginning of the string. 1' hello world '.trimStart() // returns 'hello world ' String.prototype.trimEnd(), String.prototype.trimRight(): Trims whitespace from the end of the string. 1' hello world '.trimEnd() // return ' hello world' String.prototype.valueOf: Returns the primitive value of the specified object.","link":"/2019/08/30/Methods-of-the-String-in-JavaScript/"},{"title":"Querying InfluxDB With the HTTP API","text":"The HTTP API is the primary means for querying data in InfluxDB. To perform a query send a GET request to the /query endpoint, set the URL parameter db as the target database, and set the URL parameter q as your query. 1curl -G 'http://localhost:8086/query?pretty=true' --data-urlencode \"db=mydb\" --data-urlencode \"q=SELECT \\\"value\\\" FROM \\\"cpu_load_short\\\" WHERE \\\"region\\\"='us-west'\" InfluxDB returns JSON. The results of your query appear in the 'result' array. If an error occurs, InfluxDB sets an 'error' key with an explanation of the error. 123456789101112131415161718192021222324252627282930{ \"results\": [ { \"statement_id\": 0, \"series\": [ { \"name\": \"cpu_load_start\", \"columns\": [ \"time\", \"value\" ], \"values\": [ [ \"2015-01-29T21:55:43.702900257Z\", 2 ], [ \"2015-01-29T21:55:43.702900257Z\", 0.55 ], [ \"2015-06-11T20:46:02Z\", 0.64 ] ] } ] } ]} Note: Appending pretty=true to the URL enables pretty-printed JSON output. While this is useful for debugging or when queryting directly with tools like curl, it is not recommended for production use as it consumes unnecessary network bandwidth. Multiple queriesSend multiple queries to InfluxDB in a single API call. Simply delimit each query using a semicolon 1curl -G 'http://localhost:8086/query?pretty=true' --data-urlencode \"db=mydb\" --data-urlencode \"q=SELECT \\\"value\\\" FROM \\\"cpu_load_short\\\" WHERE \\\"region\\\"='us-west';SELECT count(\\\"value\\\") FROM \\\"cpu_load_short\\\" WHERE \\\"region\\\"='us-west'\"","link":"/2017/06/30/Querying-InfluxDB-with-the-HTTP-API/"},{"title":"React Hooks","text":"Basic HooksuseState1const [state, setState] = useState(initialState) Returns a stateful value and a function to update it. During subsequent re-renders, the first value returned by useState will always be the most recent state after applying updates. Functional updatesIf the new state is computed using the previous state, you can pass a function to setState. The function will receive the previous value and return an updated value. Note: Unlike the setState method found in class component, useState does not automatically merge upate objects. useReducer is more suited for managing state objects that contains multiple sub-values. Lazy initializationThe initialState argument is the state used during the initial render. In subsequent renders, it is disregarded. If the initial state is the result of an expensive computation, you may provide a function instead, which will be executed only on the initial render. useEffect1useEffect(didUpdate) Accept a function that contains imperative, possibly effectful code. Mutations, subscriptions, timers, logging and other side effects are not allowed inside the main body of a function component. Instead, use useEffect. The functino passed to useEffect will run after the render is committed to the screen. By default, effects run after every completed render, but you can choose to fire it only when certain values have changed. Cleaning up an effect1234567useEffect(() =&gt; { const subscription = props.source.subscribe() return () =&gt; { // Clean up the subscription subscription.unsubscribe() }}) Timing of effectsUnlike componentDidMount and componentDidUpdate, the function passed to useEffect fires after layout and paint, during a deferred event. This makes it suitable for the many common side effects, like setting up subscriptions and event handlers, because most types fo work shouldn’t block the browser from updating the screen. useMutationEffect and useLayoutEffect have the same signature as useEffect and only differ in when they are fired. Although useEffect is deferred until after the browser has painted, it’s guaranteed to fire before any new renders. Conditionally firing an effect1234567useEffect( () =&gt; { const subscription = props.source.subscribe() return () =&gt; subscription.unsubscribe() }, [props.source],) useContext1const context = useContext(Context) Accepts a context object(the value returned from React.createContext) and returns the current context value, as given by the nearest context provider for the given context. When the provider updates, this hook will trigger a rerender with the latest context value. Additional HooksuseReducer1const [state, dispatch] = useReducer(reducer, initialState) An alternative to useState. Accepts a reducer of type (state, action) =&gt; newState, and returns the current state paired with a dispatch method. 123456789101112131415161718192021222324252627const initialState = { count: 0 }function reducer(state, action) { switch (action.type) { case 'reset': { return initialState } case 'increment': { return { count: state.count + 1 } } case 'decrement': { return { count: state.count - 1 } } default: return state }}function Counter({ initialCount }) { const [state, dispatch] = useReducer(reducer, { count: initialCount }) return ( &lt;&gt; Count: {state.count} &lt;button onClick={() =&gt; dispatch({ type: 'reset' })}&gt;Reset&lt;/button&gt; &lt;/&gt; )} Lazy initializationuseReducer accepts an optional third argument, initialAction. If provided, the initial action is applied during the initial render. This is useful for computing an initial state that includes values passed via props. useCallback123456const memoizedCallback = useCallback( () =&gt; { doSomething(a, b) }, [a, b],) Returns memoized callback. Pass an inline callback and an array of inputs, useCallback will return a memoized version of the callback that only changes if one of the inputs has changed. This is useful when passing callbacks to optimized child components that rely on reference equality to prevent unnecessary render. Note: The array of inputs is not passed as arguments to the callback. Conceptually, though, that’s what represent: every value referenced inside the callback should also appear in the inputs array. useMemo1const memoizedValue = useMemo(() =&gt; computeExpensiveValue(a, b), [a, b]) Returns a memoized value. Pass a “create” function and an array of inputs, useMemo will only recompute the memoized value when one of the inputs has changed. This optimization helps to avoid expensive calculations on every render. If no array is provided, a new value will be computed whenever a new function instance is passed as the first argument.(With an inline function, on every render) useRef1const refContainer = useRef(initialValue) useRef returns a mutable ref object whose .current property is initialized to the passed argument(initialValue). The returned object will persist for the full lifetime of the component. A common use case is to access a child imperatively: 123456789101112function TextInputFocusButton() { const inputEl = useRef(null) const onButtonClick = () =&gt; { inputEl.current.focus() } return ( &lt;&gt; &lt;input ref={inputEl} type=\"text\" /&gt; &lt;button onClick={onButtonClick}&gt;Focus the input&lt;/button&gt; &lt;/&gt; )} useImperativeMethods1useImperativeMethods(ref, createInstance, [inputs]) useImperativeMethods customizes the instance value that is exposed to parent component when use ref. As always, imperative code using refs should be avoided in most cases. useImperativeMethods should be used with forwardRef 12345678910function FancyInput(props, ref) { const inputRef = useRef() useImperativeMethods(ref, () =&gt; ({ focus: () =&gt; { inputRef.current.focus() }, })) return &lt;input ref={inputRef} /&gt;}FancyInput = forwardRef(FancyInput) In this example, a parent component that renders &lt;FancyInput ref={fancyInputRef} /&gt; would be able to call fancyInputRef.current.focus(). useMutationEffectThe signature is identical to useEffect, but it fires synchronously during the same phase that React performs its DOM mutations, before sibling components has been updated. Prefer the standard useEffect when possible to avoid blocking visual updates. Note: Avoid reading from the DOM in useMutationEffect. If you do, you can cause performance problems by introducing layout trash. useLayoutEffectThe signature is identical to useEffect but it fires synchronously after all DOM mutations. Use this to read layout from the DOM and synchronously re-render. Updates scheduled inside useLayoutEffect will be flushed synchronously, before the browser has a chance to paint. Fires in the same phase as componentDidMount and componentDidUpdate","link":"/2018/11/20/React-Hooks/"},{"title":"Requiring Modules in Node.js","text":"1const config = require('/path/to/file') The main object exported by the require module is a function. When Node invokes that require() function with a local file path as the function’s only argument, Node goes through the following sequence of steps: Resolving: To find the absolute path of the file. Loading: To determine the type of the file content. Wrapping: To give the file its private scope. This is what makes both the require and module objects local to every file we require. Evaluating: This is what the VM eventually does with the loaded code. Caching: So that when we require this file again, we don’t go over all the steps another time. Resolving a local path1234567891011// in NODE REPL&gt; moduleModule: { id: '&lt;repl&gt;', exports: {}, parent: undefined, fielname: null, loaded: false, children: [], paths: [...]} Every module object gets an id property to identify it. This id is usually the full path to the file, but in a REPL session it’s simply &lt;repl&gt;. Node modules have a one-to-one relation with files on the file-system. We require a module by loading the content of a file into memory. However, since Node allows many ways to require a file(for example, with a relative path or a pre-configured path), before we can load the content of a file into the memory we need to find the absolute location of that file. When we require a find-me module, without specifying a path: 1require('find-me') Node will look for find-me.js in all the paths specified by module.paths in order. 12345678910// in NODE REPL&gt; module.paths[ '/Users/samer/learn-node/repl/node_modules', '/Users/samer/learn-node/node_modules', '/Users/samer/node_modules', '/Users/node_modules', '/node_modules', '/Users/samer/.node_modules', '/Users/samer/.node_libraries', '/usr/local/Cellar/node/7.7.1/lib/node' ] The paths list is basically a list of node_modules directories under every directory from the current directory to the root directory. It also includes a few legacy directories whose use is not recommended. If Node can’t find find-me.js in any of these paths, it will throw a ‘cannot find module error’. Requiring a folderModules don’t have to be files. We can also create a find-me folder under node_modules and place an index.js file in there. The same require('fine-me') line will use that folder’s index.js file. An index.js file will be used by default when we require a folder, but we can control what file name to start under the folder using the main property in package.json. require.resolveIf you want to only resolve the module and not execute it, you can use the require.resolve function. This behaves exactly the same as the main require function, but does not execute the file. This can be used, for example, to check whether an optional package is installed or not and only use it when it’s available. exports, module.exports, and asynchronous loading of modulesIn any module, exports is a special object. exports variable inside each module is just a reference to module.exports which manages the exported properties. When we reassign the exports variable, that reference is lost and we would be introducing a new variable instead of changing the module.exports object. The module.exports object in every module is what the require function returns when we require that module. Let’s talk about the loaded attribute on every module. The module module use the loaded attribute to track which modules have been loaded(true value) and which modules are still being loaded(false value). The exports object becomes complete when Node finishes loading the module(and label it so). The whole process of requiring/loading a module is synchronous. That’s why we were able to see the modules fully loaded after one cycle of the event loop. This also means that we cannot change the exports object asynchronously. JSON and C/C++ addonsWe can natively require JSON files and C++ addon files with the require function. You don’t need to specify the extensions. If a file extension was not specified, the first thing Node will try to resolve is a .js, then .json, and it will parse the .json file if found as a JSON text file. After that Node will try to find a binary .node file. Requiring JSON file is useful, for example, everything you need to manage in that file is some static configuration values, or some values that you periodically read from an external source. For example, if we had the following config.json file: 1234{ \"host\": \"localhost\", \"port\": 8080} We can require it directly like this: 1const { host, port } = require('./config') All code you write in Node will be wrapped in functionsNode’s wrapping of modules is often misunderstood. To understand it, let me remind you about the exports/module.exports relation. We can use the exports object to export properties, but we cannot replace the exports object directly because it’s just a reference to module.exports. 123exports.id = 52; // This is okexports = { id: 52 }; // This will not workmodule.exports = { id: 52 }; // This is ok How exactly does this exports object, which appears to be global for every module, get defined as a reference on the module object? In a browser, when we declare a variable in a script like this: 1var answer = 12; That answer variable will be globally available in all scripts after the script that define it. This is not the case in Node. When we define a variable in one module, the other module modules in the program will not have access to that variable. So how come variables in Node are magically scoped? The answer is simple. Before compiling a module, Node wraps the module code in a function, which we can inspect using the wrapper property of the module module. 12345~ $ node&gt; require('module').wrapper[ '(function (exports, require, module, __filename, __dirname) { ', '\\n});' ]&gt; Node does not execute any code you write in a file directly. It executes this wrapper function which will have your code in its body. This is what keeps the top-level variables that are defined in any module scoped to that module. This wrapper function has 5 arguments: exports, require, module, __filename, __dirname. This is what makes them appear to look global when in fact they are specific to each module. All of these arguments get their value when Node execute the wrapper function. exports is defined as a reference to module.exports prior to that. require and module are both specific to the function to be executed, and __dirname/__filename variables will contain the wrapped module’s directory path and absolute filename. Since every module gets wrapped in a function, we can actually access that function’s arguments with the arguments keyword: 12345678910111213141516171819202122232425262728~/learn-node $ echo \"console.log(arguments)\" &gt; index.js~/learn-node $ node index.js{ '0': {}, '1': { [Function: require] resolve: [Function: resolve], main: Module { id: '.', exports: {}, parent: null, filename: '/Users/samer/index.js', loaded: false, children: [], paths: [Object] }, extensions: { ... }, cache: { '/Users/samer/index.js': [Object] } }, '2': Module { id: '.', exports: {}, parent: null, filename: '/Users/samer/index.js', loaded: false, children: [], paths: [ ... ] }, '3': '/Users/samer/index.js', '4': '/Users/samer' } What happens is roughly equivalent to: 12345function (require, module, __filename, __dirname) { let exports = module.exports; // Your Code... return module.exports;} If we change the whole exports object, it would no longer be a reference to module.exports. The require objectThere is nothing special about require. It’s an object that acts mainly as a function that takes a module name or path and return the module.exports object. We can simply override the require object with our own logic if we want to. For exmaple, maybe for testing purposes, we want every require call to be mocked by default and just return a fake object instead of the required module exports object. 123require = function () { return { mocked: true }} After doing the above reassignment of require, every require('something') call in the script will just return the mocked object. The require object also has properties of its own. We’ve seen the resolve property, which is a function that performs only the resolving step of the require process. We’ve also seen require.extensions above. There is also require.main which can be helpful to determine if the script is being required or run directly. Say, for example, that we have this simple printFrame function in print-in-frame.js 1234567// In print-in-frame.jsconst printFrame = (size, header) =&gt; { console.log('*'.repeat(size)) console.log(header) console.log('*'.repeat(size))} We want to use this file in two ways: From the command line directly like this: 1node print-in-frame 8 hello With require 12const print = require('./print-in-frame.js')print(5, 'hello') Those are two different usages. We need a way to determine if the file is being run as a stand-alone script or if it is being required by other scripts. 123456789101112const printFrame = (size, header) =&gt; { console.log('*'.repeat(size)) console.log(header) console.log('*'.repeat(size))}if (require.main === module) { // the file is being executed directly printFrame(process.argv[2], process.argv[3])} else { module.exports = printFrame} All module can be cachedCaching is important to understand. Say that we have the following ascii-art.js file that prints a cool looking header: 12345############# We want to display this header every time we require the file, so when we require the file twice, we want the header to show twice: 12require('./ascii-arg'); // it will show the headerrequire('./ascii-arg'); // it won't show the header The second require will not show the header because of modules’ caching. Node caches the first call and does not load the file on the second call. We can see this cache by printing require.cache after the first require. The cache registry is simply an object that has a property for every required module. Those properties values are the module objects used for each module. We can simply delete a property from that require.cache object to invalidate that cache. If we do that, Node will reload the module to recache it.","link":"/2017/08/18/Requiring-Modules-in-Node-js/"},{"title":"Rocket of Rust","text":"IntroductionRocket’s design is centered around three core philosophies: Function declaration and parameter type should contain all necessary information to validate and process a request. This immediately prohibits APIs where request state is retrieved from a global context. As a result, request handling is self-contained in Rocket: handlers are regular functions with regular arguments. All request handling information should be typed. Because the web and HTTP are themselves untyped(or stringly typed, as some call it), this means that something or someone has to convert strings to native types. Rocket does this for you with zero programming overhead. Decisions should not be forced. Templates, serialization, sessions and just about everything else are all pluggable, optional components. While Rocket has official support and libraries for each of these, they are completely optional and swappable. Getting Started1cargo new hello-rocket --bin Add Dependencies 123[dependencies]rocket = \"0.3.3\"rocket_codegen = \"0.3.3\" 12345678910111213#![feature(plugin)]#![plugin(rocket_codegen)]extern crate rocket;#[get(\"/\")]fn index() -&gt; &amp;'static str { \"Hello World\"}fn main () { rocket::ignite().mount(\"/\", routes![index]).launch();} It creates an index route, mount the route at the / path, and launches the application. Compile and run the program with cargo run, you should see the following: 1234567891011🔧 Configured for development. =&gt; address: localhost =&gt; port: 8000 =&gt; log: normal =&gt; workers: [core count * 2] =&gt; secret key: generated =&gt; limits: forms = 32KiB =&gt; tls: disabled🛰 Mounting '/': =&gt; GET /🚀 Rocket has launched from http://localhost:8000 OverviewRocket provides primitives to build web servers and applications with Rust: the rest is up to you. In short, Rocket provides routing, pre-processing of requests and psot-processing of response. Your application code instructs Rocket what to pre-process and post-process and fills the gaps between pre-processing and post-processing. LifeCycleRocket’s main task is to listen for incoming web prequests, dispatch the request to the application code, and retur a response to the client. We call the process that goes form request to response the ‘lifecycle’. The lifecycle can be summarized as following sequence of steps: Routing Rocket parse an incoming HTTP request into native structure that your code operates on indirectly. Rocket determines which request handler to invoke by matching against route attributes declared in your application. Validation Rocket validates the incoming request against types and guards present in the matched route. If validation fails, Rocket forwards the request to the next matching route or calls an error handler. Processing The request handler associated with the route is invoked with validated arguments. This is the main business logic of an application. Processing completes by returning a Response. Response The returned Response is processed. Rocket generates the appropriate HTTP response and sends it to the client. This completes the lifecycle. Rocket continues listening for requesting, restarting the lifecycle for each incoming request. RoutingRocket applications are centered around routes and handlers. A route is a combination of: A set of parameters to match an incoming request against. A handler to process the request and return a response. A handler is simply a function that takes an arbirary number of arguments and returns any arbitrary type. The parameters to match against include static paths, dynamic paths, path segments, forms, query string, request format specifiers and body data. Rocket uses attributes, which look like function decoration in other languages to make declaring routes easy. Routes are declared by annotating a function, the handler, with a set of parameters to match against. A complete route declaration looks like this: 1234#[get(\"/world\")]fn world() -&gt; &amp;'static str { \"Hello World\"} This declare the world route to match against the static path /world on incoming GET requests. The world route is simple, but additional route parameters are necessary when building more interesting application. MountingBefore Rocket can dispatch requests to a route, the route needs to be mounted. Mounting a route is like namespacing it. Routes are mounted via the mount method on a Rocket instance. A Rocket instance is typically created with the racket::ignite() static method. The mount method takes: A path to namespace a list of routes under. A list of route handlers through the routes! macro, typing Rocket’s code generation to your application. For instance, to mount the world route we declared above, we can write the following: 1rocket::ignite().mount(\"/hello\", routes![world]); This create a new Rocket instance via the ignite function and mounts the world route to the /hello path. As a result, GET requests to the /hello/world path will be directed to the world function. NamespacingWhen a route is declared inside a module other than the root, you may find yourself with unexpected errors when mounting: 123456789mod other { #[get(\"/world\")] pub fn world() -&gt; String { \"Hello World\" }}fn main () { rocket::ignite().mount(\"/hello\", routes![world]);} This occurs because the routes! macro implicitly converts the route’s name into the name of a structure generated by Rocket’s code generation. The solution is to name the route by a module path instead: 1rocket::ignite().mount(\"/hello\", routes![other::world]); LaunchingNow that Rocket knows about the route, you can tell Rocket to start accepting requests via the launch method. The method starts up the server and wait for incoming requests. When a request arrives, Rocket finds the matching route and dispatches the requests to the route’s handler. We typically call launch from the main function. Our complete Hello World application thus looks like: 12345678910111213#![feature(plugin)]#![plugin(rocket_codegen)]extern crate rocket;#[get(\"/world\")]fn world() -&gt; String { \"Hello World\"}fn main () { rocket::ignite().mount(\"/hello\", routes![world]).launch();}","link":"/2017/11/06/Rocket-of-Rust/"},{"title":"Quick Reference of D3","text":"Selectionsd3.select()Returns a reference to the first element found. d3.selectAll()Returns references to all found elements selection.append()Takes a selection, creates a new element inside of it, then returns a reference to the newly created element. 1const newCirlce = svg.append('circle') selection.remove()Takes a selection, removes it from the DOM, and returns a reference to the deleted selection. selection.text()Takes a selection, sets its text content, and returns a reference to the acted-upon selection. selection.attr()Takes a selection, sets an attribute value, and returns a reference to the acted-upon selection. selection.style()Takes a selection, sets an inline CSS style, and returns a reference to the acted-upon selection. selection.classed()Takes a selection, adds or remove a class, and returns a reference to the acted-upon selection; true adds the specified class, false removes it. selection.each()Takes a selection, and runs an arbitrary function for each element in the selection, with the this context set to the element being acted upon. 1d3.selectAll('circle').each(zoomAndEnhance) Dataselection.data()Takes a selection, calculates the difference between the number of elements and number of data value, and binds the array of data value to any existing elements(or not existing placeholder elements). selection.datum()Takes a selection, and binds a single data value to a single element. 1svg.append('path').datum(dataset).attr('d', line) selection.enter()Takes a selection and returns a subselection of ‘new’ placeholder elements. selection.merge()Takes a selection and merges it with another specified selection, returning a newly merged selection. 1bars.enter().append('rect').merge(bars) // merge enter subselection with existing selection. selection.exit()Takes a selection and returns a subselection of ‘exiting’ elements. selection.remove()Takes a selection and removes associated elements from the DOM. 1bars.exit().remove() function (d) { … }Use anonymouse functions to access data values bound to element via d. function (d, i) { … }Including i to get the index value of each element in the selection. selection.fitler()Takes a selection and returns a new (sub)selection 12345d3.selectAll('circle') .filter(function (d) { return d &gt; 15 }) .style('color', 'red') d3.csv()Loads an external CSV file, parses the contents into JSON, then hands off the results to a callback function. 123d3.csv('food.csv', function(data) { console.log(data)}) d3.json()Loads an external JSON file, parse the content into JSON, then hands off the results to a callback function. d3.request()Loads an arbitrary external file, then hands off the result to a callback function. 1234d3.request('interesting_data.txt') .get(function (res) { // Do something }) Transitionsselection.transition()Takes a selection, and initiates a new transition, so values specified after this point will be interpolated over time(rather than set immediately). 1234d3.selectAll('circle') .attr('cx', 0) .transition() .attr('cx', 100) selection.delay()Takes a transition, and sets the delay, in milliseconds. 12345d3.selectAll('circle') .attr('cx', 0) .transition() .delay(1000) .attr('cx', 100) transition.duration()Takes a transition and sets the duration in milliseconds. transition.ease()Takes a transition and sets the easing to be used. transition.on()Takes a transition, and binds a function to be executed at either the start or end. 1234567d3.selectAll('circle') .attr('cx', 0) .transition() .attr('cx', 100) .on('end', function () { console.log('All done') }) Scaled3.scaleLinear()Creates a new linear scale function. scaleLinear.domain()Sets a linear scale’s input domain. scaleLinear.range()Sets a linear scale’s output range. scaleLinear.rangeRound()Sets a linear scale’s output range, and have all values output by the scale rounded to the nearest whole number. scaleLinear.nice()Expands a linear sclae’s domain to the nearest round values. 1xScale.nice() scaleLinear.clamp()Forces any values output by this scale to be constrainted (rounded to be) within the specified range. 1xScale.clamp(true) d3.min()Returns the smallest value in an array. d3.max()Returns the largest value in an array. Axesd3.axisTop, d3.axisRight, d3.axisBottom, d3.axisLeftCreate a new axis generator function, with specified orientation. axis.scale()Takes an axis, and specifies the scale to be used. axis.ticks()Takes an axis, and specifies a target number of ticks to be used. axis.tickValues()Takes an axis, and specifies the values to be labeled with ticks. selection.call()Takes a selection, and calls an arbitrary method to act upon the selection; commonly used to generate an axis. 1svg.append('g').call(xAxis) Interactivityselection.on()Takes a selection, and binds an event listener 12d3.select('#button') .on('click', () =&gt; { ... }) d3.select(this)Within an anonymous function, this refers to the element current being acted upon Numebrs, Dates, and Timesd3.range()Generates an array of sequential numbers. 1d3.range(5); // Returns [0, 1, 2, 3, 4] d3.format()Creates a new number formatter, for convertiing numbers to strings. d3.timeParse()Creates a new time parser, for converting strings to Date Object. 12const parseTime = d3.timeParse(\"%m/%d/%y\")parseTime('02/20/17') d3.timeFormat()Creates a new time formatter, for converting Data Object to strings. 12const formatTime = d3.timeFormat(\"%b %e\")formatTime(new Date)","link":"/2017/07/11/Quick-Reference-of-D3/"},{"title":"Rxjs API","text":"CreateYou can create an Observable from scratch by using the Create operator. You pass this operator a function that accepts the observer as its parameter. Write this function so that it behaves as an Observable – by calling the observer’s onNext, onError, and onCompleted methods appropraitely. A well-formed finite Observable must attempt to call either the observer’s onCompleted method exactly once or its onError method exactly once, and must not thereafter attempt to call any of the observer’s other methods. 12345678910111213141516171819202122var source = Rx.Observable.create(function(observer) { observer.onNext(32) observer.onCompleted() // this is optional. return function () { console.log('disposed') }})var subscription = source.subscribe( function (x) { console.log('Next: ' + x) } function (err) { console.log('Error: ' + err) } function () { console.log('Completed') }) DeferDo not create the Observable until the observer subscribes, and create a fresh Observable for each observer. The Defer operator waits until an observer subscribes to it, and then it generates an Observable, typically with an Observable factory function. It does this afresh for each subsciber, so although each subscriber may think it is subscribing to the same Observable, in fact each subscriber gets its own individual sequence. In some circumstances, waiting until the last minute to generate the Observable can ensure that this Observable contains the freshest data.] 1234567891011121314151617var source = Rx.Observable.defer(function () { return Rx.Observable.return(42)})var subscription = source.subscribe( function (x) { console.log('Next: ' + x) } function (err) { console.log('Error: ' + err) } function () { console.log('Completed') }) Empty/Never/ThrowEmpty create an Observable that emits no items but terminates normally Never create an Observable that emits no items and does not terminates Throw create an Observable that emits no items and terminates with an error The Empty, Never, Throw operators generate Observables with very specific and limited behavior. These are useful for testing purposes, and sometimes also for combining with other Observables or as parameters to operators that expect other Observables as parameters. 12345var source = Rx.Observable.empty()var source = Rx.Observable.never()var source = Rx.Observable.return(52).selectMany(Rx.Observable.throw(new Error('error'))) FromConvert various other objects and data types into Observables. When you work with Observables, it can be more convenient if all of the data you mean to work with can be represented as Observables, rather than as a mixture of Observables and other types. This allows you to use a single set of operators to govern the entire lifespan of the data stream. Iterables, for example, can be thought of as a sort of synchronous Observable; Futures, as a sort of Observable that always emits only a single item. By explicitly converting such objects to Observables, you allow them to interact as peers with other Observale. In RxJS, the from operator converts an array-like or iterable object into an Observable that emits the items in that array or iterable. A String, in this context, is treated as an array of characters. The operator also takes three additional, optional parameters: a transforming function that takes an item from the array or iterable as input and produces an item to be emmited by the resulting Observable as output a second argument to pass into","link":"/2017/05/08/Rxjs-API/"},{"title":"RxjsV6","text":"animationFrame - scheduler1const animationFrame: any; Perform task when window.requestAnimationFrame would fire. When animationFrame scheduler is used with delay, it will fall back to async scheduler behaviour. Without delay, animationFrame scheduler can be used to create smooth browser animations. It makes sure scheduled task will happen just before next browser content repaint, thus performing animations as efficiently as possible.","link":"/2018/07/10/RxjsV6/"},{"title":"Short Clip of RxJS","text":"CreationRx.Observable.create is an alias for the Observable constructor, and it takes one argument: the subscribe function. 1234var observable = Rx.Observable.create(function subscribe (observer) { observer.next(1) // ...}) Observable can be created with create, but usually we use the so-called creation operators, like, of, from, interval, etc. Subscription12345observable.subscribe({ next: console.log, error: console.error, complete: () =&gt; console.log('done'),}) Subscribing to an Observable is like calling a function, providing callbacks where the data will be delivered to. ExecutionThe code inside Observable.create(function subscribe (observer) { /*...*/ }) represents an Observable execution, a lazy computation that only happens for each Observer that subscribes. The execution produces multiple values over time, either synchronous or asynchronous. There are three types of values on Observable Execution can deliver: ‘Next’ notification: sends a value such as a Number, a String, an Object, etc. ‘Error’ notification: sends a JavaScript Error or exception. ‘Complete’ notification: does not send a value. In an Observable Execution, zero to infinite Next notifications may be delivered. If either an Error or Complete notification is delivered, then nothing else can be delivered afterwards. It’s a good idea to wrap any code in subscribe with try/catch block that will deliver an Error notification if it catches an exception: 123456789var observable = Rx.Observable.create(function subscribe (observer) { try{ observer.next(1) observer.next(2) observer.complete() } catch (err) { observer.error(err) }}) Disposing Observable ExecutionsBecause Observable Executions may be infinite, and it’s common for an Observer to want abort execution in finite time, we need an API for cancelling an execution. Since each execution is exclusive to one Observer only, once the Observer is done receiving values, it has to have a way to stop the execution, in order to avoid wasting computation power or memory resources. observable.subscribe will return the Subscription object. 1var subscription = observable.subscribe(x =&gt; console.log(x)) The Subscription represents the ongoing execution, and has a minimal API which allows you to cancel that execution. 1subscription.unsubscribe() When you subscribe, you get back a Subscription, which represents the ongoing execution. Just call unsubscribe() to cancel the execution. You can return a custom unsubscribe function within function subscribe() 123456789var observale = Rx.Observable.create(function subscribe (observer) { var intervalID = setInterval(() =&gt; { observer.next('hi') }, 1000) return function unsubscribe() { clearInterval(intervalID) }}) ObserverAn Observer is a consumer of values delivered by an Observable. Observers are simply a set of callbacks, one of each type of notification delivered by the Observable: next, error, complete. 12345var observer = { next: console.log, error: console.error, complete: () =&gt; console.log('done'),} To use the observer, provide it to the subscirbe of an Observable. When subscribing to an Observable, you may also just provide the callbacks as arguments, without being attached to an Observer object. 1234567observable.subscribe(console.log)// it will be treated asobservable.subscribe({ console.log, err =&gt; console.error('Observer got an error: ' + err), () =&gt; console.log('Observable got a complete notification'),}) SubscriptionA Subscription is an object that represents a disposable resource, usually the execution of an Observable. A subscription has one important method, unsubscribe, that takes no arguments and just disposes the resources held by the subscription. Subscriptions can also be put together, so that a call to an unsubscribe() of one Subscription may unsubscribe multiple Subscriptions. You can do this by ‘ading’ one subscription into another: 12345678var observable1 = Rx.Observable.interval(300)var observable2 = Rx.Observable.interval(500)var subscription = observable.subscribe(x =&gt; console.log('first: ' + x))var childSubscription = observable2.subscribe(x =&gt; console.log('second: ' + x))subscription.ad(childSubscription)subscription.unsubscribe() SubjectA RxJS Subject is a special type of Observable that allows values to multicasted to many Observers. While plain Observable are unicast(each subscribed Observer owns an independent execution of the Observable), Subjects are multicast. A Subject is like an Observable, but can mutlicast to many Observers. Subjects are like EventEmitter: they maintain a registry of many listener. Every Subject is an Observable. Given a Subject, you can subscribe to it, providing an Observer, which will start receiving values normally. Every Subject is an Observer. It is an object with the methods next(), error(e), and complete(). 123456789101112131415var subject = new Rx.Subject()subject.subscribe({ next: (v) =&gt; console.log('observerA: ' + v)})subject.subscribe({ next: (v) =&gt; console.log('observerB: ' + v)})// as observablesubject.next(1)subject.next(2)var observable = Rx.Observable.from([1,2,3])// as observerobservable.subscribe(subject) multicasted ObservablesA multicasted Observable uses a Subject under the hood to make multiple Observers see the same Observable execution. 1234567891011121314var source = Rx.Observable.from([1, 2, 3])var subject = new Rx.Subject()var multicasted = source.multicast(subject)// There are, under the hood, `subject.subscribe({...})`multicasted.subscribe({ next: v =&gt; console.log(`observerA ${v}`)})multicasted.subscribe({ next: v =&gt; console.log(`observerB ${v}`)})// This is, under the hood, `source.subscribe(subject)`multicasted.connect() multicast returns an Observable that looks like a normal Observale, but works like a subject when it comes to subscribing. multicast returns a COnnectableObservable, which is simply an Observable with the connect method. The connect method is important to determine exactly when the shared Observable execution will start. Because connect() does source.subscribe(subject) under the hood, connect() returns a Subscription, whcih you can unsubscribe from in order to cancel the shared Observable execution. Reference CountingCalling connect() manually and handling the Subscription is often cumbersome. Ususally we want to automatically connect when the first Observer arrives, and automatically cancel the shared execution when the last Observer unsubscribe. Consider the following example where subscriptions occurs as outlined by this list: First Observer subscribes to the mutlicasted Observable. The multicasted Observable is connected The next value 0 is delivered to the first Observable. Second Observer subscribes to the multicasted Observable. The next value 1 is delivered to the first Observer. The next value 1 is delivered to the second Observer. First Observer unsubscribes from the mutlicasted Observable. The next value 2 is delivered to the second Observer. Second Observer unsubscribes from the mutlicasted Observable. The connection to the multicasted Observable is unsubscribed. 12345678910111213141516171819202122232425var source = Rx.Observable.interval(500)var subject = new Rx.Subject()var multicasted = source.multicast(subject)var subscription1, subscription2, subscriptionConnectsubscription1 = multicasted.subscribe({ next: v =&gt; console.log('observerA: ' + v)})subscriptionConnect = multicasted.connect()setTimeout(() =&gt; { subscription2 = multicasted.subscribe({ next: v =&gt; console.log('observerB: ' + v) })}, 600)setTimeout(() =&gt; { subscription1.unsubscribe()}, 1200)setTimeout(() =&gt; { subscription2.unsubscribe() subscriptionConnect.unsubscribe()}, 2000) If we wish to avoid explicit calls to connect(), we can use ConnectableObservable’s refCount() method(reference Counting), which returns an Observable that keeps track of how many subscribers it has. When the number of subscribers increases from 0 to 1, it will call connect() for us, which starts the shared execution. Only when the number of subscribers decreases from 1 to 0 will it be fully unsubscribed, stopping further execution. refCount makes the multicasted Observable automatically start executing when the first subscriber arrives and stop executing when the last subscriber leaves. Below is an example: 1234567891011121314151617181920212223242526var source = Rx.Observable.interval(500)var subject = new Rx.Subject()var refCounted = source.multicast(subject).refCount()var subscription1, subscription2, subscriptionConnectconsole.log('observerA subscribed')subscription1 = refCounted.subscribe({ next: v =&gt; console.log('observerA: ' + v)})setTimeout(() =&gt; { console.log('observerB subscribed') subscription2 = refCounted.subscribe({ next: v =&gt; console.log('observerB: ' + v) })}, 600)setTimeout(() =&gt; { console.log('observerA unsubscribed') subscription1.unsubscribe()}, 1200)setTimeout(() =&gt; { console.log('observerB unsubscribed') subscription2.unsubscribe()}, 2000) The refCount() method only exists on ConnectableObservable, and it returns an Observable, not another ConnectableObservable. BehaviorSubjectOne of the variant of Subjects is the BehaviorSubject, which has a notion of ‘the current value’. It stores the latest value emitted to its consumers, and whenever a new Observer subscribes, it will immediately receive the ‘current value’ from the BehaviorSubject. BehaviorSubjects are useful for representing ‘values over time’. For instance, an event stream of birthdays is a Subject, but the stream of a person’s age would be a BehaviorSubject. ReplaySubjectA ReplaySubject is similar to a BehaviorSubject in that it can send old values to new subscribers, but it can also record a part of the Observable execution. A ReplaySubject records multiple values from the Observable execution and replays them to new subscribers. When creating a ReplaySubject, you can specify how many values to replay: 12345678910111213141516var subject = new Rx.ReplaySubject(3) // buffer 3 values for new subscriberssubject.subscribe({ next: v =&gt; console.log('ObserverA: ' + v)})subject.next(1)subject.next(2)subject.next(3)subject.next(4)subject.subscribe({ next: v =&gt; console.log('ObserverB: ' + v)})subject.next(5) You can also specify a window time in milliseconds, besides of the buffer size, to determine how old the recorded values can be. 123var subject = new Rx.ReplaySubject(3, 500)// ... AsyncSubjectThe AsyncSubject is a variant where only the last value of the Observale execution is sent to its observers, and only when the execution completes. 1234567891011121314151617var subject = new Rx.AsyncSubject()subject.subscribe({ next: v =&gt; console.log('ObserverA: ' + v)})subject.next(1)subject.next(2)subject.next(3)subject.next(4)subject.subscribe({ next: v =&gt; console.log('ObserverB: ' + v)})subject.next(5)subject.complete() OperatorsAn Operator is a function which creates a new Observable based on the current Observable. This is a pure operation: the previous Observable stays unmodified. An Operator is essentially a pure function which takes one Observable as input and generates another Observable as output. Subscirbing to the output Observable will also subscribe to the input Observable. 1234567891011121314function multiplyTen(input) { var output = Rx.Observable.create(function subscribe(observer) { input.subscribe({ next: v =&gt; observer.next(10 * \u0006v), error: err =&gt; observer.error(err), complete: () =&gt; observer.compelte() }) }) return output}var input = Rx.Observable.from([1, 2, 3])var output = multiplyTen(input)output.subscribe(x =&gt; console.log(x)) Notice that a subscribe to output will cause input Observable to be subscirbed. It’s called operator subscription chain. Instance OperatorsInstance operators are methods on Observable instances. 123456789101112Rx.Observable.prototype.multiplyByTen = function multiplyByTen () { var input = this return Rx.Observable.create(function subscirbe (observer) { input.subscribe({ next: v =&gt; observer.next(10 * v), error: (err) =&gt; observer.error(err), complete: () =&gt; observer.complete(), }) })}var observable = Rx.Observable.from([1, 2, 3]).multiplyByTen() Instance operators are functions that use the this keyword to infer waht is the input Observable. Static OperatorsStatic operators are functions attached ot the Observable class directly. A static operator uses no this keyword internally, but instead relies entirely on its arguments. Static Operators are usually used to create Observables from scratch. 1var observable = Rx.Observable.interval(1000 /* number of milliseconds */) Some combination operators may be static, such as merge, combineLatest, concat, etc. These make sense as static operators because they take multiple Observables as input, not just one.","link":"/2017/08/01/Short-Clip-of-RxJS/"},{"title":"Scaling Node.js App","text":"Strategies of ScalabilityThe workload is the most popular reason we scale our applications, but it’s not the only reason. We also scale our applications to increase their availability and tolerance to failure. CloningThe easiest thing to do to scale a big application is to clone it mulitple times and have each cloned instance handle part of the workload(with a load balancer). This does not cost a lot in term of development time and it’s highly effective. This strategy is the minimum you should do and Node.js has the built-in module, cluster, to make is easier for you to implement the cloning strategy on a single server. DecomposingWe can also scale an application by decomposiing it based on functionalities and services. This means having mulitple, different applications with different code bases and sometimes with their own dedicated databases and User Interfaces. This strategy is commonly associated with the term Microservice, where micro indicates that those services should be small as possible, but in reality, the size of the service is not what’s important but rather the enforement of loose coupling and high cohesion between services. SplittingWe can also split the application into multiple instances where each instance is responsible for only a part of the application’s data. This strategy is often named horizontal partitioning, or sharding, in database. Data partitioning requires a lookup step before each operation to determine which instance of the application to use. Successfully scaling a big application should eventually implement all three strategies. The Cluster ModuleThe cluster module can be used to enable load balancing over an environement’s multiple CPU cores. It’s based on the child process module fork method and it basically allows us to fork the main application process as many times as we have CPU cores. It will then take over and load balance all requests to the main process across all forked processs. The cluster module is Node’s helper for us to implement the cloning scalability strategy, but only on one machine. When you have a big machine with a lot resources or when it’s easier and cheaper to add more resources to one machine ratherthan adding new machine, the cluster module is a greate option for a really quick implementation of the cloning strategy. Even small machines usually have multiple cores and even if you’re not worried about the load on your Node server, you should enable the cluster module anyway to increase your server availability and fault-tolerance. It’s a simple step and when using a process manager like PM2, for example, it becomes as simple as just providing an argument to the launch command. The structure of what the cluster module does is simple. We create a master process and that master process forks a number of worker processes and manage them. Each worker process represents an instance of the application that we want to scale. All incoming requests are handled by the master process, which is the one that decides which worker process should handle the incoming request. The master process’s job is easy because it actually just uses a round-robin algorithm to pick a worker process. This is enabled by default on all platform except windows and it can be globally modified to let the load-balancing be handled by the operation system self. The round-robin algorithm distributes the load evenly across all available processes on a rotational basis. The first request is forwarded to the first worker process, the second to the next worker process in the list, and so on. When the end of the list is reached, the algorithm starts again from the beginning. Load-Balancing an HTTP ServerLet’s clone and load balance a simple HTTP server using the cluster module. Here’s the simple Node’s hello-world example server slightly modified to simulate some CPU work before responding: 123456789101112// server.jsconst http = require('http')const pid = process.pidhttp.createServer((req, res) =&gt; { for (let i = 0; i &lt; 1e7; i++) { // simulate CPU work } res.end(`Handled by process ${pid}`)}).listen(8080, () =&gt; { console.log(`Started process ${pid}`)}) Before we create a cluster to clone this server into multiple workers, let’s do a simple benchmark of how many requests this server can handle per second. We can use Apache benchmarking tool for that. After running the simple server.js code above, run this ab command: 1ab -c200 http://localhost:8080/ This command will test-load the server with 200 concurrent connections for 10 seconds. The single node server was able to handle about 51 requests per seconds. Now that we have a reference benchmark, we can scale the application with the cloning strategy using the cluster module. On the same level as the server.js file above, we can create a new file(cluster.js) for the master process with this content: 12345678910111213// cluster.jsconst cluster = require('cluster')const os = require('os')if (cluster.isMaster) { const cpu = os.cpus().length console.log(`Forking for ${cpu} CPUS`) for (let i = 0; i &lt; cpus; i++) { cluster.fork() }} else { require(./server)} In cluster.js, we first required both the cluster module and the os module, we use the os module to read the number of CPUS cores we can work with using os.cpus(). The cluster module gives us the handy Boolean flag isMaster to determine if this cluster.js file is being loaded as a master process or not. The first time we execute this file, we will be executing the master process and that isMaster flag will be set to true. In this case, we can instruct the master process to fork our server as many times as we have CPU cores. Now we just read the number of CPUs we have using the os module, then with a for loop over that number, we call the cluster.fork method. The for loop will simple create as many workers as the number of CPUs in the system to take advantage of all the available processing power. When the cluster.fork line is executed from the master process, the current file, cluster.js, is run again, but this time in worker mode with the isMaster flag set to false. There is actually another flag set to true in this case if you need to use it, which is the isWorker flag. When the application runs as a worker, it can start doing the actual work. This is where we need to define our server logic, which, for this example, we can do by requiring the server.js file that we already have. That’s basically it. That’s how easy it is to take advantage of all the processing power in a machine. To test the cluster, run the cluster.js file. It’s important to understand that these are completely different Node.js processes. Each worker process here will have its own event loop and memory space. When we now hit the web server multiple times, the requests will start to get handled by different worker processes with different process ids. The worker will not be exactly rotated in sequence because the cluster module performs some optimizations when picking the next worker, but the load will be somehow distributed among the different worker process. We can use the same ab command above to load-test this cluster of processes: Now the cluster can handle 181 requests per seconds. Broadcasting Messages to All WorkersCommunicating between the master process and the workers is simple because under the hood the cluster module is just using the child_process.fork API, which means we also have communication channels available between the master process and each workers. Based on the server.js/cluster.js example above, we can access the list of worker objects using cluster.workers, which is an object that holds a reference to all workers and can be used to read information about these workers. Since we have communication channels between master process and all workers, to broadcast a message to all them we just need a simple loop over all the workers: 123Object.values(cluster.workers).forEach(worker =&gt; { worker.send(`Hello Worker ${worker.pid}`)}) We simple used Object.values to get an array of all workers from the cluster.workers object. Then for each worker we can use the send function to send over any value that we want. In a worker file, server.js in our example, to read a message received from this master process, we can register a handler for the message event on the global process object: 123process.on('message', (msg) =&gt; { console.log(`Message from master: ${msg}`)}) Every worker received a message from the master process. Note how the workers did not start in order. Let’s make this communication example a little bit more practical. Let’s say we want our server to reply with the number of users we have created in our database. We will create a mock function that returns the number of users we have in the database and just have it square its value every time it’s called: 123456// **** Mock DB Callconst numberOfUsersInDB = function () { this.count = this.count || 5 this.count = this.count * this.count return this.count} Every time numberOfUsersInDB is called, we’ll assume that a database connection has been made. In the master process mode, we can use the same loop to broadcast the users count value to all workers: 12345678910111213// Right After the fork loop within the isMaster=true blockconst updateWorkers = () =&gt; { const usersCount = numberOfUsersInDB() Object.values(cluster.workers).forEach(worker =&gt; { worker.send({ usersCount, }) })}updateWorkers()setInterval(updateWorkers, 10000) Here we’re invoking updateWorkers for the first time and then invoking it every 10 seconds using a setInterval. This way, every 10 seconds, all workers will receive the new user count value over the process communication channel and only one database connection will be made. In the server code, we can use the userCount value using the same message event handler. We can simply cache that value with a module global variable and use it anywhere we want. 12345678910111213141516const http = require('http')const pid = process.pidlet usersCounthttp.createServer((req, res) =&gt; { for (let i = 0; i &lt; 1e7; i++); res.write(`Handled by process: ${pid}`) res.end(`Users: {usersCount}`)}).listen(8080, () =&gt; { console.log(`Start process ${pid}`)})process.on('message', msg =&gt; { usersCount = msg.usersCount}) The above code makes the worker web server respond with the cached usersCount value. If you test the cluster code now, during the first 10 seconds you’ll get ‘25’ as the users count from all workers(and only one DB request would be made). Then after another 10 seconds, all workers would start reporting the new user count: 625(and only one DB request would be made). This is all possible thanks to the communication channels between the master process and all workers. Increasing Server AvailabilityOne of the problems in running a single instance of a Node application is that when that instance crashes, it has to be restarted. This means some downtime between these two actions, even if the process was automated as it should. This also applies to the case when the server has to be restarted to deploy new code. With one instance, there will be downtime which affects the availability of the system. When we have multiple instances, the availability of the system can be easily increased with just a few extra lines of code. To simulate a random crash in the server process, we can simply do a process.exit call inside a timer that fires after a random amount of time: 1234// In server.jssetTimeout(() =&gt; { process.exit(1) // death by random timeout}, Math.random() * 10000) When a worker process exits like this, the master process will be notified using the exit event on the cluster model object. We can register a handler for that event and just fork a new worker process when any worker process exits. 12345678// Right after the fork loop within the isMaster=true blockcluster.on('exit', (worker, code, signal) =&gt; { if (code !== 0 &amp;&amp; !worker.exitedAfterDisconnect) { console.log(`Worker ${worker.id} crashed. Starting a new worker...`) cluster.fork() }}) It’s good to add the if condition above to make sure the worker process actually crashed and was not manually disconnected or killed by the master process itself. If the main process is going to kill the worker, it can use the disconnect methods on the worker and in that case, the exitedAfterDisconnect flag will be set to true. The if statement above will guard to not fork a new worker for that case. If we run the cluster with the handler above(and the random crash in server.js), after a random number of seconds, workers will start to crash and the master process will immediately fork new workers to increase the availability of the system. You can actually measure the availability using the same ab command and see how many requests the server will not be able to handle overall. Zero-downtime RestartsWe have multiple instances running, so instead of restarting them together, we can simply restart them one at a time to allow other workers to continue to serve requests while one worker is being restarted. Implementing this with the cluster module is easy. Since we don’t want to restart the master process once it’s up, we need a way to send this master process a command to instruct it to start restarting its workers. This is easy on Linux system because we can simply listen to a process signal like SIGUSR2, which we can trigger by using the kill command on the process id and passing that signal: 1234// In Nodeprocess.on('SIGUSR2', () =&gt; { ... })// To trigger that$ kill -SIGUSR2 PID This way, the master process will not be killed and we have a way to instruct it to start doing something. SIGUSR2 is a proper signal to use here because this will be a user command. If you’re wondering why not SIGUSR1, it’s because Node uses that for its debugger and you want to avoid any conflicts.. When the master process receives the SIGUSR2 signal, that means it’s time for it to restart its workers, but we want to do that one worker at a time. This simply means the master process should only restart the next worker when it’s done restarting the current one. 12345678910111213141516function restartWorker = (workerIndex) =&gt; { const worker = workers[workerIndex] if (!worker) return worker.on('exit', () =&gt; { if (!worker.exitedAfterDisconnect) return console.log(`Exited process ${worker.process.pid}`) cluster.fork().on('listening', () =&gt; { restartWorker(workerIndex + 1) }) }) worker.disconnect()}restartWorker(0) Inside the restartWorker function, we got a reference to the worker to be restarted and since we will be calling this function recursively to form a sequence, we need a stop condition. When we no longer have a worker to restart, we can just return. We then basically want to disconnect this worker (using worker.disconnect), but before restarting the next worker, we need to fork a new worker to replace this current one that we’re disconnecting. We can use the exit event on the worker itself to fork a new worker when the current one exists, but we have to make sure that the exit action was actually triggered after a normal disconnect call. We can use the exitedAfterDisconnect flag. If this flag is not true, the exit was caused by something else other than our disconnect call and in that case, we should just return and do nothing. But if the flag is set to true, we can go ahead and fork a new worker to replace the one that we’re disconnecting. When this new forked worker is ready, we can restart the next one. However, remember that the fork process is not synchronous, so we can’t just restart the next worker after the fork call. Instead, we can monitor the listening event on the newly forked worker, which tells us that this worker is connected and ready. When we get this event, we can safely restart the next worker in sequence. That’s all we need for a zero-downtime restart. Process monitors like PM2, make all the tasks we went through so far extremely easy and give a log more features to monitor the health of a Node’s application. Shared State and Sticky Load BalancingWhen we load balance a Node application, we lost some features that are only suitable for a single process. This problem is somehow similar to what’s known in other languages as thread safety, which is about sharing data between threads. In our case, it’s sharing data between worker processes. For example, with a cluster setup, we can no longer cache things in memory because every worker process will have its own memory space, If we cache something in one worker’s memory, other workers will not have access to it. If we need to cache things with a cluster setup, we have to use a separate entity and read/write to that entity’s API from all workers. This entity can be a database server or if you want to use in-memory cache you can use a server like Redis or create a dedicated Node process with a read/write API for all other workers to communicate with. Don’t look at this as a disadvantage, because using a separate entity for your application caching is part of decomposing your app for scalability. You should probably be doing that even if you’re running on a single core machine.","link":"/2017/08/22/Scaling-Node-js-App/"},{"title":"Simple Api of Mongoose","text":"Two methods to connect to Mongo DB mongoose.connect mongoose.createConnection 123456const dbURL = 'mongodb://...'const dbOptions = { user: 'db_user', pass: 'db_pass'}const adminConnection = mongoose.createConnection(dbURL, dbOptions) Close Connection123456789101112131415mongoose.connection.close(() =&gt; { console.log('Connection cvlosed')})adminConnection.close(() =&gt; { console.log('adminConnection closed')})// auto close when process exitprocess..on('SIGINT' () =&gt; { mongoose.connection.close(() =&gt; { console.log('Mongoose disconnected through app termination') process.exit(0) })}) Cache Error123mongoose.connection.on('error', (err) =&gt; { console.log('Mongoose connection error: ' + err)}) db.js123456789101112131415161718192021222324252627// /model/db.jsconst mongoose = require('mongoose')const dbURL = 'mongodb://...'mongoose.connect(dbURL)mongoose.connection.on('connected', () =&gt; { console.log('Mongoose connected to ' + dbURL)})mongoose.connection.on('error', (err) =&gt; { console.log('Mongoose connection error: ' + err)})mongoose.connection.on('disconnected', () =&gt; { console.log('Mongoose disconnected')})process.on('SIGINT', () =&gt; { mongoose.connection.close(() =&gt; { console.log('Mongoose disconnected through app termination') })})// app.jsdb = require('./model/db') Schema and Model in Mongoose Everything in Mongoose starts with a Schema. Each schema maps to a MongoDB collection and defines the shape of the documents within that collection. 12345678const Schema = mongoose.Schemaconst userSchema = new Schema({ name: String, pass: String, email: String, createTime: String, lastLogin: String,}) Schema to define table structure. Model to manipulate collection. Use model to create documents in Mongodb. 123456789101112131415161718192021222324// create modelconst User = mongoose.model('User', userSchema)// create instance, namely documentconst newUser = new User({ ...})// insert document to dbnewUser.save((err, doc) =&gt; { err &amp;&amp; console.error(err) console.log('doc is saved')})// create and insertUser.create({...}, (err, doc) =&gt; { err &amp;&amp; console.error(err) console.log('doc saved')})// add staitc methodsuserSchema.statics.findUsersByType = function (type, cb) { return this.find({ type: this.type }, cb)} Model.$where(argument: string | Function): , creates a Query and specifies a $where condition 1Blog.$where('this.username.indexOf(\"val\") !== -1').exec(function (err, docs) {}) Model#increment() search1User.find({ type: 'type' }).where('age').gt(2).limit(10).exec() remove123User.remove({ type: 'type' }, (err, res) =&gt; { err &amp;&amp; console.error(err)}) update1234567User.find({ type: 'type' }).update({ $set: { date: new Date() }}, (err) =&gt; { err &amp;&amp; console.error(err)}) More…","link":"/2017/07/10/Simple-Api-of-Mongoose/"},{"title":"Short Clip of TypeScript(1)","text":"Basic TypesBoolean, Number, String, Array, Tuple, Enum, Any, Void, Null, Undefined, Never 123456789101112131415161718192021222324252627282930313233// Booleanlet isDone: boolean: false// Numberlet decimal: number = 6// Stringlet color: string = 'red'// Arraylet list: number[] = [1, 2, 3]let list: Array&lt;number&gt; = [1, 2, 3]// Tuplelet x: [string, number] = ['hello', 10]// Enumenum Color {Red, Green, Blue}let c: Color = Color.Green // 1// Anylet notSure = 5notSure = 'not sure'// Voidfunction warnUser (): void { alert('This is my warning message')}// Neverfunction error(message: string): never { throw new Error(message)} Note: By default null and undefined are subtypes of all other types, that means you can assign null and undefined to something like number However, when using --strictNullChecks flag, null and undefined are only assignable to void and their respective types. This helps avoid many common errors. In cases where you want to pass in either a string or null or undefined, you can use the union type string | null | undefined. Type assertions123let someValue = 'this is a string'let strLength: number = (&lt;string&gt;someValue).lengthlet strLength: number = (someValue as string).length Variable DeclarationsInterfaces One of TypeScript’s core principles is that type-checking focuses on the shape that value have. This is sometimes called ‘duck typing’ or ‘structural subtyping’. In TypeScript, interface fill the role of naming these types and are a powerful way of defining contracts within your code as well as contracts with code outside your project. 12345678function printLabel(labelObj: { label: string }) {}// Orinterface LabelledValue { label: string;}function printLabel(labelObj: LabelledValue) {} Optional Properties1234interface SquareConfig { color?: string; width?: number;} Readonly Properties123456interface Point { readonly x: number; readonly y: number;}let ro: ReadonlyArray&lt;number&gt; Note: Readonly Array 123456let a: number[] = [1, 2, 3]let ro: ReadonlyArray&lt;number&gt; = aro[0] = 12 // errorro.push(5) // errorro.legnth = 100 // errora = ro // error You can’t assign the entire ReadonlyArray back to a normal array. Instead, you could do this: 1a = ro as number[] Object literals get special treatment and undergo excess property checking when assigning them to other variables, or passing them as arguments. If an object literal has any properties that the target type doesn’t have, you’ll get an error. Adding Index SignatureAdd a string index signature if you’re sure that the object can have some extra properties that are used in some special way. 12345interface SquareConfig { color?: string; width?: number; [propName: string]: any;} Function TypesTo describe a function type with an interface, we give the interface a call signature. This is like a function declaration with only the parameter list and return type given. Each parameter in the parameter list requires both name and type. 12345678910interface SearchFunc { (source: string, subString: string): boolean;}let mySearch: SearchFuncmySearch = function (source: string, subString: string) { let result = source.search(subString) return result &gt; -1} Indexable TypesSimilarly to how we can use interfaces to describe function types, we can also describe types that we can ‘index into’ like a[10] or ageMap['daniel']. Indexable types have an index signature that describes the types we can use to index into the object, along with the corresponding return types when indexing. 123456789101112interface StringArray { [index: number]: string;}let myArray: StringArraymyArray = ['Bob', 'Fred']let myStr: string = myArray[0]// readonlyinterface ReadonlyStringArray { readonly [index: number]: string} Class TypesImplementing an interface. One of the most common uses of interfaces is explicitly enforcing a class meets a particular contract. 1234567891011121314inerface ClockInterface { currentTime: Date; setTime(d: Date);}class Clock implements ClockInterface { currentTime: Date setTime(d: Date) { this.currentTime = d } constructor (h: number, m: number) { }} Interface describe the public side of the class, rather than both the public and private side. This prohibits you from using them to check that a class also have particular types for the private side of the class instance. Difference between the static and instance side of classes. When working with classes and interfaces, it helps to keep in mind that a class have two types: the type of static side and the type of the instance side. When a class implements an interface, only the instance side of the class is checked. Notice: constructor sits in the static side, it is not included in this check. Extending Interfaces123456789101112interface Shape { color: string;}interface Square extends Shape { sideLength: number;}let square = &lt;Square&gt;{}square.color = 'blue'square.sideLength = 10 An interface can extend multiple interface, creating a combination of all of the interfaces. 12345678910111213interface Shape { color: string;}interface PenStroke { penWidth: number;}interface Square extends Shape, PenStroke { sideLength: number;}let square = &lt;Square&gt;{} Hybrid Types123456789101112interface Counter { (start: number): string; interval: number; reset(): void;}function getCounter(): Counter { let counter = &lt;Counter&gt;function (start: number) counter.interval = 123; counter.reset = function () {} return counter} Interface Extending Classes When an interface type extends a class type it inherits members of the class but not their implementations. It is as if the interface has declared all of the members of the class without providing an implementation. Interface inherits even the private and protected members of a base class. This means that when you create an interface that extends a class with private or protected members, that interface type can only be implemented by that class or a subclass of it. 1234567891011class Control { private state: any;}interface SelectableControl extends Control { select(): void}class Button extends Control { select() {}} ClassesExample: 1234567891011class Greeter { greeting: string; constructor (message: string) { this.greeting = message; } greet() { return 'Hello, ' + this.greeting; }}let greeter = new Greeter('world') Class Inheritance12345678910111213141516171819202122232425262728293031class Animal { name: string; constructor(theName: string) { this.name = theName } move(distanceInMeters: number = 0) { console.log(`${this.name} moved ${distanceInMeters}`) }}class Snake extends Animal { constructor (name: string) { super(name) } move(distanceInMeters = 5) { console.log('Slithering...') super.move(distanceInMeters) }}class Hores extends Animal { constructor (name: string) { super(name) } move(distanceInMeters = 45) { console.log('Galloping...') super.move(distanceInMeters) }} Public, Private, Protected Modifiers Public by default Private: when a member is marked private, it cannot be accessed from outside of its containing class. Protected: The protected modifier acts much like the private modifier with exception that members declared protected can also be accessed by instance of deriving classes. Namely the protected property can be used in instance method. Readonly Modifier Readonly properties must be initialized at their declaration or in the constructor. Accessors TypeScript supports getters/setters as a way of intercepting accesses to a member of an object. 123456789class Employee { private _fullName: string; get fullName(): string { return this._fullName; } set fullName(newName: string) { this._fullName = newName; }} Static Properties1234567891011class Grid { static origin = {x: 0, y: 0} calculateDistanceFromOrigin(point: {x: number, y: number}) { let xDist = (point.x - Grid.origin.x) let yDist = (point.y - Grid.origin.y) retrun Math.sqrt(xDist * xDist + yDist * yDist) / this.scale } constructor (public scale: number) { // ... }} Abstract Classes Abstract classes are base classes from which other classes may be derived. They may not be instantiated directly. Unlike an interface, an abstract class may contain implementation detail for its members. The abstract keyword is used to define abstract classes as well as abstract methods within an abstract class. 123456abstract class Animal { abstract makeSound: void; move(): void { console.log('roaming the earth...') }} Methods within an abstract class that are marked as abstract do not contain an implementation and must be implemented in derived classes. Abstract methods share a similar syntax to interface methods. Both define the signature of a method without including a method body. 1234567891011121314151617181920abstract class Department { constructor (public name: string) { } printName (): void { } abstract printMeetng () :void // must be implemented in derived classes}class AccountDepartment extends Department { constructor (){ super('Accounting and Auditing') } printMeetng (): void { // ... } generateReports () : void { // ... }} Advanced TechniquesConstructor Functions When you declare a class in TypeScript, you are actually creating multiple declarations at the same time. The first is the type of the instance of the class. 123456789101112class Greeter { greeting: string; constructor (message: string) { this.greeting = message; } greet () { return 'Hello, ' + this.greeting; }}let greeter: Greeter;greeter = new Greeter('world') Here when we say let greeter: Greeter, we’re using Greeter as the type of instance of the class Greeter. Almost we use the class constructor as a type. Using a class as an interface A class declaration creates two things: a type representing instances of the class, and a constructor function. 12345678class Point { x: number; y: number;}interface Point3d extends Point { z: number;}","link":"/2017/07/31/Short-Clip-of-TypeScript(1)/"},{"title":"Simple Example of DAPP","text":"Use truffle to init ProjectContract of Adoption1234567891011121314151617// contracts/Adoption.solpragma solidity ^0.4.4;constract Adoption { address[16] public adopters; function adopt (uint petId) public returns (uint) { require(petId &gt;= 0 &amp;&amp; petId &lt;= 15); adopters[petId] = msg.sender; return petId; } function getAdopters () public returns (addresss[16]) { return adopters; }} Test12345678910111213141516171819202122232425262728// test/TestAdoption.solpragma solidity ^0.4.4;import \"truffle/Assert.sol\";import \"truffle/DeployedAddress.sol\";import \"../contracts/Adoption.sol\";contract TestAdoption { Adoption adoption = Adoption(DeployedAddress.Adoption()); function testUserCanAdoptPet () { uint returnedPetId = adoption.adopt(8); uint expected = 8; Assert.equal(returenedPetId, expected, \"Adoption of Pet Id 8 should be recorded\"); } function testGetAdopterAddressByPetId () { address expected = this; address adopter = adoption.adopters(8); Assert.equal(adopter, expected, \"Owner of Pet Id 8 should be recorded\"); } function testGetAdopterAddressByPetIdInArray () { address expected = this; address[16] memory adopters = adoption.getAdopters(); Assert(expected, adopters[8], \"Owner of Pet Id 8 should be recoreded\"); }} CompileMigrateTestRPCMetaMaskUIinitWeb31234567if (typeof web3 !== 'undefined') { App.web3Provider = web3.currentProvider web3 = new Web3(App.web3Provider)} else { App.web3Provider = new web3.providers.HttpProvider('http://localhost:8545') web3 = new Web3(App.web3Provider)} initContract12345$.JSON('Adoption.json', function (data) { const AdoptionArtifact = data App.contracts.Adoption = TruffleContract(AdoptionArtifact) App.contracts.Adoption.setProvider(App.web3Provider)}) Invoke Contract123456789let adoptionInstanceApp.contracts.Adoption.deployed().then(function (instance) { adoptionInstance = instance return adoptionInstance.getAdopters.call()}).then(function (adopters) { // ...}) 12345678910111213141516const petId = 8let adoptionInstanceweb3.eth.getAccounts(function (error, accounts) { if (error) { console.error(error.message) } const account = accounts[0] App.contracts.Adoption.deployed() .then(function (instance) { adoptionInstance = instance return adoptionInstance.adopt(petId, { from: account }) }) .then(function (result) { // ... })})","link":"/2017/09/13/Simple-Example-of-DAPP/"},{"title":"Simple Example of Line Chart With D3v4","text":"Import D31&lt;script src=\"https://d3js.org/d3.v4.min.js\"&gt;&lt;/script&gt; Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// set sizeconst margin = { top: 50, right: 50, bottom: 50, left: 50,}const width = window.innerWidth - margin.left - margin.rightconst height = window.innerHeight - margin.top - margin.bottom// Set Point Numberconst n = 21// X scale will use the index of our dataconst xScale = d3.scaleLinear() .domain([0, n-1]) // input .range([0, width]) // output// Y scale will use the randomly generated numberconst yScale = d3.scaleLinear() .domain([0, 1]) // input .range([height, 0]) // output// d3's line generatorconst line = d3.line() .x(function(d, i) { return xScale(i) // set the x value for the line generator }) .y(function(d, i) { return d.y // set the y value for the line generator }) .curve(d3.curveMonotoneX) // apply smoothing to the lineconst dataset = d3.range(n) .map(function(d) { return { y: d3.randomUniform(1)() } })// Add SVG to the pageconst svg = d3.select('body') .append('svg') .attr('width', width + margin.left + margin.right) .attr('height', height + margin.top + margin.bottom) .append('g') .attr('transform', `translate(${margin.left}, ${margin.top})`)// Call the X axis in a group tagsvg.append('g') .attr('class', 'x axis') .attr('transform', `translate(0, ${height})`) .call(d3.axisBottom(xScale)) // Create an axis component with d3.axisBottom// Call the Y axis in a group tagsvg.append('g') .attr('class', 'y axis') .call(d3.axisLeft(yScale))// Append the path, bind the data, and call the line generatorsvg.append('path') .datum(dataset) // bind data to the path .attr('class', 'line') .attr('d', line) // call the line generator// Append a circle for each data pointsvg.selectAll('.dot') .data(dataset) .enter().append('circle') .attr('cx', function (d, i) { return xScale(i) }) .attr('cy', function (d, i) { return yScale(dy) }) .attr('r', 5) Add style123456789.line { fill: none; stroke: cyan; storke-width: 3;}.dot { fill: #ffab00; stroke: #FFF;}","link":"/2017/08/29/Simple-Example-of-Line-Chart-with-D3v4/"},{"title":"Simple About InfluxDB","text":"Install InfluxDB on MacOS12brew updatebrew install influxdb To run influxDB at startup, run this command 1ln -sfv /usr/local/opt/influxdb/*.plist ~/Library/LaunchAgents Now, to start InfluxDB, run this command(Accept the request of incoming connections in the window that appears) 1influxd -config /usr/local/etc/influxdb.conf Check if InfluxDB worksInfluxDB exposes an API with which one can easily check its good working condition. Here’s what you will receive in return for this curl command 123456curl -sl -I localhost:8086/pingHTTP/1.1 204 No ContentContent-Type: application/jsonRequest-Id: 95b307f8-5d6b-11e7-8002-000000000000X-Influxdb-Version: v1.3.0Date: Fri, 30 Jun 2017 08:10:31 GMT Terminology, difference with SQL databaseLike all non-relational database, InfluxDB for its own vocabulary your need to know before starting Measurement is equivalent to SQL table Tags is similar to a indexed column in a SQL database Fields is similar to the column not indexed in a SQL database Points is equivalent to line(row) in a SQL database Database Management MethodsThere are 6 methods to manage database CREATE DATABASE DROP DATABASE DROP SETS DELETE DROP MEASUREMENT DROP SHARD Create a Database1CREATE DATABASE &lt;database_name&gt; [WITH [DURATION &lt;duration&gt;] [REPLICATION &lt;n&gt;] [SHARD DURATION &lt;shard_duration&gt;] [NAME &lt;retention-policy-name&gt;]] Basic Setting database_name: name of the database duration: you can set the period of data retention(conversation) but it makes more sense to implement a retention policy. Delete a database (drop database)1DROP DATABASE &lt;database_name&gt; Establish a retention policyInfluxDB incorporates a system of automatic deletion of data. It is the policy of Retention. Spent some time, data is automatically deleted from the base. This mechanism is very convenient because it for a good grasp of size of the base and we don’t have to worry about the maintenance operation. Free to each set the lifetime of any particular measure. If you want to follow the temperature of its microprocessor, one less may be sufficient, instead the retention policy must be more flexible if we want to compare the temperature in a House form one year to the other. It will also think about the system upstream, you don’t have to store a measurement of atmosphere temperature every 10 seconds! A measurement per minutes, 15 minutes, that’s enough. Instead in an industrial process, we certainly want to go for the second… or a lot less. We therefore for 3 methods Create: to create a rule of conservation of data Alter: to change a rule Drop: to remove a rule Create a retention policy1CREATE RETENTION POLICY &lt;name_politic_retention&gt; ON &lt;name_database&gt; DURATION: &lt;duration&gt; REPLICATION: &lt;n&gt; [SHARD DURATION &lt;duration duration_shard&gt;] [DEFAULT] Parameters name_politic_retention: a short name without spaces of preference name_database: the database on which applies the retention policy duration: duration of data retention. It’s a literal expression which must respect the convention InfluxDB duration_shard: the duration of storage of the data in the buffer zone n: number of replication(required), put 1 if no cluster installed 1CREATE RETENTION POLICY 'one_day_only' WE 'NOAA_water_database' DURATION 1 d REPLICATION 1 This policy keeps the records during a day(one_day_only) based NOAA_water_database. The data are stored in space shard 1 day. Replication 1 indicates that a copy of each item is copied in the cluster. Modify retention policy(alter retention policy)This method allows to change an existing retention policy 1ALTER ... Destroyed a retention policy(drop retention policy)1DROP RETENTION ... Discover the InfluxDB ShellNow we know some methods, we will provide to run some test","link":"/2017/06/30/Simple-about-InfluxDB/"},{"title":"Solidity CheatSheet","text":"Global VariablesBlock block.coinbase: address - current block miner’s address block.difficulty: uint - current block difficulty block.gaslimit: uint - current block gaslimit block.number: uint - current block number block.timestamp: uint - current block timestamp Msg msg.data: bytes - complete calldata msg.gas: uint - remaining gas msg.sender: address - sender of the message(current call) msg.value: uint - number of wei sent with the message Now now: uint - current block timestamp(alias for block.timestamp) Tx tx.gasprice: uint - gas price of the transaction tx.origin: address - sender of the transaction (full call chain) Global Functions assert(bool condition): abort execution and revert state changes if condition is false(use for internal error) require(bool condition): abort execution and revert state changes if condition is false(use for malformed input or error in external component) revert(): abort execution and revert state changes block.blockhash(uint blockNumber) returns (bytes32): hash of the given block - only works for 256 most recent blocks sha256(…) returns (bytes32): compute the SHA-256 hash of the (tightly packed) arguments keccak256(…) returns (bytes32): compute the Ethereum-SHA-3(Keccak-256) hash of the (tightly packed) arguments sha3(…) returns (bytes32): alias for keccak256 ecrecover(bytes32 hash, uint8 v, bytes32 r, bytes32 s) returns (address): recover address associated with the public key from elliptic curve signature addmod(uint x, uint y, uint k) returns (uint): compute (x + y) % k where the addition is performed with arbitrary precision and does not wrap around at 2 ** 256 mulmod(uint x, uint y, uint k) returns (uint): compute (x * y) % k where the addition is performed with arbitrary precision and does not wrap around 2 ** 256 selfdestruct(address recipient): destroy the current contract, sending its funds to the given address suicide(address recipient): alias for selfdestruct .balance: uint256: balance of the Address in Wei .send(uint256 amount) returns (bool): send given amount of Wei to Address, returns false on failure .transfer(uint256 amount): send given amount of Wei to Address, throws on failure. Scope Variables this: current contract’s type - the current contract, explicitly convertable to address super: the contract one level higher in the inheritance hierarchy Function Visibility Specifier public: visible externally and internally(creates accessor function for storage/state variables) private: only visible in the current contract external: only visible externally(only for functions) - i.e. can only be message-called) internal: only visible internally Modifiers pure: for function - disallows modification or access of state - this is not enforced yet view: for function - disallows modifiction of state - this is not enforced yet payable: for function - allows them to receive Ether together with a call constant: for state variable - disallow assignment(except initialization), does not occupy storage slot contant: for function - same as view anonymous: for events - does not store event signature as topic indexed: for event parameters - store the parameter as topic","link":"/2017/11/10/Solidity-CheatSheet/"},{"title":"Solidity Style Guide","text":"Layout4 spaces per indentation level Use spaces for indentation Use blank lines 1234567contract A { // ...}contract B { // ...} Blank lines may be omitted between groups of related one-liners 1234contract A { function spam(); function ham();} Use UTF-8 or ASCII encoding Place import statements at the top of the file Functions should be be grouped according to their visibility and ordered: constructor fallback function (if exists) external public internal private Within a grouping, place the constant functions last. Use white spaces in expressions Avoid extraneous whitespaces inthe following situations: immediately inside parenthesis, brackets or braces, with the exception of single line function declaration. 12345spam(ham[1], Coin({name: \"han\"})):// exceptionfunction singleLine() { spam() } More than one space around an assignment or other operator to align with 123x = 1;y = 2;long_variable = 3; Don’t include a whitespace in the fallback function 1234567function() { // ...}// not function () { // ...} For control structure whose body contains a single statement, omitting the braces is ok if the statement is contained on a single line 1234if (x &lt; 10) x += 1;else x -= 1; Function declaration 1234567891011121314151617181920212223242526function increment(uint x) returns (uint) { return x + 1;}// visibility precedes custom modifierfunction increment(uint x) public onlyOwner returns (uint) { return x + 1;}// long parameters listfunction increment( uint x1, uint x2, uint x3, uint x4, uint x5, uint x6,) { // ...}// long visibility modifier listfunction increment (uint x) public onlyOwner priced{ // ...} Stirng should be quoted with double-quotes. Contract and Library Names should be named using the CapWords style. 12SimpleToken,SmartBank, Event Names should use CapWords Function Names should use CamelCase Function Arguments should use CamelCase Local and State Variables should use CamelCase Constants should be named with all captial letters with underscores seperating words: MAX_BLOCKS Modifier should use CamelCase","link":"/2017/11/14/Solidity-Style-Guide/"},{"title":"Simple Usage of SW","text":"Register123456navigator.serviceWorker.register('your_service_worker,js', { scope: 'your_path_name' }).then((worker) =&gt; { console.log('[SW] Registration succeeded.')}).catch((err) =&gt; { console.log('[SW] Registration failed with ' + err)}) Unregister12345678910111213141516navigator.serviceWorker.getRegistration('your_service_worker.js', { scope: 'your_path_name' }).then((worker) =&gt; { if (worker &amp;&amp; worker.unregister) { worker.unregister() .then((isUnregistered) =&gt; { if (isUnregistered) { console.log('[SW] Unregister succeeded') } else { console.log('[SW] Unregister failed') } }) }}).catch((err) =&gt; { console.log('[SW] Unregister failed with ' + err)}) Worker.js123456789101112self.addEventListener('install', (event) =&gt; { console.log('[Worker] installing')})self.addEventListener('activate', (event) =&gt; { console.log('[Worker] ready')})self.addEventListener('fetch', (event) =&gt; { console.log(event.request.url) return}) LifeCycle Download and ParseAfter registration of Service Worker, browser will download and parse the script from specified url. 12345678910/* In main.js */if ('serviceWorker' in navigator) { navigator.serviceWorker.register('./sw.js') .then((worker) =&gt; { console.log('Service Worker Registered') }) .catch((err) =&gt; { console.log('Service Worker Failed to Register') })} InstallingAfter successfully parsed, browser will install the Service Worker. Once the Install finished, the worker will emit install event, and waiting for activating. If the install failed, Service Worker will be Redundant 123456789/* In sw.js */self.addEventListener('install', (event) =&gt; { event.waitUntil( caches.open(currentCacheName) .then((cache) =&gt; { return cache.addAll(arrayOfFilesToCache) }) )}) If there is an event.waitUntil(promiseObj) method in the event, the installing event will not be successful until the Promise within it is solved. If the Promise is rejected, the install event fails and the Service Worker became redundant Installed / WaitingIf the installation is successful, the Service Worker moves to the installed(also called waiting) state. In this state it is a valid, but not yet active, worker. It is not yet in control of the document., but rather is waiting to take control form the current worker. ActivatingThe activating state will be triggered for a waiting Service Worker in one of the following scenarios - if there is no current active worker already if the self.skipWaiting() method is called in the Service Worker script if the user has navigated away from the page, thereby releasing the previous active worker. if a specified period of time has passed, thereby releasing the previous active worker During the activating state, the active event in the Service Worker script is carried out. In a typical activate event, we clear files from old caches. 12345678910111213/* In sw.js */self.addEventListener('activate', (event) =&gt; { event.waitUntil( // get all the cache names caches.keys().then((cacheNames) =&gt; { return Promise.all( cacheNames.filter((cacheName) =&gt; { }) ) }) )}) ActivateIf the worker is activated, it will emit active event, and take over all fetch from page. If active failed, the worker will be Redundant RedundantOnce a worker is redundant, it won’t have effect on page. Dependencies fetch promise CacheStorage: store Cache Object Cache: store Request/Response Pair Object Example: Cache Static Resource listen to install to cache static resource listen to fetch to intercept request and return cached static Resource 12345678910111213141516171819202122232425262728293031var CACHE_NAME = 'my-site-cache-v1'var urlsToCache = [ '/', '/styles/main.css', '/script/main.js',]// cache resource after installationself.addEventListener('install', (event) =&gt; { // perform install steps event.waitUntil( caches.open(CACHE_NAME) .then((cache) =&gt; { console.log('Opened Cache') return cache.addAll(urlsToCache) }) )})// listen to fetch, use cache if cachedself.addEventListener('fetch', (event) =&gt; { event.responseWith( caches.match(event.request) .then((response) =&gt; { if (response) { return response } return fetch(event.request) }) )}) Version Controls1234567891011var deleteObsoleteCache = () =&gt; { return caches.keys().then((keys) =&gt; { var all = keys.map((key) =&gt; { if (key.indexOf(CACHE_PREFIX) !== -1 &amp;&amp; key.indexOf(CACHE_VERSION) === -1) { console.log('[SW] Delete cache: ' + key) return caches.delete(key) } }) return Promise.all(all) })} Whitelist1234567891011121314151617181920212223242526272829303132// resource whitelistconst allAssets = [ '//your.cdn.com/app.css', '//your.cdn.com/app.js',]// matchconst matchAssets = (requestUrl) =&gt; { const urlObj = new URL(requestUrl) const noProtocolUrl = urlObj.href.substr(urlObj.protocol.length) if (allAssets.includes(noProtocolUrl)) { return true } return false}// listen to fetch, proxy fetch matching Whitelistself.addEventListener('fetch', (event) =&gt; { try { const requestUrl = event.target.url const isGet = event.request.method === 'GET' const assetMatches = matchAssets(requestUrl) if (!assetMatches || !isGet) { return } const resource = cacheFirstResponse(event) event.responseWith(resource) } cache (err) { console.log('[SW] handle fetch event error') return }})","link":"/2017/07/01/Simple-usage-of-SW/"},{"title":"Some Concepts on BlockChain","text":"Getting BlockChain Data: Blocks; Transactions; Sending Transactions; Cryptocurrency Functions: Generating Private/Public keys, Hashing, Address Encoding etc; Creating transactions; Signing transactions; Support functions; Build A Block Receive the transaction broadcase; Verify the crypto in the transaction; Add it to the unconfirmed Pool; Do some hard maths on all the transactions in the pool; Broadcast the Block to the network; The Block is added to the blockchain; Blockchains as Distributed Database Everyone running the Bitcoin client is part of the network; New blocks are boradcast to the network; Everyone updates their local copy of the blockchain; If you’re behind the current height of the chain, you can ask other nodes for copies of the Blocks needed to catch-up; Implications: Tranactions take time to ‘confirm’; Each transaction, once it’s in an accepted block has a height; Each increase in blockchain height is called a confirmation; A transaction 5 blocks below the top of the chain is said to have ‘6 confirmations’; The merchant cant decide how many confirmations is sensible to warit for; Current default is it wait for 6 confirmations for anything of value; Blocks store data, in Bitcoin, it’s the transactions, but it could be any digital data; Blocks are created periodically(on average, 10mins for Bitcoin) by a process called ‘mining’; A block represents a set of events that have occurred over a particular time frame(ususally, since the previous block); Block aren’t identified by their height, but by their id; (may be multiple blocks at same height) Block id is the hash of the metadata in the block; Block id is a digial fingerprint of that block; Some metadata: A version number of the block format; A link to the previous block that came immediately before it; Merkle root of all the transactions in the block; Timestamp of when the block was created; Mining difficulty; Nonce for Proof-of-Work; All the transactions that were recorded in this block; All the transactions in the block are used to create the Merkle Root Hash; It’s added to the other metadata in the header, with a nonce; We hash the whole thing, look at the resulting hash, if it starts with a required number of leading ‘0’(which means the hash need to be small enough), we’ve solved the block and broadcast it; If not, we increment the nonce and try again; Repeat until we find the leading zero; Difficulty defines how many leading zeros when solveing the block; The more zeros we need to find, the more attemps at hashing we need. More hashing power becomes the driving force amongst miners; Miner insert a special transaction at the beginning of block called ‘coinbase’ transaction. This ‘pays’ the miner for the work they did, and collects the transaction fees from all the transactions; Transactions Transactions tranfer control of coins from inputs to outputs; Control is enforced by cryptography; Construct A Transaction You need the address of the person you’re going to pay; Find UTXO’s Unspent Transaction Outputs that exceed the amount you wish to pay; Calculate the transaction fee(optional but recommended); Create the outputs with the correct scriptPubKey; scriptPubKey defines who can spend the coin by specifying a small verification program that is run in order to perform that verification. Sign the transaction details; Broadcast the transaction, see if it works;","link":"/2017/07/25/Some-Concepts-on-BlockChain/"},{"title":"Some Note on Blockchain","text":"Getting BlockChain Data: Blocks; Transactions; Sending Transactions; Cryptocurrency Functions: Generating Private/Public keys, Hashing, Address Encoding etc; Creating transactions; Signing transactions; Support functions; Build A Block Receive the transaction broadcase; Verify the crypto in the transaction; Add it to the unconfirmed Pool; Do some hard maths on all the transactions in the pool; Broadcast the Block to the network; The Block is added to the blockchain; Blockchains as Distributed Database Everyone running the Bitcoin client is part of the network; New blocks are boradcast to the network; Everyone updates their local copy of the blockchain; If you’re behind the current height of the chain, you can ask other nodes for copies of the Blocks needed to catch-up; Implications: Tranactions take time to ‘confirm’; Each transaction, once it’s in an accepted block has a height; Each increase in blockchain height is called a confirmation; A transaction 5 blocks below the top of the chain is said to have ‘6 confirmations’; The merchant cant decide how many confirmations is sensible to warit for; Current default is it wait for 6 confirmations for anything of value; Blocks store data, in Bitcoin, it’s the transactions, but it could be any digital data; Blocks are created periodically(on average, 10mins for Bitcoin) by a process called ‘mining’; A block represents a set of events that have occurred over a particular time frame(ususally, since the previous block); Block aren’t identified by their height, but by their id; (may be multiple blocks at same height) Block id is the hash of the metadata in the block; Block id is a digial fingerprint of that block; Some metadata: A version number of the block format; A link to the previous block that came immediately before it; Merkle root of all the transactions in the block; Timestamp of when the block was created; Mining difficulty; Nonce for Proof-of-Work; All the transactions that were recorded in this block; All the transactions in the block are used to create the Merkle Root Hash; It’s added to the other metadata in the header, with a nonce; We hash the whole thing, look at the resulting hash, if it starts with a required number of leading ‘0’(which means the hash need to be small enough), we’ve solved the block and broadcast it; If not, we increment the nonce and try again; Repeat until we find the leading zero; Difficulty defines how many leading zeros when solveing the block; The more zeros we need to find, the more attemps at hashing we need. More hashing power becomes the driving force amongst miners; Miner insert a special transaction at the beginning of block called ‘coinbase’ transaction. This ‘pays’ the miner for the work they did, and collects the transaction fees from all the transactions; Transactions Transactions tranfer control of coins from inputs to outputs; Control is enforced by cryptography; Construct A Transaction You need the address of the person you’re going to pay; Find UTXO’s Unspent Transaction Outputs that exceed the amount you wish to pay; Calculate the transaction fee(optional but recommended); Create the outputs with the correct scriptPubKey; scriptPubKey defines who can spend the coin by specifying a small verification program that is run in order to perform that verification. Sign the transaction details; Broadcast the transaction, see if it works;","link":"/2017/07/22/Some-Note-on-Blockchain/"},{"title":"Snippet of GitHub Actions","text":"Core Conceptions for GitHub Actions Workflow A configurable automated process Workflow run An instance of the workflow that runs when the pre-configured event occurs Workflow file The YAML file that defines the workflow configuration with at least one job. Job A defined task made up of steps. Each job is run in a fresh instance of the virtual environement. Step A step is a set of tasks performed by a job. Each step in a job executes in the same virtual environment, allowing the actions in that job to share information using the filesystem. Action Individual tasks that combined as steps to create a job. Actions are the smallest portable building block of a workflow. Configuring a workflowAbout workflows Store workflows in the .github/workflows directory in the root of the repository Create a workflow file At the root of the repository, create a directory named ./github/workflows to store the workflow files. In .github/workflows, add a .yml or .yaml file for the workflow. Use Workflow syntax for GitHub Actions reference documentation to choose events to trigger an action, add actions, and customize the workflows. Commit the changes in the workflow file to the branch where the workflow is desired to run. 1234567891011121314151617181920name: Greet Everyone# This workflow is triggered on pushes to the repositoryon: [push]jobs: build: # Job name is Greeting name: Greeting # This job runs on Linux runs-on: ubuntu-latest steps: # This step uses GitHub's hello-world-javascript-action - name: Hello World use: actions/hello-world-javascript-action@v1 with: who-to-greet: 'Mona the Octocat' id: hello # This step prints an output (time) from the previous step's action - name: Echo the greeting's time run: echo 'The time was $\\{\\{ steps.hello.outputs.time }}.' Configuring a build matrixTo test across multiple operating system, platforms, and language versions at the same time, a matrix could be set up. A build matrix provides different configurations for the virtual environment to test. 12345runs-on: $\\{\\{ matrix.os }}strategy: matrix:: os: [ubuntu-14.04, ubuntu-18.04] node: [6, 8, 10] Using the checkout actionThere are several standard actions you can use in your workflow. The checkout action is a standard action that you must include in your workflow before other actions when: Your workflow requires a copy of your repository’s code, such as when you’re building and testing your repository or using continuous integration. There’s at least one action in your workflow that is defined in the same repository. To use the standard checkout action without furthur specifications, including this step: 1- uses: actions/checkout@v1 Using v1 in this example ensures you’re using a stable version of the checkout action. The shallow clone your repository, or copy only the latest version of your repository, set the fetch-deptch with the with syntax: 123- uses: actions/checkout@v1 with: fetch-depth: 1 Referencing actions in your workflowTo reference actions in your workflow file with the correct syntax, you must consider where the action is defined. Workflows can use actions defined in A public repository The same repository where your workflow file references the actions A publised Docker container image on Docker Hub 12345678jobs: my_first_job: steps: - uses: actions/setup-node@v1 with: node-version: 10.x - uses: ./.github/actions/hello-world-action - uses: docker://alpine:3.8 Workflow syntax for GitHub ActionsnameThe name of the workflow. onRequired The name of the GitHub event that triggers the workflow.string, array and map are acceptable 12on: pushon: [push, pull_request] on..When using the push and pull_request events, you can configure a workflow to run on specific branches or tags 12345678on: push: branches: - master - 'release/*' tags: - v1 - v1.0 on..pathsWhen using the push and pull_request events, you can configure a workflow to run when at least one modified file matches a pattern defined in paths. 123456on: push: paths: - '*' - '!*.js' ``` jobsA workflow run is made up of one or more jobs. Jobs run in parallel by default. To run jobs sequentially, you can define dependencies on other jobs using the jobs.&lt;job_id&gt;.needs keywords. Each job runs in a fresh instance of the virtual environment specified by runs-on. jobs.Each job must have an id to associate with the job. The key job_id is a string and its value is a map of the job’s configuration data. You must replace &lt;job_id&gt; with a string that is unique to the jobs object. The &lt;job_id&gt; must start with a letter or _ and contain only alphanumeric characters, - or _. 12345jobs: my_first_job: name: My first job my_second_job: name: My second job jobs..nameThe name of the job displayed on GitHub jobs..needsIdentifies any jobs that must complete successfully before this job will run. It can be a string or array of string 123456jobs: job1: job2: needs: job1 job3: needs: [job1, job2] jobs.runs-onRequired The type of virtual host machine to run the job on. Each job runs with a fresh instance of the virtual environment specified by runs-on: Available virtual machine types are: ubuntu-latest, ubuntu-18.04 or ubuntu-16.04 windows-latest, windows-2019 or windows-2016 macOS-latest, macOS-10.14 jobs..stepsA job contains a sequence of tasks called steps. Steps can run commands, run setup tasks, or run an action in your repository, a public repository, or an action published in a Docker registry. Each step run in its own process in the virtual environment and has access to the workspace and filesystem. Because steps run in their own process, changes to environment variables are not preserved between steps. 12345678910111213141516name: Greeting from Monaon: pushjobs: my-job: name: My Job runs-on: ubuntu-latest steps: - name: Print a greeting env: MY_VAR: Hi there! My name is FIRST_NAME: Mona LAST_NAME: Octocat run: | echo $MY_VAR $FIRST_NAME $LAST_NAME. jobs..steps.idA unique identifier for the step. You can use the id to reference the step in contexts. jobs..steps.ifYou can use the if conditional to prevent a step from running unless a condition is met. Expression in an if conditional do not require the $\\{\\{ }} syntax. 1234steps: - name: My first step if: github.event_name == 'pull_request' &amp;&amp; github.event.action == 'unassigned' run: echo This event is a pull request that had an assignee removed jobs..step.nameA name for the step to display on GitHub. jobs..steps.usesSelects an action to run as part of a step in your job. An action is a reusable unit of code. The version of the action is strongly recommended to be included in the action by specifying a Git Ref, SHA, or Docker tag number. jobs..steps.withA map of the input parameters defined by the action. Each input parameter is a key/pair. Input parameters are set as environment variables. The variable is prefixed with INPUT_ and converted to uppercase. 123456789jobs: my_first_step: steps: - name: My first step uses: actions/hello_world@master with: first_name: Mona # INPUT_FIRST_NAME middle_name: The # INPUT_MIDDLE_NAME last_name: Octocat # INPUT_LAST_NAME jobs..steps.with.args// TODO: jobs.steps.with.entrypoint// TODO: jobs..steps.envSets environment variables for steps to use in the virtual environment. Public actions may specify expected environment variables in the README file. If you are setting a secret in an environment variable, you must set secrets using the secrets context. 1234steps: - name: My first step env: GITHUB_TOKEN: $\\{\\{ secrets.GITHUB_TOKEN }}","link":"/2019/09/16/Snippet-of-GitHub-Actions/"},{"title":"Start at Headless","text":"Run Chrome without chrome, it brings all modern web platform features provided by Chromium and the Blink rendering engine to the command line. A headless browser is a great tool for automated testing and server environments where you don’t need a visible UI shell. Starting Headless (CLI)The easiest way to get started with headless mode is to open the Chrome binary from the command line. If you’ve got Chrome 59+ installed, start Chrome with the -- headless flag: 12345chrome \\ --headless \\ # Runs Chrome in headless mode --disable-gpu \\ # Temporarily needed for now --remote-debugging-port=9222 \\ https://www.chromestatus.com # URL to open. Defaults to about:blank chrome should point to your installation of Chrome. Command line featuresIn some cases, you may not need to programmatically script Headless Chrome. There are some useful command line flags to perform common tasks. Printing the DOMThe --dump-dom flag prints document.body.innerHTML to stdout: 1chrome --headless --disable-gpu --dump-dom https://www.chromestatus.com/ Create a PDFThe --print-to-pdf flag creates a PDF of the page 1chrome --headless --disable-gpu --print-to-pdf https://chromestatus.com/ Taking screenshotsTo capture a screenshot of a page, use the --screenshot flag: 1234chrome --headless --disable-gpu --screenshot https://chromestatus.com/# Size of a standard letterhead.chrome --headless -disable-gpu --screenshot --window-size=1280,1696 https://chromestatus.com/ REPL modeThe --repl flag runs Headless in a mode where you can evaluate JS expression in the browser, right from the command line: 12345chrome --headless --disable-gpu --repl https://chromestatus.com/&gt;&gt;&gt; location.href{\"result\":{\"type\":\"string\",\"value\":\"https://www.chromestatus.com/features\"}}&gt;&gt;&gt; quit","link":"/2017/08/27/Start-at-Headless/"},{"title":"Start in Protobuf","text":"Protocol Buffers are a language-neutral, platform-neutral, extensible way of serializing structured data for use in commnucations protocols, data storage, and more, originally designed at Google. Protobuf.js is a pure JS implementation with TypeScript support for node.js and browser. It’s easy to use, blazingly fast and works out of the box with .proto files. InstallationNode.js 1npm install protobufjs 1var protobuf = require('protobufjs') Browsers 1&lt;script src=\"../protobuf.js\"&gt;&lt;/script&gt; DistributionsWhere bundle size is a factor, there are additional stripped-down versions of the full-library(~19kb gzipped) available that excldue certain functinality when working with JSON descriptor, and/or reflection only, see the light-library(~16kb gzipped) that excludes the parser. CommonJS entry point is: 1var protobuf = require('protobufjs/light') When working with statically generated code only, see the minimal library(~6.5kb gzipped) that also excludes reflection. CommonJS entry point is: 1var protobuf = require('protobufjs/minimal`) UsageBecause JS is a dynamically typed language, protobuf.js introduces the concept of a valid message in order to provide the best possible performance. Valid Message A valid message is an object not missing any required fields and exclusively composed of JS types understood by the wire format writer. There are two possible types of valid messages and the encoder is able to work with both these for convenience: Message Instance (explicit instance of message classes with default values on their prototype) always (have to) satisfy the requirements of a valid message by design. Plain JavaScript Objects that just so happen to be composed in a way satisfying the requirements of a valid message as well. In a nutshell, the wire format writer understoods the following types: Field Type Expected JS type(create, encode) Conversion (fromObject) s-/u-/int32s-/fixed32 number (32 bit integer) `value 0if signed&lt;br&gt;value &gt;&gt;&gt; 0` is unsigned s-/u-/int64s-/fixed64 Long-like(optimal)number(53 bit integer) Long.fromValue(value) with long.jsparseInt(value, 10) otherwise floatdouble number Number(value) bool boolean Boolean(value) string string String(value) bytes Uint8Array(optimal)Buffer(optimal under node)Array.&lt;number&gt;(8 bit integers) base64.decode(value) if a stringObject with non-zero.length is assumed to be buffer-like enum number (32 bit integer) Looks up the numeric id if a string message Valid Message Message.fromObject(value) Explicit undefined and null are considered as not set if the field is optional Repeated fields are Array.&lt;T&gt; Map fields are Object.&lt;string, T&gt; with the key being the string representation of the respective value or an 8 character long binary hash string for Long-likes. Types marked as optimal provide the best performance because no conversion step(i.e. number to low and high bits or base64 string to buffer) is required. For performance reasons, each message class provides a distinct set of methods with each method doing just one thing. This avoid unnecessary assertions / redundant operations where performance is a concern but also forces a user to perform verification explicityly where necessary. Methods Message.verify(message: Object): null | string Message.encode(message: Message | Object[, writer: Writer]): Writer Message.encodeDelimited(message: Message | Object[, writer: Writer]): Writer Message.decode(reader: Reader | Uint8Array): Message Message.toObject(message: Message[, options: ConversionOptions]): Object Message.verify(message: Object): null | string Verifies that a plain js object satisfies the requirements of a valid message and thus can be encoded without issues. Instead of throwing, it returns the error message as a string, if any: 123var payload = 'invalid (not an object)'var err = AwesomeMessage.verify(payload)if (err) throw Error(err) Message.encode(message: Message | Object[, writer: Writer]): Writer Encodes a message instance or valid plain javascript object. This method does not implicit verify the message and it’s up to user to make sure that the payload is a valid message. 1var buffer = AwesomeBuffer.encode(message).finish() Message.encodeDelimited(message: Message | Object[, writer: Writer]): Writer Works like Message.encode but additionally prepends the length of the message as a varint. Message.decode(reader: Reader): Message Decode a buffer to a message instance. If required fields are missing, it throws a util.ProtocolError with an instance property set to the so far decoded message. If the wire format is invalid, it throws an Error. 123456789try { var decodedMessage = AwesomeMessage.decode(buffer)} cache (e) { if (e instanceof protobuf.util.ProtocolError) { // e.instance holds the so far decoded message with missing required fields } else { // wire format is invalid }} Message.decodeDelimited(reader: Reader | Uint8Array): Message works like Message.decode but additionally reads the length of the message prepended as a varint Message.create(properties: Object): Message Creates a new message instance from a set of properties that satisfy the requirements of a valid message. Where applicable, it is recommended to prefer Message.create over Message.fromObject because it doesn’t perform possibly redundant conversion. 1var message = AwesomeMessage.create({ awesomeField: 'AwesomeString' }) Message.fromObject(object: Object): Message Converts any non-valid plain javascript object to a message instance using the conversion steps outlined within the table above. Message.toObject(message: Message[, options: ConversionOptions]): Object Converts a message instance to an arbitrary plain javascript object for interoperability with other libraries or storage. The resulting plain javascript object might still satisify the requirements of a vlaid message depending on the actual conversion options specified, but most of the time it does not. 123456789var object = AwesomeMessage.toObject(message, { enums: String, longs: String, bytes: String, defaults: true, arrays: true, objects: true, oneofs: true,}) For reference, the following diagram aims to display relationships between the different methods and the concepts of a valid message: In other words: verify indicates that calling create or encode directly on the plain object will [result in a valid message respectively] succeed. fromObject, on the other hand, does conversion from a broader range of plain objects to create valid message. ExamplesUsing .proto filesIt is possible to load existing .proto files using the full library, which parses and compiles the definitions to ready to use (reflection-based) message classes: 123456package awesomepackagesyntax = \"proto3\"message AwesomeMessage { string awesome_field = 1; becomes awesomeField} 1234567891011121314151617181920212223242526272829303132333435363738protobuf.load('awesome.proto', function(err, root) { if (err) { throw err } // Obtain a message type var AwesomeMessage = root.lookupType('awesomepackage.AwesomeMessage') // Exemplary payload var payload = { awesomeField: 'AwesomeField' } // Verify the payload if necessary(i.e. when possible incomplete or invalid) var errMsg = AwesomeMessage.verify(payload) if (errMsg) throw Error(errMsg) // Create a new message var message = AwesomeMessage.create(payload) // or use .fromObject if conversion is necessary // Encode a message to an Uint8Array(browser) or Buffer (node) var buffer = AwesomeMessage.encode(message).finish() // ... do something with message // Decode an Uint8Array(browser) or Buffer(node) to a message var message = AwesomeMessage.decode(buffer) // ...do something with message // If the application uses length-delimited buffers, there is also encodeDelimited and decodeDelimited. // Maybe conver the message back to a plain object var object = AwesomeMessage.toObject(message, { loings: String, enums: String, bytes: String, // see Conversions })}) Additionally, promise syntax can be used by omitting the callback, if preferred: 1protobuf.load('awesome.proto').then(root =&gt; {}) Using JSON DescriptorsThe library utilize JSON descriptor that are equivalent to a .proto definition. For example, the following is identical to the .proto definition seen above: 12345678910111213// awesome.json{ \"nested\": { \"AwesomeMessage\": { \"fields\": { \"awesomeField: { \"type\": \"string\", \"id\", 1 } } } }} JSON descriptor closely resemble the internal reflection structure: Exclusively using JSON descriptor instead of .proto files enables the use of just the light library(the parser isn’t requried in this case) A JSON descriptor can either be loaded the usual way: 123protobuf.load('awesome.json', function(err, root) { if (err) throw Error(err)}) Or it can be loaded inline: 1234var jsonDescriptor = require('./awesome.json') // exemplary for nodevar root = protobuf.Root.fromJSON(jsonDescriptor)// Continue at 'Obtain a message type' above More Info here Usage with TypeScriptThe library ships with its own type definitions and modern editors will automatically detect and use them for code completion. The npm package depends on @types/node because of Buffer and @types/long because of Long. If you are not building for node and/or using long.js, it should be safe to exclude them manually. Using the JS APIThe API shown above works pretty much the same with TypeScript. However, because everything is typed, accessing fields on instances of dynamically generated message classes requries either using bracket-notation(i.e. message[‘awesomeField’]), or explicit casts. 123456789101112131415import { load } from 'protobufjs'load('awesome.proto', function(err, root) { if (err) throw Error(err) const AwesomeMessage = root.lookupType('awesomepackage.AwesomeMessage') let message = AwesomeMessage.create({ awesomeField: 'hello' }) cnosole.log(`message = ${JSON.stringify(message)}`) let buffer = AwesomeMessage.encode(message).finish() console.log(`Buffer = ${Array.prototype.toString.call(buffer)}`) let decoded = AwesomeMessage.decode(buffer) console.log(`decoded = ${JSON.stringify(decoded)}`)})","link":"/2017/12/22/Start-in-Protobuf/"},{"title":"Simple Guide of Jest","text":"Install1yarn add --dev jest Simple Case123456// sum.jsfunction sum (a, b) { return a + b}module.exports = sum 12345678// sum.test.jsconst test = require('jest')const expect = require('expect')const sum = require('./sum')test('adds 1 + 2 to equals 3', () =&gt; { expect(sum(1, 2).toBe(3))}) With Babel1yarn add --dev babel-jest 12345678910// .babelrc{ \"presets\": [ [ \"env\", { \"targets\": { \"node\": \"current\" } }] ]} Jest will automatically define NODE_ENV as test. It will not use development section like Babel does by default when no NODE_ENV is set. babel-jest is automatically installed when installing Jest and will automatically transform files if a babel configuration exists in your project. To avoid this, you can explicitly reset the transform configuration option: In package.json 12345{ \"jest\": { \"transform\": {} }} GlobalsIn your test files, Jest puts each of its methods and objects into the global environment. You don’t need to require or import anything to use them. Methods afterAll(fn): Runs a function after all the tests in this file have completed. If the function returns a promise, Jest waits for that promise to resolve before continuing. This is often useful if you want to clean up some global setup state that is shared across tests. If afterAll is inside a describe block, it runs at the end of the describe block. afterEach(fn): Runs a function after each test in this file. If the function returns a promise, Jest waits for the promise to resolve before continuing. This is often useful if you want to clean up some temprary state that is created by each test. If afterEach is inside a describe block, it only runs after the tests that are inside this describe block. beforeAll(fn): similar to afterAll() beforeEach(fn): similar to afterEach() describe(name, fn): create a block that groups together several related tests in one ‘test suite’. For example, if you have a myBeverage object that is supposed to be delicious but not sour, you could test it with: 1234567891011121314const myBeverage = { delicious: true, sour: false,}describe('my beverage', () =&gt; { test('is delicious', () =&gt; { expect(myBeverage.delicious).toBeTruthy() }) test('is not sour', () =&gt; { expect(myBeverage.sour).toBeFalsy() })}) This isn’t required - you can just write the test block directly at the top level. describe.only(name, fn): You can use describe.only if you want to run only one describe block 123456789describe.only('my beverage', () =&gt; { test('is delicious', () =&gt; { expect(myBeverage.delicious).toBeTruthy() })})describe('my other beverage', () =&gt; { // ...will be skipped}) describe.skip(name, fn): you can use describe.skip if you do not want to run a particular describe block: 123456789describe('my beverage', () =&gt; { test('is delicious', () =&gt; { expect(myBeverage.delicious).toBeTruthy() })})describe.skip('my other beverage', () =&gt; { // ... will be skipped}) require.requireActual(moduleName): returns the actual module instead of a mock, bypassing all checks on whether the module should receive a mock implementation or not. require.requireMock(moduleName): returns a mock module instead of the actual module, bypassing all checks on whether the module should be required normally or not. test(name, fn): Also under the alias it(name, fn), all you need in a test file is that the test method which runs a test. For example, let’s say there’s a function inchesOfRain() that should be zero. Your whole test could be: 123test('did not rain', () =&gt; { expect(inchesOfRain()).toBe(0)}) The first argument is the test name; the second argument is a function that contains the expectations to test If a promise is returned from test, Jest will wait for the promise to resolve before letting the test complete. 12345test('has lemon in it', () =&gt; { return fetchBeverageList().then(list =&gt; { expect(list).toContain('lemon') })}) Even though the call to test will return right away, the test doesn’t complete until the promise resolves as well. test.only(name, fn): similar to describe.only() test.skip(name, fn): similar to describe.skip()","link":"/2017/05/31/Simple-Guide-of-Jest/"},{"title":"Styles in D3","text":"fillThe fill style will fill the element being presented with a specifed color. By default, most element will be filled with black. strokeThe stroke style applies a color to lines opacityThe opacity style has the effect of varying an element’s transparency. The valid range for opacity is from 0 to 1. We should make the distinction at this point that opacity affects the entire element, whereas the following fill-opacity and stroke-opacity affect only the fill and stroke respectively. fill-opacityThe fill-opacity style changes the transparency of the fill of an element. stroke-opacityThe stroke-opacity style changes the transparency of the stroke of an element. stroke-widthThe stroke-width style adjusts the width of the line of an element. The value specified when setting stroke-width in pixels. stroke-dasharrayThe stroke-dasharray style allows us to form element lines with dashes instead of solid lines. 1.style('stroke-dasharray', ('10, 3')) stroke-linecapThe stroke-linecap style allows control of the shape of the ends of lines. There are three shape options: butt: The line simply butts up to the starting or ending position and is cut off squarely. round: The line is rounded in propotionto its width. square: The line is squared off but exnteded in propotion to its width. stroke-linejoinThe stroke-linejoin style specifies the shape of the join of two lines. This would be used on path, polyline and polygon. There are three line join options: miter: The join is squared off as would be expected at the join of two lines. round: The outside portion of the join is rounded in proportion to its width. bevel: The join has a straight edged outer portion clipped off to provide a slightly more contoured effect while still being regular. writing-modeThe writing-mode style changes the orientation of the text so that it prints out top to bottom. It has a single option ‘tb’ that accomplishes this. glyph-orientation-verticalThe glyph-orientation-vertical style changes the rotation of the individual glyphs(characters) in text and if used in conjunction with the writing-mode style (and set to 0) will allow the text to be displayed vertically with the letters orientation vertically as well. 1234567holder.append('text') .style('fill', 'black') .style('writing-mode', 'tb') .style('glyph-orientation-vertical', 0) .attr('x', 200) .attr('y', 100) .text('Hello World')","link":"/2017/08/31/Styles-in-D3/"},{"title":"Start at Pug","text":"Install Pug1yarn add pug Overviewpug.compile() will compile the Pug source code into a JavaScript function that takes a data object(called locals) as an argument. Call that resultant function with your data, then it will return a string of HTML rendered with your data. The compiled function can be re-used, and called with different sets of data. 12// - template.pugp #{name}'s Pug source code! 123456789101112131415const pug = require('pug')// Compile the source codeconst compiledFunction = pug.compile('template.pug')// Render a set of dataconsole.log(compiledFunction({ name: 'Timothy'}))// \"&lt;p&gt;Timothy's Pug source code!&lt;/p&gt;\"// Render another set of dataconsole.log(compiledFunction({ name: 'Forbes'}))// \"&lt;p&gt;Forbes' Pug source code!&lt;/p&gt;\" Pug also provides the pug.render() family of functions that combine compileing and rendering into one step. However, the template function will be re-compiled every time render is called, which might impact performance. Alternatively, you can use the cache option with render, which will automatically store the compiled function into an internal cache. 123456const pug = require('pug')// Compile template.pug and render a set of dataconsole.log(pug.renderFile('template.pug', { name: 'Timothy'})) Use with ExpressPug fully integrates with Express, as a supported view engine. Production DefaultsIn Express, the environmental variables NODE_ENV is designed to inform the web application of the execution environment: whether it is in development or in production. Express and Pug automatically modify the defaults of a few options in production environment, to provide a better out-of-the-box experience for users. Specifically, when process.env.NODE_ENV is set to 'production', and Pug is used with Express, the compileDebug option is false by default, while the cache option is true. API ReferenceAll API mehtods accept the following set of options: filename: string The name of the file being compiled. Used in exceptions, and required for relative include and extend. Default to Pug basedir: string The root directory of all absolute inclusion doctype: string If the doctype is not specified as part of the template, you can specify it here. It is sometimes useful to get self-closing tags and remove mirroring of boolean attributes. filters: object Hash table of custom filters. Default to undefined self: boolean Use a self namespaces to hold the locals. It will speed up the compilation, but instead of writing variable you will have to write self.variable to access to property of the locals object. Default to false debug: boolean If set to true, the tokens and function body are logged to stdout compileDebug: boolean If set to true, the function source will be included in the compiled template for better error messages. It is enabled by default, unless used with express in production mode. globals: Array Add a list of global names to make accessible in templates cache: boolean If set to true, compiled functions are cached. filename must be set as the cache key. Only applies to render functions. Default to false inlineRuntimeFunctions: boolean Inline runtime functions instead of require-ing them from a shared version. For compileClient functions, the default is true(so that one does not have include the runtime). For all other compilation or rendering types, the default is false name: string The name of the template function. Only applies to compileClient function. Default to template. Methods pug.compile(source[, options]) Compile a Pug template to a function, which can be rendered multiple times with different locals. source: string the source pug template to compile options: An option object returns: function A function to generate the HTML from an object containing locals 1234var pug = require('pug')var compiledTemplate = pug.compile('string of pug', options)var html = compiledFunction(locals) pug.compileFile(path[, options]) Compile a Pug template from a file to a function, which can be rendered multiple times with different locals. path: string The path to a Pug file options: An option object returns: function A function to generate HTML from an object containing locals 123var pug = require('pug')var compiledTemplate = pug.compileFile('path to pug file', options)var html = compiledTemplate(locals) pug.compileClient(source[, options]) Compile a Pug template to a string of JavaScript, which can be used client side along with Pug runtime. source: string The Pug template to compile options: an option object returns: string A string of JavaScript representing a function 123var pug = require('pug')var compiledTemplate = pug.compileClient('string of pug', options)var html = compiledTemplate(locals) pug.render(source[, options[, callback]]) source: string The source pug template to render options: an options object callback: function Node.js-style callback receiving the rendered results. The callback is called synchronously. returns: string The resulting HTML String pug.renderFile(path[, options[, callback]]) path: string the path to the pug file to render option: an options object callback: function Node.js-style callback receiving the rendered results. This callback is called synchronously. returns: function The resulting HTML stirng AttributesTag attributes look similar to HTML(with optional commas), but their values are just regular JavaScript. 1a(href='google.com') Google =&gt; &lt;a href=\"google.com\"&gt;Google&lt;/a&gt; Normal JavaScript expression works fine: 12var authenticated = truebody(class=authenticated ? 'authed' : 'anon') =&gt; &lt;body class=\"authed\"&gt;&lt;/body&gt; Multiline Attributes123456input( type='checkbox' name='agreement' checked)=&gt; &lt;input type=\"checkbox\" name=\"agreement\" checked /&gt; If your JavaScript runtime supports ES6 template strings, you can use that syntax for attributes. 123456789101112input(data-json=` { \"very-long\": \"piece of\", \"data\": true }`)=&gt; &lt;input data-json=\" { &amp;quot;very-long&amp;quot;: &amp;quot;piece of &amp;quot;, &amp;quot;data&amp;quot;: true }\"/&gt; Quoted AttributesIf your attribute name contains odd character that might interfere with JavaScript syntax, either quote it using &quot;&quot; or '', or use commas to separate different attributes. 123div(class='div-class', (click)='play()')div(class='div-class' '(click)'='play()')=&gt; &lt;div class=\"div-class\" (click)=\"play()\"&gt;&lt;/div&gt; Attribute Interpolation Simply write the attribute in JavaScript: 1234567var url = 'pub-test.html'a(href='/' + url) Link =&gt; &lt;a href='/pub-test.html'&gt;Link&lt;/a&gt;var btnType = 'info'var btnSize = 'lg'button(type='button' class=`btn btn-${btnType} btn-${btnSize}`)=&gt; &lt;button type=\"button\" class=\"btn btn-info btn-lg\"&gt;&lt;button&gt; Boolean Attributes1234input(type='checkbox' checked) =&gt; &lt;input type=\"checkbox\" checked=\"checked\" /&gt;input(type='checkbox' checked=true) =&gt; &lt;input type=\"checkbox\" checked=\"checked\" /&gt;input(type='checkbox' checked=false) =&gt; &lt;input type=\"checkbox\" /&gt;input(type='checkbox' checked=true.toString()) =&gt; &lt;input type=\"checkbox\" checked=\"true\" /&gt; Style AttributesThe style attribute can be a string, like any normal attribute, but it can be an object, which is handy when styles are generated by JavaScript: 1a(style={color: 'red', background: 'green'}) =&gt; &lt;a style=\"color:red;background:green;\"&gt;&lt;/a&gt; Class AttributesThe class attribute can be a string, like any normal attribute, but is also can be an array of class names, which is handy when generated from JavaScript. 1234var classes = ['foo', 'bar', 'baz']a(class=classes) =&gt; &lt;a class=\"foo bar baz\"&gt;&lt;/a&gt;a.bang(class=classes class=[bing]) =&gt; &lt;a class=\"bang foo bar baz bing\"&gt;&lt;/a&gt; It can also be an object which maps class names to true or false values. This is useful for applying conditional classes: 12var currentURL = '/about'a(class={active: currentURL === '/about' href='/about'}) =&gt; &lt;a class=\"active\"&gt;&lt;/a&gt; Class LiteralClasses may be defined using a .classname syntax: 1a.button =&gt; &lt;a class=\"button\"&gt;&lt;/a&gt; Since divs are such a common choice of tag, it is default if you omit the tag name: 1.content =&gt; &lt;div class=\"content\"&gt;&lt;/div&gt; ID Literal1a#main-link =&gt; &lt;a id=\"main-link\"&gt;&lt;/a&gt; &amp;attributesPronounced as and attributes, the &amp;attributes syntax can be used to expode an object into attributes of an element: 1dev#foo(data-json=\"foo\")&amp;attributes({'data-foo': 'bar'}) =&gt; &lt;div id=\"foo\" data-json=\"foo\" data-foo=\"bar\" /&gt; CaseThe case statement is a shorthand for JavaScript’s switch, it takes the following form: 12345678var friends = 10case friends when 0 p you have no friends when 1 p you have a friend default p you have #{friends} friends Case Fall ThroughYou can use fall through, just as you would in a JavaScript switch statement 12345678var friends = 0case friends when 0 when 1 p you have very few friends default p you have #{friends} friends The difference, however, is a fall through in JavaScript happens whenever a break statement is not explicitly included. CodePug allows you to write inline JavaScript code in your templates. There are three types of code: Unbuffered, Buffered, and Unescaped Buffered. Unbuffered CodeUnbuffered code starts with -. It does not directly add anything to the output 12345678- for (var x = 0; x &lt; 3; x++) li item=&gt;&lt;li&gt;item&lt;/li&gt;&lt;li&gt;item&lt;/li&gt;&lt;li&gt;item&lt;/li&gt; Pug also supports block unbuffered code: 12345678910111213- var list = ['Uno', 'Dos', 'Tres', 'Cuatro', 'Cinco', 'Seis'] each item in list li= item=&gt; &lt;li&gt;Uno&lt;/li&gt; &lt;li&gt;Dos&lt;/li&gt; &lt;li&gt;Tres&lt;/li&gt; &lt;li&gt;Cuatro&lt;/li&gt; &lt;li&gt;Cinco&lt;/li&gt; &lt;li&gt;Seis&lt;/li&gt; Buffered CodeBuffered code start with =. It evaluates the JavaScript expression and outputs the result. For security, buffered code is first HTML excaped. 123p = 'This code is &lt;escaped&gt;!'=&gt; &lt;p&gt;This code is &amp;lt;escaped&amp;gt;!&lt;/p&gt; it can also be written inline with attributes, and supports the full range of JavaScript expression: 1p= 'This code is' + ' &lt;escaped&gt;!' =&gt; &lt;p&gt;This code is &amp;gt;escaped&amp;gt;!&lt;/p&gt; Unescaped Buffered CodeUnescaped buffered code starts with !=. It evaluates the JavaScript expression and outputs the result. Unescaped buffered code does not perform any escaping, so is unsafe for user input. 1p != 'This code is &lt;strong&gt;not&lt;/strong&gt; escaped!' =&gt; &lt;p&gt;This code is &lt;strong&gt;not&lt;/strong&gt; escaped!&lt;/p&gt; CommentsBuffered comments look the same as single-line JavaScript comments. They act sort of like markup tags, producing HTML comments in the rendered page. Like tags, buffered comments must appear on their own line: 123456789// just some paragraphsp foop bar=&gt;&lt;!-- just some paragraph --&gt;&lt;p&gt;foo&lt;/p&gt;&lt;p&gt;bar&lt;/p&gt; Pug also supports unbuffered comments, Simply ass a hyphen(-) to the start of the comment. These are only for commenting on the Pug code itself, and do not appear in the rendered HTML. 123456//- will not output within markupp foo=&gt;&lt;p&gt;foo&lt;/p&gt; Block Comments12345body//- Comments for your templates writers. Use as much text as you want// Comments for your HTML readers Use as much text as you want ConditionalsPug’s first-class conditional syntax allows for optional parenthese. 1234567891011121314- var user = { description: 'foo bar baz '}- var authorized = false#user if user.description h2.green Description p.description= user.description else if authorized h2.blue Description p.description. User has no description why not add one... else h2.red Description p.description User has no description Pug also provides the conditional unless which works like a negated if. The following are equivalent: 1234567unless user.isAnonymous p You're logged in as #{user.name}=if !user.isAnonymous p You're logged in as #{user.name} FiltersIncludeInclude allow you to insert the contents of one Pug file into another. 123456789101112131415161718// index.pugdoctype htmlhtml include includes/head.pug body h1 My Site p Welcome to my super lame site include includes/foot.pug// includes/head.pughead title My Site script(src='/javascripts/jquery.js') script(src='/javascripts/app.js')// includes/foot.pugfooter#footer p Copyright (c) foobar If the path is absolute(e.g. include /root.pug), it is resolved by prepending options.basedir. If no file extension is given, .pug is automatically appended to the file name. Including Plain TextIncluding non-Pug files simply includes their raw text. 123456789101112131415161718// index.pugdoctype htmlhtml head style include style.css body h1 My Site p Welcome to my super lame site script include script.js// style.cssh1 { color: red;}// script.jsconsole.log('Yor are awesome') Template InheritancePug supports template inheritance. Template instance works via block and extends keyword. In a template, a block is simply a ‘block’ of Pug that a child template may replace. This process is recursive. Pug blocks can provide default content, if appropriate. Providing default content is purely optional, though. The example below defines block scripts, block content and block foot 1234567891011// layout.pughtml head title My Site - #{title} block scripts script(src='/jquery.js') body block content block foot #footer p some footer content To extend this layout, create a new file and use the extends directive with a path to the parent template(if no file extension is given, .pug is automatically appended to the file name). Then define one or more blocks to override the parent block content. 123456789101112// page-a.pugextends layout.pugblock scripts script(src=\"/jquery.js\") script(src=\"/pets.js\")block content h1= title - var pets = ['cat', 'dog'] each petName in pets include pet.pug 12// pet.pugp= petName Block append/prependPug allows you to replace, prepend and append blocks Suppose you have default scripts in a head block that you wish to use on every page you might do this: 1234567891011121314// layout.pughtml head block head script(src=\"/vendor/jquery.js\") script(src=\"/vendor/caustic.js\") body block content// page.pugextends layoutappend head script(src=\"/vendor/three.js\") InterpolationString Interpolation, EscapedConsider the placement of the following tempalte’s locals: title, author and theGreat 1234567- var title = 'On Dogs'- var author = 'enlore'- var theGreat = '&lt;span&gt;escaped!&lt;/span&gt;'h1= titlep Written by #{author}p This will be safe: #{theGreat} This can be valid JavaScript expression, so you can do whatever feels good. 12- var msg = 'not my inside voice'p This is ${msg.toUpperCase()} String Interpolation, UnescapedYou don’t have to play it safe, you can buffer unescaped values into your templates too 123- var riskyBusiness = '&lt;em&gt;Some of the girts&lt;/em&gt;'.quote p joel: !{riskyBusiness} Keep in mind that buffering unescaped content into your templates can be mighty risky if that content comes fresh from your users. Tag InterpolationInterpolation works not only on JavaScript values, but on Pug as well, just use the tag interpolation syntax like so: 12p. Interpolate #[strong strongly word] there Whitespace ControlThe tag interpolation syntax is especially useful for inline tags, where whitespace before and after the tag is significant. By default, however, Pug removes all spaces before and after tags. IterationPug supports two primary methods of iteration: each and while each123456789101112131415161718ul each val, index in [1, 2, 3, 4] li= index + ': ' + valul each val, index in {1: 'one', 2: 'two'} li= index + ': ' + val- var values = []ul each val in values.length ? values : ['There is no value'] li= valul each val in values li= val else li There is no value While1234- var n = 0ul while n &lt; 4 li= n++ MixinsMixins allow you to create reusable blocks of Pug 12345678910// Declarationmixin list ul li foo li bar li baz// Use+list+list 123456789101112mixin pet(name) li.pet= nameul +pet('cat') +pet('dog')=&gt;&lt;ul&gt; &lt;li class=\"pet\"&gt;cat&lt;/li&gt; &lt;li class=\"pet\"&gt;dog&lt;/li&gt;&lt;/ul&gt; Mixin AttributesMixins also get an implicit attributes argument, which is taken from the attributes passed to the mixin 123456mixin link(href, name) a(class!=attributes.class href=href)= name+link('/foo', 'foo')(class=\"btn\")=&gt;&lt;a class=\"btn\" href=\"foo\"&gt;foo&lt;/a&gt; Note: The values in attributes by default are already escaped, you should use != to avoid escaping them a secondtime. Rest ArgumentsYou can write mixins that takes an unknown number of arguments using the rest arguments syntax 123456mixin list(id, ...items) ul(id=id) each item in items li= item+list('my-list', 1,2,3,4) Plain TextPug provides four ways of getting plain text Inline in a TagThe easiest way to add plain text is inline. The first term on the line is the tag itsel. Everything after the tag and one space will be the text content of that tag. 1p This is plain old &lt;em&gt;text&lt;/em&gt; content. Literal HTMLWhole lines are also treated as plain text when they begin with a left angle bracket (&lt;), which may occasionally be useful for writing literal HTML tags in places that could otherwise be inconvenient. 12345&lt;html&gt;body p Indenting the body tag there will make no difference p HTML itself isn not whitespace-sensitive&lt;/html&gt; Piped TextAnother way to add plain text to templates is to prefix a line with a pipe character (|). This method is useful for mixing plain text with inline tag. 12345p | The pipe always goes at the beginning of its own line, | not counting indentation.=&gt;&lt;p&gt;The pipe always goes at the beginning of its own line, not counting indentation.&lt;/p&gt; Block in a TagOften you might want large blocks of text wihtin a tag. To do this, just add a . right after the tag name, or after the closing parenthesis, if the tag has attributes. 12345script. if (usingPug) console.log('You are awesome') else console.log('use pug') TagsBy default, text at the start of a line (or after only white space) represents an HTML tag. Indented tags are nested. To save space, Pug provides an inline syntax for nested tags. 1a: img =&gt; &lt;a&gt;&lt;img /&gt;&lt;/a&gt; self-closing tag 12foo/ =&gt; &lt;foo /&gt;foo(bar='baz')/ =&gt; &lt;foo bar=\"baz\" /&gt;","link":"/2017/08/29/Start-at-Pug/"},{"title":"Tutorial Part 1 of Dapp","text":"Spawning a new DappThe dapp will use modern JS technologies: NPM, Webpack2, React, Babel, ES6, JSX and oo7. Clone a skeleton repo from parity: 1git clone https://github.com/paritytech/skeleton mydapp This will make your a new repo with everything ready. cd in to it and remove the origin repository lest it confuse Git. It’s liberally licensed (Apache 2.0) so you don’t have to worry about open sourcing your own code(though obviously you’ll be enlightened and want to do that anyway.) The next stage is to get all dependencies installed, NPM makes this rather easy, but the bundled script makes it even easier 1./init.sh This should grab and install all that is required. The next thing to do is to build the final web-ready version of the fledling dapp. We use webpack for this. 1webpack You now have a basic dapp built. Configuring its lookWhile your dapp may well be built, it is not yet easily discoverable. You would have to host it somewhere. This can be done traditionally with a web server but for development, we will use Parity’s in-built hosting. Parity uses a special ‘manifest’ file called to figure out how to display the entry for your dapp in Parity Wallet. This file is called manifest.json and must be placed in the root of your dapp’s directory, in our case, thi sis our ‘build’ directory, dist. Open an editor to edit dist/manifest.json you’ll see something like: 12345678{ \"id\": \"skeleton\", \"name\": \"Skeleton\", \"description\": \"A skeleton dapp\", \"version\": \"0.1\", \"author\": \"parity Technologies Ltd\", \"iconUrl\": \"title.png\"} The id is the dapp’s unique identity: change that from skeleton to mydapp The name is the dapp’s user-visible name: change that to My Dapp The description is a user-visible by-line describing what the dapp is good for. version is the dapp’s version - you can leave that at 0.1 for now. You can change the author to your name. The iconUrl is the path(within dist) to a square(best to make it 128 x 128) icon for your dapp. Getting it visible in ParityTo get Parity to discover your dapp, it needs to be placed into a place that Parity will see it in its local ‘dapps’ directory. We will make a symbolic linke for our dapp’s dist directory(containing all of the ready-built dapp) in Parity’s dapp directory. Parity’s directory structure is different depending on your system. For Mac, Parity’s local dapp directory sits at $HOME/Library/Application Support/io.parity.ethereum/dapps Once you have it linked, you should start(or restart, if already running) Parity and head to the Application Page of Parity Wallet. There you will see your new dapp: Note: If you are not running npm start in parity/src/js to have a development instance your URL is likely localhost:8180 instead of port 3000.","link":"/2017/07/13/Tutorial-Par1-of-Dapp/"},{"title":"Start in Drizzle ","text":"Drizzle is a collection of front-end libraries that make wirting dapp front-ends easier and more predicable. The core of Drizzle is based on Redux Store, so you can access to the spectacular development tools around Redux. We take care of synchronizing your contract data, transaction data and more. Things stay fast because you declare what to keep in sync. Fully reactive contract data, including state, events and transactions Declarative, so you’re not wasting valuable cycles on unneeded data. Maintainer access to underlying functionaliy. Web3 and your contract’s methods are still there, untouched. Installation1yarn add drizzle If use React you can use drizzle-react and (optionally) its companion drizzle-react-components Drizzle uses web3 1.0 and web sockets, be sure your development environment can support these. Import the provider 1import { Drizzle, generateStore } from 'drizzle' Create an options object and pass in the desired contract artifacts for Drizzle to instantiate. Other options are available, just keep going on. 123456789101112// import contractimport SimpleStorage from './../build/contracts/SimpleStorage.json'import TutorialToken from './../build/contracts/TutorialToken.json'const options = { contracts: [ SimpleStorage ]}const drizzleStore = generateStore(this.props.options)const drizzle = new Drizzle(this.props.options, drizzleStore) Contract InteractionDrizzle provides helpful methods on top of the default web3 Contract methods to keep you calls and transactions in sync with the store. cacheCall()Gets contract data. Calling the cacheCall() function on a contract will execute the desired call and return a corresponding key so the data can be retrieved from the store. When a new block is received, Drizzle will refresh the store automatically if any transactions in the block touched our contract. Note: We have to check that Drizzle is initialized before fetching data. A simple if statement such as below is fine for display a few pieces of data, but a better approach for larger dapps is to use a loading component. Drizzle built one in drizzle-react-component as well. 1234567891011121314// Assuming we're observing the store for changesvar state = drizzle.store.getState()// If Drizzle is initialized (and therefore web3, accounts, and contracts ), continueif (state.drizzleStatus.initialized) { // Declare this call to be cached and synchornized. We'll receive the store key for recall const dataKey = drizzle.contracts.SimpleStorage.methods.storedData.cacheCall() // Use the dataKey to display data from the store return state.contracts.SimpleStorage.methods.storedData[dataKey].value}// If Drizzle isn't initialized, display some loading indicationreturn 'loading' The Contract instance has all of its standard web3 properties and methods. For example, you could still call as normal if you don’t want something in the store: 1drizzle.contracts.SimpleStorage.methods.storedData().call() // different from methods.storedData.cacheCall() cacheSend()Sends a contract transaction. Calling the cacheSend() function on a contract will send the desired transaction and return a correnponding hash so the status can be retrieved from the store. The last argument can optionally be an options object with the typical from, gas, gasPrice keys. Drizzle will update the transaction’s state in the store(pending, success, error) and store the transaction receipt. Note: We have to check that Drizzle is initialized before fetching data. A simple if statement such as below is fine for display a few pieces of data, but a better approach for larger dapps is to use a loading component. 123456789101112131415161718// Assuming we're observing the store of changesvar state = drizzle.store.getState()// if Drizzle is initialized ( and therefore web3, accounts, and contracts ), continueif (state.drizzleStatus.initialized) { // Declare this transaction to be observed. We'll receive the stackId of reference. const stackId = drizzle.contracts.SimpleStorage.methods.set.cacacheSend(2, {from: '0x3f...'}) // Use the dataKey to display the transaction status if (state.transactionStack[stackId]) { const txHash = state.trasnactionStack[stackId] return state.transactions[txHash].status }}// If Drizzle isn't initialized, display some loading indication.return 'loading' The contract instance has all of its standard web3 properties and methods. 1drizzle.contracts.SimpleStorage.methods.set(2).send({from: '0x3f...'}) Options1234567891011121314{ contracts, events: { contractsName: [ eventName ] }, web3: { fallback: { type url } }} Contracts: Array, Required, an array of contract artifacts files Events: Object, an object consisting of contract names each containing an array of strings of the event names we’d like to listen for and sync with the store Web3: Object, options regarding web3 instantiation Fallback: Object, an object consisting of the type and url of a fallback web3 provider. This is used if no injected provider, such as MetaMask or Mist, is detect. type: string, the type of web3 fallback, currently ws is the only possibility url: string, the full websocket url. For example, ws://127.0.0.1:8546 How data stays fresh Once initialized, Drizzle instantiates web3 and our desired contracts, then observes the chain by subscribing to new block headers Drizzle keeps track of contract calls so it knows what to synchronize When a new block header comes in, Drizzle checks that the block isn’t pending, then goes through the transactions looking to see if any of them touched our contracts If they did, we replay the calls already in the store to refresh any potentially altered data. If they didn’t we continue with the store data.","link":"/2018/03/13/Start-in-Drizzle/"},{"title":"Things We Can Do With the Simple Graph of D3","text":"Original Setting up and configuring the AxesChange the text sizeThe default size is 10px with the font type of sans-serif. There are a couple of different ways that we could change the font size and either one is valid. The first way is to specify the font as a style when drawing an individual axis. 1234svg.append('g') .style('font', '14px times') .attr('transform', `translate(0, ${height})`) .call(d3.axisBottom(xScale)) There are a few things to notice here. Firstly, we do indeed have a larger font and it appears to be of the type ‘times’. Secondly, the y axis has remained as 10px sans-serif. Lastly, the number of values represented on the x axis has meant that with the increase in font size there is some overlapping going on By this way, you can change stype of x axis while leaving y axis away. But if you want to change two axis meanwhile, you’d better use class. Change the number of ticks on an axisNow we shall address the other problem taht cropped up when we change the size of the text. We have overlapping values on the x axis. The axis component includes a function to specify the number of ticks on an axis. 1234svg.append('g') .attr('class', 'axis') .attr('transform', `translate(0, ${height})`) .call(d3.axisBottom(xScale).ticks(5)) Here you may face a confusion: When you specify ticks to 5 or 4, or 3, there’re always 5 ticks, and if you specify ticks to 2, the axis ticks will be 2 representing month. This is because D3 is making a command decision for you as to how your ticks should be best displayed. The following is the list of time interval that D3 will consider when setting automatic ticks on a time based aaxis: 1, 5, 15 and 30-second 1, 5, 15 and 30-minute 1, 3, 6 and 12-hour 1 and 2-day 1-week 1 and 3-month 1-year You can specify custom time interval by d3.axisBottom(xScale).ticks(d3.timeDay.every(4)). Rotating text labels for a graph sizeAn answer to the problem of overlapping axis values might to be rotate the text to provide more space. 123456789svg.append('g') .attr('class', 'axis') .attr('transform', `translate(0, ${height})`) .call(d3.axisBottom(xScale).ticks(10)) .selectAll('text') .style('text-anchor', 'end') .attr('dx', '-0.8em') // move the end of the text away from the line .attr('dy', '0.15em') // move the end of the text away from the line .attr('transform', 'rotate(-65)') Formatting a date / time axis with specified values123456789svg.append('g') .attr('class', 'axis') .attr('transform', `translate(0, ${height})`) .call(d3.axisBottom(xScale).tickFormat(d3.timeFormat('%Y-%m-%d'))) .selectAll('text') .style('text-anchor', 'end') .attr('dx', '-0.8em') .attr('dy', '0.15em') .attr('transform', 'rotate(-65)') Adding Axis Labels123456// text label for the x axissvg.append('text') .attr('transform', `translate(${width/2}, ${height + margin.top + 20})`) .style('text-anchor', 'middle') .text('Date') Add y axis 1234567svg.append('text') .attr('transform', 'rotate(-90)') .attr('y', 0 - margin.left) .attr('x', 0 - height / 2) .attr('dy', '1em') .style('text-anchor', 'middle') .text('Value') Something may confused you: And add the title… Smoothing out graph lines1.curve(d3.curveBasis) Make a dashed line12345svg.append('path') .datum(data) .attr('class', 'line') .style('stroke-dasharry', ('3, 3')) .attr('d', line) Obviously stroke-dasharray is a style is a style for the path element, but the magic is the numbers. Essentially they describe the on length and off length of the line. So '(3, 3)' translates to 3px on and 3px off. You can try '5, 5, 5, 5, 5, 5, 10, 5, 10, 5, 10, 5' Of course you can apply this style on axis or any where you prefer. Filling an aera under the graphFilling an area with a solid color isn’t too hard. CSS for an area fill123.area { fill: lightsteelblue} Define the area function1234const area = d3.area() .x((d) =&gt; (xScale(d.date))) .y0(height) .y1((d) =&gt; (yScale(d.close))) Draw the area1234svg.append('path') .datum(data) .attr('class', 'area') .attr('d', area) If you want to fill the area above the graph 1234const area = d3.area() .x(d =&gt; (xScale(d.date))) .y0(d =&gt; (yScale(d.close))) y1(0) Add a drop shadow to allow text to stand out on graphics12345text.shadow { stroke: white; stroke-width: 4px; opacity: 0.8;} Add grid lines to a graph.We are going to use the axis function to generate two more axis elements(one for x and one for y) but for these ones of drawing the main lines and the labels, we’re just going to draw the tick lines. CSS12345678.grid line { stroke: lightgrey; stroke-opacity: 0.7; shape-rendering: crispEdges;}.grid path { stroke-width: 0;} Here we use shape-rendering: crispEdges to make the lines narrow. And set .grid path{ stroke-width: 0; } to dismiss line of top and right line, it will be like this if we remove the css style: Define the grid line functions123456789// gridlines in x axis functionfunction make_x_gridlines() { return d3.axisBottom(xScale).ticks(5)}// gridlines in y axis functionfunction make_y_gridlines() { return d3.axisLeft(yScale).ticks(5)} Draw the lines12345678910// add the x gridlinessvg.append('g') .attr('class', 'grid') .attr('transform', `translate(0, ${height})`) .call(make_x_gridlines().tickSize(-height).tickFormat(''))// add the y gridlinessvg.append('g') .attr('class', 'grid') .call(make_y_gridlines().tickSize(-width).tickFormat('')) 1axis.tickSize([size]) In our example, we are setting our ticks to a length that corresponding to the full height or width of the graph, which of course means that they extend across the graph and have the appearance of grid lines. The last thing that is included in the code to draw the grid lines is the instruction to suppress printing any label for the ticks: 1.tickForamt('')","link":"/2017/08/30/Things-we-can-do-with-the-simple-Graph-of-D3/"},{"title":"Tutorial Part 3 of Dapp","text":"Parity BondsIt’s time to get down and dirty with the blockchain. For this we will introduce the oo7-parity package, which provides a high-level reactive Bond API. To set this up, all we need do is import bonds from the oo7-parity module, so ensure you have this at the top of your file: 1import { bonds } from 'oo7-parity' Watch the blockFor our first task, we will introduce the simplest of all bonds: bonds.height. This evaluates to the number of the latest block, expressed as a simple number. In app.jsx: 1234567export class App extends React.Component { render () { return ( &lt;Rspan&gt;{bonds.height}&lt;/Rspan&gt; ) }} It’s not especially pretty so you can add some style on it. We also provide the formatBlockNumber function: 1const formatBlockNumber = (\u0006n) =&gt; '#' + ('' + n).replace(/(\\d)(?=(\\d{3})+$)/g, '$1,') You can use it through 1import { bonds, formatBlockNumber } from 'oo7-parity' BlocksThe block number is great and all, but perhaps we’re more intereseted in the latest block itself. Parity can help us there with the bonds.blocks object. This is a lazy-evaluated ‘array’ of bonds which can subscribe to. To give yourself an idea of its capabilities, let’s try it out in the console. First we will expose the bonds object to the environment by adding this at the end of our obejct’s constructor: 1window.bonds = bonds Having reloaded, quickly open the Chrome JS console, alter the environment to 127.0.0.1 and evaluate the block at number 69 with bonds.blocks[69].log() Note that since it’s all asynchronous, we must use the .log() trick to feed the result into the console (it’s exactly equivalent to .map(console.log)) The result is, of course, the block object representing the 69th mined block on this chain. Naturally, bonds.blocks is able to accept any number, even a bond, as its subscript. Let’s make our dapp always give us the timestamp of the latest block. 1234&lt;div&gt; Latest block timestamp is: &lt;Rspan&gt;{bonds.blocks[bonds.blocks.height].map(b =&gt; b.timestamp).map(_ =&gt; _.toString())}&lt;/Rspan&gt;&lt;/div&gt; That map is a bit cumbersome, the bond API knows about subscripting, which means the .timestamp can be moved out of the map Furthermore, bonds.blocks[bonds.height] is a fairly common expression. So much so that it has a shorter alias: bonds.head, so in fact the simplest means of expressing this becomes: 1{ bonds.head.timestamp.map(_ =&gt; _.toString())} Composing expressionsThese expressios are sometimes very useful, but often you want to do some blockchain based computation on this information. Parity puts various means at your disposal to help you here: bonds.balance(address): evaluates to the current balanece of account at address bonds.transactionCount(address): evaluates to the current transaction count (‘nonce’) of account at address bonds.code(address): evaluates to the current ‘contract’ code of account at address bonds.storageAt(address, location): evaluates to the value in storage location of account at address Use the first one: 123456&lt;div&gt; Current block authors balance is: &lt;Rspan&gt; {bonds.balance(bonds.head.author).map(formatBalance)} &lt;/Rspan&gt;&lt;/div&gt; Our balanceParity can help us get information about our own accounts in a reactive manner. Some apis like: bonds.coinbase: evaluates to the node’s current block authoring address. bonds.accounts: evaluates to the list of accounts available for the dapp to use. bonds.me: evaluates to the preferred account for this dapp to use. In parity, this is the account visible in the Parity Signer at the bottom right of the page. bonds.accountsInfo: evaluates to the mapping between dapp-visible addresses and account metadata.","link":"/2017/07/13/Tutorial-Part-3-of-Dapp/"},{"title":"Time to Start Fastify","text":"Getting StartedInstall1yarn add fastify First Server123456789101112131415// Require the framework and instantiate itconst fastify = require('fastify')()// Declare a routefastify.get('/', (req, reply) =&gt; { reply.send({ hello: 'world', })})// Run the serverfastify.listen(3000, (err) =&gt; { if (err) throw err console.log(`Server is running on ${fastify.server.address().port}`)}) Schema Serialization123456789101112131415161718192021222324const fastify = require('fastify')()const opts = { schema: { response: { 200: { type: 'object', properties: { hello: { type: 'string' } } } } }}// Declare a route with an output shcemafastify.get('/', opts, (req, reply) =&gt; { replysend({ hello: 'world' })})fastify.listen(3000, (err) =&gt; { if (err) throw err console.log(`Server is running on ${fastify.server.address().port}`)}) RegisterRegister routes in seperate files 123456789101112131415161718192021// server.jsconst fastify = require('fastify')()fastify.register(require('./route'))const opts = { hello: 'world', something: true,}fastify.register([ require('./another-route'), require('./yet-another-route'),], opts, (err) =&gt; { if (err) throw err})fastify.listen(3000, (err) =&gt; { if (err) throw err console.log(`Server is running on ${fastify.server.address().port}`)}) 1234567// route.jsmodule.exports = (fastify, options, next) { fastify.get('/', (req, reply) =&gt; { replysend({ hello: 'world' }) }) next()} or async/await: 12345module.exports = async (fastify, options) =&gt; { fastify.get('/', (req, reply) =&gt; { replysend({ hello: 'world' }) })} Server Methodsserverfastify.server: The Node Core server object. readyFunction called when all the plugins has been loaded. It takes an error parameter if something went wrong. 1fastify.ready(err =&gt; { if (err) throw err }) listenStarts the server on the given port after all the plugins loaded, internally waits for the .ready() event. The callback is the same as the Node Core. 123fastify.listen(3000, err =&gt; { if (err) throw err}) Specifying an address is also supported: 123fastify.listen(3000, '127.0.0.1', err =&gt; { if (err) throw err}) routeMethod to add routes to the server, it also have shorthands. routes iteratorThe fastify instance is an Iterable object with all the registered routes. The route properties are the same the developer has declared. closefastify.close(callback), call this function to close the server instance and run the onClose hook. decorate*Function useful if you need to decorate the fastify instance, Reply or Request. registerFastify allows the user to extends its functionalities with plugins. A plugin can be a set of routes, a server decorator or whatever. useFunction to add middlewares to Fastify. addHookFunction to add a specific hook in the lifecycle of Fastify. loggerThe logger instance. InjectFake http injection(for testing purpose). setSchemaCompilerSet the schema compiler for all routes. setNotFoundHandlerfastify.setNotFoundHandler(handler(req, reply)): set the 404 handler. This call is fully encapsulated, so different plugins can set different not found handlers. setErrorHandlerfastify.setErrorHandler(handler(err, reply)): set a function that will be called whenever an error happens. The handler is fully encapsulated, so different plugins can set different error handlers. Routes1fastify.route(options) method: currently it supports DELETE, GET, HEAD, PATCH, POST, PUT, and OPTIONS, it could be an array of methods. url: the path of the url to match this route (alias: path) schema: an object containing the schemas for the request and response. They need to be in JSON Schema format. body: validates the body of the request if it is a POST or PUT. querystring: validates the querystring. This can be a complete JSON Schema Object, with the property type of object and properties object of parameters, or simply the values of what would be contained in the properties object as shown below. params: validates the params. response: fitler and generate a schema for the response, setting a schema allows us to have 10-20% more throughput. beforeHandler(req, res, done): a function called just before the request handler, useful if you need to perform authentication at route level for example, it could also be and array of functions. handler(req, reply): the function that will handle this request. request if defined in Request. reply is defined in Reply. Exmaple 1234567891011121314151617181920212223242526272829303132333435363738fastify.route({ method: 'GET', url: '/', schema: { querystring: { name: { type: 'string' }, excitement: { type: 'integer' }, }, response: { 200: { type: 'object', properties: { hello: { type: 'string' } } } }, }, handler: function (req, reply) { reply.send({ hello: 'world', }) }})fastify.route({ method: 'GET', url: '/', schema: {/*..*/}, beforeHandler: function (req, reply, done) { // auth done() }, handler: function(req, reply) { reply.send({ hello: 'world', }) }}) ShortHandsfastify.method(path, [options], handler) 123456789101112131415161718const opts = { schema: { response: { 200: { type: 'object', properites: { hello: { type: 'string' } } } } }}fastify.get('/', opts, (req, reply) =&gt; { reply.send({ hello: 'world', })}) fastify.all(path, [options], handler) will add the same handler to all the supported methods. Async/Await12345fastify.get('/', options, async (req, reply) =&gt; { var data = await getData() var processed = await processData(data) return processed}) Route Prefixing123456789101112// server.jsconst fastify = require('fastify')()fastify.register(require('./routes/v1/users'), { prefix: '/v1',})// routes/v1/usersmodule.exports = function (fastify, opts, next) { fastify.get('/user', handler_v1) next()} Now your client can access to /v1/user. Be aware that if you use fastify-plugin this option won’t work. LoggingLogging is disabled by default, and you can enable it by passing { logger: true } or { logger: { level: 'info' } } when you create the fastify instance. 12345678910const fastify = require('fastify')({ logger: true,})fastify.get('/', options, (req, reply) =&gt; { req.log.info('Some info about the current request') reply.send({ hello: 'world', })}) MiddlewaresFastify provides out of the box an asynchronous middleare engine compatible with Express and Restify middlewares. Fastify middleware don’t support the full syntax middleware(err, req, res, next) because error handling is done inside Fastify. Also if you are using a middleware taht bundles different, smaller middlewares such as helmet, we recommand to use the single module to get better performances. 1234567fastify.use(require('cors')())fastify.use(require('dns-prefetch-control')())fastify.use(require('frameguard')())fastify.use(require('hide-powered-by')())fastify.use(require('hsts')())fastify.use(require('ienoopen')())fastify.use(require('x-xss-protection')()) If you need to run a middleware only under certain path, just pass the path as first parameter to use and you are done. Note that this does not support routes with parameters, (eg: /users/:id/comments) and wildcard is not supported in multiple paths. 12345678const serveStatic = require('serve-static')// single pathfastify.use('/css', servveStatic('/asserts'))// wildcard pathfastify.use('/css/*', servveStatic('/asserts'))// multiple pathsfastify.use(['/css', '/js'], servveStatic('/asserts')) HookBy using the hook you can interact directly inside the lifecycle of Fastify, there are three different Hooks that you can use(in order of execution): onRequest preHandler onResponse onClose Example: 1234567891011121314fastify.addHook('onRequest', (req, res, next) =&gt; { // some code next()})fastify.addHook('preHandler', (req, res, next) =&gt; { // some code next()})fastify.addHook('onResponse', (res, next) =&gt; { // some code next()}) If you want to pass a custom error code to the user, just use the reply.code(): 12345fastify.addHook('onRequest', (req, res, next) =&gt; { // some code reply.code(400) next(new Error('some error'))}) The error will be handled by Reply The unique hook that is not inside the lifecycle is 'onClose', this one is triggered when you call fastify.close() to stop the server, and it is useful if you have some plugins that need a ‘shutdown’ part, such as a connection to database. Only for this hook the parameters of the functions changes. 1234fastify.addHook('onClose', (instance, done) =&gt; { // some code done()}) ScopeExcept for onClose all the hooks are encapsulated this means that you can decide where your hooks should run by using register. beforeHandlerbeforeHandler is not a standard hook like preHandler, but is a function that your register right in the route option that will be executed only in the specified route. beforeHandler is executed always after the preHandler hook. 1234567891011121314151617181920212223242526272829fastify.addHook('preHander', (req, reply, done) =&gt; { // your code done()})fastify.route({ method: 'GET', url: '/', schema: {/*...*/}, beforeHandler: (req, reply, done) =&gt; {/*...*/ ;done()} handler: (req, reply) =&gt; { reply.send({ hello: 'world' }) }})fastify.route({ method: 'GET', url: '/', shcema: {/*...*/}, beforeHandler: [ function first (req, reply, done) { done() }, function second (req, reply, done) { done() } ], handler: function (req, reply) { reply.send({ hello: 'world' }) }}) DecoratorsIf you need to add functionalities to the Fastify instance, the decorator api is what you need. This api allows you to add new properties to the Fastify instance, a property value is not restricted to be a function, could also be an object or a string for example. UsagedecorateJust call the decorate api and pass the name of the new property and its value. 123fastify.decorate('utility', () =&gt; { // something very useful}) As said above, you can decorate the instance with other values and not only functions: 1234fastify.decorate('conf', { db: 'some db', port: 3000,}) Once you decorate the instance you can access the value every time you need by using the name you passed as parameter: 12fastify.utility()console.log(fastify.conf.db) Decorators are not overwritable, if you try to declare a decorator already declared, decorate will throw an exception. decorateReplyAs the name suggest, this api is needed if you want to add new methods to the Reply core object. Just call the decorateReply api and pass the name of the new property and its value. 123fastify.decorateReply('utility', function () { // something very useful}) Note: using an arrow function will break the binding of this to the Fastify reply instance. decorateRequest123fastify.decorateRequest('utility', function () { // something very useful}) Note: using an arrow function will break the binding of this to the Fastify request instance. extendServerErrorIf you need to extend the standard server error, this api is what you need. You must pass a function that returns an Object, Fastify will extend the server error with the returned object of your function. The function will receive the original error object. 1234567891011121314fastify.extendServerError(err =&gt; { return { timestamp: new Date(), }})/* The resulting object will be: { error: string, message: string, statusCode: number, timestamp: date, }*/ Sync and Asyncdecorate is synchronous API, if you need to add a decorator that has an asynchronous bootstrap, could happen that Fastify boots up before your decorator is ready. To avoid this issue you must use register api in combination with fastify-plugin. DependenciesIf your decorator depends on another decorator, you can declare the dependencies of your function, it’s pretty easy, you just need to add an array of strings(representing the names of the decorators your are depending on) as third parameter. 1fastify.decorate('utility', fn, ['greet', 'log']) If a dependency is not satisfied, decorate will throw an exception. hasDecorator1fastify.hasDecorator('utility') Validation and SerializeFastify uses a schema based approach and even if it is not mandatory we recommend to use JSON Schema to validate you routes and serialize your output, internally Fastify compiles the schema in a highly performance function. ValidationThe route validation internally uses Ajv, which is highly performant JSON validator. Validate the input is very easy, just add the fields that you need inside the route schema and you are done. The supported validations are body: Validates the body of the request if it is a POST or PUT querystring: Validates the querystring. This can be a complete JSON Schema object, with the property type of object and properties object of parameters, or simply the values of what would be contained in the properties object as shown below. params: Validates teh route params. headers: Validates teh request headers. Example: 123456789101112131415161718192021222324252627const schema = { body: { type: 'object', properties: { someKey: { type: 'string'}, someOtherKey: { type: 'number' }, } }, querystring: { name: { type: 'string' }, excitement: { type: 'integer' }, }, params: { type: 'object', properties: { par1: { type: 'string' }, par2: { type: 'number' }, }, }, headers: { type: 'object', properties: { 'x-foo': { type: 'string' }, }, required: ['x-foo'], }} Schema CompilerThe schemaCompiler is a function that returns a function that validates the body, url parameters, headers and query string. The default schemaCompiler returns a function that implements the ajv validation interface. fastify use it internally to speed the valiation up. SerializeUsually you will send your data to the clients via JSON, and Fastify has a powerful tools to help you: fast-json-stringify, which is used if you have provided an output schema in the route options. 1234567891011const schema = { response: { 200: { type: 'object', properties: { value: { type: 'string' }, otherValue: { type: 'boolean' }, } } }} As you can see the response schema is based on the status code, if you want to use the same schema for mutliple status code, you can use 2xx. 1234567891011121314151617const schema = { response: { '2xx': { type: 'object', properties: { value: { type: 'string' }, otherValue: { type: 'boolean' }, } }, 201: { type: 'object', properties: { value: { type: 'string' } } } }} Lifecycle12345678910111213141516171819202122232425Incoming Request │ └─▶ Instance Logger │ └─▶ Routing │ 404 ◀─┴─▶ onRequest Hook │ 4**/5** ◀─┴─▶ run Middlewares │ 4**/5** ◀─┴─▶ Parsing │ 415 ◀─┴─▶ Validation │ 400 ◀─┴─▶ preHandler Hook │ 4**/5** ◀─┴─▶ beforeHandler │ 4**/5** ◀─┴─▶ User Handler │ └─▶ Reply │ │ │ └─▶ Outgoing Response │ └─▶ onResponse Hook ReplyThe second parameter of the handler function is Reply. Reply is a core Fastify object that exposes the following functions: .code(statusCode) .header(name, value) .type(value): Set the header Content-Type .redirect([code, ] url): default code 302 .serializer(function): Set a custom serializer for the payload .send(payload) .sent: A boolean value that you can use if you need to know it send has already been called. 123456fastify.get('/', options, (request, reply) =&gt; { reply .code(200) .type('application/json') .send({ hello: 'world' })}) CodeIf not set via reply.code, the resulting statusCode will be 200 HeaderSets a custom header to the response. If you not set a Content-Type header, Fastify assumes that you are using application/json, unless you are send a stream, in that case Fastify recognize it and sets the Content-Type at application/octet-stream. RedirectRedirects a request to the specified url, the status code is optional, default to 302. 1reply.redirect('/home') TypeSets the content type for the response. It’s the shortcut for reply.header('Content-Type', 'application/json') SerializerSendObjectsIf you are sending JSON Objects, send will serialize the object with fast-json-stringify if you setted an output schema, otherwise fast-safe-stringify PromisesSend handle natively the promsies and supports out of the box async-await: 12345678910111213fastify.get('/promises', options, (req, reply) =&gt; { const promise = new Prmise(/*...*/) reply .code(200) .send(promise)})fastify.get('/async-await', options, async (req, reply) =&gt; { let res = await new Promise(resolve =&gt; { setTimeout(resolve, 200, { hello: 'world' }) }) return res}) StreamsSend can also handle streams out of box, internally uses pump to avoid leaks of file description. If you are sneding a stream and you have not setted a Content-Type header, send will set it at application/octet-stream. ErrorsIf you pass to send an object that is an instance of Error, Fastify will automatically create error structured as the following: 12345{ error: string, // the http error message message: string, // the user error message statusCode: number, // the http status code} RequestThe first parameter of the handler function is Request. Request is a core Fastify object containing the following fields: query body params: the params matching the URL headers req: the incoming HTTP request from Node core log 12345678fastify.post('/:params', options, (req, reply) =&gt; { console.log(request.body) console.log(request.query) console.log(request.params) console.log(request.headers) console.log(request.req) request.log.info('some info')}) Content Type ParserNatively Fastify supports only application/json content-type. If you need to support different content types you can use the addContentTypeParser api. Catch All12345fastify.addContentTypeParser('*', function (req, done) { var data = '' req.on('data', chunk =&gt; {data += chunk}) req.on('end', () =&gt; done(data))}) PluginsFastify allows the user to extend its functionalities with plugins. A plugin can be a set of routes, a server decorator or whatever. The API you will need for one or more plugins is register. By default, register creates a new scope, this means that if you do some changes to the Fastify instance(via decorate), this change will not be reflected to the current context ancestors, but only to its sons. 123456fastify.register(plugin, [options])fastify.register([ require('./another-route'), require('./yet-another-route'),], opts) Craete a PluginCreate a plugin is very easy, you just need to create a function that takes three paremters, the fastify instance, an options object and the next callback. 12345module.exports = (fastify, opts, next) =&gt; { fastify.decorate('utility', () =&gt; {}) fastify.get('/', handler) next()} Handle the ScopeYou have two ways to tell Fastify to avoid the creation of a new context: Use the fastify-plugin module Use the skip-override hidden property We recomended to use the fastify-plugin module, because it solves this problem for you, and you can pass as parameter a version range of Fastify taht your plguin support. 123456const fp = require('fastify-plguin')module.exports = fp(function(fastify, opts, next) { fastify.decorate('utility', () =&gt; {}) next()}, '0.x')","link":"/2017/10/23/Time-to-start-fastify/"},{"title":"Type Compatibility in TypeScript","text":"Type Compaibility in TypeScript is based on Structural Subtyping. Structural Typing is a way of relating types based solely on their members. This is in contrast with nominal typing. Consider the following code: 1234567891011interface Named { name: string}class Person { name: string}let p: Named// OK, because of structural typingp = new Person() In nominally-typed language like C# or Java, the equivalnet code would be error because the Person class does not explicitly describe itself as being an implementor of the Named interface. TypeScript’s structural type system was designed based on how JavaScript code is typically written. Because JavaScript widely uses anonymous objects like function expressions and object literals, it’s much more natural to represent the kinds of relationship found in JavaScript libraries with a structural type system instead of a nominal one. The basic rule for TypeScript’s structural type system is the x is compatible with y if y has at least the same members as x. 12345678interface Named { name: string;}let x: Named;// y's inferred type is { name: string, location: string }let y = { name: 'Alice', location: 'Seattle' }x = y To check whether y can be assigned to x, the compiler checks each property of x to find a corresponding compatible property in y. In this case, y must have a member called name that is a string, so the assignment is allowed. The same rule for assignment is used when checking function call arguments The Type Compatibility in Variable Assignment and Function Arguments. Comparing Two Functions12345let x = (a: number) =&gt; 0let y = (b: number, s: string) =&gt; 0y = x // OKx = y // Error The check if x is assignable to y, we first look at the parameter list. Each parameter in x must have a corresponding parameter in y with a compabile type. So x is assignable to y, but y is not assignable to x Now let’s look at how return types are treated, using two functions that differs only by their return type: 12345let x = () =&gt; ({ name: 'Alice' })let y = () =&gt; ({ name: 'Alice', location: 'Seattle' })x = y // OKy = x // Error The type system enforces that the source function’s return type be a subtype of the target type’s return type.","link":"/2017/06/12/Type-Compatibility-in-TypeScript/"},{"title":"Tutorial Part 2 of Dapp","text":"oo7 BondsNow we have our basic dapp harness, we can start introducing more interesting functionality. Without too much ado, let’s get started. Head in to src/client/scripts/app.jsx. You will see our basic file: 123456789import React from 'react'export class App extends React.Component { render () { return ( &lt;div&gt;Hello World&lt;/div&gt; ) }} This is a JSX file. Baiscally means that can handle embedded HTML when describing how React components should be rendered. Your first BondThe first thing we’ll do is introduce the oo7 library. This introduces into Javascript the notion of reactive value known as ‘bonds’. Reactive values are similar to normal variables, except that any places in which they are used will automatically upate themselves as the value changes. The oo7 package is still very much in development, as such there might be one or two rough edges in this tutorial. Our first example will just demonstrate how Bond can introduce effortless reactivity by dynamically replicating the contents of an editable text field into a &lt;span&gt;. Import the needed components by placing three lines at the top of app.jsx 123import { Bond } from 'oo7'import { Rspan } from 'oo7-react'import { InputBond } from 'parity-reactive-ui' Next we need to introduce a new instance of a Bond. It will represent the current contents of a text field. We will initialize it in our class’s contructor. Insert these lines directly into the App class decalration. 1234constructor () { super () this.bond = new Bond()} Your code should now look like this: 12345678910111213141516import React from 'react'import { Bond } from 'oo7'import { Rspan } from 'oo7-react'import { InputBond } from 'parity-reactive-ui'export class App extends React.Component { constructor () { super () this.bond = new Bond() } render () { return ( &lt;div&gt;Hello World&lt;/div&gt; ) }} Next we need to create the text entry field and the &lt;span&gt; element(in which the text field’s contents will be reflected). We will use a version of Semantic UI’s Input element which has been specially modified to propagate the value into a named Bond. This is called InputBond. Similarly, for the span we will use a special ‘reactive’ version of the span element which is able to accept Bonds as children and values of certain properties. This is known as Rspan. Change the &lt;div&gt;Hello World&lt;/div&gt; line to: 1234&lt;div&gt; &lt;InputBond bond={this.bond} placeholder=\"Go ahead and type some text\" /&gt; &lt;Rspan&gt;{this.bond}&lt;/Rspan&gt;&lt;/div&gt; As you see there’s not all that much here, we just tell the text field input InputBond to place its value into this.bond and conversely tell Rspan to display that value from this.bond. Run webpack and let it watch your files to ensure your dapp is continuously rebuilt. 1npm start Transforming BondsBonds don’t just have to pass on data; they can also represent transformations on the data. One example of a transform on text would be simple upper-casing. A function to upper-case text would be text =&gt; text.toUpperCase() 1&lt;Rspan&gt;{this.bond.map(t =&gt; t.toUpperCase())}&lt;/Rspan&gt;","link":"/2017/07/13/Tutorial-Part2-of-Dapp/"},{"title":"Tutorial Part 4 of Dapp","text":"Calling ContractsContract API basically comes in three pieces. Firstly, there’s state-changing transaction like tranferring tokens to a counter-party. Secondly, there’s event reception and reporting that happen when such a state change occurs. Finally, there is inspection of the contract state through calling constant function. Our first contractThe first contract we will deal with is the global(name) registry. If you are not yet familiar, this is a registry that exists on all sensible blockchain which records fields of information for any desired name. The registry records onwership information so that names can be registered and their information changed at a later date. The registry contract has a fairly simple API for inspecting. We only need to worry about two functions: getOwner(bytes32) -&gt; address, given the Keccak hash of name, this returns the address of its owner, if it has been reserved. getData(bytes32, bytes32) -&gt; bytes32, given the Keccak hash of a name and a second field key, this returns the associated data. There are subordinate functions to the latter such as getAddress and getUint which coerce the data into some other type. It is important to note that amongst the standardised field keys are: \u0006A the address primarily associated with the name; if you’re wanting to send funds to the name, this is where to send them(assuming it’s not null) CONTENT the bytes32 which equals the Keccak hash of any content associated with this name. e.g. If the name represents a dapp, then this would be the hash of the dapp’s content. IMG the bytes32 which equals the Keccak hash of an associated image; this might be a person’s avatar or the dapp icon, depending on what is being named. Let’s begin by displaying the address associated with the name gavofyork. To do this we will need to create a special Bond-API contract object. The function to do this is bonds.makeContract; It takes the address and the ABI of the contract and returns an object with Bond – returning functions for each of the contract’s functions. The address is easy enough to find; this can be determined via the parity.api.parity.registry call. The ABI spec is rather long and can be derived from the contract code available at the ethcode/contracts repository. Since there is only a single canonical registry, Parity, conveniently constructs this for you and provides it at the bonds.registry object. To figure out the primary associated address of the gavofyork name, we can use the getAddress call, together with the parity.api.util.sha3 call to take the Keccak hash of our name. The full expression would be: 1bonds.registry.getAddress(parity.api.util.sha3('gavofyork')) Typing parity.api.util.sha3(...) every time you want to look up a name in the registry gets tedious fast. Happily, Parity provides a number of derivative helper functions as part of the bonds'registry object: lookupDate, lookupAddress, lookupUint and lookupOwner. They are all just like the get- prefixed brethren, but do the hashing for you. Our expression therefore can become: 1bonds.registry.lookupAddress('gavofyork', 'A') Let’s get this in to our dapp, Change the render()ed HTML to: 1234&lt;div&gt; gavofyorks address is: &lt;Rspan&gt;{bonds.registry.lookupAddress('gavofyork', 'A')}&lt;/Rspan&gt;&lt;/div&gt; Dynamic lookups123456789101112131415161718export class App extends React.Component { constructor () { super() this.bond = new Bond() } render () { return ( &lt;div&gt; Address of &lt;InputBond bond={this.bond} placeholder=\"Lookup a name\" /&gt; is:&lt;br /&gt; &lt;Rspan&gt;{bonds.registry.lookupAddress(this.bond, 'A')}&lt;/Rspan&gt; Its balance is &lt;Rspan&gt; {bonds.balance(bonds.registry.lookupAddress(this.bond, 'A')).map(formatBalance)} &lt;/Rspan&gt; &lt;/div&gt; ) }} Derivative contractsTypically the registry is used to lookup the address of a second contract that you would actucally like to use. Let’s suppose that second contract is the GithubHint contract; if you’re not already familiar, the GithubHint contract allows you to suggest which URLs might serve content for a particular hash.It’s a semi-centralized, hacky alternative to content-addressable-delivery systems like BitTorrent/Kademlia, Swarm and IPFS. We use it widely in Parity as a means of content dissemination. Since is a ‘standard’ contract in Parity, the ABI for it is available in oo7-parity as GitHubHintABI. The address changes per chain, but can be discovered via the registry under the name ‘githubhint’. The expression would therefore be bonds.registry.lookupAddress('githubhint', 'A'). Though we mustn’t forget to import GitHubHint 1import { GitHubHintABI } form 'oo7-parity' The GithubHint contract has only a single inspection method: entries. This takes a bytes32 and returns three items(via an array). There are three kinds of entry: Github repository entries, whereby the first and second items form the addresss of a particular commit of a particular repository; general URLs, where the first item is a URL and the second is the null hash; and empty entries where both items are null. The third item is always the owner (if any) of the entry and the only account capable of changing the hint information. In this small demo, we’ll assume that we are looking up only URLs and so are only interested in the first item. We therefore want an expression like: 1GitHubHint.entries(hash)[0] Where hash is some content hash and GitHubHint is the contract object. Putting this all together we can change our dapp to: 123456789101112131415export class App extends React.Component { constructor () { super() this.bond = new Bond() this.GitHubHint = bonds.makeContract(bonds.registry.lookupAddress('githubhint', 'A'), GitHubHintABI) } render () { return ( &lt;div&gt; URL for content &lt;HashBond bond={this.bond} floatingLabelText=\"Content-Hash\" /&gt; is: &lt;Rspan&gt;{this.GithubHint.entries(this.bond)[0]}&lt;/Rspan&gt; &lt;/div&gt; ) }} Note that we are using HashBond from oo7-react rather than InputBond. This just ensures that we enter only valid 32-byte hashes. Ensure that the import line is changed to: 1import { InputBond, HashBond } from 'parity-reactive-ui'","link":"/2017/07/14/Tutorial-Part-4-of-Parity/"},{"title":"Usage of Chai","text":"Chains to be been is that which and has have with at of same not negative any of assertions following in the Chains 1expect(foo).to.not.equal('bar') deep set the deep flag, later used by the equal and property assertions 1expect(foo).to.deep.equal({bar: 'bar'}) any set the any flag, (opposite of the all flag), later used in the keys assertion 1expect(foo).to.have.any.keys('bar', 'foo') all set the all flag, (opposite of the any flag), later used by the keys assertions 1expect(foo).to.have.all.keys('bar', 'foo') a(type) @param {String} type @param {String} message [optional] The a and an assertion are aliases that can be used either as language chains or to assert a value’s type 1234// typeofexpect('test').to.be.a('string')// language chainexpect(foo).to.be.an.instanceof(Foo) include(value) @param {Object | String | Number} obj @param {String} message [optional] The include and contain assertion can be used as either property based language chains or methods to assert the inclusion of an object in an array or a substring in a string. 123expect([1,2,3]).to.include(2)expect('foobar').to.contain('foo')expect({ foo: 'foo', bar: 'bar' }).to.include.keys('foo') ok Assert that the target is truthy 12expect('everything').to.be.okexpect(undefined).to.not.be.ok true Assert that the target is true 12expect(true).to.be.trueexpect(1).to.be.true false Assert that the target is false 12expect(false).to.be.falseexpect(0).to.be.false null Assert that the target to be null 1expect(null).to.be.null undefined Assert that the target is undefined 1expect(undefined).to.be.undefined NaN Assert that the target is NaN 1expect('foo').to.be.NaN exist Assert that the target is neither null nor undefined 1expect('foo').to.be.exist empty Assert that the target’s length is 0. For Array and String, it will check the length of propertes. For Object, it will check the length of enumerable keys 1expect([]).to.be.empty arguments Assert that the target is an arguments object 123function test () { expect(arguments).to.be.arguments} equal(value) @param {Mixed} value @param {String} message [optional] Assert that the target is strictly equal(===) to value. Alternately, if the .deep flag is set, assert that the target is deeply equal to value 12expect('hello').to.equal('hello')expect({foo: 'foo'}).to.deep.equal({foo: 'foo'}) eql(value) @param {Mixed} value @param {String} message [optional] 1expect({foo: 'foo'}).to.eql({foo: 'foo'}) above(value) @param {Number} value @param {String} message [optional] Assert that the target is greater than value 1expect(10).to.be.above(5) Can also be used in conjunction with length to assert a minimum length. 1expect('foo').to.have.length.above(2) least(value) @param {Number} value @param {String} message [optional] Assert that the target is greater than or equal to value 1expect(10).to.be.at.least(10) used for length too below(value) @param {Number} value @param {String} message [optinal] Assert that the target is less than value 1expect(5).to.be.below(10) used for length too most(value) @param {Number} value @param {String} message [optinal] Assert that the target is less than or equal to value 1expect(5).to.be.at.most(5) used for length o within(start, finish) @param {Number} start lowerbound inclusive @param {Number} finish upperbound inclusive @param {String} message [optional] Assert that the target is within a range 1expect(28).to.be.within(2, 30) used for length too instanceof(constructor) @param {Constructor} constructor @param {String} message [optional] 1234567var Tea = function (name) { this.name = name,}var Chai = new Tea('chai')expect(Chai).to.be.an.instanceof(Tea)expect([1,2,3]).to.be.an.instanceof(Array) property(name[, value]) @param {String} name @param {Mixed} value [optional] @param {String} message [optional] Assert that the target has a property name, optionally asserting that the value of that property is strictly equal to value. If the deep flag is set, you can use dot- and bracket-notation for deep reference into objects and arrays. 12expect(obj).to.have.property('foo')expect(obj).to.have.property('foo', 'bar') to be continued","link":"/2017/04/21/Usage-of-Chai/"},{"title":"Web App Manifest","text":"The web app manifest provides information about an application(such as name, author, icon and description) in a JSON text file. The purpose of the manifest is to install web application to the homescreen of a device, providing users with quicker access and a richer experience. Web app manifest are part of a collection of web technologies called progressive web apps, which are web applications that can be installed to the homescreen of a device without needing the user to go through an app store, along with other capabilities such as being available offline and receiving push notification. Deploying a manifestWeb app manifests are deployed in your HTML pages using a link tag in the head of your document. 1&lt;link ref=\"manifest\" href=\"/manifest.json\" /&gt; Example12345678910111213{ \"name\": \"HackerWeb\", \"short_name\": \"Hacker\", \"start_url\": \".\", \"display\": \"standalone\", \"background_color\": \"#fff\", \"description\": \"A simple readable Hacker New app.\", \"icons\": [{ \"src\": \"images/touch/homescreen48.png\", \"sizes\": \"72x72\", \"\u0006type\": \"image/png\" }]}","link":"/2017/07/29/Web-App-Manifest/"},{"title":"Usage of Mock","text":"Installation1yarn add mockjs Simple Usage1234567const Mock = require('mock')const data = Mock.mock({ 'list|1-10': [{ 'id|+1': 1 }]})console.log(JSON.stringify(data)) Data Template Definition(DTD)Each attribute consists of three parts: 12345// attribute name// attribute rule// attribute value'name|rule': value rule is optional 12345678910// rules{ 'name|min-max': value, 'name|count': value, 'name|min-max.dmin-dmax': value, 'name|min-max.dcount': value, 'name|count.dmin-dmax': value, 'name|count.dcount': value, 'name|+step': value,} 12345'name|min-max': string // repeat 'string' less than or equal to 'min', more than or equal 'max''name|count': string // repeat 'string' 'count' times.'name|+1': 0, // auto incresing with step 1 from 0'name|min-max': number // generate a number &gt;=min and &lt;=max'name|min-max.dmin-dmax': number // generate a float, the integer part &gt;=min and &lt;=max, the deciaml part remains dmin - dmax bits. 12345678910111213Mock.mock({ 'number1|1-100.1-10': 1, 'number2|123.1-10': 1, 'number3|123.3': 1, 'number4|123.10': 1.123})// =&gt;{ \"number1\": 12.92, \"number2\": 123.51, \"number3\": 123.777, \"number4\": 123.1231091814} Data Placeholder Definition(DPD)Placeholder hold a position in attribute string, and will dismiss in result. Use Mock.Random to generate data. 12@placeholder@placeholder(opt1[, opt2]) 1234567891011121314151617Mock.mock({ name: { first: '@FIRST', middle: '@FIRST', last: '@LAST', full: '@first @middle @last' }})// =&gt;{ \"name\": { \"first\": \"Charles\", \"middle\": \"Brenda\", \"last\": \"Lopez\", \"full\": \"Charles Brenda Lopez\" }} Mock.mock()Mock.mock(rurl?, rtype?, template | function(options))Mock.mock(template)Generate mock data Mock.mock(rurl, template)Intercept rurl(regexp) request, and generate according template. Mock.mock(rurl, function(options))Intercept rurl request and call function(options) to return the mock data. Mock.mock(rurl, rtype, template)Intercept the request matching rurl and rtype. Mock.mock(rurl, rtype, function(options))Intercept the request matching rurl and rtype. options conssits of (url, type, body) Mock.setup()Mock.setup(settings) Set action when intercept ajax request. 123{ timeout: ''} timeout: set time responding time, ‘300’, ‘300-600’, default to ‘10-100’ 123Mock.setup({ timeout: '200-400',}) Mock.RandomUtils to generate Random data. 12345678var Random = Mock.RandomRandom.email()Mock.mock('@email') // use with placeholderMock.mock({ email: '@email'}) | Type | Mehtod || Baisc | boolean, natural, integer, float, character, string, range, date, time, datetime, now || Image | image, dataImage || Color | color || Text | paragraph, sentence, word, title, cparagraph, csentence, cword, ctitle || Name | first, last, name, cfirst, clast, cname || Web | url, domain, email, ip, tld || Address | area, region || Helper | capitalize, upper, lower, pick, shuffle || Miscellaneous | guid, id | Mock.Random.boolean(min?, max?, current?)‘min’ and ‘max’ decide the possibility of ‘current’ ‘current’ will appear in possibility of min/(min + max) to max(min + max) Mock.Random.natural(min?, max?)Mock.Random.integer(min?, max?)Mock.Random.float(min?, max?, dmin?, dmax?)Mock.Random.character(pool?)pool represents the character pool pool: ‘lower/upper/number/symbol’123456{ lower: &apos;abcdefghijklmnopqrstuvwxyz&apos;, upper: &apos;ABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;, number: 0123456789, symbol: &apos;!@#$%^&amp;*()[]&apos;} Mock.Random.string(pool?, min?, max?)pool: available string poolmin: min-length, default to 3max: max-length, default to 7 Mock.Random.range(start?, stop, step?)Mock.Random.date(format?)Mock.Random.time(format?)Mock.Random.datetime(format?)Mock.Random.now(unit?, format?)Mock.Random.image(size?, background?, foreground?, format?, text?)Mock.Random.dataImage(size?, text?)Mock.Random.color()Mock.Random.hex()Mock.Random.rgb()Mock.Random.rbga()Mock.Random.hsl()Mock.Random.paragraph(null | length | min, max) | Mock.Random.cparagraph(null | length | min, max)Mock.Random.sentence(null | length | min, max) | Mock.Random.csentence(null | length | min, max)Mock.Random.workd(null | length | min, max) | Mock.Random.cword(pool?, min?, max?)Mock.Random.title(null | length | min, max) | Mock.Random.ctitle(null | length | min, max)Mock.Random.first() | Mock.Random.last() | Mock.Random.name(middle?) | Mock.Random.cfirst() | Mock.Random.clast() | Mock.Random.cname()Mock.Random.url(protocol?, host?)Mock.Random.protocol() | Mock.Random.domain() | Mock.Random.tld() | Mock.Random.email(domain?) | Mock.Random.ip()Mock.Random.region() | Mock.Random.province() | Mock.Random.city(prefix?) | Mock.Random.county(prefix?) | Mock.Random.zip()Mock.Random.captilize(word) | Mock.Random.upper(str) | Mock.Random.lower(str) | Mock.Random.pick(arr) | Mock.Random.shuffle(arr)Mock.Random.guid()Generate a GUID Mock.Random.id()Generate a Personal Identity Mock.Random.increment(step?)Mock.valid(template, data)Check if the data is matching the template","link":"/2017/08/29/Usage-of-Mock/"},{"title":"Usage","text":"","link":"/2017/04/20/Usage/"},{"title":"Usage of Node-Influx","text":"IntroductionInfluxDB is a time series database, so it would make sense that the concept of time is moderately important when dealing with it. By default, Influx will store all dates you give to it as a nanosecond precision timestamp, whereas in JavaScript, most of the time we’re dealing with millisecond precision timestamps, which we get from Date.now() or myDate.getTime(). This presents a bit of a problem for us JavaScripters, since nanosecond-precision timestamps are stored as 64-bit unsigned integers that JavaScript simply cannot represent accurately. 123node-influx git:(master) node&gt; 14759854802310356771475985480231035600 This module tries to make dates as easy as possible for you to deal with, and out of the box everything should ‘just work’. There are three places that dates can get passed around: Dates coming rom Influx queries, like select * from my_series Dates being interpolated into Influx queries Dates being used when writing points on the line protocol, via .writePoints() or .writeMeasurement(). To deal with this, we introduce a new type called NanoDate. These dates behave just like the normal Date type, but have two additional methods: .getNanoTime() and .getNanoISOString(). They behave just like the normal .getTime() and getISOString methods, but they both return nanosecond-precision strings instead of millisecond-precision numbers and timestamps. 1234expect(myNanoDate.getTime()).to.equal(1475985480231)expect(myNanoDate.getNanoTime()).to.equal('1475985480231035677')expect(myNanoDate.toISOString()).to.equal('2016-10-09T03:58:00.231Z')expect(myNanoDate.toNanoISOString()).to.equal('2016-10-09T03:58:00.231035677Z') All times returned from Influx queries are parsed to INanoDates. For example you can do something like the following: 123influx.query('select * from perf').then(results =&gt; { result.forEach(row =&gt; console.log(`Used ${row.cpu} at ${row.time.toNanoISOString()}`))}) When writing data to Influx, all write methods accept INanoDates in all situation. This means if you select data from Influx and want to update a data point, you can pass the time right back into write method. (Remember, points within series are unique by their time) If you have a nanosecond timestamp from some external source, you can convert it to INanoDate using toNanoDate. 123456import { toNanoDate } from 'influx'const myNanoDate = toNanoDate('1475985480231035600')expect(myNanoDate.getTime()).to.equal(1475985480231)expect(myNanoDate.getNanoTime()).to.equal('1475985480231035600')expect(myNanoDate.toNanoISOString()).to.equal('2016-10-09T03:58:00.231035600Z') Finally, if you want to embed a iNanoDate into an Influx query, you should use toNanoString to do so: 1influx.query(`select * from perf where time &gt; \"${myNanoDate.toNanoISOString()}\"`) Browser SetupFor Node.js, influx can be installed and you can use it out of the box. 1yarn add influx@next You can tell Webpack to use this module by adding the following section in your webpack.config.js: 1234567const http = path.resolve(__dirname, 'node_modules/stream-http/index.js')module.exports = { resolve: { alias: { http, https: http }, }} ReferenceClass Summary attr name public ExponentialBackoff public Expression: Expression is used to build filtering expression, like those used in WHERE clausespublic | InfluxDB:InfluxDB is the public interface to run queries against your databasepublic | Measurement:Measurement creates a reference to a particular measurementpublic | Pool:The Pool maintains a list available Influx hosts and dispatches requests to thempublic | Raw:You can provide Raw values to Influx methods to prevent it from escaping your provided string.public | RequestError:An RequestError is thrown when a query generates errorful results in a 300&lt;= error &lt;=500public | ResultError:An ResultError is thrown when a query generates errorful results from Influxpublic | ServiceNotAvailableError:An ServiceNotAvailableError is returned as an error from requests that result in a &gt;500 error code interface Summary attr name public IBackoffStrategy: The IBackoffStrategy dictates behavior to use when hosts in the connection pool start failingpublic | INanoDate:An INanoDate is a type of Date that holds a nanosecond-precision unix timestamppublic | IResults:IResults are returned from the InfluxBD#query mehtod Function Summary attr name public toNanoDate(timestamp: String): NanoDate: Covers a nanoseconds unix timestamp to a INanoDate for node-influx. Variable Summary attr name public Precision: Object :Precision is a map of available influx time precisionpublic | escape: Object:tagEscaper escapes tag keys, tag values and field keys. Typedef Summary attr name public FieldType: Number: FieldType is an enumeration of influxDB field data typespublic | IClusterConfig: Object:A IClusterConfig can be provided into new InfluxDB(config) when you have a multiple influx nodes to connect topublic | IPingStats: Object:IPingStats is returned from InfluxDB#pingpublic | IPoint: ObjectIPoint is passed to the client’s write methods to store a point in InfluxDBpublic | IPoolOptions: ObjectPool options can be passed into the database to configure the behavior of the connection Poolpublic | IQueryOptions: ObjectThe IQueryOptions allows you to configure how queries are run against Influxpublic | ISchemaOptions: ObjectSchema options can be passed into the new InfluxDB() constructor to help define the shape of your data.public | ISingleHostConfig: ObjectA ISingleHostConfig can be provided into new InfluxDB(config) when you have a single Influx address to connect topublic | IWriteOptions: ObjectIWriteOptions configure how points are written in the database.","link":"/2017/06/30/Usage-of-Node-Influx/"},{"title":"WS on Node","text":"Create WS Server12345678// get WS Objectconst WebSocket = require('ws')// Create new Server Instanceconst ws = new WebSocket.Server({ port: 80, // port verifyClient: socketverify // (optional)function to verify connection}) new WebSocket.Server(options[, callback])12345678910111213options: { host: string, port: number, backlog: number, // the maximum length of the queue of pending connection. server: http.Server | https.Server, // a pre-created Node Http Server. verifyClient: function, // a function which can be used to validate incoming connections. handleProtocols: function, // a function which can be used to handle the WebSocket subprotocols. path: string, // Accept only connections matching this path. noServer: boolean, // Enable no server mode. clientTracking: boolean, // Specifies whether or not track clients. perMessageDeflate: boolean | object, // Enable/Disable permessage-deflate. maxPayload: number, // Maximum allowed message size in bytes.} Create a new server instance. One of port, server, or noServer must be provided or an error is thrown. Set VerifyClient12345678function socketverify(info) { // connect if return true var origin = info.origin.match(/*...*/) if (/*...*/) { return true } return false} If verifyClient is not set then the handshake is automatically accepted. If it is is provided with a single argument then that is: 12345info: { origin: string, // The value in the Origin header indicated by the client. req: http.incomingMessage, // The client HTTP GET request. secure: boolean, // `true` is `req.connection.authorized` or `req.connection.encrypted` is set.} If the verifyClient provided with 2 arguments, the second one is cb, which accepts result: boolean, code: number, name: string. Handle Request123456789101112131415161718192021ws.on('connect', (socket) =&gt; { // the socket is a connect to client // usually you should push it in an array for management socket.onmessage = message socket.onclose = close socket.onerror = error socket.onopen = open})function message(msg) { // ...}function error(err) { // ...}function close() { // ...}function open() { // ...} EventsMethodsSending msg1socket.send(data[, options[, callback]]) data: binary or string options: mask: true | false 是否使用掩码 binary: true | false 是否二进制流 compress: true | false 是否压缩 callback: 回调 close connection1socket.close([code], [data]) code: 返回一个状态码 data: 结束连接时发送的信息 pause1socket.pause() resume1socket.resume() PING1socket.ping([data], [options], [dontFailWhenClosed]) data: ping 的时候发送的信息 options: 同 send dontFailWhenClosed: true | false // 如果连接断开, 是否抛出错误 PONG1socket.pong([data], [options], [dontFailWhenClosed]) Ping 和 Pong 的区别在于, 一个包含 ping 帧(0x9), 一个包含 pong 帧(0xA) pong 是对于接到 ping 之后的回应, 让双方都知道连接还存在 streamterminate","link":"/2017/07/31/WebSocket-on-Node/"},{"title":"Writing Data in InfluxDB With HTTP API","text":"Create a database using the HTTP APITo create a database send a POST request to the /query endpoint and set the URL parameter q to CREATE DATABASE &lt;new_database_name&gt;. The example below sends a request to InfluxDB running on locahost and create the database mydb. 1curl -i -XPOST http://localhost:8086/query --data-urlencoded \"q=CREATE DATABASE mydb\" Writing data using the HTTP APIThe HTTP API is the primary means of writing data into InfluxDB, by sending POST requests to the /write endpoint. The example below writes a single point to the mydb database. The data consist of the measurement cpu_load_short. the tag keys host and region with the tag values server01 and us-west, the field key value with a field value of 0.64 and the timestamp 434055562000000000. 1curl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary 'cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000' When writing points, you must specify an existing database in the db query parameter. Points will be written to db‘s default retention policy if you do not supply a retention policy via the rp query parameter. The body of the POST - we call this the Line Protocol - contains the time-series data that you wish to store. They consist of a measurement, tags, fields, and a timestamp. InfluxDB requires a measurement name. Strictly speaking, tags are optional but most series include tags to differentiate data sources and to make querying both easy and efficient. Both tag keys and tag values are strings. Field keys are required and always strings, and by default, field values are floats. The timestamp - supplied at the end of the line in Unix time in nanoseconds since January 1, 1970 UTC - is optional. If you do not specify a timestamp InfluxDB uses the server’s local nanoseconds timestamp in Unix epoch. Anything that has to do with tim ein InfluxDB is always UTC. Writing multiple pointsPost multiple points to multiple series at the same time by separating each point with a new line. Batching points in this manner results in much higher performance. The following example writes three points to the database mydb. The first point belongs to the series with the measurement cpu_load_short and tag set host-server02 and has the server’s local timestamp The second point belongs to the series with the measurement cpu_load_short and tag set host=server02,region=us-west and has the specified timestamp 1422568543702900257. The third point has the same specified timestamp as the second point, but it is written to the series with the measruement cpu_load_short and tag set direction=in,host=server01,region=us-west 1curl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary 'cpu_load_short,host=server02 value=0.67 cpu_load_short,host=server02,region=us-west value=0.5 cpu_load_short,direction=in,host=server01,region=us-west value=0.2' Writing points from a fileWrite points from a file by passing @filename to curl. The data in the file should follow InfluxDB’s line protocol syntax Example of a properly-formatted file(cpu_data.txt) 123cpu_load_short,host=server02 value=0.2cpu_load_short,host=server02,region=us-west value=0.5cpu_load_short,direction=in,host=server01,region=us-west value=0.2 Write the data in cpu_data.txt to the mydb datbase with: 1curl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary @cpu_data.txt Note: If your data file has more than 5000 points, it may be necessary to split that file into several files in order to write your data in batches to influxDB. By default, the HTTP request times out after five seconds. InfluxDB will still attempt to write the points after that time out but there will be no confirmation that they were successfully written. Schemaless DesignInfluxDB is a schemaless database. You can add new measurement, tags, and fields at any time. Note that if you attempt to write data with a different type than previous used(for example, writing a string to a field that previously accepted integers), InfluxDB will reject those data. HTTP response summary 2xx: If you write request received HTTP 204 No Content, it was a success 4xx: InfluxDB could not understand the request 5xx: The system is overloaded or significantly impaired.","link":"/2017/06/30/Writing-Data-in-InfluxDB-with-HTTP-API/"},{"title":"What Blockchain Came With","text":"MindMap","link":"/2018/02/14/What-Blockchain-came-with/"},{"title":"applyMiddleware 与 Enhancer","text":"import { createStore, applyMiddleware, compose } from &apos;redux&apos; const store = createStore( reducer, preloadedState, // &amp;lt;----- 可选，前后端同构的数据同步 compose( // &amp;lt;------------ 还记得吗？compose 是从右到左的哦！ applyMiddleware( // &amp;lt;-- 这货也是 Store Enhancer 哦！但这是关乎中间件的增强器，必须置于 compose 执行链的最后 middleware1, middleware2, middleware3 ), enhancer3, enhancer2, enhancer1 ) )","link":"/2016/08/25/applymiddleware-e4-b8-8e-enhancer/"},{"title":"Accordion With jQuery","text":".accordion{ margin:50px auto; width: 380px; cursor:pointer;}.accordion .item{ height:100px;}.accordion .item h3{ display:inline-block; vertical-align:middle; height: 100%; padding-left: 50px; font-size: 20px; font-weight: 400;}.accordion .item h3:before{ content:””; display:inline-block; vertical-align:middle; height: 100%;}.accordion .item:first-of-type{ background-color: #620808; color:#f4ce74;}.accordion .item:nth-of-type(2){ background-color: #a53f3f; color:#ffe9c1;}.accordion .item:nth-of-type(3){ background-color: #f4ce74; color:#620808;}.accordion p{ font-family:arial; font-size: 18px; font-weight: 400; padding: 15px; display:none; margin:0; box-shadow: inset 0 3px 7px rgba(0,0,0,.2);}.accordion p:first-of-type{ background-color: #620808; color:#f4ce74;}.accordion p:nth-of-type(2){ background-color: #a53f3f; color:#ffe9c1;}.accordion p:nth-of-type(3){ background-color: #f4ce74; color:#620808;} ### Item1 Lorem ipsum dolor sit amet, consectetur adipisicing elit. Distinctio in error ipsa facere, veritatis fuga incidunt tempore perferendis placeat. Dolore iste laborum porro possimus officia ratione rerum cumque itaque ullam. ### Item2 Lorem ipsum dolor sit amet, consectetur adipisicing elit. Distinctio in error ipsa facere, veritatis fuga incidunt tempore perferendis placeat. Dolore iste laborum porro possimus officia ratione rerum cumque itaque ullam. ### Item3 Lorem ipsum dolor sit amet, consectetur adipisicing elit. Distinctio in error ipsa facere, veritatis fuga incidunt tempore perferendis placeat. Dolore iste laborum porro possimus officia ratione rerum cumque itaque ullam. /HTML/ section.accordion div.item h3{Item1} p{Lorem} div.item h3{Item2} p{Lorem} div.item h3{Item3} p{Lorem} /CSS/ body{ background-color: #f6704b; } { margin:0; padding: 0; } .accordion{ margin:50px auto; width: 380px; background-color: #ccc; cursor:pointer; } .accordion .item{ height:100px; } .accordion .item h3{ display:inline-block; vertical-align:middle; height: 100%; padding-left: 50px; font-size: 20px; font-weight: 400; } .accordion .item h3:before{ content:””; display:inline-block; vertical-align:middle; height: 100%; } .accordion .item:first-of-type{ background-color: #620808; color:#f4ce74; } .accordion .item:nth-of-type(2){ background-color: #a53f3f; color:#ffe9c1; } .accordion .item:nth-of-type(3){ background-color: #f4ce74; color:#620808; } .accordion p{ font-family:arial; font-size: 18px; font-weight: 400; padding: 15px; display:none; box-shadow: inset 0 3px 7px rgba(0,0,0,.2); } .accordion p:first-of-type{ background-color: #620808; color:#f4ce74; } .accordion p:nth-of-type(2){ background-color: #a53f3f; color:#ffe9c1; } .accordion p:nth-of-type(3){ background-color: #f4ce74; color:#620808; } /jQuery*/ (function($) { ‘use strict’; $(“.item”).on(“click”,function(){ $(this).next().slideToggle(100); $(“p”).not($(this).next()).slideUp(‘fast’); }); }(jQuery)); (function($) { ‘use strict’; $(“.item”).on(“click”,function(){ $(this).next().slideToggle(100); $(“p”).not($(this).next()).slideUp(‘fast’); }); }(jQuery));","link":"/2016/06/20/accordion-with-jquery/"},{"title":"Writing Upgradable Contracts in Solidity","text":"Original Ethereum contracts are immutable – once deployed to the blockchain they cannot be updated, yet the need to change their logic with time is ultimately necessary. During a contract upgrade the following factors need to be considered: Block gas limit(4712388 for Homestead) Upgrade transaction tend to be large due to the amount of processing they have to complete e.g. deploy a contract, move data, move references. Inter-contract dependencies when a contract is compiled, all of its imports are compiled into the contract thus leading to a ripple effect when you want to swap out a contract which is being referenced by other contract. These two are related, as having more dependencies affects the size of your deployed contracts and the overall transaction size of the upgrade. The implementation patterns below work to minimise the upgrade gas costs as well as loosening the coupling of contracts without breaking Solidity type safety. Note that for the sake of simplying the examples, we have omitted the implementation of security and permission. Avoiding large data copy operationsStoring data is expensive(SSTORE operation costs 5000 or 20000 gas) and upgrading contracts containing large storage variables runs the chance of hitting the transaction gas limit during the copying of its data. You may therefore want to isolate your datastore from the rest of your code, and make it as flexible as possible, so that it is unlikely to need to be upgrade. Depending on your circumstances, how large of a datastore you need and whether you expect its structure to change often, you may choose a strict definition or a loosely typed flat store. Below is an example of the latter which implements support for storing a sha3 key and value pairs. It is the more flexible and extensible option. This ensures data schema changes can be implemented without requiring upgrades to the storage contract. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061contract EternalStorage { mapping(bytes32 =&gt; uint) UIntStorage; function getUIntValue(bytes32 record) constant returns (uint) { return UIntStorage[record]; } function setUIntValue(bytes32 record, uint value) { UIntStorage[record] = value; } mapping(bytes32 =&gt; string) StringStorage; function getStringValue(bytes32 record) constant returns (string) { return StringStorage(record); } function setStringValue(bytes32 record, string value) { StringStorage[record] = value; } mapping(bytes32 =&gt; address) AddressStorage; function getAddressValue(bytes32 record) constant returns (address) { return AddressStorage[record]; } function setAddressValue(bytes32 record, address value) { AddressStorage[record] = value; } mapping(bytes32 =&gt; bytes) BytesStorage; function getBytesValue(bytes32 record) constant returns (bytes) { return BytesStorage[record]; } function setBytesValue(bytes32 record, bytes value) { BytesStorage[record] = value; } mapping (bytes32 =&gt; bool) BooleanStorage; function getBooleanValue(bytes32 record) constant returns (bool) { return BooleanStorage[record]; } function setBooleanValue(bytes32 record, bool value) { BooleanStorage[record] = value; } mapping (bytes32 =&gt; int) IntStorage; function getIntValue(bytes32 record) constant returns (int) { return IntStorage[record]; } function setIntValue(bytes32 record, int value) { IntStorage[record] = value; }} For upgrades you can then just switch the upgraded contract to point to the new EternalStorage contract instance without having a copy of its data. Use Libraries to Encapsulate LogicLibraries are special form of contracts that are singletons and not allowed any storage variables. The advantage of libraries in the context of upgrades is that they allow encapsulation of business logic or data management logic into singleton instance that cost only upgrading one and not many contracts. Example below shows a library used for adding a Proposal to storage. 1234567891011121314import \"EternalStorage.sol\";library ProposalsLibrary { function getProposalCount(address _storageContract) constant returns (uint256) { return EternalStorage(_storageContract).getUIntValue(sha3(\"proposalCount\")); } function addProposal(address _storageContract, bytes32 _name) { var idx = getProposalCount(_storageContract); EternalStorage(_storageContract).setBytes32Value(sha3(\"proposal_name\", idx), _name); EternalStorage(_storageContract).setUIntValue(sha3(\"proposal_eth\", idx), 0); EternalStorage(_storageContract).setUIntValue(sha3(\"ProposalCount\"), idx + 1); }} Under the cover, library functions are called using delegatecall from the calling contract which has the advantage of passing the msg.sender and msg.value seamlessly. You can therefore write your library code as if it were just part of your contract, without having to worry about the sender or value chagning. The example below shows a sample Organization contract using ProposalsLibrary to interact with data storage. 1234567891011121314import \"ProposalsLibrary.sol\";contract Organization { using ProposalsLibrary for address; address public eternalStorage; function Organization(address _eternalStorage) { eternalStorage = _eternalStorage; } function addProposal(bytes32 _name) { eternalStorage.addProposal(_name); }} With libraries, there is a slight gas overhead on each call. However, it makes deploying a new contract much cheaper. Use ‘interface’ to decouple inter-contract communicationAbstract Contract implementation behind an interface that only define its function siguatures. This is a well known pattern in object oriented programming. 12345678910111213import \"ITokenLedger.sol\";contract Organization { ITokenLedger public tokenLedger; function Organization(address _tokenLedger) { tokenLedger = ITokenLedger(_tokenLedger); } function generateToekns(uint256 _amount) { tokenLedger.generateTokens(_amount); }} Here instead of importing the entire TokenLedger.sol contract, we use an interface containing just the function signatures. This eases any possible upgrades to TokenLedger which don’t affect its interface, too, which with this model can be implemented without redeploying the Organization contract.","link":"/2018/03/05/Writing-Upgradable-Contracts-in-Solidity/"},{"title":"Array.from()","text":"Array.from() 方法可以将一个类数组对象或可遍历对象转化为真正的数组.在 ES6 中, Class 语法允许我们为内置类型(比如 Array) 和自定义类新建子类(比如叫 subArray), 这些子类也会继承父类的静态方法, 比如 subArray.from(), 调用该方法后会返回子类 subArray 一个实例, 而不是 Array 的实例. 语法Array.from(arrayLike[, mapFn[, thisArg]]) `&lt;/pre&gt; ### 参数 #### arrayLike 想要转换成真实数组的类数组对象或可遍历对象 #### manFn 可选参数, 如果制定了该参数, 则最后生成的数组会经过 map 操作 #### this.Arg 可选参数, 执行 mapFn 时的 this 的值 ### 描述 可以使用 Array.from()将下面的两种对象转换成数组 - 类数组对象(拥有 length 属性和若干索引属性的任意对象) - 可遍历对象(可以迭代出其他对象, 比如有 Map 和 Set) Array.from(obj,mapFn,thisArg) 相当于 Array.from(obj).map(mapFn,thisArg) ### 应用 &lt;pre&gt;`var obj = {length:5}; // return {length:5} var arr =Array.from(obj); // namely Array.from({length:5}), return [undefined * 5] Array.isArray(arr); //return true var arr1 = Array.from(obj,(v,k) =&amp;gt; k); //return [0,1,2,3,4]","link":"/2016/07/20/array-from/"},{"title":"Babel-Polyfill 入门","text":"yarn add babel-polyfill import &apos;babel-polyfill&apos; `&lt;/pre&gt; babel-polyfill 提供了全局访问 API, 如 Promise, Set 以及 Map, 但是 polyfill 提供的 api 可能会污染到全局作用域, 特别在你把代码导报为第三方库给其他人用时, 或者你无法控制代码运行环境时, 都可能存在问题 `babel` 提供了 `transform-runtime` 插件来解决此问题, `transform-runtime` 提供一个沙盒机制来组织全局变量的污染 &gt; 需要注意, transform-runtime 依赖于 babel-runtime &lt;pre&gt;`# transform-runtime 只应用于开发环境 yarn add --dev babel-plugin-transform-runtime # 其依赖包 babel-runtime 需要打包到生产环境 yarn add babel-runtime `&lt;/pre&gt; &lt;pre&gt;`// .babelrc { &quot;plugins&quot;: [&quot;transform-runtime&quot;] } or { &quot;plugins&quot;: [ [&quot;transform&quot;, { &quot;helpers&quot;: false, &quot;polyfill&quot;: false, &quot;regenerator&quot;: true, &quot;moduleName&quot;: &quot;babel-runtime&quot;, }] ] }","link":"/2017/02/04/babel-polyfill-e5-85-a5-e9-97-a8/"},{"title":"Api of Axios","text":"alias axios.request(config) axios.get(url[, config]) axios.delete(url[, config]) axios.head(url[, config]) axios.options(url[, config]) axios.post(url[, data[, config]]) axios.put(url[, data[, config]]) axios.patch(url[, data[, config]]) Config Optionsurl is required, and get is the default method 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758{ url: 'string', method: 'get', baseUrl: 'https://some-domain.com/api/', // prepended to url unless url is absolute, transformRequest: [function (data) { return data }], transformResponse: [function (data) { return data }], headers: { 'X-Requested-With': 'XMLHttpRequest', }, params: { // url params to be sent with the request, plain object or URLSearchParams Object ID: 12345, }, paramsSerializer: function (params) { return Qs.stringify(params, { arrayFormat: 'brackets' }) }, data: { // the data sent as request body, only applicable for request method 'PUT', 'POST', 'PATCH'. When no transformRequest is set, must be one of the following types: string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams, FormData(Browser only), File(browser only), Blob(browser only), Stream(Node only), Buffer(Node only) firstName: 'fred', }, timeout: 1000, withCredentials: false // default adapter: function (config) { // allows custom handling of requests which makes testing easier. }, auth: { username: 'janedoe', password: '...', }, responseType: 'json', // default xsrfCookieName: 'XSRF-TOKEN', // defualt onUploadProgress: function (progressEvent) { }, onDownloadProgress: function(progressEvent) { }, maxContentLength: 2000, validateStatus: function (status) { return status &gt;= 200 &amp;&amp; status &lt; 300 // default }, maxRedirects: 5, // default httpAgent: new http.Agent({ keepAlive: true }), httpsAgent: new http.Agent({ keepAlive: true }), proxy: { // defines the hostname and port of the proxy server host: '127.0.0.1', port: 9000, auth: { username: '...', password: '...', } }, cancelToken: new CancelToken(function (cancel) { })} response Schema12345678{ data: {}, status: 200, statusText: 'OK', headers: {}, config: {}, request: {},} errors123456789101112axios.get('/user/123').catch((err) =&gt; { if (err.response) { // err.response.data // err.response.status // err.response.headers } else if (res.request) { } else { }}) get12345678910111213141516171819axios.get('/user?ID=12345').then((res) =&gt; { console.log(res)}).catch(err =&gt; { console.log(err)})axios.get('/user', { params: { ID: 12345, }}).then((res) =&gt; { console.log(res)}).catch((err) =&gt; { console.log(err)}) post12345678910axios.post('/user', { firstName: 'Fred', lastName: 'Flintstrong',}).then((res) =&gt; { console.log(res)}).catch((err) =&gt; { console.log(err)}) concurrency123456789101112function getUserAccount () { return axios.get('/user/12345')}function getUserPermissions () { return axios.get('/user/12345/permissions')}axios.all([getUserAccount(), getUserPermissions()]).then(axios.spread(function (acct, perms) { // Both request are now complete})) config1234567891011121314151617axios({ method: 'post', url: '/user/12345', data: { firstName: 'Fred', lastName: 'Flintstone', }})axios({ method: 'get', url: 'http://bit.ly/2mTM3n\u0006', responseType: 'stream',}).then((res) =&gt; { res.data.pipe(fs.createWriteStream('ada_lovelace.jpg'))})","link":"/2017/04/29/api-of-axios/"},{"title":"Babel-Polyfill or Babel-Runtime","text":"The babel-polyfill and babel-runtime modules are sued to serve the same function in two different ways. Both modules ultimately serve to emulate an ES6 environment. Both babel-polyfill and babel-runtime emulate an ES6 environment with two things: a slew of polyfills as provided by core-js complete generator runtime babel-polyfill accomplishes this task by assigning methods on the global or on native type prototypes which means that once required, as far as the javascript runtime you’re using is concerned, ES6 methods and object simply exist. If you were to require babel-polyfill in a script run under node v0.1.0 – a runtime which does not natively support the Promise API – your script would then have access to the Promise object. As far as you are concerned, you’re suddenly using an environment that support the Promise object. babel-runtime does something very similar, but in a way that does not pollute native object prototypes or the global namespace. Instead, babel-runtime is a module that you can list as a dependency of your application like any other module, which polyfills ES6 methods. In other words and continuing the example from above, while you may not have the Promise object available to you, you now have the same functionality available to you from require('babel-runtime/core-js/promise'). By itself, this is useful but inconvenient. Fortunately, babel-runtime is not intended to be used by itself. Rather, babel-runtime is intended to be paired with the transform – babel-plugin-transform-runtime – which will automatically rewrite your code such that you can write your code using the Promise API and it will be transformed to use the Promise-like object exported by babel-runtime babel-polyfill offers you the conveniences of gloablly defined objects without having to transform your code further. However, as with anything that mutates a global, this can introduce collision between versions, etc. babel-runtime, on the other hand, will not suffer from collision as everything is name-spcaed. Since the module will be defined in your package.json, it can be versioned like everything else. The tradeoff, however, is that a transform can only do so much. The runtime remaps methods according to a definitions map. Anecdotally, this has covered each of my use-cases but there may be an obscure method or two which is not remapped. There are also certain cases where your intent is ambiguous. In such cases, the transform won’t know exactly what to do. ConclusionTo summarize, with the general case for Babel 6, there are two main steps you’ll need to perform: Provide your code with an emulated ES6 environment by either requiring babel-polyfill or requiring the babel-runtime module plus the babel-plugin-transform-runtime transform: 1234// for babel-polyfill, either add:require('babel-polyfill')// for babel-runtime, install the module, then use the babel-plugin-transform-runtime transform by including it in your .babelrc file.","link":"/2017/05/21/babel-polyfill-or-babel-runtime/"},{"title":"Baisc Usage of Redux-Observable","text":"First of AllcreateEpicMiddleware(rootEpic)createEpicMiddleware is used to create an instance of the actual redux-observable middleware, and you should provide a single, root Epic Arguments rootEpic: Epic: The root Epic [options: Object]: The optional configuration. dependencies: If given, it will be injected as the 3rd argument to all Epics, adapter: An adapter object which can transform the input/output streams provided to your epics, Usually used to adapt a stream library other than RxJS v5, like adapter-rxjs-v4 or adapter-most Options: * `input: ActionsObservable =&amp;gt; Any`: Transforms the input stream of actions, `ActionsObservable` that is passed to your root Epic(transformation takes place before it is passed to the root Epix) * `output: any =&amp;gt; Observable`: Transforms the return value of root Epic(transform takes place after the root epic returned it) ReturnsMiddlewareAPI: An instance of the redux-observable middleware Exampleimport { createStore, applyMiddleware, compose } from &apos;redux&apos; import { createEpicMiddleware } from &apos;redux-observable&apos; import { rootEpic, rootRotuer } from &apos;./modules/root&apos; const epicMiddleware = createEpicMiddleware(rootEpic) export default function configureStore () { const store = createStore( rootRotuer, applyMiddleware(epicMiddleware) ) return store } `&lt;/pre&gt; ### `combineEpics(...epic)` `combineEpics` allows you to take multiple epics and combine them into a single one #### Arguments `...epics: Epic[]`: The epics to combine #### Return `(Epic)`: An Epic that merges the output of every Epic provided and passes along the `ActionObservable` and redux store as arguments ### Example &lt;pre&gt;`import { combineEpics } from &apos;redux-observable&apos; import pingEpic from &apos;./ping&apos; import fetchUserEpic from &apos;./fetchUser&apos; export default combineEpics( pingEpic, fetchUser ) `&lt;/pre&gt; ### `EpicMiddleware` An instance of the redux-observable middleware To create it, pass your root Epic to `createEpicMiddleware` `replaceEpic(nextEpic)`: Replaces the epic currently by the middleware, it is an advanced API. You might need this if your app implement code splitting and you want to load some of the epics dynamically or you&apos;re using hot reloading. ### Create Epic &lt;pre&gt;`const pingEpic = action$ =&amp;gt; action$.ofType(&apos;PING&apos;).mapTo({type: &apos;PONG&apos;}) `&lt;/pre&gt; ### Cancellation &lt;pre&gt;`import { ajax } from &apos;rxjs/observable/dom/ajax&apos; const fetchUserEpic = action$ =&amp;gt; action$.ofType(&apos;FETCH_USER&apos;).mergeMap( action =&amp;gt; ajax.getJSON(`/api/user/${action.payload}`) .map(res =&amp;gt; fetchUserFulfilled(res)) .takeUntil(action$.ofType(&apos;FETCH_USER_CANCELLED&apos;)) ) `&lt;/pre&gt; ### Handling Error &lt;pre&gt;`import { ajax } from &apos;rxjs/observable/dom/ajax&apos; const fetchUserEpic = action$ =&amp;gt; action.ofType(&apos;FETCH_USER&apos;).mergeMap( action =&amp;gt; ajax.getJSON(`/api/users/${action.payload}`) .map(res =&amp;gt; fetchUserFulfilled(res)) .catch(err =&amp;gt; Observable.of({ type: &apos;FETCH_USER_REJECTED&apos;, payload: err.xhr.response, error: true, })) ) `&lt;/pre&gt; ### dependencies Injecting &lt;pre&gt;`import { createEpicMiddleware, combineEpics } from &apos;redux-observable&apos; import { ajax } from &apos;rxjs/observable/dom/ajax&apos; import rootEpic from &apos;./somewhere&apos; const epicMiddleware = createEpicMiddleware(rootEpic, { dependencies: { getJSON: ajax.getJSON } }) const fetchUserEpic= (action$, store, { getJSON }) =&amp;gt; action$.ofType(&apos;FETCH_USER&apos;).mergeMap( (action) =&amp;gt; getJSON(`/api/users/${action.payload}`) .map(res =&amp;gt; ({ type: &apos;FETCH_USER_REJECTED&apos;, payload: res })) ) `&lt;/pre&gt; ### Adding New Epics Asynchronously/Lazily &lt;pre&gt;`import { BehaviorSubject } from &apos;rxjs/BehaviorSubject&apos; import { combineEpics } from &apos;redux-observable&apos; const epic$ = new BehaviorSubject(combineEpics(epic1, epic2)) const rootEpic = (action$, store) =&amp;gt; epic$.mergeMap(epic =&amp;gt; epic(action$, store)) // sometime later ... add another Epic, keeping the state of the old ones... epic$.next(asyncEpic1) // and again later add another epic$.next(asyncEpic2)","link":"/2017/03/20/baisc-usage-of-redux-observable/"},{"title":"BFC 基本概念","text":"Box: CSS 布局的基本单位Box 是 CSS 布局的对象, 和基本单位, 直观点来说, 就是一个页面是由很多个 Box 组成的. 元素的类型和 display 属性, 决定了这个 Box 的类型. 不同类型的 Box, 会参与不同的 Formatting Context(一个决定如何渲染文档的容器), 因此 Box 内的元素会以不同方式渲染.盒子的类型: block-level: display:block的 block, list-item, table 元素会形成 block-level box, 并参与 Block formatting context. inline-level box: display:inline的 inline-block, inline-table 元素会形成 inline-level box, 并参与 inline formatting context; run-in box: CSS3才有, 略; Formatting ContextFormatting Context 是 W3C CSS2.1规范中的一个概念, 是页面中的一块渲染区域, 并有一套渲染规则, 决定了其子元素如何定位, 以及其他元素的关系和相互作用. 最常见的的 Formatting Context 有 Block Formatting Context(BFC) 和 Inline Formatting Context(IFC).CSS2.1中只有 BFC 和 IFC, 在 CSS3中添加了 GFC 和 FFC BFC 的定义BFC 直译为”块级格式上下文”, 是一个独立的渲染区域, 只有 Block-level Box 可以参与, 他规定了内部的 Block-level Box 如何布局, 并且与这个区域外部毫不相干. BFC 布局规则 内部的 Box 会在垂直方向依次排列 Box 垂直方向的距离由 margin 决定, 属于同一个 BFC 的两个相邻的 Box 的 margin 会发生坍塌 BFC 内部不会发生 float box 重叠 BFC 就是页面上的一个隔离的独立容器, 容器内的子元素不会影响到外部的元素, 反之亦然 计算 BFC 高度的时候, 浮动元素也参与计算(使用 border 消除父元素坍塌的原理) BFC 内部每一个 Box 的左外边缘(margin-left)会碰触容器的左边缘(border-left)(如果是从右向左的格式, 则是碰触右边缘) BFC 的通俗理解BFC 容器是一个独立的箱子, 里面的元素的布局不受外部元素影响.我们往往利用这个特性来消除浮动元素对其他非浮动的兄弟元素及其子元素带来的影响.并且在一个 BFC 容器中, 块盒和行盒都会沿其父元素的边框排列 BFC 成因 float 属性不为 None; position 为 Absolute 或 Fixed display 为 inline-block, table-cell, table-caption, flex, inline-flex overflow 不是 visible BFC 的作用与原理自适应两栏布局","link":"/2016/07/15/bfc-e5-9f-ba-e6-9c-ac-e6-a6-82-e5-bf-b5/"},{"title":"Bootstrap 4 Guide Written by BS3","text":"Make new features of BS4 by BS3","link":"/2016/05/19/bootstrap4/"},{"title":"Button Transition With Background-Position","text":"button{ color:maroon; border:1px solid maroon; font-size:50px; padding:20px 40px; border-radius:15px; transition-duration:0.5s; position:relative; overflow:hidden;}button:hover{ color:#fff;}.left{ background:-webkit-linear-gradient(left, maroon 50%, transparent 50%); background-size:200% 100%; background-position:100% 0%;}.left:hover{ background-position:0% 0%;}.angle{ background:-webkit-linear-gradient(225deg, maroon 50%, transparent 50%); background-size:250% 100%;}.angle:hover{ background-position:100% 0%;}.close{ background:-webkit-linear-gradient(left, transparent 50%, maroon 50%); background-size:200% 100%;}.close:after{ content:””; position:absolute; z-index: -1; top:0; left:0; right: 0; bottom: 0; background:-webkit-linear-gradient(left, maroon 50%, transparent 50%); background-size:200% 100%; background-position:100% 0%; transition-duration:.5s;}.close:hover{ background-position:50% 0%;}.close:hover:after{ background-position:50% 0%;}} Left Angle Closebutton{ color:maroon; border:1px solid maroon; font-size:50px; padding:20px 40px; border-radius:15px; transition-duration:0.5s; position:relative; overflow:hidden; } button:hover{ color:#fff; } .left{ background:-webkit-linear-gradient(left, maroon 50%, transparent 50%); background-size:200% 100%; background-position:100% 0%; } .left:hover{ background-position:0% 0%; } .angle{ background:-webkit-linear-gradient(225deg, maroon 50%, transparent 50%); background-size:250% 100%; } .angle:hover{ background-position:100% 0%; } .close{ background:-webkit-linear-gradient(left, transparent 50%, maroon 50%); background-size:200% 100%; } .close:after{ content:&quot;&quot;; position:absolute; z-index: -1; top:0; left:0; right: 0; bottom: 0; background:-webkit-linear-gradient(left, maroon 50%, transparent 50%); background-size:200% 100%; background-position:100% 0%; transition-duration:.5s; } .close:hover{ background-position:50% 0%; } .close:hover:after{ background-position:50% 0%; } } &lt;/pre&gt;","link":"/2016/06/17/button-transition-with-background-position/"},{"title":"Box-Shadow小用法","text":"box-shadow 常规用法基础语法box-shadow 属性向边框添加一个或多个阴影; box-shadow: (inset) x-offset, y-offset, blur, spread color; 模拟多边框div{ width: 100px; height: 100px; margin: 100px; border:5px solid ; box-shadow: inset 0 0 0 5px #ccc, 0 0 0 5px #333; } `&lt;/pre&gt; 要注意: box-shadow 毕竟不是实际边框, 不占据实际空间, 也不属于 `box-sizing`范围 ### 模拟半透明遮罩层 &lt;pre&gt;`#foo{ width:200px; height:200px; background:#FFF; box-shadow:0 0 0 1920px rgba(0,0,0,.5); } `&lt;/pre&gt; ### 多重 box-shadow 绘制简图案 &lt;pre&gt;`&amp;lt;div class=&quot;bg&quot;&amp;gt; &amp;lt;div class=&quot;cloud&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; .bg{ width: 100%; height: 100px; padding: 10px; background-color: #00bcd4; } .cloud{ width: 50px; height: 50px; margin: 20px auto; background-color: #FFF; border-radius:50%; box-shadow:80px 10px 0 10px #FFF, 50px 0 0 20px #FFF, 10px -10px #FFF, -10px 10px 0 10px #FFF; } `&lt;/pre&gt; ### 多重 shadow 实现立体感 &lt;pre&gt;`&amp;lt;div&amp;gt;Solid&amp;lt;/div&amp;gt; div{ width: 200px; line-height: 68px; font-size: 48px; text-align: center; color:rgba(0,0,0,.3); text-shadow: 1px 1px 0 rgba(0,0,0,.55), 2px 1.5px 0 rgba(0,0,0,.25), 3px 2px 0 rgba(0,0,0,.2), 4px 2.5px 0 rgba(0,0,0,.15), 5px 3px 0 rgba(0,0,0,.1); }","link":"/2016/06/23/box-shadow-e5-b0-8f-e7-94-a8-e6-b3-95/"},{"title":"Card Style - 1","text":"_,_:before,*:after{ box-sizing: border-box; } .wrapper{ padding-top: 40px; padding-bottom: 40px; } .wrapper:focus{ outline:0; } .clash-card{ background-color: #fff; width: 300px; display: inline-block; margin:auto; border-radius: 20px; position:relative; text-align: center; box-shadow: -1px 15px 30px -12px black; z-index: 9999; } .clash-card__image{ position: relative; height: 230px; margin-bottom: 35px; border-top-left-radius: 20px; border-top-right-radius: 20px; } .clash-card__image--barbarian{ background: url(\"http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/barbarian-bg.jpg\") } .clash-card__image--barbarian img{ width: 400px; position: absolute; top: -65px; left: -70px; } .clash-card__level{ text-transform: uppercase; font-size: 12px; font-weight: 700; margin-bottom: 3px; } .clash-card__level--barbarian{ color:#EC9B3B; } .clash-card__unit-name{ font-size: 26px; color:#000; font-weight: 900; margin-bottom: 5px; } .clash-card__unit-description{ padding: 20px; margin-bottom: 10px; } .clash-card__unit-stats--barbarian{ background: #EC9B3B; } .clash-card__unit-stats--barbarian .one-third{ border-right: 1px solid #BD7C2F; } .clash-card__unit-stats{ color:#fff; font-weight: 700; border-bottom-left-radius: 15px; border-bottom-right-radius: 15px; overflow: hidden; } .clash-card__unit-stats .one-third{ width: 33.33%; float: left; padding: 20px 15px; } .clash-card__unit-stats sup{ position: absolute; } .clash-card__unit-stats .stat{ position: relative; font-size: 20px; margin-bottom: 10px; } .clash-card__unit-stats .stat-value{ text-transform: uppercase; font-weight: 400; font-size: 12px; } .clash-card__unit-stats .no-border{ border-right: none; } .clearfix:after{ content:\"\"; clear:both; visibility: hidden; height: 0; font-size: 0; } ![barbarian](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/barbarian.png) Level 5 The Barbarian Lorem ipsum dolor sit amet, consectetur adipisicing elit. Itaque, optio! Provident iure architecto atque sequi alias! Tempore alias doloremque tempora, quod enim nulla quia, saepe accusantium eius minus quisquam architecto. 20s Training 16 Speed 150 Cost ` /*HTML*/ div.wrapper div.clash-card.barbarian div.clash-card__image.clash-card_image--barbarian img.src div.cash-card__level.clash-card__level--barbarian{Level 5} div.clash-card__unit-name{The Barbarian} div.clash-card__unit-description{...} div.clash-card__unit-stats.clash-card__unit-stats--barbarian.clearfix div.one-third div.stat{20s} div.stat-value{Training} div.one-third div.stat{16} div.stat-value{Speed} div.one-third.no-border div.stat{150} div.stat-value{Cost} /*CSS*/ *,*:before,*:after{ box-sizing: border-box; } .wrapper{ padding-top: 40px; padding-bottom: 40px; } .wrapper:focus{ outline:0; } .clash-card{ background-color: #fff; width: 300px; display: inline-block; margin:auto; border-radius: 20px; position:relative; text-align: center; box-shadow: -1px 15px 30px -12px black; z-index: 9999; } .clash-card__image{ position: relative; height: 230px; margin-bottom: 35px; border-top-left-radius: 20px; border-top-right-radius: 20px; } .clash-card__image--barbarian{ background: url(\"http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/barbarian-bg.jpg\") } .clash-card__image--barbarian img{ width: 400px; position: absolute; top: -65px; left: -70px; } .clash-card__level{ text-transform: uppercase; font-size: 12px; font-weight: 700; margin-bottom: 3px; } .clash-card__level--barbarian{ color:#EC9B3B; } .clash-card__unit-name{ font-size: 26px; color:#000; font-weight: 900; margin-bottom: 5px; } .clash-card__unit-description{ padding: 20px; margin-bottom: 10px; } .clash-card__unit-stats--barbarian{ background: #EC9B3B; } .clash-card__unit-stats--barbarian .one-third{ border-right: 1px solid #BD7C2F; } .clash-card__unit-stats{ color:#fff; font-weight: 700; border-bottom-left-radius: 15px; border-bottom-right-radius: 15px; overflow: hidden; } .clash-card__unit-stats .one-third{ width: 33.33%; float: left; padding: 20px 15px; } .clash-card__unit-stats sup{ position: absolute; } .clash-card__unit-stats .stat{ position: relative; font-size: 20px; margin-bottom: 10px; } .clash-card__unit-stats .stat-value{ text-transform: uppercase; font-weight: 400; font-size: 12px; } .clash-card__unit-stats .no-border{ border-right: none; } .clearfix:after{ content:\"\"; clear:both; visibility: hidden; height: 0; font-size: 0; } `","link":"/2016/06/20/card-style-1/"},{"title":"CFB MindMap","text":"","link":"/2016/05/23/cfb-mindmap/"},{"title":"Difference Bwtween Build_assoc, Put_assoc, and Cast_assoc","text":"Cast Assoc code cast_assoc(changeset, name, opts \\ []) Casts the given association with the changeset params This function should be used when working withe the entire association at once(and not a single element of a many-style association) and using data external to the application. When updating the data, this function requires the association to have been preloaded in the changeset struct. Missing data will invoke the :on_replace behaviour defined on the association. Preloading is not necessary for newly built structs. The parameters for the given association will be retrieved from changeset.params. Those parameters are expected to be a map with attributes, similar to the ones passed to cast/4. Once parameter are retrieved, cast_assoc/3 will match those parameters with the associations already in the changeset record For example, imagine a user has many addresses relationship where post data is sent as follow 1234%{\"name\" =&gt; \"John Doe\", \"addresses\" =&gt; [ %{\"street\" =&gt; \"Some where\", \"country\" =&gt; \"Brzil\", \"id\" =&gt; 1}, %{\"street\" =&gt; \"Else where\", \"country\" =&gt; \"Poland\"},]} and then 1234user|&gt; Repo.preload(:addresses)|&gt; Ecto.Changeset.cast(params, [])|&gt; Ecto.Changeset.cast_assoc(:addresses) Once cast_assoc/3 is called, Ecto will compare those params with the addresses already associated with the user and acts as follows: If the parameter does not contain an ID, the parameter data will be passed to changeset/2 with a new struct and become an insert operation If the parameter contains an ID and there is no associated child with such ID, the parameter data will be passed to changeset/2 with a new struct and become an insert operation If the parameter contains an ID and there is an associated children with such ID, the parameter data will be passed to changeset/2 with the existing struct and become an update operation. If there is an associated child with an ID and its ID is not given as parameter, the :on_replace callback for that association will be invoked Code1234567891011121314151617181920`cast_assoc/3` is useful when the associated data is managed alongside the parent struct, all at once.To work with a single element of an association, other functions are more appropriate. For example to insert a single associated struct for a `has_many` association it's much easier to construct the associated struct with `Ecto.build_assoc/3` and persist it directly with `Ecto.Repo.insert/2`Furthurmore, if each side of the association is managed seperately, it is prefereable to use `put_assoc/3` and directly instruct Ecto how the association should look like.For example, imagine you are receiving a set of tags you want to associate to an user. Those tags are meant to **exist upfront**. Using `cast_assoc/3` won't work as desired because the tags are not managed alongside the user. In such cases, `put_assoc/3` will work as desired. With the given parameters: %{\"name\" =&gt; \"John Doe\", \"tags\" =&gt; [\"linear\"]}and then tags = Repo.all(from t in Tag, where: t.name in ^params[\"tags\"]) user |&gt; Repo.preload(:tags) |&gt; Ecto.Changeset.cast(params) # no need to allow :tags as we put them directly |&gt; Ecto.Changeset.put_assoc(:tags, tags) # explicitly set the tagsnote the changeset must have been previously `cast` using `cast/4` before this function is called. 123456789101112131415161718192021222324252627282930313233343536def cast_assoc(changeset, name, opts \\\\ []) when is_atom(name) do cast_relation(:assoc, changeset, name, opts)enddefp cast_relation(type, %Changeset{} = changeset, key, opts) do { key, param_key } = cast_key(key) %{data: data, types: types, params: params, changes, changes } = changeset %{related: related} = relation = relation!(:cast, type, key, Map.get(types, key)) params = params || %{} {changeset, required?} = if opts[:required] do {update_in(changeset.required, &amp;[key|&amp;1]), true} else {changeset, false} end on_cast = Keyword.get_lazy(opts, :with, fn -&gt; on_cast_default(type, related) end) original = Map.get(data, key) changeset = case Map.fetch(params, params_key) do {:ok, value} -&gt; current = Relation.load!(data, original) case Relation.cast(relation, value, current, on_cast) do {:ok, change, relation_valid?} when change != original -&gt; missing_relation(%{changeset | change: Map.put(changes, key, changes), valid?: changeset.valid? and relation_valid?}, key, current, required?, relation, opts) :error -&gt; %{changeset | errors: [{key, {message(opts, :invalid_message, \"is invalid\"), [type: expected_relation_type(relation)]}} | changeset.errors], valid? false} _ -&gt; missing_relation(changeset, key, current, required?, relation, opts) end :error -&gt; missing_relation(changeset, key, current, required?, relation, opts) end update_in changeset.types[key], fn {type, relation} -&gt; {type, %{relation | on_cast: on_cast}} endend Put AssocAs alternative to cast_assoc/3 cast_assoc/3 is useful when the associated data is managed alongside the parent struct, all at once. If each side of the association is managed seperately, it is preferable to use put_assoc/3 and directly instruct Ecto how the association should look like. For example, imagine you are receiving a set of tags you want to associate to an user. Those tags are meant to exist upfront. Using cast_assoc/3 won’t work as desired because the tags are not managed alongside the user. In such cases, put_assoc/3 will work as desired. 1%{\"name\" =&gt; \"John Doe\", \"tags\" =&gt; [\"lieanr\"]} and then: 123456tags = Repo.all(from t in Tag, where: t.name in ^params[\"tags\"])user|&gt; Repo.preload(:tags)|&gt; Ecto.Changeset.cast(params)|&gt; Ecto.Changeset.put_assoc(:tags, tags) ExampleBuild_AssocGen an instance with foreign key 123456iex&gt; post = Ecto.build_assoc(user, :posts, %{header: \"Clickbait header\", body: \"No real contet\"})%EctoAssoc.Post{__meta__: #Ecto.Schema.Metadata&lt;:built, \"posts\"&gt;, body: \"No real content\", header: \"Clickbait header\", id: nil, user: #Ecto.Association.NotLoaded&lt;association :user is not loaded&gt;, user_id: 1}iex&gt; Repo.insert!(post) Put_AssocAdd association to changeset which is not persisted 123iex&gt; post_changeset = Ecto.Changeset.change(post)iex&gt; post_with_tags = Ecto.Changeset.put_assoc(post_changeset, :tags, [misc_tag])iex&gt; Repo.insert!(post_with_tags) Conclusioncast_assoc when you want to cast external parameters, like the ones from a form, into an association. put_assoc when you already have an association struct build_assoc receive an existing struct(for example user), that was persisted to the database, and builds a struct(for example post, based on its association(for example :posts), with the foreign key field(for example user_id).","link":"/2018/05/15/cast-assoc/"},{"title":"CFB HomePage(RWD)","text":"Chinafiremag.cn is a non-responsive website and this is a prototype of RW one.","link":"/2016/05/19/cfb/"},{"title":"Clip-Path, Polygon 图形构建","text":"clip-path 的前身是 SVG, 支持二维坐标 polygon 的作用是根据二维点坐标, 依次连线, 最后闭合形成遮罩区域 clip-path:polygon 生成三角形的过程非常简单 .path{ clip-path: polygon(5px, 10px, 16px, 3px, 16px, 17px); } polygon 对点的数目没有限制, 所以可以生成各种几何图案 clip-path 还可以用 transition 过渡或者 animation 动画, 很好的弥补了 CSS3 的 transform 变换的不足 polygon 动画有一个重要前提, 那就是坐标的数目在变化前后必须一样. 这样就浏览器就能实现连续动画.","link":"/2016/08/26/clip-path-polygon-e5-9b-be-e5-bd-a2-e6-9e-84-e5-bb-ba/"},{"title":"CO Module","text":"Co v4co@4.0.0 has been released, which now relies on promises. It is a stepping stone towards the aysnc/await proposal. The primary API change is how co() is invoked. Before, co returned a “thunk”, which you then called with a callback and optional arguments. Now, co() return s a promise. co(function* (){ var result = yield Promise.resolve(true); return result; }).then(function (value) { console.log(value); }, function(err) { console.error(err.stack); }); `&lt;/pre&gt; If you want to convert a `co`-generator-function into a regular function that returns a promise, you now use `co.wrap(fn*)`. &lt;pre&gt;`var fn = co.wrap(function*(val) { return yield Promise.resolve(val); }); fn(true).then(function(val){ }) `&lt;/pre&gt; ### Platform Compatibility `co@4+` requires a `Promise` implementation. For version of node `&amp;lt; 0.11` and for many older browsers, you should/must include your own `Promise` polyfill. Node v4+ is supported out of the box, you can use `co` without flags or polyfills. ### Installation &lt;pre&gt;`$ npm install co `&lt;/pre&gt; ### Examples &lt;pre&gt;`var co = require(&apos;co&apos;); co(function*(){ // yield any promise var result = yield Promise.resolve(true); }).catch(onerror); co(function*(){ // resolve multiple promises in parallel var a = Promise.resolve(1); var b = Promise.resolve(2); var c = Promise.resolve(3); var res = yield[a, b, c]; console.log(res); // =&amp;gt; [1,2,3] }).catch(onerror); // errors can be try/catched co(function*() { try{ yield Promise.reject(new Error(&apos;boom&apos;)); } catch (err) { console.error(err.message); // &apos;boom&apos; } }); function onerror(err){ // log any uncaught errors // co will not throw any errors you do not handle // HANDLE ALL YOUR ERRORS console.error(err.stack); }","link":"/2016/07/31/co-module/"},{"title":"Command Line Cheat Sheet","text":"Directoriespwd: print working directory cd &lt;directory&gt;: change directory to &lt;directory&gt; cd ..: change directory to parent one ls: list directory contents ls -la: list detailed directory contents, including hidden files mkdir &lt;directory&gt;: create new directory named &lt;directory&gt; Outputcat &lt;file&gt;: output the contents of &lt;file&gt; less &lt;file&gt;: output the contents of &lt;file&gt; using the less command(which supports paginations etc.) head &lt;file&gt;: output the first 10 lines of &lt;file&gt; &lt;cmd&gt; &lt;file&gt;: impose &lt;cmd&gt; on &lt;file&gt; clear: clear the command line window Filesrm &lt;file&gt;: delete &lt;file&gt; rm -r &lt;directory&gt;: clear contents of &lt;directory&gt; rm -f &lt;file&gt;: force-delete &lt;file&gt; rm -rf &lt;directory&gt;: force clear &lt;directory&gt; mv &lt;file-old&gt; &lt;file-new&gt;: rename &lt;file-old&gt; mv &lt;file&gt; &lt;directory&gt;: move file to &lt;directory&gt; cp &lt;file&gt; &lt;directory&gt;: copy &lt;file&gt; to &lt;directory&gt; cp -r &lt;directory1&gt; &lt;directory2&gt;: copy whole &lt;directory1&gt; to &lt;directory2&gt;(overwrit) touch &lt;file&gt;: Update file or create file Permissionschmod 755 &lt;file&gt;: change permission of &lt;file&gt; to 755 chmod -R 600 &lt;directory&gt;: change permission of &lt;directory&gt; and its content to 600 chown &lt;user&gt;:&lt;group&gt; &lt;file&gt;: Change ownership of &lt;file&gt; to &lt;user&gt; and &lt;group&gt; Searchfind &lt;dir&gt; -name ‘&lt;file&gt;’: find all files named &lt;file&gt; inside &lt;dir&gt;(support regex) grep ‘&lt;text&gt;’ &lt;file&gt;: output all occurrence of &lt;text&gt; inside &lt;file&gt;(add -i for case-insensitivity) grep -rl ‘text’ &lt;dir&gt;: search for all files container &lt;text&gt; inside &lt;dir&gt; Networkping &lt;host&gt;: ping &lt;host&gt; and display status whois &lt;domain&gt;: output whois information for &lt;domain&gt; curl -O &lt;url/to/file&gt;: download &lt;file&gt;(via HTTP[S] or FTP) ssh &lt;username&gt;@&lt;host&gt;: establish an SSH connection to &lt;host&gt; with user &lt;username&gt; scp &lt;file&gt; &lt;user&gt;@&lt;host&gt;:/remote/path: Copy &lt;file&gt; to a remote &lt;host&gt; Processesps ax: output currently running process top: display live information about currently running processes kill &lt;pid&gt;: Quit process with ID","link":"/2016/09/07/command-line-cheat-sheet/"},{"title":"CommonChunks 插件","text":"作用就是提取代码中的公共模块, 然后将公共模块打包到一个独立的文件中, 以便在其他的入口和模块中使用. // in main.js var a = require(&apos;./a&apos;); a.sayHello(); var b = require(&apos;./b&apos;); b.sayHello(); var c = require(&apos;./c&apos;); c.sayHello() `&lt;/pre&gt; &lt;pre&gt;`// in main2.js var a = require(&apos;./a&apos;); a.sayHello(); var b = require(&apos;./b&apos;); b.sayHello(); `&lt;/pre&gt; a, b, c 和之前一样, 只有一个 sayHello 方法. 打包后看到`bundle.main.js` 和`bundle.main2.js` 中分别包含了 a, b, c 三个模块, 其中 a, b 是要使用`CommonChunksLoader` 提取出来的公共模块. ### 配置 CommonChunksLoader &lt;pre&gt;`var webpack = require(&apos;webpack&apos;); module.exports = { entry:{ main1: &apos;./main&apos;, main2: &apos;./main2&apos; }, output:{ filename: &apos;bundle.[name].js&apos; }, plugins:[ new webpack.optimize.CommonsChunkPlugin(&apos;common.js&apos;,[&apos;main1&apos;,&apos;main2&apos;]) ] } ; `&lt;/pre&gt; 第一行中, 添加 webpack 引用, 然后添加`plugins` 选项, 引用`webpack.optimize.CommonsChunkPlugin` 来提取公共模块, 参数`common.js` 表示公共模块的文件名, 后面的数组表示依赖这个模块的入口文件. 重新打包后, 生成三个文件 &lt;pre&gt;`bundle.main1.js, bundle.main2.js common.js 其中 bundle.main1.js 只包含了c模块, bundle.main2.js则没包含任何模块. 当然, 生成了common.js 还需要在 html 中进行引用, 而且要先于 main1, main2","link":"/2016/08/16/commonchunks-e6-8f-92-e4-bb-b6/"},{"title":"CommonJS 规范","text":"概述CommonJS 是服务器端模块的规范, Node.js 采用了这个规范 根据 CommonJS 规范, 一个单独的文件就是一个模块 加载模块使用 require 方法, 该方法读取一个文件并执行, 最后返回文件内部的 exports 对象. // example.js console.log(&apos;evaluating example.js&apos;); var invisible = function(){ console.log(&apos;invisible&apos;); } exports.message = &apos;h1&apos;; exports.say = function(){ console.log(message) } `&lt;/pre&gt; 使用 require 方法, 加载 example.js 模块 &lt;pre&gt;`var example = require(&apos;./example.js&apos;); `&lt;/pre&gt; 这时变量 example 就对应模块中 exports 对象, 可以通过这个对象应用模块中提供的各种方法. &lt;pre&gt;`{ message: &apos;h1&apos;, say: [Function] } `&lt;/pre&gt; require 方法默认读取 js 文件, 所以可以省略 .js 扩展名 &lt;pre&gt;`var example = require(&apos;./example&apos;) `&lt;/pre&gt; js 文件名前需要加上路径, 可以是相对路径, 也可以是绝对路径. 如果省略路径, node.js 会认为添加一个核心模块, 或者已经安装在本地 node_modules 目录中的模块. 如果加载的是一个目录, node.js 会首先寻找该目录中的 package.json 文件, 加载该文件 main 属性指定的模块, 否则就寻找该目录下的 index.js 文件 定义一个最简单的模块 &lt;pre&gt;`exports.add = function(a,b){return a+b}; `&lt;/pre&gt; //add.js 为 exports 对象添加一个 add 方法, &lt;pre&gt;`var addition = require(&apos;./add&apos;); addition.add(1,2); //3 `&lt;/pre&gt; 稍复杂的例子 &lt;pre&gt;`//foobar.js function foobar(){ this.foo = function(){ console.log(&apos;hello foo&apos;) }; this.bar = function(){ console.log(&apos;hello bar&apos;) }; } exports.foobar = foobar; `&lt;/pre&gt; 调用 &lt;pre&gt;`var foobar = require(&apos;./foobar&apos;).foobar, test = new foobar(); test.bar(); //&apos;hello bar&apos; `&lt;/pre&gt; 有时不需要 exports 返回一个对象, 而仅需要返回一个函数, 就写成 module.exports &lt;pre&gt;`module.exports = function(){ console.log(&apos;hello world&apos;) } `&lt;/pre&gt; ### AMD 规范与 CommonJS 规范的兼容性 CommonJS 规范加载模块是同步的, 也就是说, 只有加载完成, 才能执行后面的操作. AMD 规范则是非同步加载模块, 允许指定回调函数. 由于 Node.js 主要用于服务器编程, 模块文件一般都已经存在于本地硬盘, 所以加载起来比较快, 不需要考虑非同步加载的方式, 所以 CommonJS 的规范比较适用. 但是, 如果是浏览器环境, 要从服务器端加载模块, 这时就必须采用非同步模式, 因此浏览器端一般采用 AMD 规范. AMD 规范适用 define 方法定义模块 &lt;pre&gt;`define([&apos;package/lib&apos;, function(lib){ function foo(){ lib.log(&apos;hello world!&apos;); } return { foo:foo }; }]) `&lt;/pre&gt; AMD 规范允许输出的模块兼容 CommonJS 规范,在这时 define 方法需要写成如下格式 &lt;pre&gt;`define(function(require, exports, module) var someModule = require(&apos;someModule&apos;); var anotherModule = require(&apos;anotherModule&apos;); someModule.doTheAwesoem(); anotherModule.doMoreAwesome(); exports.asplode = function(){ someModule.doTheAwesoem(); anotherModule.doMoreAwesome(); }; );","link":"/2016/07/25/commonjs-e8-a7-84-e8-8c-83/"},{"title":"Component API","text":"setState(nextState(obj)[, callback(function)])设置 nextState 的某个键值, 然后下一次 EventLoop 的时候 this.state 会被更新注意, setState 方法中的回调函数在组件重新渲染后才被调用 replaceState(nextState(obj)[, callback(function)])类似于 setState(), 但是会删除已存在的 state 键, 相当于重新初始化State forceUpdate([callback(function)])强制渲染组件注意该方法的回调函数也是在组件重新渲染完成后调用 getDOMNode()返回组件所处的 DOM 元素 isMounted()返回一个 Boolean 值, 如果组件加载到了 DOM, isMount() 返回 true.","link":"/2016/07/21/component-api/"},{"title":"Component Children","text":"this.props.children Children allow you to pass components as data to other components, just like any other prop you use. The special thing about children is that React provides support through its ReactElement API and JSX. XML children translate perfectly to React children. var MyDiv = React.createClass({ render: function(){ return &amp;lt;div&amp;gt;{this.props.children}&amp;lt;/div&amp;gt; } }); ReactDOM.render( &amp;lt;MyDiv&amp;gt; &amp;lt;span&amp;gt;Hello&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;World&amp;lt;/span&amp;gt; &amp;lt;/MyDiv&amp;gt;, node ); `&lt;/pre&gt; ### this.props.children If you look at the **JSX** transform, you&apos;ll find that XML children are appended as arguments to the _React.createElement_ call. Most often, your component will render content and include the children in the _render_ output. This is a great way to create UI components, like cards, headers, and buttons. Occasionally, you may want to interact with the children, maybe mutating or separating them. Be careful here and remember to treat **this.props.children** as an **opaque data structure**. Instead of working with **this.props.children** directly, use the **React.Children** utilities to work with children. &lt;pre&gt;`var ListComponent = React.createClasss({ render: function(){ var children = React.Children.map( this.props.children, function(child){ return &amp;lt;li&amp;gt;{child}&amp;lt;li&amp;gt; } ); return &amp;lt;ul&amp;gt;{children}&amp;lt;/ul&amp;gt;; } }); var middleChildren = [ &amp;lt;strong key=&apos;2&apos;&amp;gt;Child 2&amp;lt;/strong&amp;gt;, &amp;lt;a href=&apos;#&apos; key=&apos;3&apos;&amp;gt;Child 3&amp;lt;/a&amp;gt; ]; ReactDOM.render( &amp;lt;ListComponent&amp;gt; &amp;lt;span&amp;gt;Child 1&amp;lt;/span&amp;gt; {middleChildren} &amp;lt;em&amp;gt;Child 4&amp;lt;/em&amp;gt; &amp;lt;/ListComponent&amp;gt;, document.body );","link":"/2016/07/18/component-children/"},{"title":"Configuring ESLint","text":"Configuration Comments - use JS comments to embed configuration information directly into a file. Configuration Files - use a JS, JSON, or YAML file to specify configuration information for an entire directory and all of its subdirectories. This can be in the form of an .eslintrc file or an eslintConfig field in a package.json file, both of which ESLint will look for and reed automatically, or you can specify a configuration file on the command line. Specifying Parser OptionsESLint allows you to specify the JS language options you want to support. By Default, ESLint support only ES5 syntax. You can override that setting to enable support for ES6 and 7 as well as JSX by using parser options. Parser options are set in your .eslintrc file by using the parserOptions property. The available options are: ecmaVersion - set to 3, 5(default), 6 or 7 to specify the version of ECMAScript you want to use. sourceType - set to &quot;script&quot; (default) or &quot;module&quot; if your code is in ECMAScript modules. emcaFeatures - an object indicating which additional language features you’d like to use: * `globalReturn` - allow `return` statements in the global scope. impliedStrict - enable global strict mode (if ecmaVersion is 5 or greater) jsx: enable JSX experimentalObjectRestSpread - enable support for the experimental object rest/spread properties An example: { &quot;parserOptions&quot;:{ &quot;emcaVersion&quot;: 6, &quot;sourceType&quot;: &quot;module&quot;, &quot;ecmaFeatures&quot;: { &quot;jsx&quot;: true } }, &quot;rules&quot;:{ &quot;semi&quot;: 2 } } `&lt;/pre&gt; ### Specifying Parser By Default, ESLint uses `Espree` as its parser. You can optionally specify that a different parser should be used in your configuration file so long as the parser meets the following requirements: It must be an npm module installled locally; It must have an Esprima-compatible interface It must produce Esprima-compatible AST and token objects. Specifying ENV browser node commonjs es6 mocha `{ \"env\":{ \"browser\": true, \"node\": true } } ### Configuring Rules ESLint comes with a large number of rules, you can modify which rules your project use either using configuration comments or configuration files. To change a rules setting, you must set the rule ID equal to one of these values: - `\"off\"` or `0` to turn rule off. - `\"warn\"` or `1` to turn the rule as a warning(doesn't affect exit code) - `\"error\"` or `2` to turn the rule on as an error(exit code is 1 when triggered) ### Demo ` npm install -g eslint ` eslint –init`` 生成.eslintrc.js` 但是这个文件最好手动生成","link":"/2016/08/22/configuring-eslint/"},{"title":"Connect 相关","text":"预备知识回顾一下 Redux 基本用法 const reducer = (state = {count: 0}, action ) =&amp;gt; { switch(action.type){ case &quot;INCRESE&quot;: return {count: state.count + 1} case &quot;DECRESE&quot;: return {count: state.count - 1} default: return state; } } const actions = { increase: () =&amp;gt; { type: &apos;INCREASE&apos;}, decrease: () =&amp;gt; { type: &apos;DECREASE&apos;} } const store = createStore(reducer); store.subscribe(()=&amp;gt;{ console.log(store.getState()) }); store.dispatch(action.increase()); `&lt;/pre&gt; 通过 reducer 创建一个 store, 每当我们在 store 上 dispatch 一个 action, store 内的数据就会通过 reducer 变化. 我们当然可以直接在 React 中使用 Redux, 在最外层容器中初始化 store, 然后将 state 上的属性作为 props 层层传下去 &lt;pre&gt;`class App extends Component{ componentWillMount(){ store.subscribe((state) =&amp;gt; this.setState(state)) } render(){ return &amp;lt;Comp state={this.state} onIncrease = {()=&amp;gt;store.dispatch(actions.increase())} onDecrease = {()=&amp;gt; store.dispatch(actions.decrease())} } /&amp;gt; } `&lt;/pre&gt; 但这不是最佳方式, 最佳方式是使用 react-redux 提供的 Provider 和 connect 方法 ### 使用 React-redux 首先在最外层容器中, 把所有内容包裹在 Provider 组件中, 将之前创建的 store 作为 prop 传递给 Provider &lt;pre&gt;`const App = () =&amp;gt; { return( &amp;lt;Provider store = {store}&amp;gt; &amp;lt;Comp /&amp;gt; &amp;lt;/Provider&amp;gt; ) } `&lt;/pre&gt; Provider 中的任何一个组件(比如这里的 Comp) 如果需要使用 state 中的数据, 就必须是 `被 connect 过的`组件, 使用 connect 方法对你编写的组件(MyComp)进行包装后的产物. &lt;pre&gt;`class MyComp extends Component { // content... } const Comp = connect(...args)(MyComp); `&lt;/pre&gt; 可见 connect 是重中之重 ### connect 详解 究竟 connect 做了什么 首先看一下函数的签名: &lt;pre&gt;`connect([mapStatToProps], [mapDispatchToProps], [mergeProps], [options]) `&lt;/pre&gt; connect() 函数接受四个参数, 分别是 &lt;pre&gt;`mapStatToProps, mapDispatchToProps, mergeProps, options `&lt;/pre&gt; &lt;pre&gt;`mapStatToProps(state, ownProps): stateProps `&lt;/pre&gt; 这个函数允许我们将 store 中的数据作为 props 绑定到组件上 &lt;pre&gt;`const mapStatToProps = (state) =&amp;gt; { return { count: state.count } } `&lt;/pre&gt; 这个函数的第一个参数就是 Redux 的 store, 我们从中摘取 count 属性, 因为返回了具有 count 属性的对象, 所以 MyComp 会有名为 count 的 props 字段 &lt;pre&gt;`class MyComp extends Component{ render(){ return &amp;lt;div&amp;gt;Count: {this.props.count}&amp;lt;/div&amp;gt; } } const Comp = connect(...args)(MyComp); `&lt;/pre&gt; 当然你不必将 state 原封不动传递给组件, 可以根据 state 中的数据, 动态的输出组件需要的(最小)属性 &lt;pre&gt;`const mapStateToProps = (state) =&amp;gt; { return { greaterThanFive: state.count &amp;gt; 5 } } `&lt;/pre&gt; 第二个参数 ownProps, 是 MyComp 自己的 props, 有时候 ownProps 也会对其产生影响, 比如当你在 store 中维护一个用户列表, 而你的组件 MyComp 只关心一个用户(通过 props 中的 userId体现) &lt;pre&gt;`const mapStateToProps = (state, ownProps) =&amp;gt; { // state 是{ userList:[{id:0,name;&apos;王二&apos;}]} return { user: _.find(state.userList, {id:ownProps.userId}) } } class MyComp extends Component{ static PropTypes = { userId: PropTypes.string.isRequired, user: PropTypes.object }; render(){ return &amp;lt;div&amp;gt;UserName: {this.props.user.name}&amp;lt;/div&amp;gt; } } const Comp = connect(mapStateToProps)(MyComp) `&lt;/pre&gt; 当 state 变化, 或者 ownProps 变化时, mapStateToProps 都会被调用, 计算出一个新的 stateProps , 在与 ownProps merge 后, 更新给 MyComp 这就是将 Redux store 中的数据连接到组件的基本方法 mapDispatchToProps(dispatch, ownProps): dispatchProps connect 的第二个参数是 mapDispatchToProps, 功能是将 action 作为 props 绑定到 MyComp 上 &lt;pre&gt;`const mapDispatchToProps = (dispatch, ownProps) =&amp;gt; { return { increase: (...args) =&amp;gt; dispatch(actions.increase(...args)), decrease: (...args) =&amp;gt; dispatch(actions.decrease(...args)) } } class MyComp extends Component{ render(){ const {count, increase, decrease} = this.props return ( &amp;lt;div&amp;gt; &amp;lt;div&amp;gt;Count:{count}&amp;lt;/div&amp;gt; &amp;lt;button onClick={increase}&amp;gt;+&amp;lt;/button&amp;gt; &amp;lt;button onClick={decrease}&amp;gt;-&amp;lt;/button&amp;gt; &amp;lt;/div&amp;gt; ) } } const Comp = connect(mapStateToProps, mapDispatchToProps)(MyComp) `&lt;/pre&gt; 由于 mapDispatchToProps 方法返回了具有 increase 属性和 decrease 属性的对象, 这两个属性也会成为 MyComp 的 props 如上所示, 调用 actions.increase()只能得到一个 action 对象{type:&apos;INCREASE&apos;}, 要触发这个 action 必须要通过 dispatch 调用, dispatch 正式 mapDispatchToProps 的第一个参数, 但是为了不让 MyComp 组件感知到 dispatch 的存在, 我们需要将 increase 和 decrease 方法包装一下, 使之成为直接可以被调用的函数(即触发该方法就会触发 dispatch) Redux 本身提供了 bindActionCreator 函数, 来将 action 包装成可以直接被调用的函数 &lt;pre&gt;`import {bindActionCreator} from &apos;redux&apos; const mapDispatchToProps = (dispatch,ownProps) =&amp;gt; { return bindActionCreator({ increase: actions.increase, decrease: actions.decrease }) } 同样当 ownProps 变化时, 该函数也会被调用, 生成一个新的 dispatchProps( 在与 stateProps 和 ownPorps merge 后), 更新给 MyComp. 注意 action 的变化不会引起上述过程, 默认 action 在组件的生命周期中是固定的 [mergeProps(stateProps, dispatchProps, ownProps): props] 之前说过不管是 stateProps 还是 dispatchProps, 都需要和 ownProps merge 之后才会被赋给 MyComp, connect 的第三个参数就是来做这个事情的, 通常情况下不需要传这个参数, connect 会使用 Object.assign 方法代替该方法. 其他最后还有一个 options 参数, 比较简单, 一般也不会用到. 参考","link":"/2016/08/22/connect-e7-9b-b8-e5-85-b3/"},{"title":"Content Parser in CITA","text":"The parse now we used is 1234567891011const parser = (content: string) =&gt; { const bytes = hexToBytes(content) const decoded = pb.UnverifiedTransaction.deserializeBinary(bytes) const tx = decoded.getTransaction() return { from: tx.getFrom ? tx.getFrom() : '', to: tx.getTo ? tx.getTo() : '', data: tx.getData ? tx.getData() : '', value: tx.getValue ? tx.getValue().toString() : '' }} Here we use these methods: hexToBytes(content) =&gt; bytes pb.UnverifiesTransaction.deserializeBinary(bytes) =&gt; decoded decoded.getTransaction() =&gt; transaction transaction.{getFrom, getTo, getValue, getData} hexToBytes123456789const hexToBytes = (hex: string) =&gt; { let _hex = hex.startsWith('0x') ? hex.slice(2) : hex // remove 0x prefix let result = [] while (_hex.length &gt;= 2) { result.push(parseInt(_hex.substring(0, 2), 16)) // parse hex to bytes(int8 array) _hex = _hex.substring(2, _hex.length) } return result} pb.UnverifiedTransaction.deserializeBinary1234567891011121314151617181920212223242526272829303132333435363738394041424344const jspb = require('google-protobuf')const goog = jspbproto.UnverifiedTransaction = opt_data =&gt; { jspb.Message.initialize(this, opt_data, 0, -1, null, null)}proto.UnverifiedTransaction.deserializeBinaryFromReader = (msg, reader) =&gt; { while (reader.nextField()) { if (reader.isEndGroup()) { break } let field = reader.getFieldNumber() switch (field) { case 1: { let value = new proto.Transaction() reader.readMessage(value.proto.Transaction.deserializeBinaryFromReader) msg.setTransaction(value) } case 2: { let value = /** @type {!Uint8Array} */ (reader.readBytes()) msg.setSignature(value) break } case 3: { let value = /** @type {!proto.Crypto} */ (reader.readEnum()) msg.setCrypto(value) break } default: { reader.skipField() break } } } return msg}proto.UnverifiedTransaction.deserializeBinary = bytes =&gt; { const reader = new jspb.BinaryReader(bytes) const msg = new proto.UnverifiedTransaction() return proto.UnverifiedTransaction.deserializeBinaryFromReader(msg, reader)}","link":"/2018/05/17/content-parser-in-cita/"},{"title":"Concept of PWA","text":"Advantages of Progressive Web Apps: Reliable - Load instantly and never show the dinasaur. Fast - Respond quickly to user interactions with silky smooth animations. Enaging - Feel like a natural app on the device, with immersive user experience. What is a Progressive Web App Progressive - Works for every user, regardless of browser choice because it’s built with progressive enhancement as a core tenet. Responsive - Fits any form factor: desktop, mobile, tablet, or whatever is next. Connectively independent - Enhanced with service workers to work offline or on low-quality networks. App-like - Feels like an app, because the app shell model seperates the application functionality from application content. Fresh - Always up-to-date thanks to the service worker update process. Safe - Served via HTTPS to prevent snooping and to ensure content hasn’t been tampered with. Discoverable - Is identifiable as an ‘application’ thanks to W3C manifest and service worker registration scope, allowing search engines to find it. Re-engagable - Makes Re-engagement easy through features like push notification. Installable - Allows users to add apps they find most useful to their home screen without the hassle of an app store. Linkable - Easily share the application via URL, doesn’t require complex installation. What is App ShellThe app’s shell is the minimal HTML, CSS, JavaScript that is required to power the user interface of a progressive web app and is one of the components that ensures reliably good performance. Its first load should be extremely quick and immediately cached. ‘Chched’ means that the shell files are loaded once over the network and then saved to the local device. Every subsequent time that the user opens the app, the shell files are loaded from the local device’s cache, which results in blazing-fast startup times. App shell architecture seperates the core application infrastructure and UI from the data. All of the UI and infrastructure is cached locally using a service worker so that on subsequent loads, the PWA only needs to retrieve the necessary data, instead of having to load everything. A service worker is a script that your browser runs in the background, seperate from a web page, opening the door to features that don’t need a web page or user interaction. The app shell is similar to the bundle of code that you’d publish to an app store when building a native app. It is the core components necessary to get your app off the ground, but likely doesn’t contain the data. Using the app shell architecture allows you to focus on speed, giving the PWA similar properties to native apps: instant loading regular updates Implement App ShellCreate the HTML for the App ShellThe Components consist of: Header with a title, and app/refresh button Container for forecast cards A forecast card template A dialog for adding new cities A loading indicator 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Weather PWA&lt;/title&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"styles/inline.css\"&gt; &lt;/head&gt; &lt;body&gt; &lt;header class=\"header\"&gt; &lt;h1 class=\"header__title\"&gt;Weather PWA&lt;/h1&gt; &lt;button id=\"butRefresh\" class=\"headerButton\"&gt;&lt;/button&gt; &lt;button id=\"butAdd\" class=\"headerButton\"&gt;&lt;/button&gt; &lt;/header&gt; &lt;main class=\"main\"&gt; &lt;div class=\"card cardTemplate weather-forecase\" hidden&gt; ... &lt;/div&gt; &lt;/main&gt; &lt;div class=\"dialog-container\"&gt; ... &lt;/div&gt; &lt;div class=\"loader\"&gt; &lt;svg viewBox=\"0 0 32 32\" with=\"32\" height=\"32\"&gt; &lt;circle id=\"spinner\" cx=\"16\" cy=\"16\" r=\"14\" fill=\"none\"&gt;&lt;/circle&gt; &lt;/svg&gt; &lt;/div&gt; &lt;!-- insert link to app.js here --&gt; &lt;/body&gt;&lt;/html&gt; Notice the loader is visible by default. This ensures that the user sees the loader immediately as the page loads, giving them a clear indication that the content is loading. Start with a fast loadDifferentiating the first runUser preferences, like the list of cities a user has subscribed to, should be stored locally using IndexedBD or another fast storage mechanism. To simplify this code, here we use localStorage, which is not ideal for production apps because it is a blocking, synchronous storage mechanism that is potentially very slow on some device. 12345// Save list of cities to lcoalStorageapp.saveSelectedCities = function () { var selectedCities = JSON.stringify(app.selectedCities) localStorage.selectedCities = selectedCities} Next, let’s add the startup code to check if the user has any saved cities and render those 12345678910111213141516app.selectedCities = lcoalStorage.selectedCitiesif (app.selectedCities) { app.selectedCities = JSON.parse(app.selectedCities) app.selectedCities.forEach(function (city) { app.getForecast(city.key, city.label) })} else { app.updateForecastCard(initialWeatherForecast) app.selectedCities = [ { key: initialWeatherForecast.key, label: initialWeatherForecast.label, }, app.saveSelectedCities() ]} Use service workers to pre-cache the App ShellPWA has to be fast, and installable, which means that they work online, offline, and on intermittent, slow connections. To achieve this, we need to cache our app shell using service worker, so that it’s always available quickly and reliably. Features provided via service workers should be considered a progressive enhancement, and added only if supported by the browser. Register the service worker if it’s availableThe first step to making the app work offline is to register a service worker, a script that allows background functionality without the need of an open web page or user interaction. This takes two simple steps: Tell the browser to register the JavaScript file as the service worker Create a JavaScript file containing the service worker First, we need to check if the browser supports service worker, and if it does, register the service worker. Add the following code to app.js 1234567if ('serviceWorker' in navigator) { navigator.serviceWorker .register('./service-worker.js') .then(function () { console.log('Service Worker Registered') })} Cache the site assetsWhen the service worker is registered, an install event is triggered the first time the user visits the page. In this event handler, we will cache all the assets that are needed for the application. When the service worker is fired, it should open the caches object and populate it with the assets necessary to load the App Shell. Create a file called service-worker.js in your application root folder. This file must live in the application root because the scope for service worker is defined by the directory in which the file resides. Add this code to your new service-worker.js file. 123456789101112var cacheName = 'weatherPWA'var filesToCache = []self.addEventListener('install', function (e) { console.log('[ServiceWorker] Install') e.waitUntil( caches.open(cacheName).then(function (cache) { console.log('[ServiceWorker] Caching app shell') return cache.addAll(filesToCache) }) )}) First, we need to open the cache with caches.open() and provide a cache name. Providing a cache name allows us to version files, or separate data from the app shell so that we can easily update one but not affect other. Once the cache is open, we can then call cache.addAll(), which takes a list of URLs, then fetches them from the server and adds the response to the cache. Unfortunately, cache.addAll() is atomic, if any of the files fail, the entire cache step fails. DevTools can debug service workers. Before reloading your page, open up DevTools, go the Service Worker pane on the Application panel. When you see a blank page like this, it means that the currently open page doesn’t have any registered service workers. Now reload your page. The Service Worker pane should look like this. When you see information like this, it means the page has a service worker running. Let’s add some logic on the activate event listener to update the cache. 1234567891011121314self.addEventListener('activate', function (e) { console.log('[ServiceWorker] Activate') e.waitUntil( caches.keys().then(function (keyList) { return Promise.all(keyList.map(function (key) { if (key !== cacheName) { console.log('[ServiceWorker] Removing old cache', key) return caches.delete(key) } })) }) ) return self.clients.claim()}) This code ensures that your service worker updates its cache whenever any of the app shell files change. In order for this to work, you’d need to increment the cacheName variable at the top of your service worker file. When the app is complete, self.clients.claim() fixes a corner case in which the app wasn’t returning the latest data. You can reproduce the corner case by commenting out the line below and then doing the following steps: load app for first time so that the initial City data is shown press the refresh button on the app go offline reload the app You expect to see the newer data, but you actually see the initial data. This happens because the service worker is not yet activated. self.clients.claim() essentially lets you activate the service worker faster. Finally, let’s update the list of files required for the app shell. In the array, we need to include all of the files our app needs, including images, js, css, etc. 12345678var filesToCache = [ '/', '/index.html', '/scripts/app.js', '/styles/inline.css', '/images/clear.png', // ...] Serve the app shell from the cacheService workers provide the ability to intercept requests made from our PWA and handle them within the service worker. That means we can determine how we want to handle the request and potentially serve our own cached response. 12345678self.addEventListener('fetch', function (e) { console.log('[ServiceWorker] Fetch', e.request.url) e.responseWith( caches.match(e.request).then(function (response) { return response || fetch(e.request) }) )}) Stepping from inside, out, caches.match() evaluates the web request that triggered the fetch event, and checks to see if it’s available in the cache. It then either responds with the cached version, or uses fetch to get a copy from the network. The response is passed back to the web page with e.responseWith() Beware of the edge casesThis code must not be used in production because of the many unhandled edge cases Cache depends on updating the cache key for every change Requires everything to be redownloaded for every change Browser cache may prevent the service worker cache from updating Beware of cache-first strategies in production","link":"/2017/06/01/concept-of-PWA/"},{"title":"CSS Cube Transform","text":".container{ width:200px; height:200px; position:relative; perspective:1000px; margin:0 auto;}.cube{ width:100%; height:100%; position:absolute; transform-style:preserve-3d;}.cube figure{ width:196px; height:196px; border:2px solid #ccc; position:absolute; font-size:20px; line-height:196px; font-weight:bold; color:white; text-align:center; transition:transform 1s ease;}.cube:hover .front{ background: hsla( 0, 100%, 50%, 0.5 ); transform:translateZ(100px);}.cube:hover .back{ background: hsla( 60, 100%, 50%, 0.5 ); transform:rotateY(180deg) translateZ(100px);}.cube:hover .right{ background: hsla( 120, 100%, 50%, 0.5 ); transform: rotateY(90deg) translateZ(100px);} .cube:hover .left{ background: hsla( 180, 100%, 50%, 0.5 ); transform: rotateY(-90deg) translateZ(100px);}.cube:hover .top{ background: hsla( 240, 100%, 50%, 0.5 ); transform: rotateX(90deg) translateZ(100px);}.cube:hover .bottom{ background: hsla( 300, 100%, 50%, 0.5 ); transform: rotateX(-90deg) translateZ(100px);} Front Back Right Left Top Bottom Notice, when the rotate applied to the element, its coordinates will rotate with it. In this case, all Z-indices rotate to pointing outside the cube./*HTML*/ div.container div.cube fiture.front{Front} fiture.back{Back} fiture.right{Right} figure.left{Left} figure.top{Top} figure.bottom{Bottom} /*CSS*/ .container{ width:200px; height:200px; position:relative; perspective:1000px; } .cube{ width:100%; height:100%; position:absolute; transform-style:preserve-3d; } .cube figure{ //Set single Aspect width:196px; height:196px; border:2px solid #ccc; position:absolute; font-size:20px; line-height:196px; font-weight:bold; color:white; text-align:center; transition:transform 1s ease; } .cube:hover .front{ background: hsla( 0, 100%, 50%, 0.5 ); transform:translateZ(100px); } .cube:hover .back{ background: hsla( 60, 100%, 50%, 0.5 ); transform:rotateY(180deg) translateZ(100px); } .cube:hover .right{ background: hsla( 120, 100%, 50%, 0.5 ); transform: rotateY(90deg) translateZ(100px); } .cube:hover .left{ background: hsla( 180, 100%, 50%, 0.5 ); transform: rotateY(-90deg) translateZ(100px); } .cube:hover .top{ background: hsla( 240, 100%, 50%, 0.5 ); transform: rotateX(90deg) translateZ(100px); } .cube:hover .bottom{ background: hsla( 300, 100%, 50%, 0.5 ); transform: rotateX(-90deg) translateZ(100px); }","link":"/2016/06/16/css-cube-transform/"},{"title":"CSS 中的 Clear","text":"为什么要清除浮动一个块级元素的如果没有设置 height, 则其高度由其子元素撑开. 如果所有子元素都是浮动的(脱离标准文档流), 那么父元素就会发生”坍塌”. 两种情况清除浮动包括清除子元素浮动和清除上级元素浮动, 如果要清除上级元素浮动, 只需要设置 clear:both 即可.如果要清除子元素浮动, 可以用空标签法, clearfix 法或者 overflow 法. clear 的用法.subElement{ clear:both; } `&lt;/pre&gt; ##### clearfix(最优浮动闭合方案) 父元素添加 class=clearfix 简洁版 &lt;pre&gt;`.clearfix:before, .clearfix:after{ content:&quot;&quot;; display:table; } .clearfix:after{ clear:both; overflow:hidden; } .clearfix{ zoom:1; } `&lt;/pre&gt; 经典版 &lt;pre&gt;`.clearfix:after{ display:block; content:&quot;&quot;; clear:both; height:0; visibility:hidden } `&lt;/pre&gt; 使用时在浮动元素的父元素上添加 class=&quot;clearfix&quot; #### 简单的方法 &lt;pre&gt;`.clearfix{ overflow:auto; _height:1%; } `&lt;/pre&gt; #### 常用的方法 &lt;pre&gt;`.clearfix{ clear:both; height:0; overflow:hidden; } 在需要清除浮动的地方加上一个 div.clear 或者 br.clear(不是套上)","link":"/2016/06/13/css-e4-b8-ad-e7-9a-84-clear/"},{"title":"CSS 动画之硬件加速","text":"触发硬件加速的 CSS 属性 transform opacity filter 硬件加速的工作原理浏览器解析得到 DOM 树后, 与 CSS 形成渲染树, 渲染树上有大量的渲染元素, 每一个渲染元素都被分到一个图层中, 每个图层被加载到 GPU 形成渲染文理. 然而, transform 等 CSS 属性不会触发 GPU 的 repaint, 这些使用 transform 属性的图层都会有独立合成器进行处理. 比如某个元素具有 transform 属性, 那么会为他创建一个新的复合图层, 可以被 GPU 直接用来执行 transform 操作. 一般浏览器会在以下几种情况下创建一个独立的复合图层: 3D 或 transform &amp;lt;video 和&amp;lt;canvas&amp;gt;标签 CSS Filters 元素覆盖时(比如 z-index) 3D 和 2D 的transform 区别在于, 浏览器在页面渲染前为 3D 动画创建独立的复合图层, 而在运行期间为 2D 动画创建独立复合图层. 2D transform 在动画开始和结束的时候依旧出现了初始化和删除的 repaint. 强制使用 GPU 渲染为了避免 2D transform 动画的两次 repaint, 我们可以硬编码一些样式来解决这个问题 .solution1{ transform: translateZ(0); } .solution2{ transform: rotateZ(360deg) } 这段代码让浏览器执行3Dtransform, 进而创建一个独立的复合涂层 硬件加速缺点 内存, 如果 GPU 加载了大量文理, 容易发生内存问题 使用 GUP 渲染会影响字体的抗锯齿效果, 因为 GPU 和 CPU 渲染机制不同. 即使最终硬件加速停止了, 文本还是会在动画期间显得模糊.","link":"/2016/07/27/css-e5-8a-a8-e7-94-bb-e4-b9-8b-e7-a1-ac-e4-bb-b6-e5-8a-a0-e9-80-9f/"},{"title":"Crx-Config","text":"This is a detailed customized chrome extension configuration cheatsheet. Manifest123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111{ // required \"manifest_version\": 2, // integer indicates the version of the manifest file format. \"name\": \"Name of Extension\", \"version\": \"Version of Extension\", // One to four dot-separated integers indicating the version of the extension, \"1.2.3.1234\", and there's a field named \"version_name\" for displaying purpose, \"version_name\": \"1.0 beta\" // Recommended \"default_locale\": \"en\", // this field is required in extensions that have a '_locales' directory and must be absent in extensions that have no '_locales' directory. \"description\": \"Description of Extension\", \"icons\": { // One or more icons that represent the extension, app, or theme. \"16\": \"icon16.png\", // is used as the favicon for an extension's pages \"48\": \"icon48.png\", // 48 x 48 icon is for extension management page \"128\": \"icon128.png\" // You should always provides a 128 x 128 icon, it's used during installation and by the Chrome Extension Store. }, // Pick one or none \"browser_action\": { // use browser actions to put icons in the main chrome toolbar, to the right of the address bar. It can have a tooltip, a badge and a popup \"default_icon\": { // optional, you can use browserAction.setBadgeText, browserAction.setBadgeBackgroundColor to set the badge \"16\": \"images/icon16.png\", \"24\": \"images/icon24.png\", \"32\": \"images/icon32.png\" }, \"default_title\": \"Tooltip of Extension\", \"default_popup\": \"popup.html\" }, \"page_action\": { // use the chrome.pageAction API to put icons in the main chrome toolbar, to the right of the address bar. Page actions represent actions that can be taken on the current page, but that aren't applicable to all pages. Page actions appear grayed out when inactive. \"default_icons\": { // optional \"16\": \"images/icon16.png\", \"24\": \"images/icon24.png\", \"32\": \"images/icon32.png\" }, \"default_title\": \"Tooltip of Extension\", // optional \"default_popup\": \"popup.html\" }, // Optional \"action\": \"//TODO\", \"author\": \"//TODO\", \"automation\": \"//TODO\", \"background\": { \"scripts\": [], \"persistent\": false, // Recommended to be false \"service_worker\": \"path to the sw\" // Optional }, \"chrome_settings_override\": { \"homepage\": \"url of homepage\", \"search_provider\": {}, \"startup_pages\": [] }, \"chrome_ui_overrides\": { \"bookmarks_ui\": { \"remove_bookmark_shortcut\": true, \"remove_button\": true } }, \"chrome_url_overrides\": {}, // used to override pages provided by chrome. In addition to HTML, an override page usually has CSS and JavaScript Code. \"commands\": {}, \"content_capabilities\": {}, \"content_scripts\": [{}], \"content_security_poligy\": \"policyString\"a, \"converted_from_user-script\": \"\", \"devtools_page\": \"//TODO\", \"event_rules\": [], \"externally_connectable\": {}, \"file_browser_handlers\": [], \"file_system_provider_capabilities\": { \"configurable\": true, \"multiple_mounts\": true, \"source\": \"network\" }, \"homepage_url\": \"http://path/to/homepage\", \"import\": [], // shared modules \"export\": [], // shared modules \"incognito\": \"//TODO\", \"input_components\": \"\", \"key\": \"publicKey\", \"minimum_chrome_version\": \"versionString\", \"nacl_modules\": [], \"oauth2\": \"\", \"offline_enabled\": true, \"omnibox\": { \"keyboard\": \"aString\" // The omnibox allows you to register a keyword with chrome's address bar. }, \"optional_permissions\": [\"tabs\"], \"options_page\": \"options.html\", \"options_ui\": { \"chrome_style\": true, \"page\": \"options.html\" }, \"permissions\": [\"tabs\"], \"platforms\": \"\", \"replacement_web_app\": \"\", \"requirements\": {}, \"sandbox\": [], \"short_name\": \"short name\", \"signature\": \"\", \"spellcheck\": \"\", \"storage\": { \"managed_schema\": \"schema.json\" }, \"system_indicator\": \"\", \"tts_engine\": {}, \"update_url\": \"http://path/to/updateInfo.xml\",, \"version_name\": \"0.1 beta\", \"web_accessible_resource\": []} BrowerAction Methods1chrome.browserAction.method(params) setTitle({ title: string, tabId?: number }, callback) getTitle({ tabId?: number }, callback) setIcon({ imageData?: ImageDataType | object, path?: string | object, tabId?: number }, callback) setPopup({ tabId?: number, popup: string }, callback) getPopup({ tabId?: number }, callback) setBadgeText({ text: string, tabId?: number }, callback) getBadgeText({ tabId?: number }, callback) setBadgeBackgroundColor({ color: string or ColorArray, tabId?: number }, callback) getBadgeBackgroundColor({ tabId?: number }, callback) enable({ tabId?: number }, callback) disable({ tabId?: number }, callback) BrowserAction Events1chrome.browserAction.onClicked.addEventListener((tab: tabs.Tab) =&gt; {}) PageAction Methods1chrome.pageAction.method(params) show({ tabId: number }, callback), the page action is shown whenever the tab is selected hide({ tabId: number }, callback), hide the page action, means set the page action gray setTitle({ tabId: number, title: string }, callback) getTitle({ tabId: number }, callback) setIcon({ imageData: object | ImageDataType, path?: string | object, }), the path to the icons could be a dictionary {size =&gt; relative image path}, the actual image to be used is chosen depending on screen’s pixel density. Note that path = ‘foo’ equals to path = { ‘16’: foo }, implicitly converted into a dictionary. setPopup({ tabId: number, popup: string }, callback) getPopup({ tabId }, callback) PageAction Events1chrome.pageAction.onClicked.addEventListener((tab: tabs.Tab) =&gt; {}) BackgroundExtensions are event-driven programs used to modify or enhance the chrome browsing experience. Events are browser triggers and extensions monitor them in background scripts, then react to specified instructions. A background page is loaded when it is needed, and unloaded when it goes idle. - The extension is first installed or updated to a new version. - The background page was listening for an event, and the event is dispatched. - A content script or other extension sends a message. - Another view in the extension, such as a popup, calls `runtime.getBackgroundPage`. Register background scriptsBackground scripts are registered in the manifest under the “background” field. They are listed in an array of “background.scripts”. Remember to set “persistent” to false unless the extension uses chrome.webRequest API to block or modify network requests. Initialize the extensionListen to runtime.onInstalled event to initialize an extension on installation. Use this event to set a state or for one-time initialization, such as a context menu. 1234567chrome.runtime.onInstalled.addListener(() =&gt; { chrome.contextMenu.create({ id: 'sampleContextMneu', title: 'Sample Context Menu', contexts: ['selection'], })}) Set up listenersStructure background scripts around events the extension depends on. Defining functionally relevant events allows background scripts to lie dormant until those events are fired and prevents the extension from missing important triggers. Listeners must be registered synchronously from the start of the page. 1234// This will run when a bookmark is createdchrome.bookmark.onCreated.addListener(() =&gt; { // do something}) Do not register listeners asynchronously, as they will not be properly triggered. 123456// DO NOT DO THISchrome.runtime.onInstalled.addListener(() =&gt; { chrome.bookmarks.onCreated.addListener(() =&gt; { // do something })}) Filter eventsUse APIs that supports event filters to restrict listeners to the cases the extension cares about. If an extension is listening for the tabs.onUpdated event, try using the webNavigation.onCompleted event with filters instead, as the tabs API does not support filters. 123456789101112chrome.webNavigation.onCompleted.addListener( () =&gt; { alert('This is my favorite website') }, { url: [ { urlMatches: 'http://www.google.com', }, ], },) React to listeners1234567891011chrome.runtime.onMessage.addListener((message, callback) =&gt; { if (message.data === 'setAlarm') { chrome.alarms.create({ delayInMinutes: 5 }) } else if (message.data === 'runLogic') { chrome.tabs.executeScript({ file: 'logic.js' }) } else if (message.data === 'changeColor') { chrome.tabs.executeScript({ code: 'document.body.style.backgroundColor=\"orange\"', }) }}) Unload background scriptsData should be persisted periodically so that important information is not lost if an extension crashes without receiving onSuspend. Use the storage API to assist with this. 1chrome.storage.local.set({ variable: 'info' }) If an extension uses message passing, ensure all ports are closed. The background script will not unload until all message ports have shut. Listen to runtime.Port.onDisconnect event will give insight to when open ports are closing. Manually close them with runtime.Port.disconnect. Background scripts unload themself after a few seconds of inactivity. If any last minute cleanup is required, listen to runtime.onSuspend event. 1234chrome.runtime.onSuspend.addListener(() =&gt; { console.log('unloading') chrome.browserAction.setBadgeText({ text: '' })}) Content scriptsContent scripts are files that run in the context of web pages. By using the standard DOM, they are able to read details of the web pages the browser visits, make changes to them and pass information to their parent extension. Content scripts can access chrome APIs used by their parent extension by exchanging messages with the extension. They can also access the URL of an extension’s file with chrome.runtime.getURL() and use the result the same as other URLs. Content scripts can access the following chrome APIs directly: i18n storage runtime connect getManifest getURL id onConnect onMessage sendMessage Content scripts are unable to access other APIs directly. Work in isolated worldsContent scripts live in an isolated world, allowing a content script to makes chagnes to its JavaScript environment without conflicting with the page or additional content scripts. Inject scriptsContent scripts can be programmatically or declaratively injected. Inject ProgrammaticallyUse programmatic injection for content scripts that need to run on specific occasions. To inject a programmatic content script, provide the activeTab permission in the manifest. This grants secure access to the active site’s host and temporary access to the tabs permission, enabling the content script to run on the current active tab without specifying cross-origin premissions. 123{ \"permissions\": [\"activeTab\"]} Then content scripts can be injected as code 1234567891011chrome.runtime.onMessage.addListener((message, callback) =&gt; { if (message === 'changeColor') { chrome.tabs.executeScript({ code: 'document.body.style.backgroundColor=\"orange\"', }) } else if (message === 'runContentScript') { chrome.tabs.executeScript({ file: 'contentScript.js', }) }}) Inject declarativelyUse declarative injection for content scripts that should be automatically run on specified pages. Declaratively injected scripts are registered in the manifest.content_scripts field. 123456789101112{ \"content_scripts\": [ { \"matches\": [\"http://*.nytimes.com/*\"], // required, specifies which pages this content script will be injected into. \"css\": [\"myStyles.css\"], // optional, the list of css files to be injected into the pages. They are injected orderly. \"js\": [\"contentScript.js\"], // optional, the list of js files to be injected into orderly. \"match_about_blank\": false, // optional, whether or not to inject into the blank pages \"run_at\": \"document_idel\", // controls when the files are injected, the preferred and default config is document_idle. \"all_frames\": false, } ]} Chrome PermissionsUse the chrome.permission API to request declared optional permissions at run time rather than install time, so users understand why the permissions are needed and grant only those that are necessary. Decide which permissions are required and which are optionalAn extension can declare both required and optional permissions. In general, you should: Use required permissions when they are needed for your extension’s basic functionality. Use optional permissions when they are needed for optional features in your extension. Advantages of required permissions: Fewer prompts: An extension can prompt the user once to accept all permissions. Simpler development: Required permissions are guaranteed to be present. Advantages of optional permissions: Better security Better information for users: An extension can explain why it needs a particular permission when the user enables the relevant feature. Easier upgrades: When you upgrades your extension, chrome will not disable it for your users if the upgrade adds optional rather than required permissions. Declare optional permissions in your extension manifest with the optional_permissions key, using the same format as the permission field. Request optional permissionsRequest the permission from within a user gesture using permissions.request(). 123456789101112131415document.querySelector('#my-button').addEventListener('click', e =&gt; { chrome.permissions.request( { permissions: ['tabs'], origins: ['http://www.google.com'], }, granted =&gt; { if (granted) { // do something } else { // do something } }, )}) Check the extension’s current permissions12345678910111213chrome.permissions.contains( { permissions: ['tabs'], origins: ['http://www.google.com'], }, result =&gt; { if (result) { // the extension has the permissions } else { // the extension doesn't have the permissions } },) Remove the permissions123456789chrome.permissions.remove( { permissions: ['tabs'], origins: ['http://www.google.com'], }, removed =&gt; { // do something },) RequirementsTechnologies required by the app or extension. Hosting sites such as chrome web store may use this list to dissuade users from installing apps or extensions that will not work on their computer. Supported requirements currently include “3D” and “plugins”. MessagesSince content scripts run in the context of a web page and not the extension, they often need some way of communicating with the rest of the extension. For example, an RSS reader extension might use content script to detect the presence of an RSS feed on a page, then notify the background page in order to display a page action icon for that page. Communication between extensions and their content script scripts works by using message passing. Either side can listen for message sent from the other end, and respond on the same channel. A message can contain any valid JSON object. Simple one-time requestsIf you only need to send a single message to another part of your extension, you should use the simplified runtime.sendMessage and tabs.sendMessage. This lets you send a one-time JSON-serializable message from a content script to extension, or vice versa, respectively. 1234// send a request from content scriptchrome.runtime.sendMessage({ greeting: 'hello' }, res =&gt; { console.log(res)}) 123456// send a request from the extension to a content script works similar, except that you need to specify which tab to send it to.chrome.tabs.query({ active: true, currentWindow: true }, tabs =&gt; { chrome.tabs.sendMessage(tabs[0].id, { greeting: 'hello' }, res =&gt; { console.log(res) })}) On the receiving end, you need to set up an runtime.onMessage event listener to handle the message. 123456chrome.runtime.onMessage.addListener((req, sender, sendRespond) =&gt; { console.log(sender.tab ? `from a content script: ${sender.tab.url}` : `from the extension`) if (req.greeting === 'hello') { sendResponse({ farewell: 'goodbye' }) }}) In the above example, the sendResponse is called synchronously. If you want to call the sendResponse asynchronously, simple return true at the end. Note: If multiple pages are listening on the onMessage events, only the first to call sendResponse for a particular event will succeed in sending response. Other response will be ignored. Note: call sendResponse synchronously or return true. Without return true, sendResponse(undefined) will be called automatically and implicitly. Long-lived connectionsSometimes it’s useful to have a conversation lasting longer than one-time request. You can open a long-lived channel from content script to an extension page, or vice versa, by using runtime.connect or tab.connect. When establishing a connection, each end is given a runtime.Port object which is used for sending and receiving messages through that connection. 123456789const port = chrome.runtime.connect({ name: 'knockknock' })port.postMessage({ joke: 'Knock knock' })port.onMessage.addListener(msg =&gt; { if (msg.question === \"Who's there?\") { port.postMessage({ answer: 'Madame' }) } else if (msg.question === 'Madame who?') { port.postMessage({ answer: 'Madame... Bovary' }) }})","link":"/2020/01/06/crx-config/"},{"title":"CSS 外边距合并","text":"外边距合并的意思是两个垂直排列的块的外边距可能发生(坍塌)合并, 仅保留较大的边距. 情况一:两元素上下排列 情况二:两元素是父子关系, 若此时父元素没有设定 border, margin(或者宽度为0), 他们的上下边距也会发生合并. 情况三:自身是一个有上下外边距的空元素, 如果没有 border 和 margin, 自身的上下外边距也会合并 如果这个空元素还与另一个元素垂直排列, 会继续发生合并 对象只有普通文档流中的块元素会发生外边距合并, 如果是浮动块, 或者是绝对定位块, 他的外边距是不会合并的.","link":"/2016/07/14/css-e5-a4-96-e8-be-b9-e8-b7-9d-e5-90-88-e5-b9-b6/"},{"title":"CSS 添加条纹背景","text":".bg{ height:300px; width:300px; color:#fff;}.type1{ background: linear-gradient(#fb3 20%, #58a 80%);}.type2{background: linear-gradient(#fb3 50%, #58a 50%);}.type3{background-size:100% 30px;}.type4{ background: linear-gradient(45deg, #fb3 50%, #58a 50%); background-size:30px 30px;}.type5{ background: repeating-linear-gradient(45deg, #fb3, #58a 30px)}.type6{ background: #58a; background-image: repeating-linear-gradient(45deg, hsla(0,0%,100%,.1),hsla(0,0%,100%,.1) 15px,transparent 0, transparent 30px);} &amp;lt;body&amp;gt; &amp;lt;div class=&quot;bg type1&quot;&amp;gt;background: linear-gradient(#fb3 20%, #58a 80%);&amp;lt;br&amp;gt; 整个背景上下各有20%的纯色, 中间是过渡颜色 background: linear-gradient(#fb3 50%, #58a 50%);上下两部分都是纯色 添加 background-size:100% 30px; 宽100%, 高30px, 默认 repeat 斜向条纹修改 linear-gradient 的角度: linear-gradient(45deg, #fb3 50%, #58a 50%)添加重复:background-size:30px; 使用 repeat-linear-gradient:background: repeating-linear-gradient(45deg, #fb3, #58a 30px) &lt; div class=”bg type6”&gt;关于颜色设定, 如果我们希望条纹使用相近的颜色, 可以使用如下方法: background: #58a; background-image: repeating-linear-gradient(30deg, hsla(0,0%,100%,.1),hsla(0,0%,100%,.1) 15px,transparent 0, transparent 30px); 其原理是指定背景中最深的颜色, 其他颜色用透明度调整 &lt; div&gt;","link":"/2016/06/14/css-e6-b7-bb-e5-8a-a0-e6-9d-a1-e7-ba-b9-e8-83-8c-e6-99-af/"},{"title":"CSS Progress Bar","text":".wrapper{ position:relative; overflow:visible; width:500px; margin:0 auto;}.bar{ border:1px solid maroon; margin:40px 30px; padding: 8px 0; height:55px; background: maroon; background: -webkit-linear-gradient(left, maroon 50%, #fff 50%); background-size:200% 100%; background-position: 100% 0%; -webkit-animation: AnimationName 10s ease infinite;}@keyframes AnimationName{ 100%{ background-position:0% 0%; }}.text{ font-size:22px; margin:15px 0; text-align:center; text-transform:uppercase; text-weight:bold; background: -webkit-linear-gradient(left, #fff 50%, maroon 50%); background-size:200% 100%; background-position: 100% 0%; -webkit-background-clip:text; -webkit-text-fill-color: transparent; animation: AnimationName 10s ease infinite;} Loading Bar .bar{ border:1px solid maroon; margin:40px 30px; padding: 8px 0; height:55px; background: maroon; background: -webkit-linear-gradient(left, maroon 50%, #fff 50%); background-size:200% 100%; background-position: 100% 0%; -webkit-animation: AnimationName 10s ease infinite; } @keyframes AnimationName{ 100%{ background-position:0% 0%; }} .text{ font-size:22px; margin:15px 0; text-align:center; text-transform:uppercase; text-weight:bold; background: -webkit-linear-gradient(left, #fff 50%, maroon 50%); background-size:200% 100%; background-position: 100% 0%; -webkit-background-clip:text; -webkit-text-fill-color: transparent; animation: AnimationName 10s ease infinite; }","link":"/2016/06/16/css-progress-bar/"},{"title":"CSS3: Border-Image","text":"基本语法border-image: none|&amp;lt;image&amp;gt;[&amp;lt;slice&amp;gt;|&amp;lt;width&amp;gt;|&amp;lt;repeat&amp;gt;] border-image-source: url(&quot;…&quot;); border-image-slice:[&amp;lt;number&amp;gt;|&amp;lt;percentage] * 用于分解引入的图片, px 是默认单位, 如果用 number 则一定不能加上 px percentage 是相对于引入的 image 而言的, 例如 image 的大小为300 x 240, 若设定 slice: 25%, 30%, 15%, 20%, 等于截取了图片外侧的60px, 90px, 36px, 60px 的部分作为边框 实际上 CSS3 将该图片划分成9个部分, 再根据 width 和 repeat 进行处理后拼接成边框 四个角不会受到 repeat 的影响而产生变形, 四个边会受到 repeat 的影响而变形. border-image-width: [&amp;lt;length&amp;gt;|&amp;lt;percentage&amp;gt;|&amp;lt;number&amp;gt;|auto] * border-image-width 就是 border-width, 用于设置边框宽度 如果 slice 截取的宽度正好等于 width, 那么不会发生变形 border-image-repeat: [stretch|repeat|round] * 指定四条边的排列方式 最多接受两个参数, 第一个水平方向, 第二个垂直方向 round -&gt; 平铺 round 会压缩或伸展 sliced-block, 保证平铺过程中其完整性 repeat -&gt; 重复 repeat 不会改变 sliced-block 的完整性, 从中间开始向两边排列 stretch 拉伸","link":"/2016/06/23/css3-border-image/"},{"title":"CSS3 中的 Pointer-Events 属性","text":"功能: 阻止用户的点击产生任何效果 阻止默认鼠标指针样式的显示(比如放在&amp;lt;a&amp;gt;上不会变成pointer) 阻止 CSS 里的hover 和active状态的监听* 阻止触发 JS 事件(同上)","link":"/2016/06/15/css3-e4-b8-ad-e7-9a-84-pointer-events-e5-b1-9e-e6-80-a7/"},{"title":"CSS3 Transitions Basics","text":"Benefits of CSS 3 CSS3 Transitions are natively handled by the browser, which means they are always faster than a comparable JS animation. JS animation is more difficult. Bezier Timing FunctionsCSS3 has a transition-timing-function property which accepts keywords like ease, ease-in, and linear. However we can define our own timing function using a cubic-bezier value. It sounds and looks complicated but can be explained with some simple diagrams. linear curse ease-in-out curseit starts slowly, about 12% of the animation is completed in the first 25% of time;it ends slowly, about 12 % of the animation is completed in the last 25% of time What’s a Bezier Curve Since the animation line starts at (0, 0) and ends at (1, 1), we just need to define the points P0 and P1 in the cubic bezier value, e.g. cubic-bezier(p0x, p0y, p1x, p1y); transition-timing-function: cubic-bezier(0.25, 0.25, 0.75, 0.75) //linear transition-timing-function: cubic-bezier(0.42,0,0.58,1) //ease-in-out `&lt;/pre&gt; &lt;pre&gt;`transition-timing-function: cubic-bezier(0.5, -0.5, 0.5, 1.5) // invalid, points cannot locate outsite (0,1) Let the Tools do the Workcubic-bezier.com Ceaser Transition Property BasicsWhich CSS Properties can be animated? width padding color top border-radius transform all you can set one or more to property transition-property","link":"/2016/06/15/css3-transitions-basics/"},{"title":"CSS3: Filter","text":"英语原文: MDN:filter 总结Filter 属性用于实现”模糊”, “锐化”, “颜色替换”等图像渲染效果. Filter 通常用于调整图像, 背景, 边框的呈现. 语法filter: url(&quot;filter.svg#filter-id&quot;); filter:blur(5px); filter:brightness(.4); filter:contrast(200%); filter:drop-shadow(16px 16px 20px blue); filter:grayscale(50%); filter:hue-rotate(90deg); filter:invert(75%); filter:opacity(25%); filter:saturate(30%); filter:sepia(60%); /*Apply multiple filters*/ filter: contrast(75%) brightness(3%); /*Global Values*/ filter: inherit; filter:initial; filter:unset; `&lt;/pre&gt; ### 设置一种函数 &lt;pre&gt;`filter: &amp;lt;filter-function&amp;gt; [&amp;lt;filter-function&amp;gt;]* | none `&lt;/pre&gt; ### 给 SVG 元素 &lt;filter&gt; 引用滤镜 &lt;pre&gt;`filter: url(svg-url#element-id) `&lt;/pre&gt; ### 实例 &lt;pre&gt;`.mydiv{filter:grayscale(50%)} /*gray all images by 50% and blur by 10px*/ img{ filter: grayscale(.5) blur(10px); } `&lt;/pre&gt; #### 通过 url 函数引入一个 SVG 资源 &lt;pre&gt;`.target{filter:url(#c1):} .mydiv{filter:url(commonfilters.xml#large-blur)} `&lt;/pre&gt; ### 函数 参数可以传入百分数或小数, 34%和.34效果相同 &lt;pre&gt;`url(): 接受一个 XML 文件, 该文件设置一个 SVG 滤镜, 并通过锚点确定一个具体的滤镜元素 filter: url(resource.svg#c1) `&lt;/pre&gt; &lt;pre&gt;`blur(): 接收 radius 值为图像设置高斯模糊, radius 为标准差(px), 默认为0, 不接收百分比 `&lt;/pre&gt; &lt;pre&gt;`brightness(): 给图片应用一种线性惩罚, 使其看起来更亮或更暗, 0%对应全黑, 100%对应原图, 超过100%更亮, 默认为1; `&lt;/pre&gt; &lt;pre&gt;`contrast(): 调整图像对比度, 0对应全黑, 1对应原图, 大于1则应用更低的对比度 `&lt;/pre&gt; &lt;pre&gt;`drop-shadow(): 给图像设置一个阴影效果, 阴影是合成在图像下方的, 可以设置模糊度, 可以用特定颜色画出遮罩图的偏移版本. 函数能接受&amp;lt;shadow&amp;gt;(在 CSS3 背景中定义)类型的值, 除了 inset 关键字不可使用, 与 box-shadow 属性很相似. 不过通过滤镜, 一些浏览器会提供硬件加速 参数如下: &amp;lt;offset-x&amp;gt;和&amp;lt;offset-y&amp;gt; (不可省略) &amp;lt;blur-radius&amp;gt;(可选) &amp;lt;spread-radius&amp;gt;(可选) &amp;lt;color&amp;gt;(可选) `&lt;/pre&gt; &lt;pre&gt;`grayscale(): 将图像转为灰度图像, 1对应完全灰度图像, 0对应原图 `&lt;/pre&gt; &lt;pre&gt;`hue-rotate(): 给图像应用色相旋转, &quot;angle&quot; 设定图像会被调整的色环角度, 默认为0, 对应无变化. `&lt;/pre&gt; &lt;pre&gt;`invert(): 翻转输入图像, 即反相, 1对应完全反相, 0对应原图 `&lt;/pre&gt; &lt;pre&gt;`opacity(): 转换图像的透明程度, 0对应完全透明, 1对应原图 和 CSS3 的 opacity 功能相似, 但是一些浏览器会提供硬件加速 `&lt;/pre&gt; &lt;pre&gt;`saturate(): 修改图像饱和度, 0对应完全不饱和, 1对应原图 `&lt;/pre&gt; &lt;pre&gt;`sepia(): 将图像转为深褐色, 1对应完全深褐色, 0对应原图 复合函数 filter: contrast(175%) brightness(3%);","link":"/2016/06/23/css3-filter/"},{"title":"Css Shorthand Collection","text":"12345678910body { background: url(...) /* image */ top center / 200px 200px /* position / size */ no-repeat /* repeat */ fixed /* attachment */ padding-box /* origin */ content-box /* clip */ red; /* color */}","link":"/2017/05/19/css-shorthand-collection/"},{"title":"d3.range","text":"1d3.range([start, ]stop[, step]) Returns an array containing an arithmetic progression, similar to the Python built-in range. This method is often used to iterate over a sequence of uniformly-spaced numeric values, such as the indexes of an array or the ticks of a linear scale. If step is ommitted, it defaults to 1. If start ommitted, it defaults to 0. The stop value is exclusive; it is not included in the result. The arguments are not required to be integers; however, the results are more predicable if they are. 12d3.range(0, 1, 1/49) // BAD, and returns 50 elementsd3.range(49).map(d =&gt; (d/49)) // GOOD, and returns 49 elements","link":"/2017/07/12/d3-range/"},{"title":"D3-Scale","text":"","link":"/2017/07/13/d3-scale/"},{"title":"Debounce 函数","text":"function debounce (fn, delay) { var timer = null return function () { var context = this, args = arguments clearTimeout(timer) timer = setTimeout(function () { fn.apply(context, args) }, delay) } } `&lt;/pre&gt; Example: &lt;pre&gt;`Elm.addEventListener(&apos;click&apos;, debounce(function(event){ ... }, 250)) 可以看出, 传入 debounce 的所有函数共享计时器 timer, 因此如果在 delay 时间内再次调用 debounce(fn), 即上一次 fn 为执行而新的 fn 传入时, 上一次的 fn 的 timer 会清空, 对新传入的 fn 进行计时 其结果即是, 在 delay 时限内复数次调用 debounce 会刷新计时器","link":"/2017/02/22/debounce-e5-87-bd-e6-95-b0/"},{"title":"D3-Shape","text":"d3.shapeVisualization typically consist of discrete graphical marks, such as Symbols, arcs, lines and areas. While the ractangles of a bar chart may be easy enough to generate directly using SVG or Canvas, other shapes are complex, such as roudned annular sectors and centripetal Catmull-Rom splines. This module provides a variety of shape generators for your convenience. As with other aspects of D3, these shapes are driven by data: each shape generator exposes accessors that control how the input data are mapped to a visual representation. You might define a line generator for a time series by scaling field of your data to fit the chart. 123const lineGen = d3.line() .x(d =&gt; (d.date)) .y(d =&gt; (d.value)) This line generator can then be used to compute the d attribute of an SVG path element: 1path.datum(data).attr('d', lineGen) Or you can use it to render to a Canvas 2D context: 1lineGen.context(context)(data) Installing12&lt;script src=\"https://d3js.org/d3-path.v1.min.js\"&gt;&lt;/script&gt;&lt;script src=\"https://d3js.org/d3-shape.v1.min.js\"&gt;&lt;/script&gt; or 1yarn add d3-shape Arcs The arc genrateor produces a circular or annular sector, as in a pie or donut chart. If the difference between the start and end angles(the regular span) is greater than 2 Math.PI, the arc generator will produce a complete circle or annulus. If it is less than 2 Math.PI, arcs may have rounded corners and angular padding. Arcs are always centered at , use a transform to move the arc to a different position. 12345678910111213141516const arc = d3.arc() // construct a new arc genrator with default settings.arc({ innerRadius: 0, outerRadius: 100, startAngle: 0, endAngle: Math.PI / 2,})// orconst arc = d3.arc() .innerRadius(0) .outerRadius(100) .startAngle(0) .endAngle(Math.PI/2)arc() arc.centroid(arguments) computes the midpoint of the center line of the arc that would be generated by the given arguments. The arguments are arbitrary. They are simple propagated to the arc generator’s accessor functions along with the this object. To be consistent with the generated arc, the accessors must be deterministirc, i.e., return the same value given the same arguments. The midpoint is defined as (startAngle + endAngle) / 2 and (innerRadius + outerRadius) / 2 arc.cornerRadius([radius]) sets the corner radius to the specified function or number and returns the arc generator. arc.padAngle([angle]) sets the pad angle to the specifid function or number and returns this arc generator. The pad angle is converted to a fixed linear distances seperateing adajacent arcs, defined as padRadius * padAngle. arc.context([context]) sets the context and returns this arc generator. If context is not specified, returns the current context, which defaults to null. If the context is not null, then the generated arc is rendered to this context as a sequence of path method calls. Otherwise, a path data string representing the generated arc is returned. PiesThis pie generator does not produce a shape directly, but instead computes the necessary angles to represent a tabular dataset as a pie or donut chart. These angles can be passed to an arc generator. d3.pie() constructs a new pie generator with the default settings. pie(data[, arguments]) generates a pie for the given array of data, returning an array of objects representing each datum’s arc angle. Any additional arguments are arbitrary. They are simply propagated to the pie generator’s accessor functions along with the this object. The length of the returned array is the same as data and each element i in the returned array corresponds to the element i in the input data. Each object in the returned array has the following properties: data: the input datum; the corresponding element in the input data array. value: the numeric value of the arc index: the zero-based sorted index of arc startAgnle: the start angle of the arc endAngle: the end angle of the arc padAngle: the pad angle of the arc 12345678910111213var data = [1, 1, 2, 3, 5, 8, 13, 21];var arcs = d3.pie()(data);// to[ {\"data\": 1, \"value\": 1, \"index\": 6, \"startAngle\": 6.050474740247008, \"endAngle\": 6.166830023713296, \"padAngle\": 0}, {\"data\": 1, \"value\": 1, \"index\": 7, \"startAngle\": 6.166830023713296, \"endAngle\": 6.283185307179584, \"padAngle\": 0}, {\"data\": 2, \"value\": 2, \"index\": 5, \"startAngle\": 5.817764173314431, \"endAngle\": 6.050474740247008, \"padAngle\": 0}, {\"data\": 3, \"value\": 3, \"index\": 4, \"startAngle\": 5.468698322915565, \"endAngle\": 5.817764173314431, \"padAngle\": 0}, {\"data\": 5, \"value\": 5, \"index\": 3, \"startAngle\": 4.886921905584122, \"endAngle\": 5.468698322915565, \"padAngle\": 0}, {\"data\": 8, \"value\": 8, \"index\": 2, \"startAngle\": 3.956079637853813, \"endAngle\": 4.886921905584122, \"padAngle\": 0}, {\"data\": 13, \"value\": 13, \"index\": 1, \"startAngle\": 2.443460952792061, \"endAngle\": 3.956079637853813, \"padAngle\": 0}, {\"data\": 21, \"value\": 21, \"index\": 0, \"startAngle\": 0.000000000000000, \"endAngle\": 2.443460952792061, \"padAngle\": 0}] The first pair of parens, pie() constructs a default pie generator, the second pie()(data) invokes this generator on the dataset, returning an array of objects. Note that the returned array is in the same order as the data. LinesThe line generator produces a spline or polyline, as in a line chart. Lines also appear in many other visualization types, such as the links in hierarchical edge bundling. d3.line() constructs a new line generator with default settings. line(data) generates a line for the given array of data. Depending on this line generator’s assciated curve, the given input data may need to be sorted by x-value before being passed to the line generator. If the line generator has a context, then the line is rendered to this context as a sequence of path method calls and this function returns void. line.x(fn) specifies the x accessor. line.y(fn) specifies the y accessor. line.defined([defined]) sets the defined accessor. line.curve([curve]) sets the curve factory and returns this line genrator. If curve is not specified, returns the current curve factory, which defaults to curveLinear. d3.lineRadial() constructs a new radial line generator with the default settings. A radial line generator is equivalent to the standard cartesian line generator, except the x and y accessor are replaced with angle and readius accessors. Radial lines are always positioned relative to , use a transform to change the origin. AreasThe area generator produces an area, as in an area chart. An area is defined by two bounding lines, either splines or polilines. Typically two lines share the same x-value, differing only in y-value; most commonly, y0 is defined as a constant representing zero. The first line (the top line) is defined by x1 and y1 and is rendered first; the second line (the base line) is defined by x0 and y0 and is rendered second, with the points in reverse order. d3.area() constructs a new area generator with the default settings. area.data() generats area for the given array of data. Depending on this area generator’s associated curve. area.x([x]) sets x0 to x and x1 to null. area.x0() sets the x0 accessor. area.defined() d3.areaRadial() CurvesCurves are typically not constructed or used directly, insread being passed to line.curve and arec.curve. For example: 1234var line = d3.line() .x(function(d) { return x(d.date) }) .y(function(d) { return y(d.value) }) .curve(d3.curveCatmullRom.alpha(0.5)) d3.curveBasis(context) d3.curveBasisClosed(context) d3.curveBasisOpen(context) d3.curveBundle(context) d3.curveCardinal(context) d3.curveCardinalClosed(context) d3.curveLinear(context) d3.curveStep(context) d3.curveStepAfter(context) d3.curveStepBefore(context) LinksThe link shape generates a smooth cubic Bezier curve from a source point to a target point. The tangents of the curve at the start and end are either vertical, horizontal, or radial. d3.linkVertical(), returns a new link generator with vertical tangents. 123var link = d3.linkVertical() .x(function(d){ return d.x }) .y(function(d){ return d.y }) d3.linkHorizontal(), returns a new link generator with horizontal tangents. 123var link = d3.linkHorizontal() .x(function(d) { return d.y }) .y(function(d) { return d.x }) StacksSome shape types can be stakced, placing one shape adjacent to another. Stacked charts can show overall value and per-category value simultaneously. d3.stack(), constructs a new stack generator with the default settings. stack(data[, arguments]), generates a stack for the given array of data, returning an array of representing each series. Any additional arguments are arbitrary, they are simply propagated to accessors along with this object. The series are determined by the keys accessor; each series i in the returned array corresponds to the i th key. Each series is an array o points, where each point j corresponds to the j th element in the input data. 12345678910111213141516171819202122var data = [ {month: new Date(2015, 0, 1), apples: 3840, bananas: 1920, cherries: 960, dates: 400}, {month: new Date(2015, 1, 1), apples: 1600, bananas: 1440, cherries: 960, dates: 400}, {month: new Date(2015, 2, 1), apples: 640, bananas: 960, cherries: 640, dates: 400}, {month: new Date(2015, 3, 1), apples: 320, bananas: 480, cherries: 640, dates: 400}];// To produce a stack of this datavar stack = d3.stack() .keys([ 'apples', 'bananas', 'cherries', 'dates' ]) .order(d3.stackOrderNone) .offset(d3.stackOffsetNone)// returned[ [[ 0, 3840], [ 0, 1600], [ 0, 640], [ 0, 320]], // apples [[3840, 5760], [1600, 3040], [ 640, 1600], [ 320, 800]], // bananas [[5760, 6720], [3040, 4000], [1600, 2240], [ 800, 1440]], // cherries [[6720, 7120], [4000, 4400], [2240, 2640], [1440, 1840]], // dates] stack.keys([keys]), sets the keys accessor to the specified function or array and returns this stack generator. stack.order([order]), sets the order accessor to the specified functino or array and returns this stack generator. If order is not specified, returns the current order accessor, which default to stackOrderNone, this uses the order given by the key accessor. d3.stackOrderAscending(series) d3.stackOrderDescending(series) d3.stackOrderInsideOut(series) d3.stackOrderNone(series) d3.stackOrderReverse(series) stack.offset([offest]), sets the offset accessor to the specified function or array, and returns this stack generator. If no offset is specified, returns the current offset accessor, which default to stackOffsetNone, this uses a zero baseline. d3.stackOffsetDiverging(series, order) d3.stackOffsetExpand(series, order) d3.stackOffsetNone(series, order)","link":"/2017/07/12/d3-shape/"},{"title":"Display:table-Cell","text":"display:table-cell 属性简述display:table-cell 属性让标签元素鞥一表格单元格的形式呈现, 类似于 td 标签.table-cell与float, position:absolute 不兼容.table-cell元素可以设置 width, height, padding, 但是不能设置 margin, 和 td 标签一致. display:table-cell 与大小不固定元素的垂直居中display:table-cell 与两栏自适应布局display:table-cell 等高布局table 表格中的单元格最大的特点之一就是同一行列表元素都是登高的, 所以等高布局可以借助 table-cell 实现.匿名表格元素创建规则:CSS2中创建表格元素, 其依赖元素(比如 tr 之于 td, table 之于 tr) 会被模拟出来, 从而使得表格模型能够正常工作. 所有的表格元素都会自动在自身周围生成需要的匿名 table 对象, 使其符合 table/inline-table, table-row, table-cell 的三层嵌套关系.要实现等高布局, 所有的 table-cell 元素一定要留一个用来包裹的标签, CSS 代码如下:```.list_row{display:table-row}.list_cell{display:table-cell;width:30%,padding:1.6%; background-color:#F5F5F5;}.list_center{background-color:#F0F3F9;}//用于和旁边的 cell 区分","link":"/2016/07/20/displaytable-cell/"},{"title":"Distinction Between 'Nth-Child' and 'Nth-of-Type'","text":"In HTML &amp;lt;p&amp;gt;0&amp;lt;/p&amp;gt; &amp;lt;div&amp;gt;1&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;2&amp;lt;/div&amp;gt; &amp;lt;p&amp;gt;3&amp;lt;/p&amp;gt; &amp;lt;div&amp;gt;4&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;5&amp;lt;/div&amp;gt; &amp;lt;div&amp;gt;6&amp;lt;/div&amp;gt; The Selector div:nth-child(3) will choose the 3rd element from all elements in the level where div is, then check if the 3rd element is a ‘div’. In this case, the 3rd element is a ‘div’, so it works(&amp;lt;div&amp;gt;2&amp;lt;/div&amp;gt;), but Selector div:nth-child(4) will select the 4st element which is ‘p’ (&amp;lt;p&amp;gt;3&amp;lt;/p&amp;gt;), it’s not a ‘div’, so it doesn’t work. However, the Selector div:nth-of-type(3) will choose the 3rd ‘div’ from all ‘div’s in the level where div is, so it choose the &amp;lt;div&amp;gt;4&amp;lt;/div&amp;gt;.","link":"/2016/06/23/distinction-between-nth-child-and-nth-of-type/"},{"title":"Development of Neuron Web Extension","text":"Create Project1create-react-app neuron-web scripts-version=react-scripts-ts Add Manifest123456789101112131415161718192021222324// ./public/manifest.json{ &quot;short_name&quot;: &quot;NeuronWeb&quot;, &quot;name&quot;: &quot;Neuron Web&quot;, &quot;start_url&quot;: &quot;./index.html&quot;, &quot;display&quot;: &quot;standalone&quot;, &quot;theme_color&quot;: &quot;#000&quot;, &quot;background_color&quot;: &quot;#fff&quot;, &quot;browser_action&quot;: { &quot;default_popup&quot;: &quot;./index.html&quot;, &quot;default_title&quot;: &quot;NervosWeb&quot; }, &quot;manifest_version&quot;: 2, &quot;version&quot;: &quot;1.0&quot;, &quot;permissions&quot;: [ &quot;tabs&quot;, &quot;activeTab&quot;, &quot;clipboardWrite&quot;, &quot;http://**/*&quot;, &quot;https://**/*&quot; ], &quot;content_security_policy&quot;: &quot;script-src &apos;self&apos; &apos;unsafe-eval&apos;; object-src &apos;self&apos;&quot;} Add Style Dependencies1&lt;link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Roboto:300,400,500\"&gt; 1yarn add @mateiral-ui/{core,icons}","link":"/2018/08/27/development-of-neuron-web-extension/"},{"title":"Detail of Node Cluster","text":"ClusterA single instance of Node.js runs in a single tread. To take advantage of multi-core systems the user will sometimes want to launch a cluster of Node.js processes to handle the load. The cluster module allows you to easily create child processes that all share server port. 1234567891011121314151617181920212223242526const cluster = require('cluster')const http = require('http')const numCPUs = require('os').cpus().lengthif (cluster.isMaster) { console.log(`Master ${process.pid} is running`) // Fork workers for (let i = 0; i &lt; numCPUs; i++) { cluster.fork() } cluster.on('exit', (worker, code, signal) =&gt; { console.log(`worker ${worker.process.pid} died`) })} else { // Workers can share any TCP connection // In this case it is an HTTP Server http.createServer((req, res) =&gt; { res.writeHead(200) res.end('hello world\\n') }).listen(8000) console.log(`Worker ${process.pid} started`)} Running Node.js will now share port 8000 between the workers. How it worksThe workder processes are spawned using the child_process.fort() method, so that they can communicate with the parent via IPC and pass server handles back and forth. The cluster module supports two methods of distributing incoming connections. The first one (and the default one on all platform except Windows), is the round-robin approch, where the master process listens on a port, accepts new connections and distributes them across the workers in a round-robin fashion, with some built-in smarts to avoid overloading a worker process. The second approach is where the master process creates the listen socket and sends it to interested workers. The workers then accept incoming connection directly. The second approach should, in theory, give the best performance. In practice however, distribution tends to be very unbalanced due to operating system scheduler vagaries. Loads have been observed where over 70% of all connections ended up in just two process, out of a total of eight. Because server.listen() hands off most of the worker to the master process, there are three case where the behavior between a normal Node.js process and a cluster worker differs: server.listen({fd: 7}) Because the message is passed to the master, file descriptor 7 in the parent will be listened on, and the handle passed to the worker, rather than listening to the worker’s idea of what the number 7 file descriptor reference. (the fd will be used up sooner) server.listen(handle) Listening on handles explicitly wil cause the worker to use the supplied handle, rather than talk to the master process. If the worker already has the handle, then it’s presumed that you know what you are doing. server.listen(0) Normally, this will cause servers to listen on a random port. However, in a cluster, each worker will receive the same ‘random’ port each time they do listen(0). In essence, the port is random the first time, but predicatable thereafter. If you want to listen on a unique port, generate a port number based on the cluster worker ID. There is no routing logic in Node.js, or in your program, and no shared state between the workers. Therefore, it is important to design your program such that it does not rely on heavily on in-memory data object for things like sessions and login. Because workers are all separate processes, they can be killed or re-spawned depending on your program’s needs, without affecting other workers. As long as there are some workers still alive, the server will continue to accept connections. If no workers are alive, existing connections will be dropped and new connections will be refused. Node.js does not automatically manage the number of worker for you, however. It is yoru responsibility to manage the worker pool for your application’s needs. Class: workerA Worder Object contains all public information and method about a worker. In the master it can be obtained using cluster.workers. In a worker it can be obtained using cluster.worker Event: ‘disconnect’Similar to the cluster.on('disconnect') event, but specific to this worker. 123cluster.fork().on('disconnect', () =&gt; { // Worker has disconnected}) Event: ‘error’This event is the same as the one provided by child_process.fork() In a worker you can alse use process.on('error') Event: ‘exit’ code the exit code, if it exited Normally signal the name of the signal(e.g. SIGHUP) that caused the process to be killed. Similar to the cluster.on('exit') event, but specific to this worker 12345678910const worker = cluster.fork()worker.on('exit', (code, signal) =&gt; { if (signal) { console.log(`worker was killed by signal: ${signal}`) } else if (code !== 0) { console.log(`worker exited with error code: ${code}`) } else { console.log('worker success') }}) Event: ‘listening’ address Similar to the cluster.on(‘listening’) event, but specific to this worker. cluster.fork().on(‘listening’, (address) =&gt; { // Worker is listening}) It is not emitted in the worker Event: ‘message’ message handle | Similar to the cluster.on(‘message’) event, but specific to this worker. In a worker you can also use process.on(‘message’) As an example, here is a cluster that keeps count of the number of requests in the master process using the message system: const cluster = require(‘cluster’)const http = require(‘http’)if (cluster.isMaster) { let numReqs = 0 setInterval(() =&gt; { console.log(numReqs = ${numReqs}) }, 1000) // Count requests function messageHandler(msg) { if (msg.cmd &amp;&amp; msg.cmd === ‘notifyRequest’) { numReqs++ } } // Start workers and listen for messages containing notifyRequest const numCPUs = require(‘os’).cpus().length for (let i = 0; i &lt; numCPUs; i++) { cluster.fork() } for (const id in cluster.workers) { cluster.workers[id].on(‘message’, messageHandler) }} else { // Worker processes have a http server http.Server((req, res) =&gt; { res.writeHead(200) res.end(‘hello world’) process.send({ cmd: ‘notifyRequest’ }) }).listen(8000)} Event: ‘online’ Similar to the cluster.on(‘online’) event, but specific to this worker cluster.fork().on(‘online’, () =&gt; { // Worker is online}) It is not emitted in the worker worker.disconnect() Return: A reference to worker In a worker, this function will close all server, wait for the close event on those servers, and disconnect the IPC channel. In the master, an internal message is sent to the worker causing it to call .disconnect() on itself Cause .exitedAfterDisconnect to be set. Note that after a server is closed, it will no longer accept new connections, but connections may be accepted by any other listening worker. Existing connections will be allowed to close as usual. When no more connections exist, see server.close(), the IPC channel to the worker will close allowing it to die gracefully. Note that in a worker, process.disconnect exists, but it is not this function. Because long living server connections may block workers from disconnecting, it may be useful to send a message, so application specific actions may be taken to close them. It also may be useful to implement a timeout, killing a worker if the disconnect event has not been emiited after some time. if (cluster.isMaster) { const worker = cluster.fork() let timeout worker.on(‘listening’, (address) =&gt; { worker.send(‘shutdown’) worker.disconnect() timeout = setTimeout(() =&gt; { worker.kill() }, 2000); }) worker.on(‘disconnect’, () =&gt; { clearTimeout(timeout) })} else if (cluster.isWorker){ const net = require(‘net’) const server = net.createServer((socket) =&gt; { // connections never end }) server.listen(8000) process.on(‘messaage’, (msg) =&gt; { if (msg === ‘shutdown’) { // initiate graceful close of any connections to server } })} worker.exitedAfterDisconnect Set by calling .kill() or .disconnect(). Until then, it is undefined The boolean worker.exitedAfterDisconnect lets you distinguish between voluntary and accidental exit, the master may choose not to respawn a worker based on this value. cluster.on(‘exit’, (worker, code, signal) =&gt; { if (worker.exitedAfterDisconnect === true) { console.log(‘Oh, it was just voluntary - no need to worry’) }})// kill workerworker.kill() worker.id Each new worker is given its own unique id, this id is stored in the id While a worker is alive, this is the key that indixes it in cluster.workers. worker.isConnected() This function returns true if the worker is connected to its master via its IPC channel. false otherwise. A worker is connected to its master after it’s been created. It is disconnected after the disconnect event is emitted. worker.isDead() This function returns true if the worker’s process has terminated (either because of exiting or being signaled). Otherwise, it returns false worker.kill([signal=’SIGTERM’]) signal Name of the kill signal to send to the worker process. This function will kill the worker. In the master it does this by disconnecting the worker.process and once disconnected, killing with signal. In the worker, it does it by disconnecting the channel and exiting with code 0 Causes .exitedAfterDisconnect ot be set This method is aliased as worker.destroy() for backwords compatibility. Note that ina worker, process.kill() exists, but it is not the function. worker.process All Workers are created using child_process.fork(), the returned object from this function is stored as .process. In a worker, the global process is stored Note that the workers will call process.exit(0) if the disconnect event occurs on process and .exitedAfterDisconnect is not true. This protects against accidental disconnection. worker.send(message[, sendHandle, [callback]]) message sendHandle callback Send a message to a worker or master, optinally with a handle. In the master this sends a message to a specific worker. It is identical to ChildProcess.send() In a worker this sends a message to the master. It is identical to process.send() This example will echo back all messages from the master if (cluster.isMaster) { const worker = cluster.fork() worker.send(‘hi there’)} else if (cluster.isWorker) { process.on(‘message’, (msg) =&gt; { process.send(msg) })} Event: ‘disconnect’ worker Emitted after the worker IPC channel has disconnected. This can occur when a worker exits gracefully, is killed, or is disconnected manually(such as with worker.disconnected()) There may be a delay between the disconnect and exit events. These events can be used to detect if the process is stuck in a cleanup or if there are long-living connections. cluster.on(‘disconnect’, (worker) =&gt; { console.log(The worker #${worker.id} has disconnected)}) Event: ‘exit’ worker code the exit code, if it exited normally signal the name of the signal (e.g. ‘SIGHUP’) that caused the process to be killed. When any of the workers die the cluster module will emit the ‘exit’ events This can be used to restart the worker by calling .fork() again. cluster.on(‘exit’, (worker, code, signal) =&gt; { console.log(‘worker %d died (%s), restarting…’, worker.process.pid, signal || code) cluster.fork()}) Event: ‘fork’ worker When a new worker is forked the cluster module will emit a fork event. This can be used to log worker activity, and create your own timeout. const timeouts = []function errorMsg () { console.error(‘Something must be wrong with the connection…’)}cluster.on(‘fork’, (worker) =&gt; { timeouts[worker.id] = setTimeout(errorMsg, 2000)})cluster.on(‘listening’, (worker, address) =&gt; { clearTimeout(timeouts[worker.id])})cluster.on(‘exit’, (worker, code, signal) =&gt; { clearTimeout(timeouts[worker.id])}) Event: ‘listening’ worker address After calling listen() from a worker. when the listening event it emitted on the server, a listening event will also be emitted on cluster in the master The event handler is executed with two arguments, the worker contains the worker object and the address object contains the following connection properties: address, port and addressType. This is very useful if the worker is listening on more than one address. cluster.on(‘listening’, (worker, address) =&gt; { console.log(A worker is now connected to ${address.address}: ${address.port})}) The addressType is one of: 4: (TCPv4) 6: (TCPv6) -1: (unix domain socket) “udp4” or “udp6” (UDP v4 or v6) Event: ‘message’ worker \u0006message handle | Emitted when the cluster master receives a message from any worker. Event: ‘online’ worker After forking a new worker, the worker should respond with an online message. When the master receives an online message it will emit this event. The difference between fork and online is that fork is emitted when the master forks a worker and online is emitted when the worker is running. Event: ‘setup’ settings Emitted every time .setupMaster() is called. The settings object is the cluster.settings object at the time .setupMaster() was called and is advisory only. since multiple calls to .setupMaster() can be made in a single tick. If accuracy is important, use cluster.settings cluster.disconnect([callback]) callback called when all workers are disconnected and handles are closed Calls .disconnect() on each worker in cluster.workers When they are disconnected all internal handles will be closed, allowing the master process to die gracefully if no other event is waiting. The method takes an optional callback argument which will be called when finished. This can only be called from the master process. cluster.fork([env]) env Key/Value pairs to add to worker process environmentreturn Spawn a new worker process.This can only be called from the master process.cluster.isMaster True if the process is a master. This is determined by the process.env.NODE_UNIQUE_ID. If process.env.NODE_UNIQUE_ID is undefined, then .isMaster is truecluster.isWorker True if the process is not a master (it is the negation of cluster.isMaster)cluster.schedulingPolicyThe scheduling policy, either cluster.SCHED_RR for round-robin or cluster.SCHED_NONE to leave it to the operating system. This is a global setting and effectively frozen once you spawn the first worker or call cluster cluster.setupMaster(), whatever comes first.SCHED_RR is the default on all operating systems except Windows. Windows will change to SCHED_RR once libuv is able to effectively distribute IOCP handles without incurring a large performance hit.cluster.schedulingPolicy can also be set through the NODE_CLUSTER_SCHED_POLICY environment variable. Valid values are ‘rr’ and ‘none’cluster.settings execArgv exec args silent stdio uid gid cluster.setupMaster([settings]) settings execargssilentstdio const cluster = require(‘cluster’)cluster.setupMaster({ exec: ‘worker.js’, args: [‘–use’, ‘https’], silent: true,})cluster.fork() // https worker cluster.worker A reference to the current worker object. Not available in the master process. const cluster = require(‘cluster’)if (cluster.isMaster) { console.log(‘I am master’) cluster.fork() cluster.fork()} else if (cluster.isWorker) { console.log(I am worker #${cluster.worker.id})} cluster.workers A hash that stores the active worker objects, keyed by id field. Makes it easy to loop through all the workers. It is only available in the master process. A worker is removed from cluster.workers after the worker has disconnected and exit. The order between two events cannot be determined in advance. However it is guaranteed that the removal from the cluster.workers list happens before last disconnect or exit event is emitted. // Go through all workersfunction eachWorker(callback) { for (const id in cluster.workers) { callback(cluster.worker[id]) }}eachWorker((worker) =&gt; { worker.send(‘big announcement to all workers’)}) Should you wish to reference a worker over a communication channel, using the worker’s unique id is the easiest way to find the worker. socket.on(‘data’, (id) =&gt; { const worker = cluster.workers[id]})","link":"/2017/05/02/detail-of-node-cluster/"},{"title":"DOM Events","text":"DOM(Document Object Model) events allow event-driven programming language like JavaScript, JScript, ECMAScript, VBScript and Java to register various event handler/listener on the element nodes inside a DOM tree, e.g. HTML, XHTML, XUL, and SVG documents. EventsHTML EventsThere is a huge collection of events that can be generated by most element nodes: Mouse events; Keyboard events; HTML frame/object events; HTML form events; User interface events; Mutation events(notification of any changes to the structure of a document); Progress events(used by XMLHttpResponse, File API, …) Mouse:click, dblclick, mousedown, mouseover, mousemove, mouseout, dragstart, drag, dragenter, dragleave, dragover, drop, dragend Click: The sequence of click: mousedown, mouseup, click Mouseover: Fires when the pointing device is moved onto an element Mouseover: Fires when the pointing device is moved while it is over an element Dragstart: Fired on an element when a drag is started Dragend: The source of the drag will receive a dragend event when the drag operation is complete, whether it was sucessful or not, Keyboard:keydown, keypress, keyup HTML frame/object:load, unload, abort, error, resize, scroll Load: Fires when the user agent finishes loading all content within a document, including window, frames, objects, and images. Unlaod: Fires when the user agent removes all content from a window or frame. Abort: Fires when an object/image is stopped from loading before completely loaded. Error: Fires when an object/image/frame/ cannot be loaded properly. Resize: Fires when a document view is resized. Scroll: Fires when an element or document view is scrolled HTML form:select, change, submit, reset, focus, blur Select: Fires when a user selects some text in a text field, including input and textarea. Change: Fires when a control loses the input focus and its value has been modified since gaining focus. Submit: Fires when a form is submitted. Reset: Fires when a form is reset. Focus: Fires when an element receives focus either via the pointing device or by tab navigation. Blur: Fires when an element loses focus. User Interface:focusin, focusout, DOMActivate Mutation:DOMSubtreeModified, DOMNodeInserted, DOMNodeRemoved, DOMNodeRemovedFromDocument, DOMNodeInsertedIntoDocument, DOMAttrModified, DOMCharacterDataModified Progress:loadstart, progress, error, abort, load, loadnd Touch EventsWeb broswer running on touch-enabled devices will generate additional events Touch:touchstart, touchend, touchmove, touchenter, touchleave, touchcancel Touchstart: Fires when a finger is placed on the touch surface/screen. Touchend: Fires when a finger is removed from the touch surface/screen. Touchenter: Fires when a touch point moves onto the interactive area defined by a DOM Element Touchcancel: A user-agent must dispatch this event type to indicate when a TouchPoint has been disrupted in an implementation-specific manner, such as by moving outside the bounds of the UA window. In the W3C draft recommendation, a TouchEvent delivers a TouchList of Touch location, the modifier keys that were active, a TouchList of Touch locations within the targeted DOM element, and a TouchList of Touch lcoations that have changed since the previous TouchEvent. Internet Explorer-specific eventsIn addition to the common/W3C events, two major types of events are added by Internet Explorer. Some of the events have been implemented as de facto standards by other browsers. Clipbord:cut, copy, paste, beforecut, beforecopy, beforepaste Data binding:afterupdate, beforeupdate, cellchange, dataavailable, datasetchagned, datasetcomplete, errorudpate, rowenter, rowexit, rowsdelete, rowinserted Afterupdate: Fires immediately after a databound object has been updated. Beforeupdate: Fires before a data source has changed. Cellchange: Fires when a data source has change. Dataavailable: Fires when new data from a data source become available. Rowenter: Fires whena new row of data from the data source is available. Mouse:contextmenu, selectstart Contentmenu: Fires when the context menu is shown. Selectstart: Fires when the user starts to select text. Keyboard:help Help: Fires when the user initiates help. HTML frame/object:beforeunload, stop Beforeunload: Fires before a document is unloaded. Stop: Fires when the user stop loading the object. (unlike abort, stop event can be attached to document).","link":"/2016/07/18/dom-events/"},{"title":"Drag, Upload and Progress","text":"Dragging and dropping files from your desktop to a browser is one of the ultimate goals for web application integration, which consists of: enable file dragging and dropping onto a web page element analyze dropped files in JavaScript load and parse files on the client asynchronously upload files to the server using XMLHttpRequest2 show a graphical progress bar while the upload occurs use progressive enhancement to ensure your file upload from works in any browser The File API FileList: represents an array of selected files File: represents an individual file FileReader: an interface which allows us to read file data on the client and use it within JavaScript JavaScript EventsDragged Object dragstart drag dragend Target Object dragenter dragover dragleave drop dataTransfer dropEffect: copy | move | link | none effectAllowed: copy | move | link | copyLink | copyMove | linkMove | none | all (default) files types setDragImage(imgElement, x, y): set custom icon along dragging setData(format, data) getData(format) clearData() NoticeBy default, brower will refuse all drag actions(and file will be opened in browser if files from desktop dragged into the browser), so e.preventDefault() should be added in dropover and drop event Dragging Text will automatically set e.dataTransfer.setData('text/plain', node.innerText) Dragging File will add files to e.dataTransfer.files","link":"/2017/05/29/drag-upload-and-progress/"},{"title":"优化 HTML 结构","text":"语义化命名 语义化的 HTML 能够直接表示出某个 Tag 的业务功能; 语义化的 CSS 可以提高样式的抽象程度, 方便复用; 模块化 提高代码复用程度; 使业务逻辑更加清晰; 选择一个好的命名约定遵循单一职责原则SRP 原则即每个模块或者类应当只承担系统中的某一个单一功能, 并且该功能应当完整封装起来. 比如 CSS 组织结构中的 Carousel, NavigationBar 等, 要做成独立的 CSS Component.","link":"/2016/06/22/e4-bc-98-e5-8c-96-html-e7-bb-93-e6-9e-84/"},{"title":"侧边栏固定宽度, 主体自适应宽度的等高布局","text":"两列布局实现方法1, 浮动布局Sidebar 设置为浮动, Content Body 的 margin 设置为 Sidebar 的宽度 HTML&amp;lt;div class=&apos;sidebar&apos;&amp;gt; Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. &amp;lt;/div&amp;gt; &amp;lt;div class=&apos;contentBody&apos;&amp;gt; Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### CSS &lt;pre&gt;`*{ margin:0; padding:0 } .sidebar{ float:left; width: 220px; background-color: #ccc; } .contentBody{ margin-left: 220px; } `&lt;/pre&gt; ## 方法2, 浮动和负边距 ### HTML &lt;pre&gt;`&amp;lt;div class=&apos;sidebar&apos;&amp;gt; Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. &amp;lt;/div&amp;gt; &amp;lt;div class=&apos;contentBody&apos;&amp;gt; &amp;lt;div class=&apos;contentInner&apos;&amp;gt; Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### CSS &lt;pre&gt;`.sidebar{ float:left; width: 220px; margin-right: -100%; background-color: green; } .contentBody{ float:left; width:100%; } .contentInner{ margin-left: 220px; } `&lt;/pre&gt; # 等高实现 ## Demo1 ### HTML &lt;pre&gt;`&amp;lt;div class=&apos;container&apos;&amp;gt; &amp;lt;div class=&apos;wrapper&apos;&amp;gt; &amp;lt;div class=&apos;sidebar&apos;&amp;gt;SideBar&amp;lt;/div&amp;gt; &amp;lt;div class=&apos;content&apos;&amp;gt;Main Content&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### CSS &lt;pre&gt;`.container{ background-color:#ccc; } .wrapper{ display:inline-block; //保证 wrapper 的最小高度不小于被 float 的 sidebar border-left: 200px solid #333; //等于 sidebar 宽度 vertical-align:bottom } .sidebar{ float:left; width: 200px; margin-left: -200px; //等于 wrapper 的 border-left 宽度 } .sidebar, .content{ min-height: 200px; height: auto !important; height:200px; } `&lt;/pre&gt; ## Demo2 ### HTML &lt;pre&gt;`&amp;lt;div class=&apos;container&apos;&amp;gt; &amp;lt;div class=&apos;sidebar&apos;&amp;gt;SideBar&amp;lt;/div&amp;gt; &amp;lt;div class=&apos;content&apos;&amp;gt;Main Content&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### CSS &lt;pre&gt;`.sidebar{ background-color:#ccc; float:left; width:200px; margin-bottom:-99999px; padding-bottom:99999px; } .content{ background-color: #eee; margin-left:200px; margin-bottom:-99999px; padding-bottom:99999px; } .sidebar, .content{ min-height: 200px; height:auto!important; height:200px; } `&lt;/pre&gt; ## Demo3 ### HTML &lt;pre&gt;`&amp;lt;div class=&apos;container&apos;&amp;gt; &amp;lt;div class=&apos;wrapper&apos;&amp;gt; &amp;lt;div class=&apos;col1&apos;&amp;gt;Left Col&amp;lt;/div&amp;gt; &amp;lt;div class=&apos;col2&apos;&amp;gt;Right Col&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### CSS &lt;pre&gt;`.container{ float:left; width:100%; background:orange; position:relative; overflow:hidden; } .wrapper{ float:left; width:100%; background:green; position:relative; left:200px; } .col1{ width:200px; float:left; position:relative; margin-left:-200px; } .col2{ position:relative; margin-right:200px; }","link":"/2016/05/22/e4-be-a7-e8-be-b9-e6-a0-8f-e5-9b-ba-e5-ae-9a-e5-ae-bd-e5-ba-a6-e4-b8-bb-e4-bd-93-e8-87-aa-e9-80-82-e5-ba-94-e5-ae-bd-e5-ba-a6-e7-9a-84-e7-ad-89-e9-ab-98-e5-b8-83-e5-b1-80/"},{"title":"图片翻转+文字翻转特效","text":".box{ position:relative; perspective: 1000px; text-align:center;}.box img{ width:200px; height:auto; opacity:1; transform:translateY(0) rotateX(0); transition: all 1s ease-in-out 0s;}.box:hover img{ transform: translateY(-100%) rotateX(90deg); transform-origin: center bottom 0; opacity:0;}.box .over-layer{ position:absolute; top:0; left:0; width:100%; height:100%; transform: translateY(100%) rotateX(-90deg); opacity:0; transform-origin:top center; transition: all 1s ease-in-out;}.box:hover .over-layer{ transform: translateY(0) rotateX(0); opacity:1;} ### Web DesignerDescription /*HTML*/ div.box img[src=&quot;...&quot;] div.over-layer h3 p /*CSS*/ .box{ position:relative; perspective: 1000px; text-align:center; } .box img{ width:200px; height:auto; opacity:1; transform:translateY(0) rotateX(0); transition: all 1s ease-in-out 0s; } .box:hover img{ transform: translateY(-100%) rotateX(90deg); transform-origin: center bottom 0; opacity:0; } .box .over-layer{ position:absolute; top:0; left:0; width:100%; height:100%; transform: translateY(100%) rotateX(-90deg); opacity:0; transform-origin:top center; transition: all 1s ease-in-out; } .box:hover .over-layer{ transform: translateY(0) rotateX(0); opacity:1; }","link":"/2016/06/17/e5-9b-be-e7-89-87-e7-bf-bb-e8-bd-ac-e6-96-87-e5-ad-97-e7-bf-bb-e8-bd-ac-e7-89-b9-e6-95-88/"},{"title":"前端工作流","text":"主要操作包含: CSS 前缀补全, LESS/SASS 编译, CSS 压缩, JS 合并压缩 ,图片压缩, 部署发布 流程分解主要分为 开发过程 和 部署过程 开发过程要求每一次编辑都能在页面上即时相应 部署过程 CSS Autoprefixer Less/Sass =&gt; CSS CSS 压缩合并 CSS Sprite Retina @2x &amp; @3x 自动生成适配 imagemin 图片压缩 JS 合并压缩 项目目录结构project //项目目录|dev //开发目录| |html| |images| |scripts| |slice //合成的雪碧图| |styles|dist //生产目录| |html| |images| |scripts| |sprite //仅从 src 复制| |styles|gulpfile.js|src //源文件目录| |html| |images| |scripts| |slice //雪碧图素材| |____styles","link":"/2016/07/19/e5-89-8d-e7-ab-af-e5-b7-a5-e4-bd-9c-e6-b5-81/"},{"title":"使用 Npm 创建新工程","text":"创建一个工程目录, 并 cd 到目录中, 运行$npm init这个工具将引导你创建一个 package.json 文件, 他只覆盖了大多数一般的项目, 并尽量让默认内容全面.运行npm help json 获取 package.json 中的各个字段的文档及其定义后面可以用npm install &amp;lt;pkg&amp;gt; --save来安装一个包并将其存储为 package.json 文件中的一个依赖模块任何时间按下^C 退出.简单来说:npm init 创建或修改一个项目中的 package.json 文件默认名称(显示在括号中)是当前文件夹的名字, 如果对于提示不输入任何字符并按下 Enter 键, npm 会将默认名称当做项目名称.在完成提示内容后, npm init 将会给你一个即将创建的 package.json 文件的预览, 对于我们来说, 他看起来是这样的 { &quot;name&quot;:&quot;project-name&quot;, &quot;version&quot;:&quot;0.0.0&quot;, &quot;description&quot;:&quot;...&quot;, &quot;main&quot;:&quot;index.js&quot;, &quot;scripts&quot;:{ &quot;test&quot;:&quot;echo \\&quot;Error:no test specified\\&quot; &amp;amp;&amp;amp; exit 1&quot; }, &quot;keywords&quot;:[&quot;npm&quot;,&quot;example&quot;], &quot;author&quot;:&quot;YourName&quot;,&quot;license&quot;:&quot;MIT&quot; } `&lt;/pre&gt; 按下 Enter 进行确认, 你可以在后面随时修改, 通过编辑 package.json 或再次运行 npm init. npm init 永远也不会移除你放在 package.json 中的信息, 仅仅根据需求进行调整. ### package.json 一个项目的 package.json 文件担任下列角色 - 他为 npm 提供一切信息 - 他告诉 Node 怎样处理一个包 - 他为人们查看项目提供一个进入点 ### 创建一个包进入点 现在创建一个非常简单的脚本并将它存为 index.js &lt;pre&gt;`//index.js console.log(&quot;Hello, npm&quot;); `&lt;/pre&gt; 我们可以直接运行脚本 &lt;pre&gt;`$node index.js Hello, npm `&lt;/pre&gt; 我们可以通过使用 require, 在其他的 Node 应用中应用这段脚本. 首先进入 Node REPL, 一个交互的命令行环境: &lt;pre&gt;`$node &amp;gt; require(&apos;./index.js&apos;) Hello, npm {} `&lt;/pre&gt; ({}是 require 的返回值, 在这个例子中, 他是 index.js 的 exports 对象) Node 允许我们省略.js 扩展名, 因此我们可以简写为 require(&apos;,/index&apos;). 如果我们在同一个 REPL 会话中再次运行 require, 我们将得到相同的返回值, 但是不会得到 console.log 输出, 因为 require 不会在同一个脚本中运行两次. ./在./index 中很重要, 因为他告诉 Node 这个路径是当前文件夹的相对路径. 如果我们不显示给出绝对路径或相对路径, 而是直接给 index, Node 会在一系列文件夹中寻找匹配的模块. 回顾一下, 在 package.json 文件夹中, &apos;main&apos;:&apos;index.js&apos; 的作用是什么? 当你 require 一个包含指向 main 脚本(&apos;main&apos;:&apos;index.js&apos;)的 package.json 文件的文件夹时, Node 会认为你是在 require 这个脚本(&apos;index.js&apos;), 所以前面的代码可以简写为 &lt;pre&gt;`require(./) `&lt;/pre&gt; 现在我们可以使用 package.json 来完成上面的工作, 因为我们的脚本命名为 index.js, 他是一个文件夹的默认脚本 ### 第一个依赖模块 使用下面的命令来快速搜索 npm registry `$npm search color` 如果想要获得更多的信息, 可以跳转到 npmjs.org, 在&quot;最多依赖&quot;的列表中可以查看流行的库 安装依赖模块 `$npm install --save colors` 这条指令会在本地文件夹中创建一个名为 node_modules 的文件夹并将 colors 下载到其中. `--save`将依赖模块自动加入到 package.json 文件中. &lt;pre&gt;`&quot;dependencies&quot;{ &quot;colors&quot;:&quot;~0.6.0-1&quot; } `&lt;/pre&gt; 现在我们来重写 index.js 来使用我们的新库. colors 扩展了 String 的原型因此我们可以非常简洁的表达带有颜色的文本: &lt;pre&gt;`var colors = require(&apos;colors&apos;); console.log(&apos;Hello, &apos;.red,&apos;npm&apos;.green); 运行 index.js 文件, 你将在原来的输出中获得一个彩色字符串 node_modules 的层级当不显示指定相对路径或绝对路径时, Node 首先查找本地的 ndoe_modules 文件夹, 当你使用 npm install 指令的时候这个文件夹被自动创建. 当 Node 发现 node_modules 下有一个叫做 colors 子目录时, Node 将他当做 require 的目标.查看 node_modules/colors/package.json, 可以找到’main’:’colors’ , 因此 require colors这个文件夹时 Node 会认为 require 了 colors.js 这个脚本然后从 require 函数中返回脚本中的 exports 对象.如果找不到 colors 目录, 则会一直搜索到系统的根目录.","link":"/2016/07/20/e4-bd-bf-e7-94-a8-npm-e5-88-9b-e5-bb-ba-e6-96-b0-e5-b7-a5-e7-a8-8b/"},{"title":"图解 Git","text":"基本用法图中, History 即为本地仓库(local repository), Stage(Index) 为暂存目录, 也称为索引, Working Directory 为工作目录. git add *file* 把Current Working Directory 下的file 放入 Stage git commit 对 Stage 生成快照并放入 local Repo git reset -- *file* 用来将 Stage 恢复到上一次 commit 的状态(快照) git checkout -- *file* 把文件从 Stage 复制到 Current Working Directory, 并且丢弃本地修改 可以使用 git reset -p, git checkout -p, git add -p进入交互模式. 可以跳过 Stage, 实现 Working Directory 和 Local Repo 的直接交流. git commit -a 相当于运行 git add把Working Directory 下的文件放入 Stage 并 Commit git commit *file* 进行一次包含最后一次 Commit, 并加上 Working Directory 快照的提交, 并且文件添加到 Stage git checkout HEAD 从 Local Repo 中取出上一次 commit 的快照并回滚 图例 命令详解Diff查看两次提交之间的变动 Commit执行 Commit 的时候, git 对 Stage 中的文件做一个快照, 提交给 local repo, 记为指向父节点的新节点, 然后把 HEAD 指向新节点,图中执行 commit 后, stage 生成快照并提交给 repo, 记为新节点 f0cec, 其指向父节点 ed489, 同时 HEAD 从父节点转移至新节点. 即使当前分支是从某祖父节点出发的, git 也会生成新节点并指向该祖父节点, 并将 HEAD 指向新节点图中 maint 在 commit 前是 master 的子父节点, 在 commit 不再是 master 的祖父节点, 此时合并或衍合是必须的. 如果想更改一次commit, 使用 git commit --amend, git 会使用当前父节点进行一次新的提交, 新的子节点依旧指向该父节点, 旧的提交会被取消, 如图 CheckoutCheckout用于从 Stage 中取出文件放到 Working Directory 中, 也可用于切换分支 当给定某个文件名时, git 会从指定的节点中拷贝文件到 Stage 和 Working Directory. 比如 git checkout HEAD~ foo.c 会从 HEAD~(即当前父节点)中拷贝 foo.c 文件到 Working Directory 并加到 Stage, 如果checkout 没有添加指定节点, 就会从 Stage 中拷贝文件. 如果不指定文件名, 而是给出一个本地分支名, 则会将 HEAD 指向该分支, 即转为 current branch 如果没有指定文件名和分支名, 而是一个标签, 远程分支, SHA-1值, 或者像是 master~3之类的东西, 则得到一个匿名分支, 称为 detached HEAD( 被分离的 HEAD 标识) 当 HEAD 处于分离状态时(不指向任何有名的 branch), commit 可以正常提交, 但不会更新任何有名的 branch( 称为新的匿名分支) 此时如果切换到其他分支, 就无法返回这个匿名分支 如果想对该匿名分支创建引用, 可以用 git checkout -b *name* 来创建一个指向匿名分支的新分支 Resetreset 指令把当前分支指向另一个位置, 并且有选择的变动 Working Directory 和 Stage. 也用来从 Local Repo 中复制文件到 Stage, 不修改 Working Directory. 如果不给参数, 则当前分支指向那个节点, 并将 Stage 恢复到对应commit; 如果用 --hard 参数, 则 Working Directory 也恢复到该节点的commit, 如果用 --soft 参数, 则都不变 如果不提供版本号, 则默认 HEAD, 这样分支指向不变(依旧指向当前节点), 但是 Stage 会回滚到上一次 commit, 如果用了– hard, 则 Working Directory 也会回滚. Mergemerge 将不同的 branch 合并, 合并前, 其他分支的Stage 必须和当前分支的 Stage 相同(即合并的几个分支需要有相同的 Stage). 如果另一个分支是当前分支的祖父节点, 则合并命令将什么也不做. 如果当前节点是另一个分支的祖父节点, 则带哦之 fast-forward 合并, 即简单易懂 HEAD, 并生成一个新的 commit 如果是一次真正的合并, 默认把当前节点(ed489)和另一个节点(33104)及他们的共同祖父节点(b325c)进行一次三方合并. 结果是先保存Working Directory 和 Stage, 然后在当前节点(ed489)处提交新的节点. Cherry Pickcherry-pick 命令”复制”一个提交节点并在当前分支做一次完全一样的新提交(将某节点作为新节点). Rebase衍合是合并命令的另一种选择. 合并吧两个父分支合并进行一次提交, 提交历史不是线性的. 衍合在当前分支上重演另一个分支的历史, 提交历史是线性的, 本质上是线性化的自动的 cherry-pick 上面所有的命令都在 topic 分支中进行, 而不是 master 分支( HEAD 指向 topic), 在 master 分支上重演, 并把分支指向新的节点(就得 topic 分支被回收). 要限制回滚返回, 使用 --onto 参数","link":"/2016/05/26/e5-9b-be-e8-a7-a3-git/"},{"title":"增强页面渲染性能","text":"3D transform 启用 GPU 加速例如 transform3D, scaleZ 等可以开启浏览器硬件加速 实际上并不需要 Z 轴的动画 will-change当我们的某些行为触发页面进行大面积绘制的时候, 浏览器往往是没有准备的, 只能被动使用 CPU 去计算与重绘. 而will-change会在真正行为触发之前通知浏览器, 以开启 GPU 准备重绘. 该属性语法: will-change: auto; will-change: scroll-position; will-change: contents; will-change: trasnform; // or some will-change: opacity; // or some will-change: left,top; // or some will-change:inherit; will-change:initial; will-change: unset; `&lt;/pre&gt; 其中 auto 是用来重置的 scroll-position 是通知滚动 contents 是通知内容动画 ### 注意事项 `will-change` 虽然可以加速, 但一定要适度使用. 频繁使用 GPU 显然会导致性能(电量)消耗 不要直接写在默认状态中, 因为`will-change`会一直挂着: &lt;pre&gt;`.will-change{ will-change: transform; transition: transform .3s; } .will-change:hover{ transform: scale(1.5); } `&lt;/pre&gt; 可以让父元素 hover 的时候声明`will-change`, 这样, 移出的时候回自动`remove`, 触发返回基本上是有效元素范围 &lt;pre&gt;`.will-change-parent:hover .will-change{ will-change:transform; } .will-change{ transition:transform .3s } .will-change:hover{ transform:scale(1.5) } 如果使用 JS 添加will-change一定要及时 remove","link":"/2016/08/26/e5-a2-9e-e5-bc-ba-e9-a1-b5-e9-9d-a2-e6-b8-b2-e6-9f-93-e6-80-a7-e8-83-bd/"},{"title":"大公司怎么开发和部署前端代码","text":"原文出处: fouber个人总结 图中 a.css 是页面 index.html 的样式, 对于高访问量的页面而言, 每次访问 index.html 都需要请求 a.css, 会很影响性能. 因此我们希望这样安排 利用304, 让浏览器使用本地缓存: 304叫协商缓存, 仍然需要和服务器通信一次 进一步优化, 强制浏览器使用本地缓存( cache-control/expires ), 不需要和服务器痛心了 新的问题: 浏览器不发送资源请求, 如何更新缓存? 通过更新页面中引用的资源路径, 让浏览器主动放弃缓存, 加载新资源 下次上线把链接地址改成新版本的, 就更新了资源 如果有很多样式引用, 但是仅仅改了其中一个呢? 解决方法: 让url 的修改与文件内容关联, 即只有文件内容发生变化, 才会更新 url 利用数据摘要算法对文件请求摘要信息, 摘要信息和文件内容一一对应, 就有了一种可以精确到单个文件粒度的缓存控制依据. 把 URL 改成带摘要信息的格式: 以后如有文件修改, 就只更新对应的 URL 了 进一步提高网站性能把静态资源和动态网页分集群部署, 静态资源会被部署到 CDN 节点上, 网页中引用的资源也会变成对应的部署路径 静态资源优化方案 配置超长时间的本地缓存 — 节省带宽, 提高性能 采用内容摘要作为缓存更新依据 — 精确控制缓存 静态资源 CDN 部署 — 优化网络请求 更新资源发布路径实现非覆盖式发布 — 平滑升级","link":"/2016/06/14/e5-a4-a7-e5-85-ac-e5-8f-b8-e6-80-8e-e4-b9-88-e5-bc-80-e5-8f-91-e5-92-8c-e9-83-a8-e7-bd-b2-e5-89-8d-e7-ab-af-e4-bb-a3-e7-a0-81/"},{"title":"学习 CSS 布局","text":"Display 属性每个元素都有一个默认的 display 值, 这个与元素的类型有关. 大部分元素他们的 display 默认为 blcok 或 inline . 一个 blcok 元素通常称为 块级元素 , 一个 inline 元素通常称为 行内元素 . Block一个 Block 元素会从新开始一行并盛满容器的宽度, 默认为 blcok 的元素有 p, form, header, footer, section等. Inline一个 inline元素可以位于段落中, 包裹一些文字而不会打乱段落的布局. None一些特殊元素的默认 display 是他, 例如 script. 用于不删除元素的情况下隐藏某些元素. 和 visibility 不同, display: none不会在文档流中占据空间, 但是 visibility: hidden 则会在文档流中占据空间. inline-blcokinline 元素是可以位于段落内不导致换行的, 但是不可控制 height, width 属性 block 元素独立成段, 但是可以控制 height, width 属性 inline-block 元素可以位于段落中, 且独立控制 height, width 属性 注意事项: vertical-align属性会影响到inline-block元素, 你可能会把他的值设置为 top 需要设置每一个 inline-block 的宽度 在 HTML 代码中如果两个inline-block代码中有空格, 则实际排版中会出现空隙 Margin: auto设置 Block 元素的 width 属性可以组织他水平方向占据容器, 同时设置 margin: 0 auto; 可以令其居中显示. Box-sizingbox-sizing: border-box; 设置该元素的盒子尺寸为 border 的外尺寸 .simple{ width:500px; margin: 20px auto; padding: 20px; -webkit-box-sizing: border-box; -moz-box-sizing: border-box; box-sizing: border-box; } // simple 的 width 为 border+padding+content 的尺寸, 即元素的 border 整体宽度为 width `&lt;/pre&gt; ## Position ### static `position`默认为 `static` , 一个 `static`元素不会被&quot;positioned&quot;, 一个`position` 被设置为其他值的元素表示他会被&quot;positioned&quot;. ### relative 对`position:relativ`的元素设置 `top, bottom, left, right`属性可以使其偏离原有位置, 但是在文档流中占据原来的位置, 即偏离前的空间在文档流中作为其他元素的位置参考. ### fixed 一个`fixed` 元素会相对 window 定位, 即使页面滚动, 他在的浏览器中的位置也不会变化. `fixed` 元素不占据文档流. ### absolute `absolute` 和 `fixed` 表现类似, 只是参考系变为最近的&quot;positioned&quot; 父级元素, 如果不存在这样的父级元素, 则以 body 元素为参考. ### float ### clear 用于控制悬浮. &lt;pre&gt;`&amp;lt;div class=&apos;box&apos;&amp;gt;...&amp;lt;/div&amp;gt; &amp;lt;section class=&apos;after-box&apos;&amp;gt;...&amp;lt;/section&amp;gt; .box{ float:left; width: 200px; height: 100px; margin: 1em; } .after-box{ clear: left // 控制该元素左侧无浮动元素 } `&lt;/pre&gt; ## 控制浮动 使用浮动经常会遇到一些古怪的排版 &lt;pre&gt;`&amp;lt;div class=&apos;clearfix&apos;&amp;gt; 文字描述 &amp;lt;img src=&apos;http://zh.learnlayout.com/images/ilta.png&apos;&amp;gt; &amp;lt;/div&amp;gt; .img{ float:right; } .clearfix{ overflow: auto; // 扩大 div 阻止 img 溢出 } `&lt;/pre&gt; ## 媒体查询 &lt;pre&gt;`@media screen and (min-width:600px){ nav{ float:left; width:25%; } section{ margin-left:25%; } } @media screen and (max-width:599px){ nav li{ display: inline; } } `&lt;/pre&gt; ## Column &lt;pre&gt;`.three-column{ padding:1em; -moz-column-count: 3; -moz-column-gap: 1em; -webkit-column-count: 3; -webkit-column-gap: 1em; column-count: 3; column-gap: 1em; } `&lt;/pre&gt; 实现 div 中三列布局 ## Flexbox &lt;pre&gt;`.container{ display:-webkit-flex; display:flex; } nav{ width:200px; } .flex-column{ -webkit-flex:1;//剩余宽度的100% flex:1; } `&lt;/pre&gt; ### 使用 flex box 实现(vertical-container 内元素)垂直居中 &lt;pre&gt;`.vertical-container{ height:300px; display:-webkit-flex; display:flex; -webkit-align-items: center; -align-items: center; -webkti-justify-content: center; -justify-content: center; }","link":"/2016/05/28/e5-ad-a6-e4-b9-a0-css-e5-b8-83-e5-b1-80/"},{"title":"媒体查询","text":"语法媒体查询包括一个媒体类型和至少一个媒体属性, 这些媒体属性会被解析成真或假. 当媒体查询为真时, 相关的样式表或样式规则就会按照正常的级联规则被应用. 即使媒体查询的结果为假, &amp;lt;link&amp;gt;标签上带有媒体查询的样式表仍然会被下载. 逻辑操作符操作符 not, and 和 only, 可以用来构建复杂的媒体查询 逗号分隔符相当于 or 操作符, 其中一个为真, 则媒体查询结果为真 一个基本的媒体查询, 即一个媒体属性与默认指定的 all 媒体类型, 可能是这样子: @media (min-width: 700px) {...} `&lt;/pre&gt; 如果要添加横屏限制 &lt;pre&gt;`@media (min-width: 700px) and (orientation: landscape) {...} `&lt;/pre&gt; ### not not 关键字应用于整个媒体查询, 如 &lt;pre&gt;`@media not all and (monochrome){...} 等价于 @media not (all and (monochrome)) {...} `&lt;/pre&gt; 在逗号媒体查询列表中, not 仅否定他所在的 item. ## 媒体属性 大多数媒体属性都带有&quot; min-&quot; 和&quot; max-&quot;前缀 ### Color 值: &amp;lt;color&amp;gt; 媒体: visual 是否接受 min/max 前缀: 是 示例向所有能显示颜色的设备应用样式表 @media all and (color) {...} Aspect-ratio 值: &amp;lt;ratio&amp;gt; 媒体: visual, tactile 是否接受min/max 前缀: 是 宽高比以”宽/高”表示 示例向显示区域宽高比至少1:1的设备应用样式表 @media screen and (min-aspect-ratio: 1/1){...} Device-aspect-ratio 值: &amp;lt;ratio&amp;gt; 媒体: visual, tactile 是否接受min/max 前缀: 是 示例为宽屏设备应用样式表 @media screen and (device-aspect-ratio:16/9), screen and (device-aspect-ratio:16/10){...} Device-height 值: &amp;lt;length&amp;gt; 媒体: visual, tactile 是否接受 min/max 前缀: 是 描述输出设备的高度(整个屏幕或页的高度, 而不是渲染窗口的高度) 实例向显示在最大宽度800px 的屏幕上的文档应用样式表 `&lt;link rel=”stylesheet” media=”screen and (max-device-height: 799px)” /&gt; Device-width 值: &amp;lt;length&amp;gt; 媒体: visual, tactile 是否接受 min/max 前缀: 是 描述输出设备的宽度 Grid 值: &amp;lt;integer&amp;gt; 媒体: all 是否接受 min/max 前缀: 否 判断输出设备是网格设备还是位图设备. 如果是网格设备(例如电传打字机中断或只能显示一种字形的电话), 该值为1, 否则为0 Height 值: &amp;lt;length&amp;gt; 媒体: visual, tactile 是否接受 min/max 前缀: 是 height 描述输出设备的渲染区域高度 MonochromeOrientation 值: &amp;lt;landscape | portrait&amp;gt; 媒体: visual 是否接受 min/max 前缀: 否","link":"/2016/05/28/e5-aa-92-e4-bd-93-e6-9f-a5-e8-af-a2/"},{"title":"彻底理解 Thunk 函数","text":"生成器函数生成器(Generator)函数写成: function* func () {} `&lt;/pre&gt; 其本质也是一个函数, 所以他具备普通函数所具有的所有特性, 除此以外, 他还具有以下特性 执行生成器函数后返回一个迭代器(Iterator) 生成器函数内部可以使用 yield 或 yield*, 函数执行到 yield 的时候会暂停执行, 并返回 yield 后面表达式的值, 通过迭代器的 next() 方法返回一个对象, 该对象由 value 和 done 属性组成, 其中, value 属性值为 yield 后面表达式的值, done 属性表示生成器的执行状态 迭代器 next() 方法的参数是yield 表达式的值 当 next 指向最后一个 yield 的时候, 再次执行 next() 方法, 返回的对象中 done: true, 而 value 的值为 return 后面的表达式(默认为 undefined) 例一`function test() { return 'b'; } function* func() { var a = yield 'a'; console.log('gen', a); // 'gen: undefined' - (如果 next 方法不带参数, yield 表达式返回 undefined) var b = yield test(); console.log('gen': b); // 'gen: undefined' } var func1 = func(); var a = func1.next(); console.log('next: ' a); // 'next: {value: 'a', done: false}' var b = func1.next(); console.log('next: ' b); // 'next: {value: 'b', done: false}' var c = func1.next(); console.log('next: ' c); // 'next: {value: undefined, done: true}' ` 关于 yield*yield 暂停执行并返回后面表达式的值, 而 yield* 则将函数委托到另一个迭代器或可迭代对象 arguments`&gt; function* genFunc(){ ... yield arguments; ... yield* arguments; ... } undefined &gt; var gen = genFunc(1,2); undefined &gt; gen.next() { value: { '0': 1, '1': 2 }, done: false } &gt; gen.next() { value: 1, done: false } &gt; gen.next() { value: 2, done: false } &gt; gen.next() { value: undefined, done: true } ` Generator`&gt; function * gen1(){ ... yield 2; ... yield 3; ... } undefined &gt; function * gen2(){ ... yield 1; ... yield* gen1(); ... yield 4; ... } undefined &gt; var g2 = gen2(); undefined &gt; g2.next() { value: 1, done: false } &gt; g2.next() { value: 2, done: false } &gt; g2.next() { value: 3, done: false } &gt; g2.next() { value: 4, done: false } &gt; g2.next() { value: undefined, done: true } ` Thunk 函数在 co 的应用中, 为了能像同步代码那样书写异步代码, 比较多的使用方式是使用 thunk 函数(但不是唯一方式, 还可以是 Promise), 比如读取文件内容的异步函数 fs.readFile() 方法, 转化为 thunk 函数的方式如下 `function readFile(path, encoding){ return function(cb){ fs.readFile(path, encoding, cb); } } ` Thunk函数具备以下两个要素1. 有且只有一个参数是 callback 的函数\u00022. callback 的第一个参数是 error 使用 thunk 函数, 同时结合 co 我们就可以像书写同步代码一样书写异步代码 `var co = require('co'); var fs = require('fs'); var Promise = require('es6-promise').Promise; function readFile(path, encoding){ return function(cb) { // thunk function fs.readFile(path, encoding, cd); }; } co(function* () { // 外部不可见, 但在 co 内部其实已经转化成promise.then().catch()...链式调用的行驶 var a = yield readFile('a.txt', {encoding: 'utf-8'}); console.log(a); // a var b = yield readFile('b.txt', {encoding: 'utf-8'}); console.log(b); // b return yield Promise.resolve(a+b); }).then(function(val){ console.log(val) // ab }).catch(function(error){ console.log(error); }) ` 有一个框架 thunkify 可以帮我们轻松实现以上步骤 `var co = require('co'); var thunkify = require('thunkify'); var fs = requrie('fs'); var Promise = require('es6-promise').Promise; var readFile = thunkify(fs.readFile); co(function* () { // 外部不可见， 但在 co 内部已经转化为 promise 的链式调用 var a = yield readFile('a.txt', {encoding: 'utf-8'}); console.log(a); // a var b = yield readFile('b.txt', {encoding: 'utf-8'}); console.log(b); // b return yield Promise.resolve(a+b); }).then(function(val){ console.log(val); // ab }).catch(function(err){ console.log(err); }) ` 对于 thunkify 框架的理解注释如下： `/** Module dependencies*/var assert = require(‘assert’); /** Expose thunkify().*/ module.exports = thunkify; function thunkify(fn) { assert(‘function’ == typeof fn, ‘function required’); // 返回一个包含 thunk 函数的函数, 返回的 thunk 函数用于执行yield, 而外层的这个函数用于给 thunk 函数传递其他参数 return function() { var args = new Array(arguments.length); // 缓存上下文环境, 给 fn 提供执行环境 var ctx = this; // 将参数类数组对象转为数组(实现方式略臃肿, 可以直接用Array.from) for (var i = 0; i &amp;lt; args.length; ++i){ args[i] = argumetns[i]; } // 真正的 thunk 函数(有且只有一个参数, 并且参数是第一个参数为 err 的 callback) return function(done) { // 返回 thunk 函数 var called; // 将回调函数再包裹一层, 避免重复调用, 同时, 将包裹了的真正的回调函数 push 进参数数组(即将回调函数 done 作为最后一个参数传递给 fn) args.push(function(){ // 将回调函数 done 加到参数列表尾部, 形成 fn 需要的 [arg1, ..., done] if (called) return; called = true; done.apply(null, arguments); // 执行回调函数 }); try { // 在 ctx 环境执行 fn // 并将执行 thunkify 之后返回的函数的参数(含 done 回调) 传入, 类似于执行: // fs.readFile(path, {encoding: &apos;utf-8&apos;}, done) fn.apply(ctx,args); // 类似 fn(arg1, .., done) } catch(err) { done(err); } } }}","link":"/2016/07/30/e5-bd-bb-e5-ba-95-e7-90-86-e8-a7-a3-thunk-e5-87-bd-e6-95-b0/"},{"title":"测试小技巧","text":"每一个测试都要引入 expect, 可以创建一个test_helper.js 1234567 import { expect } from &apos;expect&apos; import sinon from &apos;sinon&apos;global.expect = expect global.sinon = sinon `然后在`mocha.opt`中添加` --require ./test/test_helper.js","link":"/2016/09/08/e6-b5-8b-e8-af-95-e5-b0-8f-e6-8a-80-e5-b7-a7/"},{"title":"测试环境搭建(Mocha + Chai + Sinon)","text":"Mocha: 用于运行测试用例 Chai: Mocha 用的断言库 Sinon: 用于创建一些 mocks/stubs/spys AriBnB 创建了一个专门针对 React 代码测试的开源程序: Enzyme Mocha 安装及环境配置npm install --save-dev mocha chai sinon `&lt;/pre&gt; 安装支持 ES6 语法的插件 &lt;pre&gt;`npm install --save-dev babel-register `&lt;/pre&gt; ### 简单测试用例 Mocha 默认会去当前目录下寻找 test 目录, 然后在其中去找后缀为 js 的文件. 如果需要修改这个目录, 可以用 Mocha 的参数设置. &lt;pre&gt;`// index.spec.js import { expect } from &apos;chai&apos;; describe(&apos;hello react spac&apos;, () =&amp;gt; { it(&apos;works!&apos;, ()=&amp;gt;{ expect(true).to.be.true; }); }); `&lt;/pre&gt; 命令行 &lt;pre&gt;`mocha --compilers js:babel-register `&lt;/pre&gt; 如果不添加`--compilers js:babel-register`, 那么 mocha 会按照默认的方式执行, 也就是`读取 spec 文件 -&amp;gt; 运行测试用例`. 使用了`--compilers js:babel-register` 之后, 执行顺序为`读取 spec 文件 -&amp;gt; 将 ES6 代码替换 ES5 代码 -&amp;gt; 运行测试用例` #### 创建测试工具库 test_helper.js 注意每个测试文件中都要引入 expect, 最好用一个库来进行管理. 创建一个新的文件 `/test/test_helper.js` &lt;pre&gt;`// test/test_helper.js import { expect } from &apos;chai&apos; import sinon from &apos;sinon&apos; global.expect = expect; global.sinon = sinon; `&lt;/pre&gt; 这里只添加了 chai 的 expect 以及引入了 sinon 现在可以将`index.spec.js` 的第一行删除, 并运行 &lt;pre&gt;`mocha --compilers js:babel-register --require ./test/test_helper.js --recursive `&lt;/pre&gt; 或者在 package.json 中创建 scripts &lt;pre&gt;`&quot;test&quot;::&quot;mocha --compilers js:babel-register --requrie ./test/test_helper.js --recursive&quot;, &quot;test:watch&quot;: &quot;npm test -- --watch&quot;","link":"/2016/08/28/e6-b5-8b-e8-af-95-e7-8e-af-e5-a2-83-e6-90-ad-e5-bb-bamocha-chai-sinon/"},{"title":"滚动视差效果","text":".container{ overflow-y:scroll; overflow-x:hidden; perspective:1px; transform-style:preserve-3d; color:yellow; text-align:center;}.bg{ width: 100vw; height: 40vh; position:relative;}h1{ padding:100px;}.bg:before{ position:absolute; top: 0; left: 0; right: 0; bottom: 0; content:””; display:block; background: url(“http://7xu8mu.com1.z0.glb.clouddn.com/katong_1.jpg“); background-size:cover; z-index: -1; transform:translateZ(-1px) scale(2);} # Hello World 原理是将图片放在bg:before, 然后为 container 设置 perspective:1px 和 preserve-3d, 并蛇者 overflow:auto(要避免 x-index 则使用 overflow-y:scroll), 然后将 bg:before 向 Z 轴移动-1px, 形成前后空间 /HTML/ div.container div.bg h1{…} p{…} /CSS/ .container{ overflow-y:scroll; overflow-x:hidden; perspective:1px; transform-style:preserve-3d; color:yellow; text-align:center; } .bg{ width: 100vw; height: 40vh; position:relative; } h1{ padding:100px; } .bg:before{ position:absolute; top: 0; left: 0; right: 0; bottom: 0; content:””; display:block; background: url(“http://7xu8mu.com1.z0.glb.clouddn.com/katong_1.jpg“); background-size:cover; z-index: -1; transform:translateZ(-1px) scale(2); }","link":"/2016/06/20/e6-bb-9a-e5-8a-a8-e8-a7-86-e5-b7-ae-e6-95-88-e6-9e-9c/"},{"title":"理解伪元素:Before 和 :After","text":"本篇中的”伪元素”特指”:before”和”:after” 语法和浏览器支持早起的伪元素是使用一个冒号声明的”:”, 在 CSS3中修订后伪元素的声明使用两个冒号”::”, 但是为了目前的兼容性考虑(IE8), 建议使用”:”声明. 伪元素会在内容元素的前后插入额外的元素, 技术上等同于 &amp;lt;p&amp;gt; &amp;lt;span&amp;gt;:before&amp;lt;/span&amp;gt; This is the main content. &amp;lt;span&amp;gt;:after&amp;lt;/span&amp;gt; 当然, 这些元素无法在文档的源码中找到","link":"/2016/07/18/e7-90-86-e8-a7-a3-e4-bc-aa-e5-85-83-e7-b4-a0before-e5-92-8c-after/"},{"title":"理解 RESTFul 架构","text":"REST 全称 Representational State Transfer(表述性状态转移), 十一组架构约束条件和原则. 如果一个架构符合 REST 的约束条件, 那么可以称为 RESTFul 架构 要理解 REST 原则, 就要从资源的定义, 获取, 表述, 关联, 状态变迁等角度入手 资源与 URI 统一资源接口 资源的表述 资源的链接 状态的转移 资源与 URI任何事物, 只要有被引用到的必要, 他就是一个资源. 要让一个资源可以被识别, 需要添加一个唯一标识, 在 Web 中这个唯一标识就是 URI(Uniform Resource Identifier). URI 既可以看成资源的地址, 也可以看成资源的名称. 如果一些信息没有使用 URI 来标识, 说明他不是一个资源 URI 的设计应该遵循可寻址原则, 具有自描述性, 需要在形式上给人以直觉上的关联 URI 设计上的一些技巧 使用 _ 或 - 提高 URI 的可读性 使用 / 表示资源的层级关系 使用 ? 过滤资源 统一资源接口RESTFul 结构应该遵循统一接口原则, 统一接口包含了一组受限的预定义操作, 不论什么样的资源, 都是通过使用相同接口进行资源访问. 接口应该使用标准 HTTP 方法如 GET, PUT, POST, 并遵循这些方法的语义 POST 和 PUT 用于创建资源时的区别: 所创建的资源的 URI 是否由客户端决定. 资源的表述客户端通过 HTTP 方法获取资源的表述, 而不是资源本身. 所谓资源的表述, 即是资源的展现, 而非其本质. 以文本为例, 可以通过 JSON, STRING 等形式表述出来, 而通过客户端获取的即是 JSON 形式的表述, 或 STRING 形式的表述. 客户端通过 HTTP 内容协商, 即 Accept 头请求一种特定个事的表述, 服务器则通过 Content-Type 通知客户端资源的表述形式 资源的连接REST 使用 HTTP 方法操作资源, 在表述格式中添加链接来引导客户端, 这种具有连接的特性称为连通 状态的转移无状态通信原则: 服务端不应该保存客户端的状态 应用状态与资源状态应该区分应用状态和资源状态, 客户端负责维护应用状态, 服务端维护资源状态. 客户端与服务端的交互应当是无状态的, 并且在每一次请求中包含处理该请求所需要的一切信息. 服务端不需要在请求间保留应用状态, 只有在接收到实际请求的时候, 服务端才会关注应用状态. 这种无状态通信原则, 使得服务端和中介能够理解独立的请求和相应. 多次请求中, 同一客户端也不再需要依赖同一服务器, 方便实现高可扩展和高可用性的服务端. 应用状态的转移“会话状态”不是作为资源状态被保存在服务端, 而是被客户端做为应用状态进行跟踪. 客户端应用状态在服务端提供的超媒体的指引下发生变迁, 服务端通过超媒体告诉客户端当前状态有哪些后续状态可以进入. 类似于网页中的’下一些’的连接.","link":"/2016/09/16/e7-90-86-e8-a7-a3-restful-e6-9e-b6-e6-9e-84/"},{"title":"生成器 Function*","text":"function* 声明定义一个 generator( 生成器), 返回一个 Generator 对象 语法 function* name([param[, param[, ...param]]]){ statements } `&lt;/pre&gt; ### 描述 Generator 是一种可以从中退出并在之后重新进入的函数, 其环境(绑定的变量)会在每次执行后被保存, 下次进入时可以继续使用 调用一个 Generator 并不马上执行它的主体, 而是返回一个 迭代器对象, 这个迭代器的 next() 方法被调用的时候, Generator 的主体会被执行至下一个 yield 表达式, 该表达式定义了迭代器的返回值 ### 示例 &lt;pre&gt;`function* idMaker(){ var index = 0; while(index &amp;lt; 3){ yield index++; } } var gen = idMaker(); //返回一个迭代器对象 console.log(gen().next().value); // 0 console.log(gen().next().value); // 1 console.log(gen().next().value); // 2 console.log(gen().next().value); // undefined 谨慎使用, 因为其内部变量保持变化, 要每次输出的相互影响","link":"/2016/07/26/e7-94-9f-e6-88-90-e5-99-a8-function/"},{"title":"编写测试","text":"设置使用 Mocha 作为测试引擎注意因为是在 node 环境下运行, 所以不能访问 DOM npm install --save-dev mocha `&lt;/pre&gt; 若想要结合 Babel 使用, 需要在 package.json 的 script 中加入一段 &lt;pre&gt;`{ &quot;scripts&quot;: { ... &quot;test&quot;: &quot;mocha --compilers js:babel/register --recursive&quot;, &quot;test:watch&quot;: &quot;npm test -- --watch&quot; } } `&lt;/pre&gt; ### Action Creators Redux 里的 action creators 会返回普通对象, 在测试 action creators 的时候我们要测试的不仅是调用了正确的action creators, 还有是否返回了正确的 action 实例 &lt;pre&gt;`export function addTodo(text){ return { type: &apos;ADD_TODO&apos;, text }; } `&lt;/pre&gt; 可以这样测试 &lt;pre&gt;`import expect form &apos;expect&apos; import * as actions from &apos;../../actions/TodoActions&apos;; import * as types from &apos;../../constants/ActionTypes&apos;; describe(&apos;actions&apos;, () =&amp;gt; { it(&apos;should create an action to add a todo&apos;, () =&amp;gt; { const text = &apos;Finish docs&apos;; const expectedAction = { type: &apos;ADD_TODO&apos;, text }; expect(actions.addTodo(text)).toEqual(&apos;expectedAction&apos;); }) }) `&lt;/pre&gt; ### 异步 Action Creators 对于使用Redux Thunk 或其他 middleware 的异步 Action Creator, 最好完全模拟 Redux Store 来测试. 可以使用 applyMiddleware() 和一个 mock store, 与可以用 nock 来模拟 HTTP 请求 实例: &lt;pre&gt;`function fetchTodosRequest () { return { type: FETCH_TODOS_REQUEST } } function fetchTodosSuccess(body) { return { type: FETCH_TODOS_SUCCESS, body } } function fetchTodosFailure(ex) { return { type: FETCH_TODOS_FAILURE, ex } } export function fetchTodo () { return dispatch =&amp;gt; { dispatch(fetchTodosRequest()) return fetch(&apos;http://example.com/todos&apos;) .then(res =&amp;gt; res.json()) .then(json =&amp;gt; dispatch(fetchTodosSuccess(json.body))) .catch(ex =&amp;gt; dispatch(fetchTodosFailure(ex))) } } `&lt;/pre&gt; 可以这样测试 &lt;pre&gt;`import expect from &apos;expect&apos; import { applyMiddleware } from &apos;redux&apos; import thunk from &apos;redux-thunk&apos; import * as actions from &apos;../../actions/counter&apos; import * as types from &apos;../../constants/ActionTypes&apos; import nock from &apos;nock&apos; const middleware = [thunk] /** * 使用中间件模拟 Redux Store */ function mockStore = (getState, expectedActions, done){ if(!Array.isArray(expectedActions)){ throw new Error(&apos;expectedActions should be an array of expected actions.&apos;) } if( typeof done !== &apos;undefined&apos; &amp;amp;&amp;amp; typeof done !== &apos;function&apos;){ throw new Error(&apos;done should either be undefined or function&apos;) } function mockStoreWithoutmiddleware(){ return { getState(){ return typeof getState === &apos;function&apos; ? getState(): getState }, dispatch(action){ const expectedAction = expectedActions.shift() try { expect(action).toEqual(expectedAction) if(done&amp;amp;&amp;amp;!expectedActions.length){ done() } return action } catch (e) { done(e) } } } } const mockStoreWithMiddleware = applyMiddleware( ...middlewares )(mockStoreWithoutMiddleware) return mockStoreWithMiddleware() } describe(&apos;async actions&apos;, () =&amp;gt; { afterEach(() =&amp;gt; { nock.clearAll() }) it(&apos;creates FETCH_TODOS_SUCCESS when fetching todos has been done&apos;, (done) =&amp;gt; { nock(&apos;http://example.com&apos;) .get(&apos;./todos&apos;) .reply(200, {todos: [&apos;do something&apos;]}) const expectedActions = [ {type: types.FETCH_TODOS_REQUEST}, {type: types.FETCH_TODOS_SUCCESS, body: { todos: [&apos;do something&apos;]}} ] const store = mockStore({todos: []}, expectedActions, done) store.dispatch(actions.fetchTodos()) }) }) `&lt;/pre&gt; ### Reducers 测试 Reducer 把 action 应用到当前 state, 并返回新的 state &lt;pre&gt;`import { ADD_TODO } from &apos;../constants/ActionTypes&apos;; const initialState = [ { text: &apos;Use Redux&apos;, completed: false, id: 0 } ] export default function todos(state = initialState, action) { switch(action.type) { case ADD_TODO: return [ { id: state.reduce((maxID, todo) =&amp;gt; Math.max(todo.id, maxId), -1) + 1, completed: false, text: action.text }, ...state ] default: return state } } `&lt;/pre&gt; 可以这样测试: &lt;pre&gt;`import expect from &apos;expect&apos; import reducer from &apos;../../reducers/todos&apos; import * as types from &apos;../../constants/ActionTypes&apos; describe(&apos;todos reducer&apos;, () =&amp;gt; { it(&apos;should return the initial state&apos;, () =&amp;gt; { expect(reducer(undefined, {})).toEqual([ { text: &apos;Use Redux&apos;, completed: false, id: 0 } ]) }) it(&apos;should handle ADD_TODO&apos;, () =&amp;gt; { expect( reducer([],{ type: types.ADD_TODO, text: &apos;Run the test&apos; }) ).toEqual( [ { text: &apos;Run the test&apos;, completed: false, id: 0 } ] ) expect( reducer([ { text: &apos;Use Redux&apos;, completed: false, id:0 } ], { type: types.ADD_TODO, text: &apos;Run the test&apos; }) ).toEqual([ { text: &apos;Run the test&apos;, completed: false, id: 1 }, { text: &apos;Use Redux&apos;, completed: false, id: 0 } ]) }) }) `&lt;/pre&gt; ### 测试 Components React Components 的优点是, 一般都很小, 并且依赖于 props, 因此测试起来很容易. 首先安装 React Test Utilities &lt;pre&gt;`npm install --save-dev react-addons-test-utils `&lt;/pre&gt; 要测试 components 我们要创建一个叫`setup()` 的辅助方法\u0002, 用来把模拟过的( stubbed ) 回调函数当做 props 传入, 然后使用 React 浅渲染来渲染组建, 这样可以依据`是否调用了回调函数`的断言来写独立的测试 &lt;pre&gt;`import React, { PropTypes, Component } from &apos;react&apos; import TodoTextInput from &apos;./TodoTextInput&apos; class Header extends Component { handleSave(text){ if(text.length !==0){ this.props.addTodo(text) } } render(){ return( &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;todos&amp;lt;/h1&amp;gt; &amp;lt;TodoTextInput newTodo = {true} onSave ={this.handleSave.bind(this)} placeholder = &apos;what needs to be done?&apos; /&amp;gt; &amp;lt;/header&amp;gt; ) } } Header.propTypes = { addTodo: PropTypes.func.isRequired } export default Header","link":"/2016/09/05/e7-bc-96-e5-86-99-e6-b5-8b-e8-af-95/"},{"title":"移动端 Border-Radius 溢出处理","text":"问题1: 部分机型下, 设置 border-radius 以及 overflow:hidden 会造成背景颜色溢出 解决: background-clip: padding-box 原理: background-clip 是颜色颜色显示区域, 设置为 padding-box 问题2: transform 的子元素在父元素 overflow:hidden 之后还是会溢出 解决办法: 在父元素加上一段 css -webkit-mask-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAAA1BMVEUAAACnej3aAAAACklEQVQI12NgAAAAAgAB4iG8MwAAAABJRU5ErkJggg==&apos;); 这是一张1px 的纯黑色图片 原理: -webkit-mask-image:url(‘’), 会在图片上添加蒙版(黑色表示将内容透明, 白色表示将内容显示, 介于中间表示半透明)","link":"/2016/09/08/e7-a7-bb-e5-8a-a8-e7-ab-af-border-radius-e6-ba-a2-e5-87-ba-e5-a4-84-e7-90-86/"},{"title":"编写 Koa 中间件","text":"Koa middlewares are simple function which return a GeneratorFunction, and accept another (middleware). When the middleware is run by an “upstream” middleware, it must manually yield to the “downstream” middleware. For example if you wanted to track how long it takes for a request to propagate through Koa by adding an x-Response-Time header field the middleware would look like the following: function *responseTime(next){ var start = new Date; yield next; var ms = new Date - start; this.set(&quot;X-Response-Time&quot;, ms+&quot;ms&quot;); } app.use(responseTime); `&lt;/pre&gt; Here is another way to write the same thing, inline: &lt;pre&gt;`app.use(function *(next){ var start = new Date; yield next; var ms = new Date - start; this.set(&quot;X-Response-Time&quot;, ms+&quot;ms&quot;); }); `&lt;/pre&gt; ### 中间件最佳实践 Imcluding Middleware accepting options, named middleware for debugging, among others #### 中间件选项 When creating public middleware it&apos;s useful to conform to the convention of wrapping the middleware in a function that accepts options, allowing users to extend functionality. Even if your middleware accepts no options, this is still a good idea to keep things uniform. Here our contrived `logger` middleware accepts a `format` string for customization, and returns the middleware itself: &lt;pre&gt;`function logger(format){ format = format || &quot;:method\\&quot;:url\\&quot;&quot;; return function*(next){ var str = format.replace(&quot;:method&quot;, this.method).replace(&quot;:url&quot;, this.url); console.log(str); yield next; } } `&lt;/pre&gt; app.use(logger()); app.use(logger(&quot;:method:url&quot;)) &lt;pre&gt;` ### 命名中间件 Naming middlewares is optional, however it&apos;s useful for debugging purpose to assign a name `&lt;/pre&gt; function logger(format){ return function *logger(next){ // ... } } &lt;pre&gt;`### 结合多个中间件 Sometimes you want to &quot;compose&quot; multiple middleware into a single middleware for easy re-use or exporting. To do so, you may chain them together with `.call(this, next)`, then return another function that yields the chain function _random(next) { if (‘/random’ == this.path) { this.body = Math.floor(Math.random()_10); } else { yield next; }}; function *backwards(next) { if (‘/backwards’ == this.path) { this.body = ‘sdrawkcab’; } else { yield next; }} function *pi(next) { if (‘/pi’ == this.path) { this.body = String(Math.PI); } else { yield next; }} function *all(next) { yield random.call(this, backwards.call(this, pi.call(this, next)));} app.use(all);```","link":"/2016/09/19/e7-bc-96-e5-86-99-koa-e4-b8-ad-e9-97-b4-e4-bb-b6/"},{"title":"浏览器同源政策及其规避方法","text":"浏览器安全的基石是”同源政策”(same-origin policy). 概述所谓”同源”, 是指三个”相同”. 协议相同: http:\\\\ 域名相同: www.example.com 与 example.com 不同 端口相同 目的同源政策的目的是为了保证用户信息安全, 防止恶意的网络窃取数据 限制范围如果非同源, 共有三种行为受到限制 Cookie, LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求无法发送 CookieCookie 是服务器写入浏览器的一小段信息, 只有同源的网站才能共享. 但是两个网页一级域名相同, 只有二级域名不同, 浏览器允许通过设置 document.domain 共享 Cookie. 举例来说, A 网页是 http://w1.example.com/a.html, B 网页是 http://w2.example.com/b.html, 那么只要设置相同的 document.domain, 这两个网页可以共享 Cookie. document.domain = &apos;example.com&apos;; `&lt;/pre&gt; 现在 A 网页通过脚本设置一个 Cookie &lt;pre&gt;`document.cookie = &apos;test1=hello&apos;; `&lt;/pre&gt; B 网页就可以读取这个 Cookie &lt;pre&gt;`var allCookie = document.cookie; `&lt;/pre&gt; 注意, 这种方法只适用于 Cookie 和 iframe 窗口, LocalStorage 和 IndexDB 无法通过这种方法, 规避同源政策. 另外, 服务器也可以在设置 Cookie 的时候指定 Cookie 所属域名为一级域名, 比如 `.example.com` &lt;pre&gt;`Set-Cookie: key=value; domain=.example.com; path=/ `&lt;/pre&gt; 这样的话, 二级域名和三级域名不用做任何设置就可以读取这个 Cookie ### iframe 如果两个网页不同源, 就无法拿到对方的 DOM, 典型的例子就是`iframe`窗口和`window.open` 方法打开的窗口, 他们与父窗口无法通信. 如果两个窗口一级域名相同, 只是二级域名不同, 那么设置`document.domain`也可以规避同源政策, 实现 DOM 获取. ### 完全不同源的网站 #### 片段识别符(fragment identifier) 片段识别符值得是 URL 中`#` 后的部分, 也就是 hash. 如果只是改变片段识别符, 页面不会重新刷新 父窗口可以把信息写入子窗口的片段识别符 &lt;pre&gt;`var src = originURL + &apos;#&apos; + data; document.getElementById(&apos;myFrame&apos;).src = src; `&lt;/pre&gt; 子窗口通过监听 `hashchange` 事件得到通知 &lt;pre&gt;`window.onhashchange = checkMessage; function checkMessage(){ var message = window.location.hash; // ... } `&lt;/pre&gt; 同样子窗口也可以改变父窗口的片段识别符 &lt;pre&gt;`parent.location.href = target + &quot;#&quot; + hash; `&lt;/pre&gt; #### window.name 浏览器窗口有 `window.name` 属性, 这个属性的最大特点是, 无论是否同源, 只要在同一个窗口里, 前一个网页设置这个属性后, 后一个网页可以读取他 父窗口先打开一个子窗口, 载入一个不同源的网站, 该网页将写入 `widnow.name` 属性 &lt;pre&gt;`window.name = data; `&lt;/pre&gt; 接着, 子窗口跳回一个与主窗口同域的网址 &lt;pre&gt;`location = &apos;http:parent.url.com/xxx.html&apos; `&lt;/pre&gt; 然后主窗口就可以读取子窗口的 `window.name` 属性了 &lt;pre&gt;`var data = document.getElementById(&apos;myFrame&apos;).contentWindow.name; `&lt;/pre&gt; 这种方法的优点是 `window.name` 容量大, 缺点是必须监听子窗口的 `window.name` 属性的变化, 影响性能. #### window.postMessage 以上信息都属于破解, HTML5 为了解决这个问题, 引入一个全新的 API: 跨文档通信 API(Cross-document messaging) 这个 API 为 `window` 对象新增一个 `window.postMessage` 方法, 允许跨窗口通信, 不论两个窗口是否同源. 举例来说, 父窗口 `http://aaa.com` 向子窗口 `http://bbb.com` 发消息, 调用 `postMessage` 方法就可以了 &lt;pre&gt;`var popup = window.open(&apos;http://bbb.com&apos;, &apos;title&apos;); popup.postMessage(&apos;Hello World&apos;, &apos;http://bbb.com&apos;); `&lt;/pre&gt; `postMessage` 方法的第一个参数是要传递的 Message, 第二个参数是接受信息的窗口的源(origin\u0002), 即`协议+域名+端口`, 也可以设置为`*`, 表示不限制域名, 向所有窗口发送. 子窗口向父窗口发送消息的写法类似 &lt;pre&gt;`window.opener.postMessage(&apos;Hello World&apos;, &apos;http://aaa.com&apos;); `&lt;/pre&gt; 通过`message`事件监听对象消息 &lt;pre&gt;`window.addEventListener(&apos;message&apos;, function(e){ console.log(e.data); }, false); `&lt;/pre&gt; `message` 事件的事件对象 `event` , 提供一下三个属性 event.source: 发送信息的窗口, 子窗口通过 event.source 引用父窗口然后发送消息`window.addEventListener('message', receiveMessage); function receiveMessage(event){ event.source.postMessage('Hello Opener', '*'); } ` ‘event.origin’: 发送信息的网址(‘http://aaa.com‘), 可以过滤不是指定来源的信息`window.addEventListener('message', receiveMessage); function receiveMessage(event){ if (event.origin != 'http://aaa.com') return; if (event.data === 'Hello World') { event.source.postMessage('Hello', event.origin); } else { console.log(event.data); } } ` ‘event.data’: 信息内容 LocalStorage通过 window.postMessage 读写其他窗口的 LocalStorage 也是可能的 例: 主窗口写入 iframe 子窗口的 localStorage `window.onmessage = function(event){ if(event.origin !== 'http://bbb.com') return; var payload = JSON.parse(event.data); localStorage.setItem(payload.key, JSON.stringify(payload.data)); }; ` 上面代码中, 子窗口将父窗口发送的消息写入自己的 localStorage 父窗口发送消息的代码如下: `var win = document.getElementByTagName('iframe')[0].contentWindow; var obj = { name: 'Jack' }; win.postMessage(JSON.stringify({key: 'storage', data: obj}), 'http://bbb.com'); ` 加强版子窗口接收消息的代码 `window.onmessage = function(e) { if (e.origin !== 'http://bbb.com') return; var payload = JSON.parse(e.data); switch(payload.method) { case 'set': localStorage.setItem(payload.key, JSON.stringify(parload.data)); break; case 'get': var parent = window.parent; var data = localStorage.getItem(payload.key); parent.postMessage(data, 'http://aaa.com'); break; case 'remove': localStorage.removeItem(payload.key); break; } }; ` 加强版的父窗口消息发送代码 `var win = document.getElementByTagName('iframe')[0].contentWindow; var obj = { name: 'Jack' }; // 存入对象 win.postMessage(JSON.stringify(key: 'storage', method: 'set', data: obj), 'http://bbb.com'); // 读取对象 win.postMessage(JSON.stringify(key: 'storage', method: 'get',), '*'); window.onmessage = function(e){ if(e.origin !== 'http://bbb.com') return; // 'Jack' console.log(JSON.parse(e.data).name); }; ` AJAX同源政策规定, AJAX 请求只能发给同源的网址, 否则会报错 除了假设服务器代理, 有三中方法规避这个限制 JSONPJSONP 是服务器与客户端跨源通信的常用方法, 最大特点是简单实用, 老式浏览器全部支持, 服务器改造非常小. 基本思想是, 网页通过添加一个&amp;lt;script&amp;gt;元素, 向服务器请求 JSON 数据,在何种做法不受同源政策限制. 服务器接收请求后, 将数据放在一个指定名字的回调函数里传回来. 首先, 网页动态插入&amp;lt;script&amp;gt;元素, 由它向跨源网址发出请求. `function addScriptTag(src) { var script = document.createElement('script'); script.setAttribute('type', 'text/javascript'); script.src = src; document.body.appendChild(script); } window.onload = function(){ addScritpTag('http://example.com/ip?callback=foo'); } function foo(data){ console.log(\"Your public IP address is: \" + data.ip); }; ` 上面的代码通过动态添加&amp;lt;script&amp;gt;元素, 向服务器example.com发出请求. 注意, 该请求的查询字符串有一个callback 参数, 用来指定回调函数的名字, 这对 JSONP 是必须的. 服务器接收到这个请求后, 会将数据放在回调函数的参数位置返回. `foo({ 'ip': '8.8.8.8' }); ` 由于&amp;lt;script&amp;gt;元素请求的脚本, 直接作为代码运行, 这时只要浏览器定义了foo函数, 该函数就会立即调用. 作为参数的 JSON 数据会被视为 JavaScript 对象, 而不是字符串, 因此避免了使用JSON.parse的步骤 WebSocketWebSocket 是一种通信协议, 使用ws://(非加密)和wss://(加密)作为协议前缀. 该协议不实行同源政策, 只要服务器支持, 就可以与他进行夸源通信. 下面是一个例子, 浏览器发出的 WebSocket 请求的头信息: `GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==Sec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13Origin: http://example.com 上面代码中, 有一个字段是Origin, 表示该请求的请求源(origin) 正式因为有了Origin这个字段, 所以 WebSocket 才没有实行同源政策, 因为服务器可以根据这个字段判断是否许可此次通信 CORSCORS 是跨源资源分享(Corss-Origin Resource Sharing) 的缩写, 是 W3C 标准, 是跨源 AJAX 请求的根本解决办法. 相比 JSONP 只能发GET请求, CORS 允许任何类型的请求.","link":"/2016/08/02/e6-b5-8f-e8-a7-88-e5-99-a8-e5-90-8c-e6-ba-90-e6-94-bf-e7-ad-96-e5-8f-8a-e5-85-b6-e8-a7-84-e9-81-bf-e6-96-b9-e6-b3-95/"},{"title":"转角跑马灯","text":".marquee{ margin-top:3rem; perspective:500px; font-size:0; font-family:”Microsoft YaHei”, “Segoe UI”, “Lucida Granda”, Helvetica, Arial;}.marquee div{ display:inline-block; height:12rem; width:30rem; position:relative;}.marquee div{ font-size:8rem; overflow:hidden;}.marquee div span{ position:absolute; width:400%; line-height:1.4;}.marquee div:first-of-type{ background:#e5233e; transform-origin: top right; transform: rotateY(-40deg); color:#fff;}.marquee div:last-of-type{ background:#b31e31; transform-origin:top left; transform:rotateY(45deg); color:#f8c9d9;}@keyframes leftcrawl{ to{ transform:translateX(-100rem);}}@keyframes rightcrawl{ to{ transform:translateX(-100rem);}}.marquee div:first-of-type span{ transform:translateX(60rem); animation:leftcrawl 14s linear infinite; text-shadow:4px 0 4px rgba(0,0,0,0.3);}.marquee div:last-of-type span{ transform:translateX(43rem); animation:rightcrawl 14s ease-out infinite;}} 跑马灯 跑马灯 /*HTML*/ div.marquee div&gt;span{跑马灯} div&gt;span{跑马灯} /*CSS*/ .marquee{ margin-top:3rem; perspective:500px; font-size:0; font-family:&quot;Microsoft YaHei&quot;, &quot;Segoe UI&quot;, &quot;Lucida Granda&quot;, Helvetica, Arial; } .marquee div{ display:inline-block; height:12rem; width:30rem; position:relative; } .marquee div{ font-size:8rem; overflow:hidden; } .marquee div span{ position:absolute; width:400%; line-height:1.4; } .marquee div:first-of-type{ background:#e5233e; transform-origin: top right; transform: rotateY(-40deg); color:#fff; } .marquee div:last-of-type{ background:#b31e31; transform-origin:top left; transform:rotateY(45deg); color:#f8c9d9; } @keyframes leftcrawl{ to{ transform:translateX(-100rem); } } @keyframes rightcrawl{ to{ transform:translateX(-100rem);} } .marquee div:first-of-type span{ transform:translateX(60rem); animation:leftcrawl 14s linear infinite; text-shadow:4px 0 4px rgba(0,0,0,0.3); } .marquee div:last-of-type span{ transform:translateX(43rem); animation:rightcrawl 14s ease-out infinite; } }","link":"/2016/06/16/e8-bd-ac-e8-a7-92-e8-b7-91-e9-a9-ac-e7-81-af/"},{"title":"跨域资源共享 CORS","text":"CORS 是一个 W3C 标准, 全称是”跨域资源共享”(cross-origin resource sharing) 他允许浏览器向跨域服务器发出 XMLHttpRequest, 从而克服了 AJAX 只能同源使用的限制 简介CORS 需要浏览器和服务器同时支持. 目前所有浏览器都支持该功能, IE 浏览器不能低于 IE10. 整个 CORS 通信过程, 都是浏览器自动完成, 不需要用户参与, 对于开发者而言, CORS 通信与同源的 AJAX 通信没有差别, 代码完全一样. 浏览器一旦发现 AJAX 跨域请求, 就会自动添加一些附加的头信息. 有时还会多出一次附加的请求, 但是用户不会有感觉. 因此, 实现 CORS 的关键是服务器, 只要服务器实现了 CORS 接口, 就可以跨域通信 两种请求CORS 请求分两类: 简单请求(simple request)和非简单请求(not-so-simple request) 只要同时满足以下两大条件, 就属于简单请求: 请求方法是: HEAD, GET 或者 POST HTTP 头信息不超出以下几种字段: Accept, Accept-Language, Content-Language, Last-Event-ID, Content-Type(只限于三个值: application/x-www-form-urlencoded, multipart/form-data, text/plain) 凡是不能同时满足上面两个条件的, 就属于非简单请求. 简单请求基本流程对于简单请求, 浏览器直接发出 CORS 请求, 具体来说, 就是在头信息中增加一个Origin字段 GET /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... `&lt;/pre&gt; 上面的头信息中, `Origin`字段用来说明, 本次请求来此哪个源(协议+域名+端口), 服务器根据这个值, 决定是否同意此次请求. 如果`Origin`指定的源, 不在许可范围内, 服务器会返回一个正常的 HTTP 响应. **浏览器**发现这个回应的头信息中没有包含`Access-Control-Allow-Origin`字段, 就知道出错了, 从而抛出一个错误, 被`XMLHttpRequest`的`onerror`回调函数捕获. 注意, 这种错误无法通过状态码识别, 因为 HTTP 回应的状态码可能是200. 如果`Origin`指定的域名在许可范围内, 服务器返回的相应, 会多出几个头信息字段 &lt;pre&gt;`Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8 `&lt;/pre&gt; 上面的头信息中, 有三个与 CORS 请求相关的字段, 都以 `Access-Control-` 开头 ##### Access-Control-Allow-Origin 这个字段是必须的, 他的值要么是请求时 `Origin` 的值, 要么是一个 `*`, 表示接收任意域名的请求 ##### Access-Control-Allow-Credentials 该字段是可选的, 是一个布尔值, 表示是否允许发送 Cookie. 默认情况下, Cookie 不包括在 CORS 请求之中. 设为 `true` 表示服务器明确许可, Cookie 可以包括在请求之中, 一起发给服务器 这个值也只能设为`true`, 如果服务器不需要浏览器发送 Cookie, 删除字段即可 ##### Access-Control-Expose-Headers 该字段可选, CORS 请求时, `XMLHttpRequest` 对象的 `getResponseHeader()` 方法只能拿到6个基本字段 - Cache-Control - Content-Language - Content-Type - Expires - Last-Modified -Pragma 如果想要拿到其他字段, 必须在 `Access-Control-Expose-Headers` 里面指定 上面的例子中, `getResponseHeader(&apos;FooBar&apos;)` 可以返回 `FooBar` 字段的值 #### withCredentials 属性 CORS 请求默认不发送 Cookie 和 HTTP 认证信息, 如果要把 Cookie 发送给服务器, 一方面要服务器同意, 指定 `Access-Control-Allow-Credentials` 字段 &lt;pre&gt;`Access-Control-Allow-Credientials: true `&lt;/pre&gt; 另一方面, 开发者需要在 AJAX 请求中打开`withCredientials`属性 &lt;pre&gt;`var xhr = new XMLHttpRequest(); xhr.withCredientials = true; `&lt;/pre&gt; 否则即使服务器同意发送 Cookie, 浏览器也不会发送 要注意, 如果要发送 Cookie, `Access-Control-Allow-Origin` 不能设置为 `*`, 必须指定明确的, 与请求网页一致的域名. 同时 Cookie 依然遵循同源政策, 只有用服务器域名设置的 Cookie 才会上传, 其他域名的 Cookie 不会上传. ### 非简单请求 #### 预检请求 非简单请求是那种对服务器有特殊要求的请求, 比如请求方法是 `PUT`, 或 `DELETE`, 或者 `Content-Type` 字段类型是 `application/json` 非简单请求的 CORS 请求, 会在正是通信钱, 增加一次 HTTP 查询请求, 称为 &quot;预检请求&quot; (preflight) 浏览器先询问服务器, 当前网页所在的域名是否在服务器的许可名单中, 以及可以使用哪些 HTTP 动词和头信息字段, 只有得到肯定的答复, 浏览器才会发出正式的 `XMLHttpRequest` 请求, 否则就报错 下面是一段浏览器的 JavaScript 脚本 &lt;pre&gt;`var url = &apos;http://api.alice.com/cors&apos; var xhr = new XMLHttpRequest(); xhr.open(&apos;PUT&apos;, url, true); xhr.setRequestHeader(&apos;X-Custom-Header&apos;, &apos;value&apos;); xhr.send() `&lt;/pre&gt; 上面代码中, HTTP 请求的方法是 `PUT`, 并且发送一个自定义头信息 `X-Custom-Header` 浏览器发现这是一个非简单请求, 就自动发出一个 &quot;预检&quot; 请求, 要求服务器确认可以这样请求. 下面是这个 &quot;预检&quot; 请求的 HTTP 头信息 &lt;pre&gt;`OPTIONS /cors HTTP/1.1 Origin: http://api.bob.com Access-Control-Request-Method: PUT Access-Control-Request-Headers: X-Custom-Header Host: api.alice.com Connection: keep-alive User-Agent: Molliza/5.0... `&lt;/pre&gt; &quot;预检&quot; 请求用的请求方法是 `OPTIONS`, 表示这个请求是用来询问的, 头信息里面, 关键字段是 `Origin`, &quot;预检&quot; 秦秋的头信息包括两个特殊字段 - Access-Control-Request-Method 这个字段是必须的, 用来列出请求方法 Access-Control-Request-Headers该字段是一个逗号分隔的字符串, 永安里指定浏览器 CORS 请求会格外发送的头信息字段 预检请求的响应服务器取得”预检”请求后, 检查Origin, Access-Control-Request-Method 和 Access-Control-Request-Header 子弹后, 确认允许跨源请求, 就可以做出回应 `HTTP/1.1 200 OK Date: Mon, 01 Dec 2008 01:15:39 GMT Server: Apache/2.0.61 (Unix) Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Content-Type: text/html; charset=utf-8 Content-Encoding: gzip Content-Length: 0 Keep-Alive: timeout=2, max=100 Connection: Keep-Alive Content-Type: text/plain ` 上面 HTTP 响应中, 关键的是 Access-Control-Allow-Origin 字段, 表示 http://api.bob.com 可以请求数据, 该字段也可以设置为*, 表示同意跨源请求. 如果浏览器否定了”预检”请求, 返回一个正常的 HTTP 响应, 但是没有任何 CORS 相关的头信息字段, 这时候浏览器会认为服务器不同意预检请求, 从而触发一个错误, 被 XMLHttpRequest 对象的 onerror 回调函数捕获, 控制台会打印如下报错信息 `XMLHttpRequest cannot load http://api.alice.com. Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. ` 服务器回应其他 CORES 相关字段如下: `Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Access-Control-Allow-Credentials: true Access-Control-Max-Age: 1728000 ` Access-Control-Allow-Method该字段是必须的, 他的值是逗号分隔的一个字符串, 表明服务器支持的跨域请求方式 Access-Control-Allow-Headers如果浏览器包含Access-Control-\u000eRequest-Headers, 则 Access-Control-Allow-Headers 也是必须的, 其值也是一个逗号分隔的字符串 Access-Control-Allow-Credentials该字段与简单请求时的含义相同 Access-Control-Max-Age该字段可选, 永安里指定本次预检请求的有效期(s), 有效期内发起跨域请求不需要预检请求. 浏览器的正常请求与回应一旦服务器通过”预检”请求, 以后每次浏览器正常的 CORS 请求, 都会和简单请求一样, 有一个Origin 头信息字段, 服务器的回应也会有一个Access-Control-Allow-Origin头信息字段 “预检”请求之后, 浏览器的正常 CORS 请求 `PUT /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com X-Custom-Header: value Access-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... ` 其中Origin字段是浏览器自动添加的 服务器的正常回应 `Access-Control-Allow-Origin: http://api.bob.comContent-Type: text/html; charset=utf-8","link":"/2016/08/02/e8-b7-a8-e5-9f-9f-e8-b5-84-e6-ba-90-e5-85-b1-e4-ba-ab-cors/"},{"title":"部署React + Redux 的 Web 开发环境","text":"好的部署需要做到两点:1. 性能优化: 包括代码执行速度, 页面载入速度2. 自动化: 减少重复工作 使用 React+Redux 的时候往往会用到其调试工具 Redux DevTools, 在手动配置 DevTools 时需要针对 Store 和 Component 进行一些配置, 然而这些都是为了方便调试的, 生产环境下我们不希望加入这些东西, 所以建议从代码上隔离 development 和 production 环境: containers/ Root.js Root.dev.js Root.prod.js ... store/ index.js store.dev.js store.prod.js `&lt;/pre&gt; 同时采用单独的入口文件, 比如上面的 containers/Root.js, 按需要加载不同环境的代码 &lt;pre&gt;`if (process.env.NODE_ENV === &apos;production&apos;){ module.exports = require(&apos;./Root.prod&apos;); } else { module.exports = require(&apos;./Root.dev&apos;); } `&lt;/pre&gt; 有一个细节需要注意: ES6 语法不支持在 if 中书写 import 语句, 所以这里采用了 CommonJS 的模块引入方法 require. 另一个需要注意的地方是按需要 import, 否则可能在打包的时候引入不必要的代码 使用 webpack 进行打包工作 &lt;pre&gt;`webpack --config webpack.config.prod.js --progress `&lt;/pre&gt; 注意要为不同的环境准备不同的 webpack 配置文件. 比如 `webpack.config.dev.js` 和 `webpack.config.prod.js` . 看一下比较关键的配置选项 ### devtools 启用 source-map, 这样 webpack 会生成两个包 - bundle.js - bundle.js.map 把用于定位源码的 source map 分离出去, 减少 bundle.js 的体积 source-map 只会在浏览器 devtools 激活时加载, 并不会影响正常页面的饿加载速度. ### plugins &lt;pre&gt;`plugins:[ new webpack.optimize.UglifyJsPlugin({ compress:{ warning: false } }), new webpack.optimize.DedupePlugin(), new webpack.optimize.OccurenceOrderPlugin() ] `&lt;/pre&gt; ### 不要忽视 NODE_ENV NODE_ENV 其实就是一个环境变量, 在 Node 中 可以通过`process.env.NODE_ENV`获取, 目前大家汪汪用这个变量区分当前是 development 还是 production. 通过 webpack 的 DefinePlugin 设置环境变量: &lt;pre&gt;`plugins:[ ... new webpack.DefinePlugin({ &apos;process.env.NODE_ENV&apos;: JSON.stingify(&apos;production&apos;) }) ] ### 添加 hash 前端公认的 Best Practice 就是给资源打上 hash 标签, 这对缓存静态资源很有用 1\\. 给 bundle.js 添加 hash 标签 `&lt;/pre&gt; output{ path: ... filename: &apos;bundle.[hash].js&apos; } &lt;pre&gt;`使用 html-webpack-plugin 这个插件自动生成带有 `&lt;/pre&gt; &amp;lt;script src=&apos;bundle.[hash].js&gt;&amp;lt;/script&gt;&apos;的 html 文件 &lt;pre&gt;`配置如下: `&lt;/pre&gt; plugins:[ ... new HtmlWebpackPlugin({ title:&apos;html title&apos;, template:&apos;./template.html&apos;, favicon: &apos;./static/images/logo.ico&apos; }) ] &lt;pre&gt;`配置 template.html `&lt;/pre&gt; &lt;!DOCTYPE html&gt; &amp;lt;html&gt; &amp;lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1.0&quot;&gt; &amp;lt;/head&gt; &amp;lt;body&gt; &lt;div id=&quot;react-container&quot;&gt;&lt;/div&gt; &amp;lt;/body&gt; &amp;lt;/html&gt; &lt;pre&gt;` 如果需要在 React Component 中添加图片, 建议采用 `&lt;/pre&gt; import LOGO.png from &apos;./static/images/logo.png&apos; &amp;lt;img src={LOGO.png} alt=&quot;&quot; /&gt; &lt;pre&gt;`使用 import 或 require 可以让 webpack 对图片进行打包 使用 file-loader 可以对图片添加 hash 标签然后返回相应的 URL module:{ loaders:[ { test: /.(png|jpg), loader:”file?name=[hash].[ext]” } ]}``` 引入 CSS可以直接在 js 文件中 require('./foo.css'), 然后使用 style-loader 和 css-loader 进行处理, 最终效果是将 css 嵌入到 HTML 的 style 标签中, 这样就不需要使用 hash CSS 较大的话, 可以考虑使用 extract-text-webpack-plugin 插件将 CSS 合并后独立为一个文件, 并自定在页面加载的时候添加 link 标签","link":"/2016/08/20/e9-83-a8-e7-bd-b2react-redux-e7-9a-84-web-e5-bc-80-e5-8f-91-e7-8e-af-e5-a2-83/"},{"title":"高性能 CSS","text":"HTML 和 CSS 本身的性能问题并不突出, 在提高可读性和可维护性的前提下, 如果能让代码运行和解析的速度更快, 则是锦上添花.使用高效的 CSS 选择器首先要知道浏览器如何解析 CSS以 .nav ul.list li div{} 为例浏览器遍历 div, 然后从遍历结果中寻找父集为 li 的对象, 依次进行选择器搜索. 所以如果选择器层级过多, 会导致性能低下.解决方法: 令第一次匹配时的数量最少, 并让整体的匹配查找次数更少.具体做法: 避免使用通配符 避免使用标签选择器和单个属性选择器作为关键选择器 不要在 id 选择器前加标签名 不要设定过多层级, 降低 CSS 和 DOM 结构的耦合度 CSS 相关的图片处理 不给图片设置尺寸: 有时候同一张图会在页面不同低昂多次使用, 比如缩略图, 正常图, 大图等. 如果图片的原始尺寸与实际需求不同, 在使用时通过缩放会给 CPU 带来额外的计算过程, 增加了图片在浏览器中的渲染时间. 网络传输过程也会占用更多带宽, 增加下载时间. 最佳做法是为需要的部分单独做一套图片, 初始页面加载时就能更快显示. 使用雪碧图, 利用 css 进行背景定位, 好处是减少请求次数, 提高图片的整体的加载速度; 缺点是需要精确计算位置(现在有一些工具可用), 维护过程复杂, 要换图片比较复杂 * 在后期使用 CSS Sprite 技术, 因为在开发的时候会比较频繁修改图片 合理组织图片 控制雪碧图的尺寸, 推荐长宽相乘不超过2500, 大小不超过200kb 合理控制背景图单元之间的距离及背景图的位置 借助相关工具 减少 CSS 代码量 定义简洁的 CSS 规则 合并相同的定义 删除无效的定义 其他途径 避免使用@ import 避免使用 IE 浏览器独有的样式 避免使用 CSS 表达式: 动态设置 CSS 属性, 可以通过 js 修改 兼容性查询 caniuse.com css3 click chart css contents and browsers compatibility","link":"/2016/07/15/e9-ab-98-e6-80-a7-e8-83-bd-css/"},{"title":"Enable Sass/scss in Phoenix","text":"Step 1: Add brunch1cd assets &amp;&amp; yarn add sass-brunch Step 2: Add plugin in brunch-config.js123456// brunch-config.jsplugins: { sass: { mode: 'native', },} Step3: Enable hot-reload1234567891011// dev.exs// add sass and scss to the patternconfig :citaDappStore, CitaDappStoreWeb.Endpoint, live_reload: [ patterns: [ ~r{priv/static/.*(js|css|png|jpeg|jpg|gif|svg|sass|scss)$}, ~r{priv/gettext/.*(po)$}, ~r{lib/citaDappStore_web/views/.*(ex)$}, ~r{lib/citaDappStore_web/templates/.*(eex)$} ] ] That’s all.","link":"/2018/04/06/enable-sass-scss-in-phoenix/"},{"title":"Event","text":"In computing, an event is an action or occurrence recognized by software that may be handled by the software. Computer events can be generated or triggered by the system, by the user or in other ways. Typically, events are handled synchronously with the program flow, that is, the software may have one or more dedicated places where events are handled, frequently an event loop. A source of events includes the user, who may interact with the software by way of, for example, keystroke on the keyboard. Another source is a hardware device such as a timer. Software can be trigger its own set of events into the event loop, e.g. to communicate the completion of a task. Software that changes its behavior in response to events is said to be event-driven, often with the goal of being inactive. Event handlerIn computer programming, an event handler is a callback subroutine that handles inputs received in a program(called a listener in Java and JavaScript). Each event is a piece of application-level information from the underlying framework, typically the GUI Toolkit. GUI events including key presses, mouse movement, action selections, and timer expiring.","link":"/2016/07/18/event/"},{"title":"Flex 属性详解","text":"display: flex|inline-flex; (修饰Flex Container, 也就是 Flex Item的父级元素)该属性修饰的元素, 其子元素将变成 flex 文档流, 称为 Flex Item 注意: CSS 的 columns 在 FlexContainer 上没有作用; float, clear, vertical-align 在 FlexItem 上没有作用 flex-direction: row|row-reverse|column|column-reverse(修饰 Flex Container)用于定义main-axis, 从而定义 flex 文档流方向 flex-wrap: nowrap|wrap|wrap-reverse; (修饰 Flex Container)nowrap: 单行显示; wrap: 多行显示; wrap-reverse: 逆向多行显示 flex-flow: &lt;’flex-direction’&gt;||&lt;’flex-wrap’&gt;; (修饰 Flex Container)这个是 flex-direction 和 flex-wrap 的缩写, 同时定义主轴和侧轴的文档流向 justify-content:flex-start|flex-end|center|space-between|space-around; (修饰 Flex Container)定义主轴线上 Flex Item 的对齐方式 flex-start: 向起始位置对齐; flex-end: 向结束位置对齐; center: 向中间靠拢; space-between: 首位 item 位于边界, 所有 items 均匀分布; space-around: 首位 item 距离边界1space, 所有 item 之间距离2space align-item: flex-start|flex-end|center|baseline|stretch; (修饰 Flex Container)定义 item 在侧轴方向的对齐方式 align-content: flex-start|flex-end|center|space-between|space-around|stretch(default); (修饰 Flex Container)校准 item 在 container 中的对齐方式, 类似于 justify-content, 本属性在单行的容器中没有效果 order: ; (修饰 Flex Item)手动指定显示顺序 flex-grow: ; (修饰 Flex Item)定义 Item 的扩张能力, 接受一个不带单位的值作为一个比例, 主要用来决 Item 对 Container 剩余空间的利用 flex-shrink: ; (修饰 Flex Item)定义 Item 的收缩能力 flex-basis: |auto(default); (修饰 Flex Item)设置伸缩基准, 剩余的空间按照比例伸缩 flex: none|[&lt;’flex-grow’&gt;&lt;’flex-shrink’&gt;? || &lt;’flex-basis’&gt;]; (修饰 Flex Item)flex-grow, flex-shrink, flex-basis 的缩写; 其中, 第二个和第三个参数是可选参数. 默认值是0 1 auto align-self: auto|flex-start|flex-end|center|baseline|stretch; (修饰 Flex Item)用于覆盖单个 Item 的对齐方式.","link":"/2016/09/17/flex-e5-b1-9e-e6-80-a7-e8-af-a6-e8-a7-a3/"},{"title":"Flux Standard Action","text":"Example: A basic Flux Standard Action { type: ‘ADD_TODO’, payload: { text: &apos;Do something&apos;, }}` An FSA that represents an error, analogous to a rejected Promise: `{ type: ‘ADD_TODO’, payload: new Error(), error: true,} Notice:1. An action MUST be a plain JavaScript Object have a type property An action MAY: have a error property have a payload property have a meta property An action MUST NOT include properties other than type, payload, error, meta TypeThe type of an action identifies to the consumer the nature of the action that has occurred. Two actions with same type MUST be strictly equivalent (using ===). By convention, type is usually string constant or a Symbol. payloadThe optional payload property MAY be any type of value. It represents the payload of the action. Any information about the action that is not the type or status of the action should be part of the payload filed. By convention, if error is true, the payload SHOULD be an error object. This is akin to rejecting a promise with an error object. errorThe optional error property MAY be set to true if the action represents an error. An action whose error is true is analogous to a rejected Promise. By convention the payload SHOULD be an error object. If error has any other value besides true, including undefined and null, the action MUST NOT be interpreted as an error. metaThe optional meta property MAY be any type of value. It is intended for any extra information that is not part of the payload.","link":"/2016/11/06/flux-standard-action/"},{"title":"解决 CommonsChunkPlugin 的 Hash 变化问题","text":"原文: Manifest File But, if we change application code and run webpack again, we see that the hash for the vendor file changes. Even though we achieved separate bundles for vendor and main bundles, we see that the vendor bundle changes when the application code changes. This means that we still don’t reap the benefits of browser caching because the hash for vendor file changes on every build and the browser will have to reload the file. The issue here is that on every build, webpack generates some webpack runtime code, which helps webpack do it’s job. When there is a single bundle, the runtime code resides in it. But when multiple bundles are generated, the runtime code is extracted into the common module, here the vendor file. To prevent this, we need extract out the runtime into a separate manifest file. Even though we are creating another bundle, the overhead is offset by the long term caching benefits that we obtain on the vendor file. 非翻译:每次打包时 vendor 文件的 hash 也会变化的原因在于, webpack 打包时必定会产生 runtime code. 当我们需要打包出 vendor.js 的时候, 尽管公共代码没有变化, 但是 webpack 会生成新的 runtime code 并注入 vendor.js, 导致其 hash 变化. 解决方法:将 vendor.js 中的 runtime code 单独打包出来, 这样只有 bundle.js 和 runtime code 的 hash 会变化, vendor.js 的代码不会变化. 具体做法:new webpack.optimize.CommonsChunkPlugin({ name: [&apos;vendor&apos;, &apos;manifest&apos;], } 这样就可以把 runtime code 打包进 manifest.js, 此后该类操作不会改变 vendor.js 的 hash 了","link":"/2017/02/01/e8-a7-a3-e5-86-b3-commonschunkplugin-e7-9a-84-hash-e5-8f-98-e5-8c-96-e9-97-ae-e9-a2-98/"},{"title":"Functor 函子","text":"class Functor { constructor (val) { this.__val = val } map (fn) { return new Functor(fn(__this.value)) } } 即将范畴 Functor@val 通过 fn 映射为范畴 Function@fn(val) Functor 本身具有 map 方法, 通过各种函数作为运算符, 映射成新的Functor","link":"/2017/02/27/functor-e5-87-bd-e5-ad-90/"},{"title":"Generator 101","text":"function * HelloGen(){ yield 100; yield 400; } var gen = HelloGen(); console.log(gen.next()); // {value: 100, done: false} console.log(gen.next()); // {value: 400, done: false} console.log(gen.next()); // {value: undefined, done: true} `&lt;/pre&gt; &lt;pre&gt;`function * HelloGen2() { var a = yield 100; var b = yield a + 100; console.log(b); } var gen2 = HelloGen2(); console.log(gen2.next()); // {value: 100, done: false} console.log(gen2.nect(500)); // {value: 600, done: false} console.log(gen2.next(1000)); // {value: undefined, done: done} // prints 1000 `&lt;/pre&gt; ### Preventing Callback Hell So, how can generators be used to avoid callback hell? First, you need to understand a simple technique that we will be using heavily with generators to write code without callbacks. #### Understanding Thunks A thunk is a partially evaluated function which accepts a single callback as the argument. Within generators, we&apos;ll be yielding thunks to write without callbacks. A simple thunk is shown below. &lt;pre&gt;`function(callback) { fs.readFile(&apos;myfile.md&apos;, &apos;utf8&apos;, callback) } `&lt;/pre&gt; Thunks can also be created dynamically as shown below: &lt;pre&gt;`function readFile(filename) { return function(callback) { fs.readFile(filename, &apos;utf8&apos;, callback); }; } `&lt;/pre&gt; #### Using `co` `co` is a nice module which helps to use thunks and generators together to create Node.js applications without callbacks. A simple application which uses `co` and the `readFile()` thunk. &lt;pre&gt;`var co = require(&apos;co&apos;); co(function* (){ var file1 = yield readFile(&apos;file1.md&apos;); var file2 = yield readFile(&apos;file2.md&apos;); console.log(file1); console.log(file2); })(); `&lt;/pre&gt; As you can see, we are no longer using callbacks. This gives us a simple way to write large modular Node apps easily. ###### How `co` Works Internally First, it calls next(null) and gets a thunk. Then, it evaluate the thunk and saves the result. Then, it calls next(savedResult)(in this case, saveResult == readFile(‘file1.md’), and next(savedResult) pass the content to var file1) Repeat these steps until next() return {done: true} A minimal version of co written to show how it works internally. ```function co(generator){ var gen = generator(); function nextItem(err, result) { var item = gen.next(result); `if (!item.done) { item.value(nextItem); // item.value is a thunk, because yield a thunk} } nextItem();}","link":"/2016/07/30/generator-101/"},{"title":"Git Cheat Sheet","text":"列出当前配置: git config --list 列出 repository 配置: git config --local --list 列出全局配置: git config --global --list 设置 git 输出彩色: git config --global color.ui auto 显示与上次提交版本的不同: git diff 提交历史: git log 显示所有提交历史: git log --oneline 列出所有分支: git branch 列出远程分支: git branch -r 切换分支: git checkout &amp;lt;branch&amp;gt; 给当前版本添加 tag: git tag &amp;lt;tag-name&amp;gt; 列出当前配置的远程端: git remote -v 添加远程端: git remote add &amp;lt;remote-name&amp;gt; &amp;lt;url&amp;gt; 下载远程端但不 merge: git fetch &amp;lt;remote&amp;gt; 下载远程端并自动 merge: git pull 删除远程端分支: git push &amp;lt;remote&amp;gt; --delete &amp;lt;branch&amp;gt; 发布标签: git push --tags 回滚到上个 commit: git reset --hard HEAD 回滚到某个版本: git reset --hard &amp;lt;commit&amp;gt; 清除 staged: git reset HEAD","link":"/2016/08/27/git-cheat-sheet/"},{"title":"Git Commands","text":"git init to init a working space into a git repo git add filename or git add . to track file or all files, and add them to stage git commit -m &quot;message&quot; to commit changes to local repo Several files can be commited together: git add file1; git add file2; git commit -m &quot;add 2 files&quot; Use regx: git add &quot;*.txt&quot;; git commit -m &quot;add all text&quot; git status to check which file has been modified git diff filename to check details of modification in filename git log to show logs git log --pretty to show concise info of log, git log --graph --pretty=online --abbrev-commit for more info git reset --hard HEAD^ to recover to last commit git reset --hard ID to recover to specific version git checkout -- filename to dismiss modification in local working space, e.g. if you delete text.txt in working space and want to recover it, git checkout -- text.txt can pull it from local repo to working space git reset HEAD filename to recover file from local repo rm filename to delete file in working space, only phisically delete the file without log git rm filename to delete file in working space and add a deletion operation in log waiting for commit git remote add origin **https** to connect to a remote repo git push -u origin master to push local repo to remote repo. -u for first push, it will connect local and remote repo for pull and push in future git clone **https** to clone a remote repo to local position git checkout -b dev create a new branch named dev, and switch to it. This command equals to git branch dev; git checkout dev git branch to check current branch git merge dev to merge modification from dev to current branch git branch -d dev to delete branch dev git merge is Fast Forward mode which will lose merge log, git merge --no-ff -m &quot;merge with no-ff&quot; will keep the merge log and make a new commit(so it needs a -m), with –no-ff you can see the merge in log Bug Branchgit stash to keep current working space git stash git checkout master git checkout -b bug-101 *fix the but* git add . git commit -m &apos;fix but-101&apos; git checkout master git merge --no-ff &apos;merge bug-101 fix&apos; bug-101 git branch -d but-101 git checkout dev #return to previous working branch git stash list #check kept working space, e.g. *stash@{0}: ... git stash apply stash@{0} #recover the working space without delete it in the list **or** git stash pop stash@{0} #recover and delete it in the list `&lt;/pre&gt; ### Omit unmerged Branch &lt;pre&gt;`git checkout -b new-feature #new branch for feature development git add featurefile git commit -m &quot;add new feature&quot; git checkout dev *requirement changed, the feature is dismissed* *new feature has not been merged, so need force Delete* git branch -D new-feature `&lt;/pre&gt; ### Coordination &lt;pre&gt;`git remote #return remote repo name, e.g. origin git remote -v #return details git push origin dev #push current branch to origin dev git checkout -b dev origin/dev #create a dev, and push it to origin/dev git pull #git fetch and merge to current branch","link":"/2016/05/21/git-commands/"},{"title":"Git Merge and Rebase","text":"Conceptual OverviewThe first thing to understand about git rebase is that it solves the same problem as git merge. Both of these commands are designed to integrate changes from one branch into another branch – they just do it in very different ways. Consider what happens when you start working on a new feature in a dedicated branch, then another team member updates the master branch with new commits. The results in a forked history which should be familiar to anyone who has used Git as a collaboration tool. Now, let’s say that the new commits in master are relevant to the feature that you’re working on. To incorporate the new commits into your feature branch, you have two options: merginor rebasing. The Merge OptionThe easiest option is to merge the master branch into the feature branch using something like the following: 12git checkout featuregit merge master Or you can condense this to a one-liner: 1git merge master feature This creates a new merge commit in the feature branch that ties together the histories of the both branches, giving you a branch structure that looks like this: Merging is nice because it’s a non-destructive operation. The existing branches are not changed in any way. This avoids all of the potential pitfalls of rebasing. On the other hand, this also means that the feature branch will have an extraneous merge commit every time you need to incorporate upstream changes. If master is very active, this can pollute your feature branch history quite a bit. While it’s possible to migrate this issue with advanced git log options, it can make it hard to other developers to understand the history of the project. The Rebase OptionAs an alternative to merge, you can rebase the feature branch onto master branch using the following commands: 12git checkout featuregit rebase master This moves the entire feature branch to begin on the top of the master branch, effectively incorporating all of the new commits in master. But, instead of using a merge commit, rebasing re-writes the project history by creating brand new commits for each commit in the original branch. The major benefit of rebasing is that you get a much cleaner project history. First, it eliminates the unnecessary merge commits required by git merge. Second, as you can see in the above diagram, rebasing also results in a perfectly linear project history – you can follow the top of feature all the way to the beginning of the project without any forks. This makes it easier to navigate your project with commands like git log. Interactive RebasingInteractive rebasing gives you the opportunity to alter commits as they are moved to the new branch. This is even more powerful than an automated rebase, since it offers complete control over the branch’s commit history. Typically, this is used to clean up a messy history before merging a feature branch into master. To begin an interactive rebasing session, pass the -i option to the git rebase command. 12git checkout featuregit rebase -i master This will open a text editor listing all of the commits that are about to be moved: 123pick 33d5b7a Message for commit #1pick 9480b3d Message for commit #2pick 5c67e61 Message for commit #3 This listing defines exactly what the branch will look like after the rebase is performed. By changing the pick command and/or reordering the entries, you can make the branch’s history look like whatever you want. For example, if the 2nd commit fixes a small problem in the 1st commit, you can condense them into a single comit with the fixup command: 123pick 33d5b7a Message for commit #1fixup 9480b3d Message for commit #2pick 5c67e61 Message for commit #3 When you save and close the file, Git will perform the rebase according to your instructions, resulting in project history that looks like the following: Eliminating insignificant commits like this makes your feature’s history much easier to understand. This is something that git merge simply cannot do. The Golden Rule of RebasingThe Golden Rule of git rebase is to never use it on public branches. For example, think about what would happen if you rebased master onto your feature branch. The rebase moves all of the commits in master onto the tip of feature. The problem is that only happened in your repo. All of the other developers are still working with the origin master. Since rebasing results in brand new commits, Git will think that your master branch’s history has diverged from everybody else’s. The only way to synchronize the two master branches is to merge them back together, resulting in an extra merge commit and two sets of commits that contain the same changes.","link":"/2017/06/14/git-merge-and-rebase/"},{"title":"Graphql-Koa-Starter","text":"Init ProjectAdd tsconfig12345678910111213141516171819202122// tsconfig.json{ \"files\": [ \"server.ts\" ], \"compilerOptions\": { \"outDir\": \"./build\", \"target\": \"es2015\", \"module\": \"commonjs\", \"moduleResolution\": \"Node\", \"sourceMap\": true, \"pretty\": true, \"strictNullChecks\": true, \"lib\": [ \"esnext\" ] }, \"exclude\": [ \"node_modules\", \"build\" ]} Add tslint123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100// tslint.json{ \"rules\": { \"align\": [ true, \"parameters\", \"arguments\", \"statements\" ], \"ban\": false, \"class-name\": true, \"curly\": true, \"eofline\": true, \"forin\": true, \"indent\": [ true, \"spaces\" ], \"interface-name\": false, \"jsdoc-format\": true, \"label-position\": true, \"max-line-length\": [ true, 140 ], \"member-access\": false, \"member-ordering\": [ true, \"public-before-private\", \"static-before-instance\", \"variables-before-functions\" ], \"no-any\": false, \"no-arg\": true, \"no-bitwise\": true, \"no-conditional-assignment\": true, \"no-console\": [ true, \"debug\", \"info\", \"time\", \"timeEnd\", \"trace\" ], \"no-construct\": true, \"no-debugger\": true, \"no-shadowed-variable\": true, \"no-duplicate-variable\": true, \"no-empty\": false, \"no-eval\": true, \"no-inferrable-types\": false, \"no-internal-module\": true, \"no-require-imports\": true, \"no-string-literal\": false, \"no-switch-case-fall-through\": true, \"no-trailing-whitespace\": false, \"no-var-keyword\": true, \"no-var-requires\": true, \"one-line\": [ true, \"check-open-brace\", \"check-catch\", \"check-else\", \"check-whitespace\" ], \"quotemark\": [ true, \"single\", \"jsx-single\", \"avoid-escape\" ], \"radix\": true, \"semicolon\": false, \"switch-default\": false, \"triple-equals\": [ true, \"allow-null-check\" ], \"typedef\": false, \"typedef-whitespace\": [ true, { \"call-signature\": \"nospace\", \"index-signature\": \"nospace\", \"parameter\": \"nospace\", \"property-declaration\": \"nospace\", \"variable-declaration\": \"nospace\" } ], \"variable-name\": false, \"whitespace\": [ true, \"check-branch\", \"check-decl\", \"check-operator\", \"check-separator\", \"check-type\" ] }} Add env1234567891011121314// env.tsimport * as envalid from 'envalid'const { url, bool, str } = envalidconst env = envalid.cleanEnv(process.env, { SERVICE_URI: str({ default: 'https://reqres.in/api' }), NODE_ENV: str({ devDefault: 'development', default: 'production' }), LOG_LEVEL: str({ default: 'info' }), CORS: bool({ devDefault: true, default: false }), GRAPHIQL: bool({ devDefault: true, default: true }),})export default env Add Nodemon123456{ \"watch\": [\"src\"], \"ext\": \"ts\", \"ignore\": [\"src/**/*.spec.ts\"], \"exec\": \"ts-node ./server.ts\"} Create Koa APP123456789101112131415// src/app.tsimport * as Koa from 'koa'import * as cors from 'koa-cors'import * as convert from 'koa-convert'import { apiRouter } from './routers'const app = new Koa()if (process.env.CORS) { app.use(convert(cors()))}app.use(apiRouter.routes()).use(apiRouter.allowedMethods())export default app Server Startup123456789101112131415161718192021// server.tsimport * as chalk from 'chalk'import env from './env'process.env = envimport app from './src/app'const port = process.env.PORT || 3001app.listen(port, () =&gt; { if (process.env.NODE_ENV === 'development') { if (process.env.GRAPHIQL) { console.log('The GraphiQL App is running at: ') console.log(chalk.cyan(`http://localhost:${port}/api/graphiql`)) } else { console.log('Koa app is running at: ') console.log(chalk.cyan(`http://localhost:${port}`)) } } else { console.log('Koa App is running') }}) Add Router1234567891011121314151617181920212223242526// ./src/routers/graphql.tsimport * as Router from 'koa-router'import * as GraphQLHttp from 'koa-graphql'import schema from '../graphql/schema'const router = new Router()// console.log(process.env)console.log(process.env)router.all('/', GraphQLHttp({ schema, graphiql: process.env.GRAPHIQL, pretty: true, errorFormat: error =&gt; { const { message, locations, path, stack } = error console.error(`GraphQL Error: `, { message, locations, path, stack, }) }}))export default router 123456789101112131415// ./src/routers/index.tsimport * as Router from 'koa-router'import graphQLRouter from './graphql'import testRouter from './test'const apiRouter = new Router({ prefix: '/api'})apiRouter.use('/graphql', graphQLRouter.routes(), graphQLRouter.allowedMethods())apiRouter.use('/test', testRouter.routes(), testRouter.allowedMethods())export { apiRouter} Config Graphql1234567891011121314151617181920212223242526272829// ./src/graphql/model.tsimport { GraphQLObjectType, GraphQLString, GraphQLNonNull,} from 'graphql'const User = new GraphQLObjectType({ name: 'User', description: 'A User', fields: () =&gt; ({ id: { type: new GraphQLNonNull(GraphQLString), resolve: (user) =&gt; user.id, }, firstName: { type: new GraphQLNonNull(GraphQLString), resolve: user =&gt; user.first_name }, lastName: { type: new GraphQLNonNull(GraphQLString), resolve: user =&gt; user.last_name } })})export { User} 12345678910111213141516171819// ./src/graphql/query.tsimport { GraphQLObjectType, GraphQLList } from 'graphql'import axios from 'axios'import { User } from './model'export default new GraphQLObjectType({ name: 'Query', description: 'Query of GraphQL', fields: () =&gt; ({ users: { type: new GraphQLList(User), resolve: (root, args) =&gt; { return axios({ url: 'https://reqres.in/api/users', }).then(res =&gt; res.data).then(res =&gt; res.data) } } })}) 1234567// ./src/graphql/schema.tsimport { GraphQLSchema } from 'graphql'import query from './query'export default new GraphQLSchema({ query})","link":"/2017/09/15/graphql-koa-starter/"},{"title":"Gulp 能够解决哪些问题","text":"通常一个前端构建流程包括: 文件清理: gulp-clear 文件拷贝: gulp-copy 文件转换: gulp-webpack 文件合并: gulp-concat 文件压缩: gulp-minify 文件服务: gulp-connect 文件监控: gulp-watch css 相关: less, sass 转换(gulp-less, gulp-sass) css 自动添加前缀(gulp-autoprefixer) js 相关: jslint(gulp-jshint) html 转换 html 模板(gulp-jade, gulp-ejs) html prettify html validator html min Gulp 通过定义gulpfile.js配置文件的方式定义流程, gulp.js 会通过调用 Node.js 来执行流程. 引入插件var gulp = require(&quot;gulp&quot;), ... `&lt;/pre&gt; ### 设定路径 &lt;pre&gt;`var paths = { styles:{ src: &quot;src/styles/**/*.less&quot;, dest: &quot;assets/styles/&quot; }, scripts:{ src: &quot;src/scripts/**/*.js&quot;, dest: &quot;assets/scripts/&quot; } }; `&lt;/pre&gt; ### 设定任务 &lt;pre&gt;`gulp.task(&quot;taskName&quot;, function(){ gulp.src(paths.styles.src) .pipe(task()) .pipe(gulp.dest(paths.styles.dest)); }); `&lt;/pre&gt; 一个 gulpfile.js 文件只是一个 Node 程序, 在 gulpfile 中可以使用任何 npm 中的模块或者其他 Node.js 并非所有的任务都是基于流, 例如删除文件 &lt;pre&gt;`function clean(){ //del 也可以和 gulp.src 一样基于模式匹配的文件路径定义方式 return del([&quot;assets&quot;]); } `&lt;/pre&gt; 如果要控制 task 顺序, 可以通过回调函数实现 gulp.task(taskName, function(fn){}) 现在新增加了串行和并行 API - gulp.parallel: 并行执行 - gulp.series: 串行执行 e.g. &lt;pre&gt;`gulp.task(&quot;one&quot;, function(done){ //do stuff done(); //回调函数 }) gulp.task(&quot;two&quot;, function(done){ //do stuff done(); }); //并行执行任务, 执行完后可以添加回调函数 gulp.task(&quot;parallelTask&quot;, gulp.parallel(&quot;one&quot;, &quot;two&quot;, function(done){ done(); })); //串行任务 gulp.task(&quot;seriesTask&quot;, gulp.series(&quot;one&quot;, &quot;two&quot;, function(done){ done(); })); `&lt;/pre&gt; ### 前端常用插件 gulp-sass: 编译 SASS browser-sync: 保持多浏览器, 多设备同步 gulp-imagemin: 压制 png/jpg/git/svg 图片 gulp-minify-css: 压缩 CSS gulp-rename gulp-concat: 合并 JS gulp-uglify: 压缩 JS gulp-autoprefixer: 添加前缀 gulp-css-spriter: 生成雪碧图 gulp-htmlmin gulp-server-livereload 拥有live-reloading的服务器使用 BrowserSync 和 gulp, 你可以轻松创建一个开发服务器, 然后同一个WiFi 中的任何设备都可以方便访问.BrowserSync 同时集成了 live-reload, 所以不需要做另外的配置. 首先安装模块npm install brower-sync --save-dev假设目前目录结构为 `gulpfile.js app/ styles/ main.css scripts/ main.js index.html ` 配置 gulpfile.js, 将 app 目录中的文件加入到服务器中, 并且所有的浏览器会在文件发生变化后自动刷新 `var gulp = requrie(\"gulp\"); var browserSync = require(\"browser-sync\").create(); var reload = browerSync.reload; //监视文件改动并重新载入 gulp.task(\"browser-sync\", function(){ browserSync.init({ server:{ baseDir: 'app' } }); gulp.watch(['*.html', 'styles/**/*.css', 'scripts/**/*.js'], {cwd: 'app'}, browserSync.reload); }); ` CSS 预处理指定浏览器无需刷新即可重载 CSS假设目录如上 `var gulp = require(“gulp”);var sass = require(“gulp-ruby-sass”);var browserSync = require(“browser-sync”).create(); gulp.task(“sass”, function(){ return sass(&quot;styles/**/*.scss&quot;) .pipe(gulp.dest(&quot;app/css&quot;) .pipe(reload({stream:true})); {);/*gulp.task(“sass”, function(){ gulp.src(&quot;styles/**/*.scss&quot;) .pipe(sass({outputstyle: &apos;compressed&apos;}).on(&apos;error&apos;,sass.logError)) .pipe(gulp.dest(&quot;app/css&quot;); });*/gulp.task(“browser-sync”, [“sass”], function(){ browserSync({ server: { baseDir: &quot;app&quot;; } }); gulp.watch(&quot;app/styles/**/*.scss&quot;, [&quot;sass&quot;], browserSync.reload); }); 设置tunnel: true 来使用一个公开的 URL 来访问本地站点","link":"/2016/07/15/gulp-e8-83-bd-e5-a4-9f-e8-a7-a3-e5-86-b3-e9-82-a3-e4-ba-9b-e9-97-ae-e9-a2-98/"},{"title":"H5 移动端注意点","text":"使用 rem 作为单位 给手机这是 100px 的字体大小, 对于320px 的手机匹配是100px, 其他手机都是按比例分配, 因此设计稿上多少像素的话, rem = 设计稿像素/100 禁用 a, button, input, opigroup, select, textare 等标签背景变暗 在移动端使用 a 标签作为按钮或文字链接的时候, 点击按钮会出现一个暗色背景, 需要在 css 中加入 a, button, input, textarea, optgroud, select{ -webkit-tap-highlight-color: rgba(0,0,0,0) } `&lt;/pre&gt; meta 基础知识 页面窗口自动调整到设别宽度, 并禁止用户缩放页面 `&lt;meta name=\"viewport\" content=\"width=device-width,initial-width:1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=0\"/&gt; ` 忽略页面中的数字识别为手机号 `&lt;meta name=\"format-detection\" content=\"telephone=no\"/&gt; ` 忽略 Android 平台对邮箱地址的识别 `&lt;meta name=\"format-detection\" content=\"email=no\"/&gt; ` 当网站添加到主屏时可隐藏地址栏, 仅针对 ios 的 safari `&lt;meta name=\"apple-mobile-web-app-capable\" content=\"yes\"/&gt; ` 移动端定义字体 `body{ font-family:\"Helvetica Neue\", Helvetica, sans-serif; } ` 设置拨打电话 `&lt;a href=\"tel:1242432423\"&gt;1242432423&lt;/a&gt; ` 设置发送短信 `&lt;a href=\"sms:123124325434\"&gt;123124325434&lt;/a&gt; ` 设置发送邮箱 `&lt;a href=”mailto:131321@21312.com”&gt;发送邮件&lt;/a&gt; 8, calc 语法, 兼容 IE9+, FF4.0, Chrome19+, Safari6+","link":"/2016/08/25/h5-e7-a7-bb-e5-8a-a8-e7-ab-af-e6-b3-a8-e6-84-8f-e7-82-b9/"},{"title":"Http Cache: Etag, Last-Modified, Cache-Control","text":"Cache-ControlCache-Control general-header field is used to specify deirectives that MUST be obeyed by all caching mechanisms along the request/response chain. When the Cache-Control allow to cache, like Cache-Control: public, max-age: 86400, it means that in this day the browser can use the cahce directly without any request to server.a 1234567import http: 'http'let server = http.createServer((req, res) =&gt; { res.setHeader('Cache-Control', 'public', 'max-age=86400') res.end('hello world')})server.listen(3000) EtagUsed for conditional HTTP request. Etag represents Version of Resource, browser will add If-None-Match in headers with request. If the resource on server has not been modified, code 304 will be returned. 123456789101112131415import http from 'http'let server = http.createServer((req, res) =&gt; { console.log(req.url, req.headers['if-none-match']) if (req.headers['if-none-match']) { // check if resource modified res.statusCode = 304 res.end() } else { res.setHeader('Etag', '0000000') res.end('hello world') }})server.listen(3000) Last-ModifiedSimilar to Etag, Last-Modified represents if the resource modified. It uses time when modified instead of version tag. The key in header is If-Modified-Since 123456789101112131415import http from 'http'let server = http.createServer((req, res) =&gt; { console.log(req.url, req.headers['if-modified-since']) if (req.headers['if-modified-since']) { // check timestamp res.statusCode = 304 res.end() } else { res.setHeader('Last-Modified', new Date().toString()) res.end('hello world') }})server.listen(3000)","link":"/2017/08/01/http-cache-Etag-Last-Modified-Cache-Control/"},{"title":"Gulp 自动化部署快速入门","text":"$ npm install —g gulp全局安装 安装前保证已经安装了 ruby $ npm install —save-dev- gulp作为项目的开发依赖( devDependence)安装到项目目录 在项目根目录下创建一个名为gulpfile.js的文件: //引用 gulp plugin var gulp = require(‘gulp’);//建立 gulp taskgulp.task(‘default’, function(){ //任务代码})&lt;/pre&gt; 在项目根目录运行 gulp 时, gulp 会直接读取gulpfile.js`中定义的任务并执行. gulp 可以将每一个你要执行的工作命名, 而默认运行的task 名为default $ gulp`运行 gulp, 运行默认的名为’ default’ 的任务( task) gulp &amp;lt;task&amp;gt; &amp;lt;othertask&amp;gt;运行指定 task gulp 基本 API gulp.src(globs[, options]) * `glob`参考 [node-glob 语法](https://github.com/isaacs/node-glob), 也可以直接写文件的路径 options:略 gulp.dest(path[,options]) * 能被`pipe`进来, 并能写文件到文件夹, 如果文件夹不存在, 则自动创建文件夹. path: String 或 Function, 可以直接写输出目录, 也可以传入一个返回路径的函数 options:略 gulp.task(name[, deps], fn) * &lt;pre&gt;`gulp.task(&apos;script&apos;,function(){ //待执行})` name: 赋予任务名称 deps: 任务列表数组, 这些任务会在当前任务运行之前完成 * task 默认以最大并发数执行, 也就是说 gulp 会一次性执行所有 task 并不做任何等待, 如果要以特定顺序执行, 需要: * 给出一个提示, 告知 task 什么时候执行完毕 * 再给出一个提示, 告知 task 依赖另一个 task 的完成 * 1234567891011var gulp = require(&apos;gulp&apos;);//返回一个 callback, 因此系统可以知道他什么时候完成gulp.task(&apos;one&apos;, function(cb){//执行一些任务 cb(err); //如果 err 不是 null 或者 undefined, 则会停止执行, 这样代表执行失败.});//定义一个所以来的 task 必须在这个 task 执行之前完成gulp.task(&apos;two&apos;, [&apos;one&apos;], function(){ //&apos;one&apos;完成后要执行的任务})gulp.task(&apos;default&apos;, [&apos;one&apos;, &apos;two&apos;]); fn:要执行的操作 gulp.watch(glob [, opts], tasks) * 监听文件, 并可以在文件发生改动的时候做一些事情, 他总会返回一个 EventEmiiter 来发射`change`事件. glob: 指定具体监听哪些文件的变动 tasks: 需要在文件变动后执行的任务 * &lt;pre&gt;`var watcher = gulp.watch(&apos;js/**/*.js&apos;, [&apos;uglify&apos;, &apos;reload&apos;]); watcher.on(‘change’, function(event){console.log(‘File’+event.path+’ was ‘+event.type+’, running tasks…’);});` 工作流程 设定任务 * gulp 可以对不同的 task 命名, 而 default 是默认的人物名称, 如果执行 gulp 的时候没有指定任务名称, 则会执行`default` 任务. `//载入 gulp plugin var gulp = require('gulp'); //定义名称为 default 的 gulp 任务 gulp.task('default', function(){ console.log('Hello Gulp Default Task'); }); //定义名称为 other 的 gulp 任务 gulp.task('other', function(){ console.log('Hello Gulp Other Task'); }) ` 执行指定的 gulp 任务 * &lt;pre&gt;`$ gulp ` * 执行默认的 default 任务 `$ gulp other ` * 执行任务`other` `$ gulp.task('default', ['other', 'script']); ` * 在 default 任务中设定要执行的任务队列可以执行多个任务 监听 * 比如我们使用`gulp-uglify`最小化 JS 时, 希望可以在每次改动 JS 的时候自动执行 gulp 最小化动作 * &lt;pre&gt;`var gulp = require(&apos;gulp&apos;), gulpUglify = require(‘gulp-uglify’);gulp.task(‘script’, function(){gulp.src(‘javascript/original/*.js’) //指定要处理的原始 JS 目录.pipe(gulpUglify()) //执行最小化.pipe(gulp.dest(‘javascript/minify’)); //最小化后部署到 JS 目录})` 添加监听 * &lt;pre&gt;`gul.task(&apos;watch&apos;, function(){ gulp.watch(‘javascript/original/*.js’, [‘script’]);})` `$ gulp watch //执行监听 ` * 执行监听后, 每次改动 javascript/origin/*.js 中所有 JS 文件时都会重新执行 script 任务. 可以用**监听所有文件 可以将watch添加到任务列表, 这样只需要指令gulp就可以执行监听 例外处理 * 经历例外错误记录任务 * 由于例外错误可能会在很多地方出现, 最好是定义为可调用的函数 * &lt;pre&gt;`function errorLog(error){ console.error(error);this.emit(‘end’);}gulp.task(‘script’, function(){gulp.src(‘…’).on(‘error’,errorLog).pipe(gulpUglify()) .pipe(gulp.dest(‘…’));});` 常用插件 gulp-uglify * `$ npm install —save-dev gulp-uglify` 将要最小化的 JS 文件放在 javascript/original 下 将最小化后的 JS 文件放在 javascript/minify 下 `var gulp = require('gulp'), gulpUgligy = require('gulp-uglify'); gulp.task('script', function(){ gulp.src('javascript/original/*js') .pipe(gulpUglify()) .pipe(gulp.dest('javascript/minify')); }) ` gulp-sass * `$ npm install —save-dev gulp-sass` * 将要编译的 Scss 文件放在 scss 目录下 * 将编译后的 CSS 文件放在 css 目录下 * &lt;pre&gt;`var gulp = require(&apos;gulp&apos;), gulpSass = required(‘gulp-sass’);gulp.task(‘styles’,function(){gulp.src(‘scss/*.scss’).pipe(gulpSass()).pipe(gulp.dest(‘css’));})` * 向 gulpSass()传入参数`{outputStyle:&apos;compressed&apos;}`输出压缩后的 CSS 文件 gulp-imagemin * 压缩图片, 支持格式有 gif, jpg, png, svg $ npm install --save-dev gulp-imagemin 指定 images/origin下所有图片都压缩, 并把压缩后的图片放到images 中 `var gulp = require('gulp'), gulpImagemin = require('gulp-imagemin'); gulp.task('image', function(){ gulp.src('images/original/**') .pipe(gulpImagemin()) .pipe(gulp.dest('images')); }) ` gulp-plumber * `$ npm install —save-dev gulp-plumber` pipe(gulpPlumber())一定要在编译 scss 及最小化 js 之前就加入(注意顺序) `var gulp = require('gulp'), gulpUglify = require('gulp-uglify'); gulp.watch('watch', function(){ gulp.watch('javascript/original/*.js', ['script']); }); gulp.task('script', function(){ gulp.src('javascript/original/*.js') .pipe(gulpPlumber()) .pipe(gulpUglify()) .pipe(gulp.dest('javascript/minify')); }); ` gulp-autoprefixer gulp-minify-css gulp-clean gulp-livereload 工作范例 明确任务 * 检查 JS 编译 Scss 合并 JS 压缩并重命名合并后的 JS 安装依赖 * `$ npm install gulp-jshint gulp-sass gulp-concat gulp-uglify gulp-rename —save-dev` 新建gulpfile.js * &lt;pre&gt;`//引入 gulp 及插件 var gulp = require(‘gulp’),gulpJshint = require(‘gulp-jshint’),gulpSass = require(‘gulp-sass’),gulpConcat = require(‘gulp-concat’),gulpUglify = require(‘gulp-uglify’),gulpRename(‘gulp-rename’);//检查 JS, 该任务会检查 js/下的 js 文件有没有报错或警告gulp.task(‘lint’,function(){gulp.src(‘./js/.js’).pipe(gulpJshint()).pipe(gulpJshint.reporter(‘default’));});//编译 Scss, 该任务会编译 scss/下的 scss 文件, 并把编译后的 css 文件保存到 /css 中gulp.task(‘sass’, function(){gulp.src(‘./scss/.scss’).pipe(gulpSass()).pipe(gulp.dest(‘./css’));});//合并, 压缩 JS 文件, 该任务会合并 js/下的所有 js 文件, 并输出到 dist/目录, 然后重命名为.min.js, 并压缩再输出到 dist/下gulp.task(‘scripts’, function(){gulp.src(‘./js/.js’).pipe(gulpConcat(‘all.js’)).pipe(gulp.dest(‘./dist’)).pipe(gulpRename(‘all.min.js’)).pipe(gulpUglify()).pipe(gulp.dest(‘./dist’));});//默认任务, 默认任务基于其他任务, 使用.run()方法关联和运行我们之前定义的方法, 使用.watch()方法监听指定目录的文件gulp.task(‘default’, function(){gulp.run(‘lint’, ‘sass’, ‘scripts’);//监听文件gulp.watch(‘./js/.js’, function(){gulp.run(‘lint’,’sass’,’scripts’);});});","link":"/2016/06/27/gulp-e8-87-aa-e5-8a-a8-e5-8c-96-e9-83-a8-e7-bd-b2-e5-bf-ab-e9-80-9f-e5-85-a5-e9-97-a8/"},{"title":"ImmutableJS Introduction","text":"Immutable data cannot be changed once created, leading to much simpler application development, no defensive copying, and enabling advanced memoization and change detection techniques with simple logic. Persistent data presetns a mutative API which does not update the data in-place, but instead always yields new updated data. Immutable.js provides many Persistent Immutable data structures including: List, Stack, Map, OrderedMap, Set, OrderedSet and Record. These data structures are highly efficient on modern JavaScript VMs by using structural sharing via ‘hash maps tries’ and ‘vector tries’ as popularized by Clojure and Scala, minimizing the need to copy or cache data. Immutable also provides a lazy Seq, allowing efficient chaining of collection methods like map and filter without creating intermediate representations. Create some Seq with Range and Repeat. Getting Startednpm install Immutable var Immutable = require('immutable'); var map1 = Immutable.Map({a:1,b:2,c:3}); var map2 = map1.set('b',50); map1.get('b'); //2 map2.get('b'); //50 The case for ImmutabilityMuch of what makes application development difficult is tracking mutation and maintaining state. Development with immutable data encourages you to think differently about how data flows through your application. Subscribing to data event throughout your application. Immutable data never change. Immutable collections should be treated as value rather than object. While objects represents some thing which could change over time, a value represents the state of that thing at a particular instance of time. This principle is most important to understanding the appropriate use of immutable data. In order to treat Immutable.js collections as values, it’s important to use the Immutable.is() function or .equals() method to determine value equality instead of === operator which determines object reference identity. var map1 = Immutable.Map({a:1,b:2,c:3}); var map2 = map1.set('b',2); assert(map1.equals(map2) === true); var map3 = map1.set('b',50); assert(map1.equals(map3) === false); Note: As a performance optimization Immutable attempts to return the existing collection when an operation would result in an identical collection, allowing for using === reference equality to determine if something definitely has not changed. This can be extremely useful when used within memoization function which would prefer to re-run the function if a deeper equality check could potentially be more costly. The === equality check is also used internally by Immutable.js and equals() as a performance as a performance optimization. If an object is immutable, it can be ‘copied’ simply by marking another reference to it instead of copying the entire object. Because a reference is much smaller than the object itself, this results in memory savings and a potential boost in execution speed for programs which rely on copies(such as an undo-stack). var map1 = Immutable.Map({'a':1,'b':2,'c':3}); var clone = map1; JavaScript-first APIWhile immutable is inspired by Clojure, Scala, Haskell and other functional programming environments, it’s designed to bring these powerful concepts to JavaScript, and therefore has an Object-Oriented API that closely mirrors that of ES6 Array, Map, and Set. The difference for the immutable collections is that methods which would mutate the collection, like push, set, unshift, or splice instead of return a new immutable collection. Methods which return new array like slice or concat instead return new immutable collections. var list1 = Immutable.List.of(1,2); var list2 = list1.push(3,4,5); var list3 = list2.unshift(0); var list4 = list1.concat(list2,list3); assert(list1.size === 2); assert(list2.size === 5); assert(list3.size === 6); assert(list4.size === 13); assert(list4.get(0) === 1); Almost all of the methods on Array will be found in similar form on Immutable.List, those of Map found on Immutable.Map and those of Set found onImmutable.Set, including collection operation like forEach(), and map(). var alpha = Immutable.Map({a:1,b:2,c:3,d:4}); alpha.map((v,k) =&amp;gt; k.toUpperCase()).join(); // 'A,B,C,D' Accepts raw JavaScript objects ‘immutable’ accepts plain JavaScript Arrays and Objects anywhere a mehtod expects an Iterable with no performance penalty. var map1 = Immutable.Map({a:1,b:2,c:3,d:4}); var map2 = Immutable.Map({c:10,a:20,t:30}); var obj = {d:100,o:200,g:300}; var map3 = map1.merge(map2,obj); // Map {a:20,b2,c:10,d:100,t:30,o:200,g:300} Immutable can treat any JavaScript Array or Object as an Iterable. You can take advantage of this in order to get sophisticated collection methods on JavaScript Objects, which otherwise have a very sparse native API. var myObject = {a:1,b:2,c:3}; Immutable.Seq(myObject).map(x=&amp;gt;x*x).toObject(); // {a:1,b:4,c:9}; Keep in Mind, when using JS objects to construct Immutable Maps, that JS Object properties are always strings, even if written in a quote-less shorthand, while Immutable Map accept keys of any type. 12345678 var obj = {1: &amp;#039;one&amp;#039;}; Object.keys(obj); // [&amp;#039;1&amp;#039;] obj[1]; // &amp;#039;one&amp;#039; obj[&amp;#039;1&amp;#039;]; // &amp;#039;one&amp;#039;var map = Immutable.fromJS(obj); map.get(&amp;#039;1&amp;#039;); // &amp;#039;one&amp;#039; map.get(1); // undefined Property access for JS Object first converts the key to a string, but since Immutable Map keys can be of any type the argument to get() is not altered. Namely Immutable Map will treat ‘1’ and 1 differently. Converts Back to Raw JS Obejcts All Immutable Iterable can be converted to plain JS Arrays and Objects shallowly with toArray() and toObject() or deeply with toJS(). All Immutable Iterables also implement toJSON() allowing them to be passed to JSON.stringify() directly. var deep = Immutable.Map({a:1,b:2,c:Immutable.List.of(3,4,5)}); deep.toObject() // {a:1,b:2,c:List [3,4,5]} deep.toArray() // [1,2,List [3,4,5]] deep.toJS() // {a:1,b:2,c:[3,4,5]} JSON.stringify(deep) // '{&quot;a&quot;:1,&quot;b&quot;,&quot;c&quot;:[3,4,5]}' Embraces ES6 Immutable takes advantage of features added to JS ES6, the latest standard version of ECMAScript, including Interators,Arrow Function, Classes, and Modules. Nested StructuresThe collections in immutable are intended to be nested, allowing for deep trees of data, similar to JSON var nested = Immutable.fromJS({a:{b:{c:[3,4,5]}}}) // Map{ a: Map { b: Map { c: List [3,4,5]}}} A few power-tool allow for reading and operating on nested data. The most useful are mergeDeep, getIn, setIn and updateIn found on List, Map and OrderedMap 12345678 var nested2 = nested.mergeDeep({a:{b:{d:6}}}) // Map {a: Map { b: { c: List [3,4,5], d: 6}}}nested2.getIn([&amp;#039;a&amp;#039;,&amp;#039;b&amp;#039;,&amp;#039;d&amp;#039;]); //6var nested3 = nested2.updateIn([&amp;#039;a&amp;#039;,&amp;#039;b&amp;#039;,&amp;#039;d&amp;#039;], value =&amp;gt; value + 1); d =&amp;gt; 7var nest4 = nested3.updateIn([&amp;#039;a&amp;#039;,&amp;#039;b&amp;#039;,&amp;#039;c&amp;#039;], list =&amp;gt; list.push(6)); c =&amp;gt; List [3,4,5,6] Lazy Seq Seq describes a lazy operation, allowing them to efficiently chain use all the Iterable methods.(such as map and filter) Seq is immutable – Once a Seq is created it cannot be changed, appended to, rerranged or otherwise modified. Instead, any mutative method called on a Seq will return a new Seq. Seq is lazy – Seq does as little work as necessary to respond to any method call. Once the Seq is used, it performs only the work necessary. Any collection can be converted to a lazy Seq with toSeq(). var seq = Immutable.Map({a:1,b:2,c:3}).toSeq(); Seq allow for the efficient chaining of sequence operations, especially when converting to a different concrete type(such as to a JS Object) seq.flip().map(k =&amp;gt; k.toUpperCase()).flip().toObject(); // Map {A: 1, B:2, C:3} Equality treats Collection as DataImmutable provides equality which treats immutable data structures as pure data, performing a deep equality check if necessary. var map1 = Immutable.Map({a:1,b:1,c:1}); var map2 = Immutable.Map({a:1,b:1,c:1}); assert(map1 !== map2) // two different instance, not same address assert(Immutable.is(map1,map2)); // have equivalent values assert(map1.equals(map2)); // alternatively use the equals methods. Immutable.is() uses the same measure of equality as Object.is including if both are immutable and all keys and values are equal using the same measure of equality. Batching Mutations Applying a mutation to create a new immutable object results in some overhead, which can add up to a minor performance penalty. If you need to apply a series of mutations locally before returning, Immutable gives you the ability to create a temporary mutable(transient) copy of a collection and apply a batch of mutations in a performance manner by using withMutations. In fact, this is exactly how Immutable applies complex mutations itself. As an example, building list2 results in the creation of 1 , not 3, new immutable Lists var list1 = Immutable.List.of(1,2,3); var list2 = list1.withMutations(function(list){ list.push(4).push(5).push(6) }); assert(list1.size === 3); assert(list2.size === 6); Note: Immutable also provides asMutable and asImmutable, but only encourages their use when withMutations will not suffice. Use caution to not return a mutable copy could result in undesired behavior. important: Only a select few method can be used in withMutations including set, push, pop. These methods can be applied directly against a persistent data-structure where other methods like map,filter,sortand splice will always return new immutable data-structure and never mutate a mutable collection.","link":"/2016/08/19/immutablejs-introduction/"},{"title":"JavaScript 事件与性能","text":"事件处理程序本质上是一种函数, 是一种对象, 存放在内存中, 设置大量的事件处理程序会使内存中的对象变多, Web 程序的性能会变得越来越差. 为了更好利用事件处理程序, 出现了事件委托, 用来提升性能 事件委托Event Delegate: 把若干个子节点上的相同事件的处理函数绑定到父节点, 从父节点统一处理子节点冒泡上来的事件, 这种技术叫做事件委托. 举例: &amp;lt;ul id=&apos;parent-list&apos;&amp;gt; &amp;lt;li id=&apos;list-1&apos;&amp;gt;List 1&amp;lt;/li&amp;gt; &amp;lt;li id=&apos;list-1&apos;&amp;gt;List 1&amp;lt;/li&amp;gt; &amp;lt;li id=&apos;list-1&apos;&amp;gt;List 1&amp;lt;/li&amp;gt; &amp;lt;li id=&apos;list-1&apos;&amp;gt;List 1&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; `&lt;/pre&gt; 通过父节点监听冒泡事件可以处理子节点上的对应事件 &lt;pre&gt;`var parentList = document.getElementById(&apos;parent-list&apos;); parentList.addEventListener(&apos;click&apos;, function(){ var target = event.target; // li if(target.nodeName.toLowerCase() === &apos;li&apos;){ alert(target.firstChild.nodeValue); } }, false) 因为事件委托依赖事件冒泡机制, 所以并不是所有事件都可以委托 最适合的事件: click, mousedown, mouseup, keydown, keyup, keypress 移除事件处理程序每当将事件处理程序制定给元素时, 运行中的浏览器代码与支持页面交互的 Js 代码之间就会建立一个连接, 这种连接越多, 页面执行越慢 如果使用完后不再使用的事件处理程序, 应当释放掉``` Submitvar button = document.getElementById(‘button’);button.onclick = function(){ button.onclick = null; event.target.firstChild.nodeValue = “Submitting”}","link":"/2016/09/27/javascript-e4-ba-8b-e4-bb-b6-e4-b8-8e-e6-80-a7-e8-83-bd/"},{"title":"innerHTML and textContext and NodeValue","text":"Summary: nodeValue is a little more confusing to use, but faster than innerHTML innerHTML parses content as HTML and takes longer(output text/html) textContent uses straight text, does not parse HTML, and is faster(output text/plain) innerText takes styles into consideration. It won’t get hidden text for instance. node.textContentThe Node.textContent property represents the text content of a node and it descendants. Syntaxexample.textContent =&quot;&amp;lt;a href='...'&amp;gt;textContent&amp;lt;/a&amp;gt;&quot;will output &amp;lt;a href='...'&amp;gt;textContent&amp;lt;/a&amp;gt; Differences from innerText textContent gets the content of all elements, including and elements, but innerText doesn’t. innerText is aware of style and will not return the text of hidden elements, whereas textContent will. As innerText is aware of CSS styling, it will trigger a reflow, whereas textContent will not. Differences from innerHTMLinnerHTML returns the HTML as its name indicates. Quite often, in order to retrieve or write text within an element, people use innerHTML. textContent should be used instead (to write or retrieve text). Because the text is not parsed as HTML, it’s likely to have better performance. node.nodeValueThe node.nodeValue property returns or sets the value of the current node. Syntaxvalue = node.nodeValue value is a string containing the value of the current node, if any.","link":"/2016/07/18/innerhtml-and-textcontext-and-nodevalue/"},{"title":"JavaScript 停止冒泡和阻止浏览器默认行为","text":"事件兼容function myFn(e){ var evt = e ? e:window.event } `&lt;/pre&gt; ### JS 停止冒泡 &lt;pre&gt;`function myFn(e){ window.event ? window.event.cancelBubble = true : e.stopPropagation(); } `&lt;/pre&gt; ### JS 阻止默认行为 &lt;pre&gt;`function myFn(e){ window.event ? window.event.returnValue = false : e.preventDefault(); } 补充event 表示事件的状态, 例如, event.target 是触发事件的对象","link":"/2016/09/27/javascript-e5-81-9c-e6-ad-a2-e5-86-92-e6-b3-a1-e5-92-8c-e9-98-bb-e6-ad-a2-e6-b5-8f-e8-a7-88-e5-99-a8-e9-bb-98-e8-ae-a4-e8-a1-8c-e4-b8-ba/"},{"title":"JavaScript 提高性能","text":"针对 js 文件的加载位置在 HTML 文件中, &lt;script&gt;标签是可以加载&lt;head&gt;或&lt;body&gt;区域的, 由于 JavaScript 执行和 UI 渲染的是单线程的, 如果加载不顺畅可能导致堵塞, 造成页面空白或卡顿.1. 如果 js 文件没有特殊要求致命需要在页面渲染之前加载, 那么应当将 &lt;script&gt;放在&lt;/body&gt;之前2. 如果这些 js 文件有明确需求先于 body 执行, 那么就在第一个 js 或者页面上先放一个载入动画 针对 js 文件的合并更快速的数据访问对于浏览器而言, 一个标识符所处的位置约深, 去读写他的速度也越慢. 如果我们需要在当前函数内多次用到某一个值, 应当用一个局部变量将其保存 DOM 操作的优化DOM 操作远比 JavaScript 的执行更耗性能, 应当尽量减少该操作对性能的消耗. function innerLi_s(){ var i = 0; for(;i&amp;lt;20;i++){ document.getElementById(&apos;Num&apos;).innerHTML += &apos;A&apos;; //进行20此循环, 每次循环都进行2次DOM 元素的访问, 一次读取 innerHTML, 一次写入 innerHTML } } // 改写为 function innerLi_s(){ var content = &apos;&apos;; var i = 0; for(;i&amp;lt;20;i++){ content += &apos;A&apos; //这里只对 js 的变量循环20次 }; document.getElementById(&apos;Num&apos;).innerHTML += content; //这里只进行2次 DOM 操作 } 减少 DOM 的重绘重排版元素的布局的改变或内容的增删改或浏览器尺寸的变化都会导致重排, 而字体颜色或背景色的修改会导致重绘. 合并同一对象的操作, 比如 background 的各个属性的修改可以合并为一个 循环的优化保存 arr.length, 避免多次访问","link":"/2016/07/25/javascript-e6-8f-90-e9-ab-98-e6-80-a7-e8-83-bd/"},{"title":"JavaScript 的闭包","text":"通常情况下, 求和函数的定义是这样的 function sum(arr){ return arr.reduce(function(x,y){ return x+y; }); } sum([1,2,3,4,5]); //15 `&lt;/pre&gt; 但是, 如果不需要立刻求和, 而是在后面的代码中根据需要进行计算, 可以选择返回一个保存了参数的求和函数 &lt;pre&gt;`function lazy_sum(arr){ var sum = function(){ return arr.reduce(function(x,y){ return x+y; }); } return sum; } `&lt;/pre&gt; 当我们调用`f = lazy_sum()`时会返回保存了参数 arr 的 sum 函数, 直到通过 f()调用 sum 函数前都不会进行求和运算, 可以节约资源. **需要注意的一点**是每一次调用 lazy_sum() 都会返回一个新的函数, 彼此相互独立, 各自占用内存空间 同时要注意, 尽管每次生成并返回的都是新的 sum 函数, 但是 lazy_sum() 的局部变量是通用的, 可参考**类方法**与**实例**的关系, 这是使用闭包的目的之一 **更要注意**: &lt;pre&gt;`function count(){ var arr = []; for(var i = 1; i&amp;lt;=3; i++){ arr.push(function(){ return i*i; }); } return arr; } var results = count(); var f1 = results[0]; var f2 = results[1]; var f3 = results[2]; 在这个例子中, f1(), f2(), f3()的返回值都是16, 原因在于:每一次循环都向 arr 推入一个(function(){})(i), 但都没有计算, 三次循环后 i 变成了4, 所以f1, f2, f3的函数接受的局部变量的值都是4.由此可知闭包保留的是变量, 而不是变量的值.如果一定要引用循环变量, 记得创建一个变量用于保存现场 闭包可以用于实现装饰器","link":"/2016/07/19/javascript-e7-9a-84-e9-97-ad-e5-8c-85/"},{"title":"JavaScript Generator","text":"作用迭代器 function* argumentsGenerator() { for (let i = 0; i &amp;lt; arguments.length; i++) { yield arguments[i]; } } `&lt;/pre&gt; 我们希望迭代传入的每个实参 &lt;pre&gt;`var argumentsIterator = argumentsGenerator(&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;); // Prints &quot;a,b,c,d&quot; console.log( argumentsIterator.next().value, argumentsIterator.next().value, argumentsIterator.next().value, argumentsIterator.next().value ) `&lt;/pre&gt; 我们可以简单的理解 - Generator 其实是生成 Iterator 的方法, argumentsGenerator 被称为 GeneratorFunction, 也有一些人把 GeneratorFunction 的返回值称为一个 Generator - yield 可以中断 GeneratorFunction 的运行, 而在 next() 时恢复运行 - 返回的 Iterator 上, 有 next 成员方法, 能够返回迭代值. 其中 value 属性包含了实际返回值, done 属性为布尔值, 标记迭代器是否完成迭代, 要注意的是, 在 done: true 后继续运行 next 方法会产生异常. 完整的 ES 实现中, for-of 循环正式为了快速迭代一个 Iterator &lt;pre&gt;`for (let value of argumetnsIterator) { console.log(value); } `&lt;/pre&gt; 可以利用 yield* 语法, 将 yield 操作代理到另一个 Generator &lt;pre&gt;`let delegatedIterator = (function*() { yield &apos;Hello!&apos;; yield &apos;Bye!&apos;; })(); let delegatingIterator = (function*() { yield &apos;Greetings!&apos;; yield* delegatedIterator; yield &apos;Ok, bye!&apos;; })(); // Prints &quot;Greetings!&quot;, &quot;Hello&quot;, &quot;Bye!&quot;, &quot;Ok, bye!&quot; for (let value of delegatingIterator) { console.log(value); } 用作流程控制co 已经将此特性封装的非常完美 Generator 之所以可以用来控制代码流程, 就是通过 yield 来将两个或多个 Generator 的执行路径相互切换, 这种切换是语句级别的, 而不是函数级调用. 其本质是 CPS 变换. 这里补充 yield 的若干行为: next 方法接收一个参数, 传入的参数是 yield 表达式的返回值: 即 yield 既可以产生数值, 也可以接收数值 throw 方法会抛出一个异常, 并终止迭代 GeneratorFunction 的 return 语句相当于一个 yield 将异步”变为”同步假设我们希望有如下语法: suspend 传入一个 GeneratorFunction suspend 返回一个简单函数, 接收一个 node 风格的回调函数 所有的异步调用都通过 yield, 看起来像同步调用 给定一个特殊的回调, 让保证异步调用的返回值作为 yield 的返回值, 并让脚本继续 GeneratorFunction 的返回值和执行过程的错误都会传入全局的回调函数","link":"/2016/07/31/javascript-generator/"},{"title":"JS 开发工具","text":"开发工具是让开发人员工作更轻松的一些软件, 传统上包括集成开发环境, 代码检查工具, 编译器, 调试工具和性能测试工具 但是 JS 是一种动态语言, 伴随他动态本质而来的是对更多运行时开发者工具的需求. Quick List Atom &amp; Atom-ternjs Chrome DevTools PageSpeed Insights BrowserSycn TraceGL ironNode ESLint Babel React Webpack + Hot Module Replacement Redux + Redux DevTools 关于工具, 主要是编辑器和运行时环境(比如浏览器) 主要用 Atom, 需要 atom-ternjs 来开启 JavaScript 智能识别 很多很棒的 Atom 插件 调试器: Chrome DevTools, 注意其 flame charts 和 dominators view 功能 性能审查: PageSpeed Insights BrowserSync是一款测试响应式布局非常好用的工具, 可以一次模拟多种浏览器(电脑, 平板, 手机)可以监视文件, 并在文件修改的时候自动重载同步刷新浏览器, 像滚动, 点击, 表单交互等动作也会跨设别同步. 视频链接 TraceGL 是一种运行时调试工具, 可以让你在软件中的方法实时调用时观察他们, 而不是手动逐步跟踪代码 视频链接 代码检查: ESLint 可配置性特别强, 每一个选项都可以设置开启或禁用, 甚至给他们添加参数. 可以创建自己的规则, 支持插件 Babel 是一种编译器, 可以让现在的 JS 代码使用 ES6+ 尚未支持的特性, JSX 等, 工作原理是讲代码转换为等价的 ES5. 文章链接 Webpack 会将模块和以来打包成针对浏览器的静态资源, 他支持大量有趣的特性, 比如模块热拔插, 可以让当前浏览器中的代码在你修改文件的时候自动更新, 而不用刷新页面. 模块热拔插 参考资料 React: 不算开发者工具","link":"/2016/08/21/js-e5-bc-80-e5-8f-91-e5-b7-a5-e5-85-b7/"},{"title":"JS 的 Date","text":"&amp;gt; var myDate = new Date() undefined &amp;gt; myDate.getYear() 116 &amp;gt; myDate.getFullYear() 2016 &amp;gt; myDate.getMonth() // 0 - 11 7 &amp;gt; myDate.getDate() // 1 - 31 28 &amp;gt; myDate.getDay() // 0 - 6, 西方以周日为一周开始, 所以0是周日 0 &amp;gt; myDate.getTime() // 从1970.1.1开始的毫秒数 1472313859531 &amp;gt; myDate.getHours() 0 &amp;gt; myDate.getMinutes() 4 &amp;gt; myDate.getSeconds() 19 &amp;gt; myDate.getMilliseconds() 531 &amp;gt; myDate.toLocaleDateString() &apos;2016-08-28&apos; &amp;gt; myDate.toLocaleString() &apos;2016-08-28 00:04:19&apos;","link":"/2016/08/27/js-e7-9a-84-date/"},{"title":"JS 获取 Input File Name","text":"获得文件路径: var filePath = document.getElementById(&quot;file&quot;).value 截取文件名: 保留后缀: * `var fileName = filePath.split(&apos;\\\\&apos;).pop()` var fileName = filePath.substring(filePath.lastIndexOf('\\\\')+1) 不保留后缀: * `var fileName = filePath.split(/\\.|\\\\/).slice(-2,-1)[0]` var fileName = filePath.substring(filePath.lastIndexOf(&quot;\\\\&quot;)+1,filePath.lastIndexPathOf(&quot;\\.&quot;))","link":"/2016/06/24/js-e8-8e-b7-e5-8f-96-input-file-name/"},{"title":"Koa-Graphql","text":"Create a GraphQL HTTP server with Koa. Usage with Koa-Router12345678910111213const Koa = require('koa')const Router = require('koa-router')const GraphqlHTTP = require('koa-graphql')const app = new Koa()const router = new Router()router.all('/graphql', graphqlHTTP({ schema: MyGraphQLSchema, graphiql: ture,}))app.use(router.routes()).use(router.allowedMethods()) OptionsThe GraphqlHTTP function accpets the following options: schema: A GraphQLSchema instance from graphql.js, required. graphiql: If true, presetns GraphiQL when the route with a /graphiql appended is loaded in a browser. We recommended that you set graphiql to ture when your app is in development, because it’s quite useful. You may or may not want it in production. rootValue: A value to pass as the rootValue to the graphql() function from graphql.js context: A value to pass as the context to the graphql() function from graphql.js. If context is not provided, the ctx object is passes as the context. pretty: If true, any JSON response will be pretty-printed. formatError: An optional function which will be used to format any errors produced by fulfilling a GraphQL operation. If no function is provided, GraphQL’s default spec-compliant formatError function will be used. extensions: An optional function for adding additional metadata to the GraphQL response as a key-value object. The result will be added to extensions field in the resulting JSON. This is often useful place to add development time metadata such as the runtime of a query or the amount of resources consumed. This may be an async function. The function is given one object as an argument: { document, variables, operationName, result } validationRules: Optional additional validation rules queries must satisfy in addition to those defined by the GraphQL spec. HTTP UsageOnce installed at a path, koa-graphql will accept requests with the parameters: query: A string GraphQL document to be executed. variables: The runtime values to use for any GraphQL query variables as a JSON object. operationName: If the provided query contains mutiple named operations, this specifies which operation should be executed. If not provided, a 400 error will be returned if the query contains multiple named operations. raw: If the graphql option is enabled and the raw parameter is provided raw JSON will always be returned instead of GraphQL even when loaded from a browser. GraphQL will first look for each parameter in the URL’s query-string: /graphql?query=query+getUser($id:ID){user(id:$id){name}}&amp;variables={&quot;id&quot;:&quot;4&quot;} If not found in the query-string, it will look in the POST request body. If the POST body has not been parsed, koa-graphql will interpret it depending on the provided Contetn-Type header: application/json: the POST body will be parsed as a JSON object. application/x-www-form-urlencoded: this POST body will be parsed as a url-encoded string of key-value pairs. application/graphql: The POST body will be parsed as GraphQL query string, which provides the query parameter.","link":"/2017/08/06/koa-graphql/"},{"title":"Koa-Router","text":"Express 式路由使用app.get, app.put, app.post 等 Named URL parameters and regexp captures String or regular expression route matching Named Routes with URL generation Responds to OPTIONS request with allowed methods Support for 405 Method Not Allowed and 501 Not Implemented Multiple route middleware Multiple routers 安装npm install koa-router `&lt;/pre&gt; ### 使用 &lt;pre&gt;`var koa = require(&quot;koa&quot;), router = require(&quot;koa-router&quot;), app = koa(); app.use(router(app)) `&lt;/pre&gt; After the router has been initialized you can register routes: &lt;pre&gt;`app.get(&quot;/users/:id&quot;, function*(next){ var user = yield User.findOne(this.params.id); this.body = user; }); `&lt;/pre&gt; ### 多路由 You can use multiple routers and sets of routes by omitting the `app` argument. For example, separate routes for two versions of an API: &lt;pre&gt;`var koa = require(&quot;koa&quot;), mount = require(&quot;mount&quot;), Router = require(&quot;koa-router&quot;); var app = koa(); var APIv1 = new Router(); var APIv2 = new Router(); APIv1.get(&quot;/sign-in&quot;, function*(){ // ... }) APIv2.get(&quot;/sign-in&quot;, function*(){ // ... }) app.use(mount(&quot;/v1&quot;, APIv1.middleware())).use(mount(&quot;/v2&quot;, APIv2.middleware())); `&lt;/pre&gt; ### 链 The http methods(get, post, etc) return their `Router` instance, so routes can be chained as you&apos;re used to with express: &lt;pre&gt;`var api = new Router(); api.get(&quot;/foo&quot;, showFoo).get(&quot;/bar&quot;, showBar).post(&quot;/foo&quot;, createFoo)","link":"/2016/09/19/koa-router/"},{"title":"Learning D3","text":"d3-arrayarray methods built-in to JavaScript array.pop =&gt; popped element array.push =&gt; array.length array.reverse =&gt; change the array array.shift =&gt; shifted element array.unshift =&gt; array.length array.sort =&gt; change the array array.splice =&gt; change the array array.concat =&gt; new Array array.join =&gt; new String array.slice =&gt; new Array array.indexOf =&gt; number array.lastIndexOf =&gt; number array.fitler =&gt; new Array array.forEach =&gt; undefined array.every =&gt; boolean array.map =&gt; new Array array.some =&gt; boolean array.reduce =&gt; array.reduceRight =&gt; yarn add d3-array Statistics d3.min(array[, accessor]) Mininum value using natural order Return undefined if the array is empty An optional accessor function may be specified, which is equivalent to calling array.map(accessor) before computing the minumum value. d3.max(array[, accessor]) Return maximum value Return undefined. if the array is empty d3.extent(array[, accessor]) Return minumum and maximum value in the given array. Return [undefined, undefined] if the array is empty d3.sum(array[, accessor]) Return the sum of the given array of numbers. Return 0 if the array is empty. ignores undefined and NaN values. d3.mean(array[, accessor]) Return the mean of the given array of numbers. Return undefined if the array is empty. Ignore undefined and NaN. d3.median(array[, accessor]) - -","link":"/2017/04/25/learning-d3/"},{"title":"Keystore","text":"Original What is a keystore fileA keystore file is en encrypted version of your unique private key that you will use to sign your transactions. If you lose this file your lose your assets. What do keystore files look like1234567891011121314151617181920{ \"crypto\": { \"cipher\": \"aes-128-ctr\", \"cipherparams\": { \"iv\": \"83dbcc02d8ccb40e466191a123791e0e\" }, \"ciphertext\": \"d172bf743a674da9cdad04534d56926ef8358534d458fffccd4e6ad2fbde479c\", \"kdf\": \"scrypt\", \"kdfparams\": { \"dklen\": 32, \"n\": 262144, \"r\": 1, \"p\": 8, \"salt\": \"ab0c7876052600dd703518d6fc3fe8984592145b591fc8fb5c6d43190334ba19\" }, \"mac\": \"2103ac29920d71da29f15d75b4a16dbe95cfd7ff8faea1056c33131d846e3097\" }, \"id\": \"3198bc9c-6672-5ab3-d995-4942343ae5b6\", \"version\": 3} Thses fields mean: cipher: The name of a symmetric AES algorithm cipherparams: The parameters required for the “cipher” algorithm above ciphertext: The private key encrypted using the “cipher” algorithm above kdf: A key derivation function used to let you encrypt your keystore file with a password kdfparams: The parameters required for the “kdf” algorithm above mac: A code used to verify your password Work flow Encrypting your private key These symmetric algorithms use a key to encrypt some data. The resulting data is encrypted and can be decrypted with the same method and the same key. The relation between cipher, cipherparams, ciphertext: cipher is the symmetric algorithm used to encrypt the private key. cipherparams are the parameters required for teh symmetric algorithm. ciphertext is the encrypted input of the symmetric input. You get the decryption-key as the output of the kdf. By this, you need to retrieve your decryption-key(namely the key used in encryption) to decrypt your private key. Protect with your passphrase To make sure unlocking your account is easy, you don’t need to remember your very long and non-user-friendly decrption-key that is used to decrypt ciphertext. Instead, the developers have opted for a passphrase-based protection. The keystore use a kdf(key derivation function) that computes the decryption-key given a passphrase and a list of parameters. kdf is the key derivation function used to compute the decryption-key from your passphrase. kdfparams are the parameters required for the function By the passphrase with kdfparams, the kdf returns your decrption-key. Make sure your passphrase is right We need to guarantee that the passphrase typed to unlock the account is right, that it is the same one as the one entered when the keystore is generated. This is where the field mac in the keystore works. Just after the kdf is executed, its result(decryption-key) and ciphertext are processed and compared to mac. If the result is the same as mac, then the passphrase was right and the decrption-key is correct. Conclusion","link":"/2019/03/16/keystore/"},{"title":"Mac OS 下 实现 Tree 指令","text":"先安装 zsh进入~/.zshrc, 添加alias tree=&quot;find . -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'&quot;回到目录, 执行source .zshrc 令修改立即生效可以使用tree指令生成文档树","link":"/2016/07/19/macos-e4-b8-8b-e5-ae-9e-e7-8e-b0tree-e6-8c-87-e4-bb-a4/"},{"title":"Koa 使用","text":"安装Koa 当前需要 node 0.11.x 并开启 –harmony(或– harmony-generators), 因为他依赖于 ES6的 generator 特性node --harmony my-koa-app.js 应用Koa 应用是一个包含中间件 generator 方法数组的对象. 当请求到来时, 这些方法会以 stack-slice 的顺序执行. Koa 的一大设计理念是, 通过其他底层中间件层提供高级”语法糖”, 而不是 Koa, 大大提高了框架的互操作性和健壮性, 并让中间件开发变得有趣. 简单例子 var koa = require(&quot;koa&quot;); var app = koa(); app.use(function*(){ this.body = &quot;Hello World&quot;; }); app.listen(3000); `&lt;/pre&gt; **注**: 与普通 function 不同, generator function 以 function* 的形式声明. ### 编写级联代码 koa 中间件以一种更加传统的方式级联. 以往的 Node 开发中, 级联是通过回调实现的, 用户友好度上有欠缺 Koa 借助 generator 实现了中间件架构 Koa 的执行代码的形式不再是简单的将控制权依次移交给一个又一个方法直到结束, 而是像一个回形针, 用户请求中间件, 遇到 yield next 关键字的时候, 会被传递给下游中间件(downstream), 在 yield next 捕获不到 downstream 的时候, 逆序返回执行代码(upstream)(yield next 后面的代码) &lt;pre&gt;`var koa = require(&quot;koa&quot;); var app = koa(); // x-response-time app.use(function* (next){ var start = new Date; yield next; var ms = new Date - start; this.set(&quot;X-Response-Time&quot;, ms+&quot;ms&quot;); }) // logger app.use(function* (next){ var start = new Date; yield next; var ms = new Date - start; console.log(&quot;%s %s - %s&quot;, this.method, this.url, ms) }); // response app.use(function* (){ this.body = &quot;Hello World&quot;; }); app.listen(3000); `&lt;/pre&gt; ### 应用配置 应用配置是 app 实例的属性, 目前支持以下配置: - app.name 应用名 - app.env 执行环境, 默认是`NODE_ENV`或者`development`字符串 - app.proxy, 当该属性为 true 时, `proxy header` 参数会被添加到信任列表中 ### app.listen(...) 一个 Koa 应用跟 HTTP Server 不是1-to-1关系, 一个或多个 Koa应用可以被加载到一块, 组成一个更大的包含一个 HTTP server 的应用 该方法创建并返回一个 http server, 并支持传递固定参数 &lt;pre&gt;`var koa = require(&quot;koa&quot;) var app = koa() app.listen(3000) `&lt;/pre&gt; 方法 app.listen(...)是一个语法糖, 等价于 &lt;pre&gt;`var http = require(&quot;http&quot;) var koa = require(&quot;koa&quot;) var app = koa() http.createServer(app.callback()).listen(3000) `&lt;/pre&gt; 这意味着可以在多个端口使用同一个 app &lt;pre&gt;`http.createServer(app.callback()).listen(3000) http.createServer(app.callback()).listen(3001) `&lt;/pre&gt; ### app.callback() 返回一个回调方法能用于 http.createServer()来处理请求, 也可以将这个回调函数挂载到 Connect/Express 应用上 ### app.use(function) 将给定的 function 当做中间件加载到应用中 ### app.keys= 设置 Cookie 签名密钥 ### 错误处理 除非应用执行环境(NODE_ENV)被配置为&quot;test&quot;, Koa 都会将所有错误信息输出到 stderr, 如果想自定义错误处理逻辑, 可以定义一个&quot;错误事件&quot;来坚挺 Koa App 中的错误: &lt;pre&gt;`app.on(&quot;error&quot;,function(err){ log.error(&quot;server error&quot;, err); }) `&lt;/pre&gt; 当 req/res 周期中出现任何错误且无法响应客户端时, koa 会把 Context(上下文)实例作为第二个参数传递给 error 事件: &lt;pre&gt;`app.on(&quot;error&quot;, function(err, ctx){ log.error(&quot;server error&quot;, err, ctx) }) `&lt;/pre&gt; ### 上下文 Koa 的 Context 把 node 的 request 和 response 对象封装在一个单独对象, 并提供许多开发 web 应用和 APIs 有用的方法. 那些 HTTP Server 开发中使用非常频繁操作, 直接在 Koa 里实现, 而不是放在更高层次的框架, 这样中间件就不需要重复实现这些通用的功能. 每个请求会创建自己的 Context 实例, 在中间件中作为 receiver 引用, 或通过 this 标示引用: &lt;pre&gt;`app.use(function* (){ this; // is the Context this.request; // is a koa Request this.response; // is a koa Response }) Context 的许多访问器和方法直接委托为他们的 ctx.request 或 ctx.response 的等价方法, 用于访问方便, 是完全相同的, 比如 ctx.type 和 ctx.length 委托与 response 对象, ctx.path 和 ctx.method 委托与 request. 请求Koa Request 对象是 node 普通 request 对象之上的抽象, 提供了日常 Http Server 中更多有用的功能 API request.header request.headers: req.header 的别名 request.method: 请求方法 request.method=: 设置请求方法, 实现中间件的时候非常有用 request.length: 将请求的 Content-length 返回为数字, 或 undefined request.url: 获取请求 URL request.url=: 设置请求 URL… 响应Koa Response 对象是 node 普通 response 对象之上的抽象, 提供了日常 Http Server 中有用的功能 API….","link":"/2016/09/19/koa-e4-bd-bf-e7-94-a8/"},{"title":"Material Design Lite Glossary","text":"","link":"/2016/05/24/materialdesignliteglossary/"},{"title":"Mac OS 下前端开发环境配置","text":"安装 homebrew终端下执行ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 配置 iterm2下载后下载配色 solarized, 然后下载 zsh 和 oh-my-zsh, 添加插件 git, osx, ruby, autojump 安装 Nginx终端下执行brew install nginx安装完成后用浏览器打卡 http://localhost:8080, 如果页面显示正常,则表示安装完成nginx 有一下几个操作 #打开 nginx nginx #nginx -s 重新加载配置|重启|停止|退出 nginx -s reload|reopen|stop|quit #测试配置是否有语法错误 nginx -t `&lt;/pre&gt; Note: 如果执行不成功, 请使用 sudo 提权 默认访问目录是 `/usr/local/Cellar/nginx/1.10.0/html` nginx 的配置文件位置为: `/usr/local/etc/nginx/nginx.conf` #### 配置 nginx 首先备份一下 nginx.conf ==&gt; nginx.conf.default 修改server 部分为: &lt;pre&gt;`server { listen 8080; server_name localhost; location /{ root /Users/YourId/Documents; //项目目录 #index index.html index.htm; } } `&lt;/pre&gt; 配置完成后启动 nginx 即可访问 ### 安装 mySQL 终端执行 `brew install mysql` 安装完成后默认没有密码, 修改密码 ``` mysql -uroot -p Enter password: mysql&gt;use mysql; mysql&gt; UPDATE user SET password=password(&quot;修改的密码&quot;) WHERE user=&apos;root&apos;; mysql 的操作命令 &lt;pre&gt;` #开启 mysql.server start #结束 mysql.server stop 配置文件位于/usr/local/Cellar/mysql/5.6.28/my.cnf","link":"/2016/07/19/mac-os-e4-b8-8b-e5-89-8d-e7-ab-af-e5-bc-80-e5-8f-91-e7-8e-af-e5-a2-83-e9-85-8d-e7-bd-ae/"},{"title":"MDL-Badge","text":"Badge: class=\"material-icons mdl-badge mdl-badge--overlap\" Badge: class=\"mdl-badge\", **the material-icons makes the text bigger, and mdl-badge--overlap makes badge overlap the text** [Badge](#): Badge in the inlink [Badge](#): Badge outside the link [Badge](#): Badge with too many characters(12345) [Badge](#): class=\"mdl-badge mdl-badge--no-background\" &amp;lt;!-- Number badge on icon --&amp;gt; &amp;lt;div class=&quot;material-icons mdl-badge mdl-badge--overlap&quot; data-badge=&quot;1&quot;&amp;gt;Badge&amp;lt;/div&amp;gt;: class=&quot;material-icons mdl-badge mdl-badge--overlap&quot;&amp;lt;br&amp;gt; &amp;lt;span class=&quot;mdl-badge&quot; data-badge=&quot;2&quot;&amp;gt;Badge&amp;lt;/span&amp;gt;: class=&quot;mdl-badge&quot;, &amp;lt;strong&amp;gt;the material-icons makes the text bigger, and mdl-badge--overlap makes badge overlap the text&amp;lt;/strong&amp;gt;&amp;lt;br&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-badge&quot; data-badge=&quot;3&quot;&amp;gt;Badge&amp;lt;/a&amp;gt;: Badge in the inlink&amp;lt;br&amp;gt; &amp;lt;a href=&quot;#&quot;&amp;gt;Badge&amp;lt;/a&amp;gt;&amp;lt;span class=&quot;mdl-badge&quot; data-badge=&quot;4&quot;&amp;gt;&amp;lt;/span&amp;gt;: Badge outside the link&amp;lt;br&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-badge&quot; data-badge=&quot;12345&quot;&amp;gt;Badge&amp;lt;/a&amp;gt;: Badge with too many characters(12345)&amp;lt;br&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-badge mdl-badge--no-background&quot; data-badge=&quot;6&quot;&amp;gt;Badge&amp;lt;/a&amp;gt;: class=&quot;mdl-badge mdl-badge--no-background&quot;","link":"/2016/05/24/mdl-badge/"},{"title":"MDL-List","text":"Document Simple List Content 1 Content 2 Content 3 Content 4 Content 5 &lt;!– Simple List –&gt;&lt;ul class=”mdl-list”&gt; &amp;lt;li class=&quot;mdl-list_item&quot;&amp;gt;&amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt;Content 1&amp;lt;/span&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-list_item&quot;&amp;gt;&amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt;Content 2&amp;lt;/span&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-list_item&quot;&amp;gt;&amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt;Content 3&amp;lt;/span&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-list_item&quot;&amp;gt;&amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt;Content 4&amp;lt;/span&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-list_item&quot;&amp;gt;&amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt;Content 5&amp;lt;/span&amp;gt;&amp;lt;/li&amp;gt; &lt;/ul&gt;` Icon List _1_ Content 1 &lt;/span&gt; _2_ Content 2 &lt;/span&gt; _3_ Content 3 &lt;/span&gt; _4_ Content 4 &lt;/span&gt; _5_ Content 5 &lt;/span&gt; `&lt;!-- Icon List --&gt; &lt;ul class=\"mdl-list\"&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-icon\"&gt;1&lt;/i&gt; &lt;p&gt;Content 1&lt;/p&gt; &lt;/span&gt;&lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-icon\"&gt;2&lt;/i&gt; &lt;p&gt;Content 2&lt;/p&gt; &lt;/span&gt;&lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-icon\"&gt;3&lt;/i&gt; &lt;p&gt;Content 3&lt;/p&gt; &lt;/span&gt;&lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-icon\"&gt;4&lt;/i&gt; &lt;p&gt;Content 4&lt;/p&gt; &lt;/span&gt;&lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-icon\"&gt;5&lt;/i&gt; &lt;p&gt;Content 5&lt;/p&gt; &lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; ` Avatars and Actions _A1_ &lt;span&gt;content 1&lt;/span&gt; [Star]() &lt;/span&gt; _A2_ &lt;span&gt;content 2&lt;/span&gt; [Star]() &lt;/span&gt; _A3_ &lt;span&gt;content 3&lt;/span&gt; [Star]() &lt;/span&gt; `&lt;!-- List Item with Avatar and Action --&gt; &lt;ul class=\"mdl-list\"&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-avatar\"&gt;A1&lt;/i&gt; &lt;span&gt;content 1&lt;/span&gt; &lt;a href=\"\" class=\"mdl-list_item-secondary-action\"&gt;Star&lt;/a&gt; &lt;/span&gt;&lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-avatar\"&gt;A2&lt;/i&gt; &lt;span&gt;content 2&lt;/span&gt; &lt;a href=\"\" class=\"mdl-list_item-secondary-action\"&gt;Star&lt;/a&gt; &lt;/span&gt;&lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-avatar\"&gt;A3&lt;/i&gt; &lt;span&gt;content 3&lt;/span&gt; &lt;a href=\"\" class=\"mdl-list_item-secondary-action\"&gt;Star&lt;/a&gt; &lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; ` Avatars and Controls _C_ Checkbox &lt;/span&gt; &lt;span class=&quot;mdl-list__item-secondary-action&quot;&gt; &lt;label for=&quot;list-checkbox-1&quot; class=&quot;mdl-checkbox mdl-js-checkbox mdl-js-ripple-effect&quot;&gt; &lt;input type=&quot;checkbox&quot; class=&quot;mdl-checkbox__input&quot; checked id=&quot;list-checkbox-1&quot;&gt; &lt;/label&gt; &lt;/span&gt; _R_ Radio &lt;/span&gt; &lt;span class=&quot;mdl-list__item-secondary-action&quot;&gt; &lt;label for=&quot;list-option-1&quot; class=&quot;mdl-radio mdl-js-radio mdl-js-ripple-effect&quot;&gt; &lt;input type=&quot;radio&quot; class=&quot;mdl-radio__button&quot; id=&quot;list-option-1&quot; name=&quot;options&quot; value=&quot;1&quot; checked=&quot;&quot;&gt; &lt;/label&gt; &lt;/span&gt; _S_ Switch &lt;/span&gt; &lt;span class=&quot;mdl-list__item-secondary-action&quot;&gt; &lt;label for=&quot;list-switch-1&quot; class=&quot;mdl-switch mdl-js-switch mdl-js-ripple-effect&quot;&gt;&lt;input type=&quot;checkbox&quot; checked class=&quot;mdl-switch__input&quot; id=&quot;list-switch-1&quot;&gt;&lt;/label&gt; &lt;/span&gt; ` &lt;!-- List with Avatar and Controls --&gt; &lt;ul class=\"mdl-list\"&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-avatar\"&gt;C&lt;/i&gt; Checkbox &lt;/span&gt; &lt;span class=\"mdl-list__item-secondary-action\"&gt; &lt;label for=\"list-checkbox-1\" class=\"mdl-checkbox mdl-js-checkbox mdl-js-ripple-effect\"&gt; &lt;input type=\"checkbox\" class=\"mdl-checkbox__input\" checked id=\"list-checkbox-1\"&gt; &lt;/label&gt; &lt;/span&gt; &lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-avatar\"&gt;R&lt;/i&gt; Radio &lt;/span&gt; &lt;span class=\"mdl-list__item-secondary-action\"&gt; &lt;label for=\"list-option-1\" class=\"mdl-radio mdl-js-radio mdl-js-ripple-effect\"&gt; &lt;input type=\"radio\" class=\"mdl-radio__button\" id=\"list-option-1\" name=\"options\" value=\"1\" checked=\"\"&gt; &lt;/label&gt; &lt;/span&gt; &lt;/li&gt; &lt;li class=\"mdl-list__item\"&gt; &lt;span class=\"mdl-list__item-primary-content\"&gt; &lt;i class=\"material-icons mdl-list__item-avatar\"&gt;S&lt;/i&gt; Switch &lt;/span&gt; &lt;span class=\"mdl-list__item-secondary-action\"&gt; &lt;label for=\"list-switch-1\" class=\"mdl-switch mdl-js-switch mdl-js-ripple-effect\"&gt;&lt;input type=\"checkbox\" checked class=\"mdl-switch__input\" id=\"list-switch-1\"&gt;&lt;/label&gt; &lt;/span&gt; &lt;/li&gt; &lt;/ul&gt; ` List of Multi-line _1_ &lt;span&gt;Content&lt;/span&gt; &lt;span class=&quot;mdl-list__item-sub-title&quot;&gt;Subtitle&lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;mdl-list__item-secondary-content&quot;&gt; &lt;span class=&quot;mdl-list__item-secondary-info&quot;&gt;Actor&lt;/span&gt; [ _Star_ ](#) &lt;/span&gt; &lt;!-- List with Text Body --&gt;* &lt;span class=&quot;mdl-list__item-primary-content&quot;&gt; _2_ &lt;span&gt;Content&lt;/span&gt; &lt;span class=&quot;mdl-list__item-text-body&quot;&gt; Lorem ipsum dolor sit amet, consectetur adipisicing elit. Laboriosam dolor asperiores totam accusantium quaerat sint nam illum ad praesentium et, reiciendis vel doloremque ex minima ipsam sit dignissimos facilis excepturi. &lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;mdl-list__item-secondary-content&quot;&gt; [ _Star_ ](#) &lt;/span&gt; `&lt;!– Two Line List with Secondary Info and Action –&gt; &amp;lt;ul class=&quot;mdl-list&quot;&amp;gt; &amp;lt;li class=&quot;mdl-list__item mdl-list__item--two-line&quot;&amp;gt; &amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt; &amp;lt;i class=&quot;material-icons mdl-list__item-avatar&quot;&amp;gt;1&amp;lt;/i&amp;gt; &amp;lt;span&amp;gt;Content&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;mdl-list__item-sub-title&quot;&amp;gt;Subtitle&amp;lt;/span&amp;gt; &amp;lt;/span&amp;gt; &amp;lt;span class=&quot;mdl-list__item-secondary-content&quot;&amp;gt; &amp;lt;span class=&quot;mdl-list__item-secondary-info&quot;&amp;gt;Actor&amp;lt;/span&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-list__item-secondary-action&quot;&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;Star&amp;lt;/i&amp;gt; &amp;lt;/a&amp;gt; &amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;!-- List with Text Body --&amp;gt; &amp;lt;li class=&quot;mdl-list__item mdl-list__item--three-line&quot;&amp;gt; &amp;lt;span class=&quot;mdl-list__item-primary-content&quot;&amp;gt; &amp;lt;i class=&quot;material-icons mdl-list__item-avatar&quot;&amp;gt;2&amp;lt;/i&amp;gt; &amp;lt;span&amp;gt;Content&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;mdl-list__item-text-body&quot;&amp;gt; Lorem ipsum dolor sit amet, consectetur adipisicing elit. Laboriosam dolor asperiores totam accusantium quaerat sint nam illum ad praesentium et, reiciendis vel doloremque ex minima ipsam sit dignissimos facilis excepturi. &amp;lt;/span&amp;gt; &amp;lt;/span&amp;gt; &amp;lt;span class=&quot;mdl-list__item-secondary-content&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-list__item-secondary-action&quot;&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;Star&amp;lt;/i&amp;gt; &amp;lt;/a&amp;gt; &amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt;","link":"/2016/05/26/mdl-list/"},{"title":"MDL-Loading","text":"Defaut Progress Bar&amp;lt;!-- Simple MDL Progress Bar --&amp;gt; &amp;lt;div class=&quot;mdl-progress mdl-js-progress&quot; id=&quot;p1&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; document.querySelector(&apos;#p1&apos;).addEventListener(&apos;mdl-componentupgraded&apos;, function(){ this.MaterialProgress.setProgress(44); }) &amp;lt;/script&amp;gt; `&lt;/pre&gt; ### Intedeterminate Progress Bar &lt;!-- MDL Progress Bar with Indeterminate Progress --&gt; &lt;div id=&quot;p2&quot; class=&quot;mdl-progress mdl-js-progress mdl-progress__indeterminate&quot;&gt;&lt;/div&gt; &lt;pre&gt;`&amp;lt;!-- MDL Progress Bar with Indeterminate Progress --&amp;gt; &amp;lt;div id=&quot;p2&quot; class=&quot;mdl-progress mdl-js-progress mdl-progress__indeterminate&quot;&amp;gt;&amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Buffering Progress Bar &lt;pre&gt;` &amp;lt;!-- MDL Progress Bar with Buffering --&amp;gt; &amp;lt;div class=&quot;mdl-progress mdl-js-progress&quot; id=&quot;p1&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; document.querySelector(&apos;#p1&apos;).addEventListener(&apos;mdl-componentupgraded&apos;, function(){ this.MaterialProgress.setProgress(33); this.MaterialProgress.setBuffer(66); }) &amp;lt;/script&amp;gt; `&lt;/pre&gt; ### Default Spinner &lt;div class=&quot;mdl-spinner mdl-js-spinner is-active&quot;&gt;&lt;/div&gt; &lt;pre&gt;`&amp;lt;div class=&quot;mdl-spinner mdl-js-spinner is-active&quot;&amp;gt;&amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Single Color Spinner &lt;div class=&quot;mdl-spinner mdl-spinner--single-color mdl-js-spinner is-active&quot;&gt;&lt;/div&gt; &lt;pre&gt;`&amp;lt;div class=&quot;mdl-spinner mdl-spinner--single-color mdl-js-spinner is-active&quot;&amp;gt;&amp;lt;/div&amp;gt;","link":"/2016/05/26/mdl-loading/"},{"title":"MDL-Button","text":"Add: class=”mdl-button mdl-js-button mdl-button–fab mdl-button–colored mdl-js-ripple-effect”, “mdl-button–fab” adds the 3D circle, “mdl-button–colored” colors the 3D circle, “mdl-js-ripple-effect” adds ripple effect ont the button Button: class=”mdl-button mdl-js-button mdl-button–raised mdl-js-ripple-effect”, “mdl-button–raised” adds the 3D Rectangle on the button. Button: class=”mdl-button mdl-js-button mdl-button–raised mdl-button–colored”, “mdl-button–colored” add Primary color to Button. Button: class=”mdl-button mdl-js-button mdl-button–raised mdl-button–accent”, “mdl-button–accent” adds Accent color ont he Button. Button: class=”mdl-button mdl-js-button mdl-button–primary”, “mdl-button–primary” adds primary color on the text. Button: class=”mdl-button mdl-js-button mdl-button–accent”, “mdl-button–accent” adds accent color on the text i: class=”mdl-button mdl-js-button mdl-button–fab mdl-button–mini-fab”, “mdl-button–mini-fab” make a mini button” &lt;!– Colored FAB Button –&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–fab mdl-button–colored mdl-js-ripple-effect”&gt;Add&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–fab mdl-button–colored mdl-js-ripple-effect”, &lt;strong&gt;”mdl-button–fab” adds the 3D circle, “mdl-button–colored” colors the 3D circle, “mdl-js-ripple-effect” adds ripple effect ont the button&lt;/strong&gt;&lt;br&gt; &lt;!– Raised Button –&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–raised mdl-js-ripple-effect”&gt;Button&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–raised mdl-js-ripple-effect”, &lt;strong&gt;”mdl-button–raised” adds the 3D Rectangle on the button.&lt;/strong&gt;&lt;br&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–raised mdl-button–colored”&gt;Button&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–raised mdl-button–colored”, &lt;strong&gt;”mdl-button–colored” add Primary color to Button.&lt;/strong&gt;&lt;br&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–raised mdl-button–accent”&gt;Button&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–raised mdl-button–accent”, &lt;strong&gt;”mdl-button–accent” adds Accent color ont he Button.&lt;/strong&gt;&lt;br&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–primary”&gt;Button&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–primary”, &lt;strong&gt;”mdl-button–primary” adds primary color on the text.&lt;/strong&gt;&lt;br&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–accent”&gt;Button&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–accent”, &lt;strong&gt;”mdl-button–accent” adds accent color on the text&lt;/strong&gt;&lt;br&gt; &lt;!– Mini FAB Button –&gt; &lt;button class=”mdl-button mdl-js-button mdl-button–fab mdl-button–mini-fab”&gt;i&lt;/button&gt;: class=”mdl-button mdl-js-button mdl-button–fab mdl-button–mini-fab”, &lt;strong&gt;”mdl-button–mini-fab” make a mini button”&lt;/strong&gt;&lt;br&gt;","link":"/2016/05/25/mdl-button/"},{"title":"MDL-Card","text":"Wide Card &amp;lt;style&amp;gt; .demo-card-wide.mdl-card{ width:512px } .demo-card-wide&amp;gt;.mdl-card__title{ color: #fff; height: 176px; background: url(&quot;https://getmdl.io/assets/demos/welcome_card.jpg&quot;) center/cover; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;div class=&quot;demo-card-wide mdl-card mdl-shadow--2dp&quot;&amp;gt; &amp;lt;div class=&quot;mdl-card__title&quot;&amp;gt; &amp;lt;h2 class=&quot;mdl-card__title-text&quot;&amp;gt;TItle&amp;lt;/h2&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__supporting-text&quot;&amp;gt; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__actions mdl-card--border&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-button mdl-js-button mdl-js-ripple-effect&quot;&amp;gt;Get Start&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__menu&quot;&amp;gt; &amp;lt;button class=&quot;mdl-button mdl-js-button mdl-js-ripple-effect&quot;&amp;gt;Share&amp;lt;/button&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; `&lt;/pre&gt; ### Square Card ![Square Card](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/squareCard.png) &lt;pre&gt;`&amp;lt;style&amp;gt; .demo-card-square.mdl-card{ width:320px; height: 320px; } .demo-card-square&amp;gt;.mdl-card__title{ color: #fff; background: url(&apos;https://getmdl.io/assets/demos/dog.png&apos;) bottom right 15% no-repeat #46B6AC; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;div class=&quot;demo-card-square mdl-card mdl-shadow--2dp&quot;&amp;gt; &amp;lt;div class=&quot;mdl-card__title mdl-card--expand&quot;&amp;gt; &amp;lt;h2 class=&quot;mdl-card__title-text&quot;&amp;gt; Square Card &amp;lt;/h2&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__supporting-text&quot;&amp;gt; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; Supporting Text; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__actions mdl-card--border&quot;&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-button mdl-js-button mdl-js-ripple-effect&quot;&amp;gt;View Update&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; `&lt;/pre&gt; ### Image Card ![Image Card](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/ImageCard.png) &lt;pre&gt;`&amp;lt;style&amp;gt; .demo-card-image.mdl-card{ width: 256px; height: 256px; background: url(&apos;https://getmdl.io/assets/demos/image_card.jpg&apos;) center/cover; } .demo-card-image&amp;gt;.mdl-card__actions{ height: 52px; padding:16px; background: rgba(0,0,0,0.2); } .demo-card-image__filename{ color: #fff; font-size: 14px; font-weight: 500; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;div class=&quot;demo-card-image mdl-card mdl-shadow--2dp&quot;&amp;gt; &amp;lt;div class=&quot;mdl-cart__title mdl-card--expand&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__actions&quot;&amp;gt; &amp;lt;span class=&quot;demo-card-image__filename&quot;&amp;gt;Image Filename&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; `&lt;/pre&gt; ### Event Card ![Event Card](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/EventCard.png) &lt;pre&gt;`&amp;lt;style&amp;gt; .demo-card-event.mdl-card{ width: 256px; height: 256px; background: #3E4EB8; } .demo-card-event&amp;gt;.mdl-card__actions{ border-color: rgba(255,255,255,0.2); } .demo-card-event&amp;gt;.mdl-card__title{ align-items: flex-start; } .demo-card-event&amp;gt;.mdl-card__title&amp;gt;h4{ margin-top: 0; } .demo-card-event&amp;gt;.mdl-card__actions{ display: flex; box-sizing: border-box; align-items: center; } .demo-card-event&amp;gt;.mdl-card__actions&amp;gt;.material-icons{ padding-right: 10px; } .demo-card-event&amp;gt;.mdl-card__title, .demo-card-event&amp;gt;.mdl-card__actions, .demo-card-event&amp;gt;.mdl-card__actions&amp;gt;.mdl-button{ color:#fff; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;div class=&quot;demo-card-event mdl-card mdl-shadow--2dp&quot;&amp;gt; &amp;lt;div class=&quot;mdl-card__title mdl-card--expand&quot;&amp;gt; &amp;lt;h4&amp;gt; Featured event:&amp;lt;br&amp;gt; May 24, 2016&amp;lt;br&amp;gt; 7 - 11pm &amp;lt;/h4&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-card__actions mdl-card--border&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-button mdl-button--colored mdl-js-button mdl-js-ripple-effect&quot;&amp;gt; Add to Calendar &amp;lt;/a&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;Evnet&amp;lt;/i&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt;","link":"/2016/05/25/mdl-card/"},{"title":"MDL-Selection","text":"Checkbox Checkbox &amp;lt;!-- Checkbox --&amp;gt; &amp;lt;label for=&quot;checkbox1&quot; class=&quot;mdl-checkbox mdl-js-checkbox mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;input type=&quot;checkbox&quot; class=&quot;mdl-checkbox__input&quot; id=&quot;checkbox1&quot;&amp;gt; &amp;lt;span class=&quot;mdl-checkbox__label&quot;&amp;gt;Checkbox&amp;lt;/span&amp;gt; &amp;lt;/label&amp;gt; `&lt;/pre&gt; ### Radio Button &lt;!-- Radio Button --&gt; &lt;label for=&quot;option-1&quot; class=&quot;mdl-radio mdl-js-radio mdl-js-ripple-effect&quot;&gt; &lt;input type=&quot;button&quot; id=&quot;option-1&quot; class=&quot;mdl-radio__button&quot; name=&quot;options&quot; value=&quot;1&quot;&gt; &lt;span class=&quot;mdl-radio__label&quot;&gt;Radio&lt;/span&gt; &lt;/label&gt; &lt;pre&gt;`&amp;lt;!-- Radio Button --&amp;gt; &amp;lt;label for=&quot;option-1&quot; class=&quot;mdl-radio mdl-js-radio mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;input type=&quot;button&quot; id=&quot;option-1&quot; class=&quot;mdl-radio__button&quot; name=&quot;options&quot; value=&quot;1&quot;&amp;gt; &amp;lt;span class=&quot;mdl-radio__label&quot;&amp;gt;Radio&amp;lt;/span&amp;gt; &amp;lt;/label&amp;gt; `&lt;/pre&gt; ### Icon Toggle &lt;!-- Icon Toggle --&gt; &lt;label for=&quot;icon-toggle-1&quot; class=&quot;mdl-icon-toggle mdl-js-icon-toggle mdl-js-ripple-effect&quot;&gt; &lt;input type=&quot;checkbox&quot; class=&quot;mdl-icon-toggle__input&quot; id=&quot;icon-toggle-1&quot;&gt; _Icon_ &lt;/label&gt; &lt;pre&gt;`&amp;lt;!-- Icon Toggle --&amp;gt; &amp;lt;label for=&quot;icon-toggle-1&quot; class=&quot;mdl-icon-toggle mdl-js-icon-toggle mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;input type=&quot;checkbox&quot; class=&quot;mdl-icon-toggle__input&quot; id=&quot;icon-toggle-1&quot;&amp;gt; &amp;lt;i class=&quot;mdl-icon-toggle__label material-icons&quot;&amp;gt;Icon&amp;lt;/i&amp;gt; &amp;lt;/label&amp;gt; `&lt;/pre&gt; ### Switch &lt;!-- Switch --&gt; &lt;label for=&quot;switch-1&quot; class=&quot;mdl-switch mdl-js-switch mdl-js-ripple-effect&quot;&gt; &lt;input type=&quot;checkbox&quot; class=&quot;mdl-switch__input&quot; id=&quot;switch-1&quot;&gt; &lt;span class=&quot;mdl-switch__label&quot;&gt;&lt;/span&gt; &lt;/label&gt; &lt;pre&gt;`&amp;lt;!-- Switch --&amp;gt; &amp;lt;label for=&quot;switch-1&quot; class=&quot;mdl-switch mdl-js-switch mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;input type=&quot;checkbox&quot; class=&quot;mdl-switch__input&quot; id=&quot;switch-1&quot;&amp;gt; &amp;lt;span class=&quot;mdl-switch__label&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;/label&amp;gt;","link":"/2016/05/27/mdl-selection/"},{"title":"MDL-Menu","text":"Left Aligned Menu Below Button i Some Action Another Action Disabled Action Yet Another Action &amp;lt;!-- Left aligned menu below button --&amp;gt; &amp;lt;button id=&quot;leftBelowButton&quot; class=&quot;mdl-button mdl-js-button mdl-button--icon mdl-button--fab&quot;&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;i&amp;lt;/i&amp;gt; &amp;lt;/button&amp;gt; &amp;lt;ul class=&quot;mdl-menu mdl-js-menu mdl-menu--bottom-left mdl-js-ripple-effect&quot; for=&quot;leftBelowButton&quot;&amp;gt; &amp;lt;li class=&quot;mdl-menu__item&quot;&amp;gt;Some Action&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-menu__item mdl-menu__item--full-bleed-divider&quot;&amp;gt;Another Action&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-menu__item&quot; disabled&amp;gt;Disabled Action&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-menu__item&quot;&amp;gt;Yet Another Action&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; ` Right Aligned Menu Below Button i Some Action Another Action Disabled Action Yet Another Action ` &lt;!-- Right aligned menu below button --&gt; &lt;button id=\"rightBelowButton\" class=\"mdl-button mdl-js-button mdl-button--icon mdl-button--fab\"&gt; &lt;i class=\"material-icons\"&gt;i&lt;/i&gt; &lt;/button&gt; &lt;ul class=\"mdl-menu mdl-js-menu mdl-menu--bottom-right mdl-js-ripple-effect\" for=\"rightBelowButton\"&gt; &lt;li class=\"mdl-menu__item\"&gt;Some Action&lt;/li&gt; &lt;li class=\"mdl-menu__item mdl-menu__item--full-bleed-divider\"&gt;Another Action&lt;/li&gt; &lt;li class=\"mdl-menu__item\" disabled&gt;Disabled Action&lt;/li&gt; &lt;li class=\"mdl-menu__item\"&gt;Yet Another Action&lt;/li&gt; &lt;/ul&gt; ` Left Aligned Menu Above Button i Some Action Another Action Disabled Action Yet Another Action ` &lt;!-- Left aligned menu above button --&gt; &lt;button id=\"leftAboveButton\" class=\"mdl-button mdl-js-button mdl-button--icon mdl-button--fab\"&gt; &lt;i class=\"material-icons\"&gt;i&lt;/i&gt; &lt;/button&gt; &lt;ul class=\"mdl-menu mdl-js-menu mdl-menu--top-left mdl-js-ripple-effect\" for=\"leftAboveButton\"&gt; &lt;li class=\"mdl-menu__item\"&gt;Some Action&lt;/li&gt; &lt;li class=\"mdl-menu__item mdl-menu__item--full-bleed-divider\"&gt;Another Action&lt;/li&gt; &lt;li class=\"mdl-menu__item\" disabled&gt;Disabled Action&lt;/li&gt; &lt;li class=\"mdl-menu__item\"&gt;Yet Another Action&lt;/li&gt; &lt;/ul&gt; ` Right Aligned Menu Above Button i Some Action Another Action Disabled Action Yet Another Action ` &lt;!– Right aligned menu above button –&gt; &amp;lt;button id=&quot;rightAboveButton&quot; class=&quot;mdl-button mdl-js-button mdl-button--icon mdl-button--fab&quot;&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;i&amp;lt;/i&amp;gt; &amp;lt;/button&amp;gt; &amp;lt;ul class=&quot;mdl-menu mdl-js-menu mdl-menu--top-right mdl-js-ripple-effect&quot; for=&quot;rightAboveButton&quot;&amp;gt; &amp;lt;li class=&quot;mdl-menu__item&quot;&amp;gt;Some Action&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-menu__item mdl-menu__item--full-bleed-divider&quot;&amp;gt;Another Action&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-menu__item&quot; disabled&amp;gt;Disabled Action&amp;lt;/li&amp;gt; &amp;lt;li class=&quot;mdl-menu__item&quot;&amp;gt;Yet Another Action&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt;","link":"/2016/05/27/mdl-menu/"},{"title":"MDL-Navigation","text":"Transparent Navigation .demo-layout-transparent{ background: url(&apos;https://getmdl.io/assets/demos/transparent.jpg&apos;) center/cover; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;div class=&quot;demo-layout-transparent mdl-layout mdl-js-layout&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header mdl-layout__header--transparent&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;!--Title--&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;!--Add spacer, to align navigation to the right--&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;!--Navigation--&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;nav class=&quot;mdl-navigation__link&quot; href=&quot;#&quot;&amp;gt;Link&amp;lt;/nav&amp;gt; &amp;lt;nav class=&quot;mdl-navigation__link&quot; href=&quot;#&quot;&amp;gt;Link&amp;lt;/nav&amp;gt; &amp;lt;nav class=&quot;mdl-navigation__link&quot; href=&quot;#&quot;&amp;gt;Link&amp;lt;/nav&amp;gt; &amp;lt;nav class=&quot;mdl-navigation__link&quot; href=&quot;#&quot;&amp;gt;Link&amp;lt;/nav&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Fixed Drawer without Header(The drawer will open automatically in large screen) ![Fixed Drawer](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/FixedDrawer1.png) &lt;pre&gt;` &amp;lt;div class=&quot;mdl-layout mdl-js-layout mdl-layout--fixed-drawer&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Fixed Header(The Header shows always, even in small screen) ![Fixed Header](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/FixedHeader.png) &lt;pre&gt;` &amp;lt;div class=&quot;mdl-layout mdl-js-layout mdl-layout--fixed-header&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;nav class=&quot;mdl-navigation mdl-navigation--large-screen-only&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt; Title &amp;lt;/span&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Fixed Header and Drawer ![Fixed Header and Drawer](http://7xu8mu.com1.z0.glb.clouddn.com/wp-content/uploads/FixedHeader&amp;Drawer.png) &lt;pre&gt;`&amp;lt;div class=&quot;mdl-layout mdl-js-layout mdl-layout--fixed-drawer mdl-layout--fixed-header&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-text--align-right&quot;&amp;gt; &amp;lt;label for=&quot;fixed-header-drawer-exp&quot; class=&quot;mdl-button mdl-js-button mdl-button--icon&quot;&amp;gt;S&amp;lt;/label&amp;gt; &amp;lt;div class=&quot;mdl-textfield__expandable-holder&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; name=&quot;sample&quot; id=&quot;fixed-header-drawer-exp&quot;&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Scrolling Header &lt;pre&gt;`&amp;lt;div class=&quot;mdl-layout mdl-js-layout&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header mdl-layout__header--scroll&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Waterfall Header &lt;pre&gt;` &amp;lt;div class=&quot;demo-layout-water mdl-layout mdl-js-layout&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header mdl-layout--water&quot;&amp;gt; &amp;lt;!-- Top Row Always Visible --&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;!-- Title --&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right&quot;&amp;gt; &amp;lt;label for=&quot;waterfall-exp&quot; class=&quot;mdl-button mdl-js-button mdl-button--icon&quot;&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;Search&amp;lt;/i&amp;gt; &amp;lt;/label&amp;gt; &amp;lt;div class=&quot;mdl-textfield__expandable-holder&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; name=&quot;sample&quot; id=&quot;waterfall-exp&quot; class=&quot;mdl-textfield__input&quot;&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;!-- Bottom Row, Invisible on Scroll --&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout-spacer&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;nav class=&quot;mdl-navigation&quot;&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;&quot; class=&quot;mdl-navigation__link&quot;&amp;gt;Link&amp;lt;/a&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Scrollable Tabs &lt;pre&gt;`&amp;lt;div class=&quot;mdl-layout mdl-js-layout mdl-layout--fixed-header&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;!-- Tab --&amp;gt; &amp;lt;div class=&quot;mdl-layout__tab-bar mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;a href=&quot;#scroll-tab-1&quot; class=&quot;mdl-layout__tab is-active&quot;&amp;gt;Tab 1&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#scroll-tab-2&quot; class=&quot;mdl-layout__tab&quot;&amp;gt;Tab 2&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#scroll-tab-3&quot; class=&quot;mdl-layout__tab&quot;&amp;gt;Tab 3&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#scroll-tab-4&quot; class=&quot;mdl-layout__tab&quot;&amp;gt;Tab 4&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#scroll-tab-5&quot; class=&quot;mdl-layout__tab&quot;&amp;gt;Tab 5&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;main class=&quot;mdl-layout__content&quot;&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel is-active&quot; id=&quot;scroll-tab-1&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 1&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;scroll-tab-2&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 2&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;scroll-tab-3&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 3&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;scroll-tab-4&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 4&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;scroll-tab-5&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 5&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;/main&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Fixed Tabs &lt;pre&gt;`&amp;lt;div class=&quot;mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-tabs&quot;&amp;gt; &amp;lt;header class=&quot;mdl-layout__header&quot;&amp;gt; &amp;lt;div class=&quot;mdl-layout__header-row&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-layout__tab-bar mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;a href=&quot;#fixed-tab-1&quot; class=&quot;mdl-layout__tab is-active&quot;&amp;gt;Tab 1&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#fixed-tab-2&quot; class=&quot;mdl-layout__tab&quot;&amp;gt;Tab 2&amp;lt;/a&amp;gt; &amp;lt;a href=&quot;#fixed-tab-3&quot; class=&quot;mdl-layout__tab&quot;&amp;gt;Tab 3&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;div class=&quot;mdl-layout__drawer&quot;&amp;gt; &amp;lt;span class=&quot;mdl-layout-title&quot;&amp;gt;Title&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;main class=&quot;mdl-layout__content&quot;&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;fixed-tab-1&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 1&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;fixed-tab-2&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 2&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;section class=&quot;mdl-layout__tab-panel&quot; id=&quot;fixed-tab-3&quot;&amp;gt; &amp;lt;div class=&quot;page-content&quot; style=&quot;height:500px&quot;&amp;gt;Tab 3&amp;lt;/div&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;/main&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;","link":"/2016/05/26/mdl-navigation/"},{"title":"MDL-Slider","text":"Default Slider &amp;lt;!-- Default Slider --&amp;gt; &amp;lt;input type=&quot;range&quot; class=&quot;mdl-slider mdl-js-slider&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;0&quot; tabindex=&quot;0&quot;&amp;gt; `&lt;/pre&gt; ### Slider with Starting Value &lt;!-- Slider with Starting Value --&gt; &lt;input type=&quot;range&quot; class=&quot;mdl-slider mdl-js-slider&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;25&quot; tabindex=&quot;0&quot;&gt; &lt;pre&gt;`&amp;lt;!-- Slider with Starting Value --&amp;gt; &amp;lt;input type=&quot;range&quot; class=&quot;mdl-slider mdl-js-slider&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;25&quot; tabindex=&quot;0&quot;&amp;gt;","link":"/2016/05/27/mdl-slider/"},{"title":"MDL-Snackbar","text":"Show Snackbar (function(){ 'user strict' var snackbarContainer = document.querySelector('#snackbar'); var showSnackbarButton = document.querySelector('#show-snackbar'); var handler = function(event){ showSnackbarButton.style.backgroundColor = ''; }; showSnackbarButton.addEventListener('click', function(){ 'user strict' showSnackbarButton.style.backgroundColor = '#' + Math.floor(Math.random() * 0xffffff).toString(16); var data={ message: \"Button Color Changed.\", timeout: 2000, actionHandler: handler, actionText: \"Undo\" }; snackbarContainer.MaterialSnackbar.showSnackbar(data); }); }()); &amp;lt;button id=&quot;show-snackbar&quot; class=&quot;mdl-button mdl-js-button mdl-button--raised mdl-js-ripple-effect&quot; type=&quot;button&quot;&amp;gt;Show Snackbar&amp;lt;/button&amp;gt; &amp;lt;div id=&quot;snackbar&quot; class=&quot;mdl-snackbar mdl-js-snackbar&quot;&amp;gt; &amp;lt;div class=&quot;mdl-snackbar__text&quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;button class=&quot;mdl-snackbar__action&quot; type=&quot;button&quot;&amp;gt;&amp;lt;/button&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;script&amp;gt; (function(){ &apos;user strict&apos; var snackbarContainer = document.querySelector(&apos;#snackbar&apos;); var showSnackbarButton = document.querySelector(&apos;#show-snackbar&apos;); var handler = function(event){ showSnackbarButton.style.backgroundColor = &apos;&apos;; }; showSnackbarButton.addEventListener(&apos;click&apos;, function(){ &apos;user strict&apos; showSnackbarButton.style.backgroundColor = &apos;#&apos; + Math.floor(Math.random() * 0xffffff).toString(16); var data={ message: &quot;Button Color Changed.&quot;, timeout: 2000, actionHandler: handler, actionText: &quot;Undo&quot; }; snackbarContainer.MaterialSnackbar.showSnackbar(data); }); }()); &amp;lt;/script&amp;gt;","link":"/2016/05/27/mdl-snackbar/"},{"title":"Mannual of Ownership in Rust ","text":"Ownership is Rust’s most unique feature, and it enables Rust to make memory safety guarantees without needing a garbage collector. Therefore, it’s important to understand how ownership works in Rust. In this chapter we’ll talk about ownership as well as several related features: borrowing, slices, and how Rust lays data out in memory. What is OwnershipRust’s central feature is ownership, although the feature is staightforward to explain, it has deep implications of the rest of the language. All programs have to manage the way they use a computer’s memory while running. Some languages ahve garbage collecion that constantly looks for no longer used memory as the program runs. In other languages, the programmer must explicitly allocate and free the memory. Rust uses a third approach: memory is managed through a system of ownership with a set of rules that the compiler checks at compile time. No run-time costs are iccured for any of the ownership features. Because ownership is a new concept for many programmers, it does take some time to get used to. The good news is that the more experienced you become with Rust and the rules of the ownership system, the more you’ll be able to naturally develop code that is safe and efficient. Ownership RulesFirst, let’s take a look at the ownership rules. Each Value in Rust has a variable that’s called its owner. There can only be one owner at a time. When the owner goes out of scope, the value will be dropped. Variable ScopeA scope is the range within a program for which an item is valid. 123fn main () { let s = \"hello\";} The variable s refers to a string literal, where the value of the string is hardcoded into the text of our program. The variable is valid from the point at which it’s declared until the end of the current scope. 123{ // s is not valid here let s = \"hello\"; // s is valid here} // the scope is over, and s is no longer valid. When s comes into scope it is valid It remains so until it goes out of scope At this point, the relationship between scopes and the valid variables are valid is similar to other programming languages. Now we’ll build on top of this understanding by introducing the String type. The String TypeTo illustrate the rules of ownership, we need a data type that is complex. We’ll use String as the example here and concentrate on the parts of String that relate to ownership. These aspects also apply to other complex data types provided by the standard library and that you create. We’ve already seen string literals, where a string value is hardcoded into our program. String literals are conveient, but they aren’t always suitable for every situation in which you want to use text. One reason is that they’re immutable. Another is that not every string value can be known when we write our code. For these situations, Rust has a second string type, String. This type is allocated on the heap and as such is able to store an amount of text that is unknown to us at compile time. You can create a String from a string literal using the from function, like so: 1let s = String::from(\"hello\") The double colon(::) is an operator that allows us to namespace this particular from function under the String type rather than using some sort of name like string_from. This kind of string can be mutated: 123let mut s = String::from('Hello')s.push_str(\", world!\")println!(\"{}\", s); So why can String be mutated but literals cannot. Memory and AllocationIn the case of a string literal, we know the contents at compile so the text is hardcoded directly in to the final executable, making string literals fast and efficient. But these properties only come from its immutability. Unfortunately, we can’t put a blob of memory into the binary for each piece of text whose size is unknown at compile time and whose size might change while running the program. With the String type, in order to support a mutable, growable piece of text, we need to allocate an amount of memory on the heap, unknown at compile time, to hold the contents. This means: The memory must be requested from the operating system at runtime. We need a way of returning this memory to the operating system when we’re done with our String That first part is done by us: when we call String::from, its implementation requests the memory if needs. This is pretty much universal in programming languages. However, the second part is different. In languages with a garbage collector(GC), the GC keeps track and cleans up memory that isn’t being used anymore, and we, as the programmer, don’t need to think about it. Without a GC, it’s the programmer’s responsibility to identify when memory is no longer being used and call code to explicitly return it, just as we did to request it. Doing this correctly has historically been a difficult programming problem. If we forget, we’ll waste memory. If we do it too early, we’ll have an invalid vairable. If we do it twice, that’s a bug too. We need to pair exactly one allocate with exact one free Rust takes a different path: the memory is automatically returned once the variable that owns it goes out of scope. 1234{ let s = String::from(\"Helloe\"); // s is valid from this point} // the scope is over These is a natural point at which we can return the memory our String needs to operating system: when s goes out of scope. When a variables goes out of scope, Rust calls a special function for us. This function is called drop, and it’s where the author of String can put the code to return the memory. Rust calls drop automatically at the closing }. Note: In C++, this pattern of deallocating resources at the end of an item’s lifetime is sometimes called Resource Acquisition Is Initialization(RAII). The drop function in Rust will be familiar to you if you’ve used RAII patterns. This patterns has profound impact on the way Rust code is written. It may seem simple right now, but the behavior of code can be unexpected in more complicated situations when we want to have multiple variables use the data we’ve allocated ont the heap. Ways Variables and Data Interact: MoveMultiple variables can interact with the same data in different ways in Rust. Let’s look at an example using an integer. 12let x = 5;let y = x; Here we got two independent variables x and y, this is because integers are simple values with a known, fixed size, and two 5 are pushed onto the stack. Now let’s look at the String version. 12let s1 = String::from(\"Hello\");let s2 = s1; This looks very similar to the previous code, so we might assume that the way it works would be the same: that is, the second line would make a copy of the value in s1 and bind it to s2. But this isn’t quite what happens. To explain this more thoroughly, let’s look at what String looks like under the covers in the Figure. A String is made up of three parts, shown on the left: a pointer to the memory that holds the contents of the string, a length, and a capacity. This group of data is stored on the stack. On the right is the memory on the heap that holds the contents. The length is how much memory, in bytes, the contents of the String is currently using. The capacity is the total amount of memory, in bytes, that the String has received from the operating system. The difference between length and capacity matters, but not in this context, so far now, it’s fine to ignore the capacity. When we assign s1 to s2, the String data is copied, meaning we copy the pointer, the length and the capacity that are on the stack. We do not copy the data on the heap that the pointer refers to. In other words, the data representation in memory looks like the figure following. Eariler, we said that when a variable goes out of scope, Rust automatically calls the drop function and cleans up the heap memory for the variable. But the fact is that both data pointers pointing to the same location. This is a problem: when s2 and s1 go out of scope, they will both try to free the same memory. This is known as a double free error. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities. To ensure memory safety, there’s one more detail to what happens in this situation in Rust. Instead of trying to copy the allocated memory, Rust considers s1 to no longer be valid and therefore, Rust doesn’t need to free anything when s1 goes out of scope. Check out what happens when you try to use s1 after s2 is created. 1234let s1 = String::from(\"hello\");let s2 = s1;println!(\"{}\", s1); You’ll get an error like this because Rust prevents you from using the invalidated reference: 12345678910error[E0382]: use of moved value: `s1` --&gt; src/main.rs:4:27 |3 | let s2 = s1; | -- value moved here4 | println!(\"{}\", s1); | ^^ value used here after move | = note: move occurs because `s1` has type `std::string::String`,which does not implement the `Copy` trait This action in Rust, similar to shallow copy, it copy pointer, length and capacity in stack, but Rust also invalidates the first variable. We call it move. s1 has been invalidated. That solves our problem, with only s2 valid, when it goes out of scope, it alone will freee the memory, and we’re done. In addition, there’s a design choice that’s implied by this: Rust will never automatically create ‘deep’ copies of your data. Therefore, any automatic copying can be assumed to be inexpensive in terms of runtime performance. Ways Variables and Data Interact: CloneIf we do want to deeply copy the heap data of the String, not just the stack data, we can use a common method called clone. 123let s1 = String::from(\"Hello\");let s2 = s1.clone();println!(\"s1 = {}, s2 = {}\", s1, s2); This works just fine, the heap data does get copied. When you see a call to clone, you know that some arbitrary code is being executed and that code may be expensive. It’s a visual indicator that something different is going on. Stack-Only Data: CopyThere’s another wrinkle we haven’t talked about yet. This code using integers. 1234let x = 5;let y = x;println!(\"x = {}, y = {}\", x, y); This code runs correctly because those types like integers that have a known size at compile time are stored entirely on the stack, so copied of the actual values are quick to make. That means there’s no reason we would want to prevent x from being valid after we created the variable y. In other words, there’s no difference between deep and shallow copying here, so calling clone wouldn’t do anything differently from the usual shallow copying and we can leave it out. Rust has a special annotation called the Copy trait that we can place on types like integers that are stored on stack. If a type has the Copy trait, an older variable is still usable after the assignment. Rust won’t let us annotate a type with the Copy trait if the type, or any of its parts, has implemented the Drop trait. If the type needs something special to happen when the value goes out of scope and we add the Copy annotation to that type, we’ll get a compile time error. As a general rule, any group of simple scalar values can be Copy, and nothing that requires allocation or is some form of resource is Copy. Here are some of the types that are Copy: All the integer types The boolean type All the floating point types Tuples, but only if they contain types a also Copy. Ownership and FunctionsThe semantics for passing a value to a function are similar to assigning a value to a variable. Passing a variable to a function will move or copy, just like assignment. 1234567891011121314151617fn main () { let s = String::from(\"Hello\"); // s comes into scope take_ownership(s); // s's value moves into the function // s is no longer valid here let x = 5; // x comes into scope make_copy(x); // x would move into the function, but i32 is Copy, so it's okay to still use x afterward.}fn take_ownership (some_string: String) { // some_string comes into scope println!(\"{}\", some_string);} // here, some_string goes out of scope and `drop` is called. The backing memory is freed.fn make_copy (some_integer: i32) { // some_integer comes into scope println!(\"{}\", some_integer);} // Here some_integer goes out of scope. If we tried to use s after the call to take_ownership, Rust would throw a compile time error. These static checks protect us from mistakes. Return Values and ScopeReturning values can also transfer ownership. 1234567891011121314fn main () { let s1 = give_ownership(); // give_ownership moves its return value into s1 let s2 = String::from(\"Hello\"); // s2 comes into scope let s2 = take_and_give_back(s2); // s2 is moved into take_and_give_back, which aslo move its returned value into s2}fn give_ownership () -&gt; String { let some_string = String::from(\"Hello\"); // some_string comes into scope some_string // some_string is returned and moves out to the calling function}fn take_and_give_back(a_string: String) -&gt; { // a_string comes into scope a_string // a_string is returned and moves out to the calling function} It’s possible to return mutiple values using a tuple. Reference and BorrowingHere is how you would define and use a calculate_length function that has a reference to an object as a parameter instead of taking ownership of the value. 1234567891011fn main () { let s1 = String::from(\"Hello\"); let len = calculate_length(&amp;s1); println!(\"The length of '{}' is {}.\", s1, len);}fn calculate_length(s: &amp;String) - usize { s.len()} First notice that all the tuple code in the variable declaration and the function return value is gone. Second, note that we pass &amp;s1 into calculate_length, and in its definition, we take &amp;String rather than String. These ampersands(&amp;) are reference, and they allow you to refer to some value without taking ownership of it. In this figure, &amp;String s pointing to String s1 Let’s take a closer look at the function call here: 12let s1 = String::from(\"Hello\")let len = calculate_length(&amp;s1) The &amp;s1 syntax lets us create a reference that refer to the value of s1, but does not own it. Because it does not own it, the value it points to will not be dropped when the reference goes out of scope. Likewise, the signature of the function uses &amp; to indicate that the type of the paramter s is a reference. 123fn calculate_length(s: &amp;String) -&gt; usize { // s is a reference to a String s.len()} // Here, s goes out of the scope. But because it does not have ownership of what it refers to, no drop happens. The scope in which the variable s is valid is the same as any function parameter’s scope, but we don’t drop what the reference points to when it goes out of scope because we don’t have ownership. Functions that have references as parameters instead of the actual values mean we won’t need to return the values in order to give back ownership, since we never had ownership. We call having references as function paramters borrowing. As in real life, if a person owns something, you can borrow it from them, When you’re done, you have to give it back. If we try to modify something we’re borrowing, it won’t work. Mutable References12345678fn main () { let mut s = String::from(\"Hello\"); change(&amp;mut s);}fn change(some_string: &amp;mut String) { some_string.push_str(', world')} First, we had to change s to be mut. Then we had to create mutable reference with &amp;mut s and accept a mutable reference with some_string: &amp;mut String. But mutable references have one big restriction: you can only mutable reference to a particular piece of data in a particular scope. This restriction allows for mutation but in a very controlled fashion. It’s something that new Rustaceans struggle with, because most languages let you mutate whenever you’d like. The benefit of having this restriction is that Rust can prevent data races at compile time. A data race is a particular type of race condition in which these three behaviors occur: Two or more pointers access the same data at the same time. At least one of the pointers is being used to write to the data. There’s no mechanism being used to synchrnize access to the data. Data races cause undefined behavior and can be difficult to diagnose and fix when you’re trying to track them down at runtime. Rust prevents this problem from happening because it won’t even compile code with data race. As always, we can use curly brackets to create a new scope, allowing for multiple mutable references, just not simultaneous ones: 12345let mut s = String::from(\"Hello\");{ let r1 = &amp;mut s;}let r2 = &amp;mut s; A similar rule exists for combining mutable and immutable references. This code results in an error: 1234let mut s = String::from(\"Hello\");let r1 = &amp;s; // no problemlet r2 = &amp;s; // no problemlet r3 = &amp;mut s; //BIG PROBLEM, mutable borrow occurs We also cannot have mutable reference while we have an immutable one. Users of an immutable reference don’t expect the values to suddently change out from under them. Dangling ReferencesIn languages with pointers, it’s easy to erroneously to create a dangling pointer, a pointer that references a location in memory that may have been given to someone else, by freeing some memory while preserving a pointer to that memory. In Rust, by contrast, the compiler guarantees the references will never be dangling references: if we have a reference to some data, the compiler will ensure that the data will not go out of scope before reference to the data does. The Rules of References At any given time, you can have either but not both of One mutable reference Any number of immutable references Referecences must always be valid. SlicesAnother data type that doesn’t have ownership is the slice. Slices let you reference a configuous sequence of elements in a collection rather tahn the whole collection. String SliceA string slice is a reference to part of a String, and looks like this: 1234let s = String::from(\"Hello world\");let hello = &amp;s[0..5];let world = &amp;s[6..11]; This is similar to taking a reference to the whole String, but with the extra [0..5] but. Rather than a reference to the entire String, it’s a reference to an internal position in the String and the number of elements that it refers to. We create slices with a range of [start_index..end_index], but the slice data structure acutally stores the starting position and the length of the slice. So in the case of let world = &amp;s[6..11];, world would be a slice that contains a pointer to the 6th byte of s and a length of value of 5. With Rust’s .. range syntax, if you want to start at the first index(0), you can drop the value before the two periods. In other words By the same token, if your slice includes the last byte of the String, you can drop the trailing number. You can also drop both values to take a slice of the entire string. 12345678910fn first_word (s: &amp;String) -&gt; &amp;str { let bytes = s.as_bytes(); for (i, &amp;item) in bytes.iter().enumerate() { if item == b' ' { return &amp;s[0..i] } } &amp;s[..]} String Literals Are Slices1let s = \"Hello, World\"; The type of s here is &amp;str: it’s a slice pointing to the specific point of the binary. This is also why string literals are immutable; &amp;str is an immutable reference. String Slices as ParametersKnowing that you can take slices of literals and Strings leads us to one more improvement on first_word, and that’s its signature: 1fn first_word(s: &amp;String) -&gt; &amp;str { If we have a string slice, we can pass that directly. If we have a String, we can pass a slice of the entire String. Defining a function to take a string slcie instead of a reference to a String makes our API more general and useful without losing any functionality. Other SlicesString slices, as you might imagine, are specific to strings. But there’s a more general slice type, too. 12let a = [1, 2, 3, 4, 5];let slice = &amp;a[1..3]; This slice has the type &amp;[i32]. It works the same way as string slices do, by storing a reference to the first element and the length.","link":"/2017/06/09/mannual-of-ownership-in-rust/"},{"title":"MDL-Table","text":"Selectable Table Material Quantity Unit Price Acrylic(Transparent) 25 $2.90 Plywood(Birch) 50 $1.25 Laminate(Gold on Blue) 10 $2.35 &amp;lt;table class=&quot;mdl-data-table mdl-js-data-table mdl-data-table--selectable mdl-shadow--2dp&quot;&amp;gt; &amp;lt;thead&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;th class=&quot;mdl-data-table__cell--non-numeric&quot;&amp;gt;Material&amp;lt;/th&amp;gt; &amp;lt;th&amp;gt;Quantity&amp;lt;/th&amp;gt; &amp;lt;th&amp;gt;Unit Price&amp;lt;/th&amp;gt; &amp;lt;/tr&amp;gt; &amp;lt;/thead&amp;gt; &amp;lt;tbody&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td class=&quot;mdl-data-table__cell--non-numeric&quot;&amp;gt;Acrylic(Transparent)&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;25&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;$2.90&amp;lt;/td&amp;gt; &amp;lt;/tr&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td class=&quot;mdl-data-table__cell--non-numeric&quot;&amp;gt;Plywood(Birch)&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;50&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;$1.25&amp;lt;/td&amp;gt; &amp;lt;/tr&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td class=&quot;mdl-data-table__cell--non-numeric&quot;&amp;gt;Laminate(Gold on Blue)&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;10&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;$2.35&amp;lt;/td&amp;gt; &amp;lt;/tr&amp;gt; &amp;lt;/tbody&amp;gt; &amp;lt;/table&amp;gt;","link":"/2016/05/27/mdl-table/"},{"title":"MDL-Tooltip","text":"Default Tooltip Title1 Follow &amp;lt;!-- Simple Tooltip --&amp;gt; &amp;lt;div class=&quot;icon material-icons&quot; id=&quot;tt1&quot;&amp;gt;Title1&amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-tooltip&quot; for=&quot;tt1&quot;&amp;gt;Follow&amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Large Tooltip &lt;!-- Simple Tooltip --&gt; &lt;div class=&quot;icon material-icons&quot; id=&quot;tt2&quot;&gt;Title2&lt;/div&gt; &lt;div class=&quot;mdl-tooltip mdl-tooltip--large&quot; for=&quot;tt2&quot;&gt;Large&lt;/div&gt; &lt;pre&gt;`&amp;lt;!-- Simple Tooltip --&amp;gt; &amp;lt;div class=&quot;icon material-icons&quot; id=&quot;tt2&quot;&amp;gt;Title2&amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-tooltip mdl-tooltip--large&quot; for=&quot;tt2&quot;&amp;gt;Large&amp;lt;/div&amp;gt; `&lt;/pre&gt; ### Rich Tooltip &lt;!-- Rich Tooltip --&gt; &lt;div class=&quot;icon material-icons&quot; id=&quot;tt3&quot;&gt;Rich&lt;/div&gt; &lt;div class=&quot;mdl-tooltip&quot; for=&quot;tt3&quot;&gt;Upload **file.zip**&lt;/div&gt; &lt;pre&gt;`&amp;lt;!-- Rich Tooltip --&amp;gt; &amp;lt;div class=&quot;icon material-icons&quot; id=&quot;tt3&quot;&amp;gt;Rich&amp;lt;/div&amp;gt; &amp;lt;div class=&quot;mdl-tooltip&quot; for=&quot;tt3&quot;&amp;gt;Upload &amp;lt;strong style=&apos;color:yellow&apos;&amp;gt;file.zip&amp;lt;/strong&amp;gt;&amp;lt;/div&amp;gt;","link":"/2016/05/27/mdl-tooltip/"},{"title":"MDL-Textfield","text":"Text Field &amp; Numeric Textfield PlaceHolder.. &amp;lt;br&amp;gt; &amp;lt;!-- Numeric Textfield --&amp;gt; &amp;lt;form action=&quot;#&quot;&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample2&quot; pattern=&quot;-?[0-9]*(.[0-9]+)?&quot;&amp;gt; &amp;lt;label for=&quot;sample2&quot; class=&quot;mdl-textfield__label&quot;&amp;gt;Numeric Textfield&amp;lt;/label&amp;gt; &amp;lt;span class=&quot;mdl-textfield__error&quot;&amp;gt;Input is not a number!&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; `&lt;/pre&gt; &lt;/form&gt; &lt;pre&gt;`&amp;lt;!-- Simple Textfield --&amp;gt; &amp;lt;form action=&quot;#&quot;&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample1&quot;&amp;gt; &amp;lt;label for=&quot;sample1&quot; class=&quot;mdl-textfield__label&quot;&amp;gt;PlaceHolder..&amp;lt;/label&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/form&amp;gt; &amp;lt;br&amp;gt; &amp;lt;!-- Numeric Textfield --&amp;gt; &amp;lt;form action=&quot;#&quot;&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample2&quot; pattern=&quot;-?[0-9]*(.[0-9]+)?&quot;&amp;gt; &amp;lt;label for=&quot;sample2&quot; class=&quot;mdl-textfield__label&quot;&amp;gt;Numeric Textfield&amp;lt;/label&amp;gt; &amp;lt;span class=&quot;mdl-textfield__error&quot;&amp;gt;Input is not a number!&amp;lt;/span&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/form&amp;gt; `&lt;/pre&gt; ### Floating Label Textfield &lt;!-- Floating Label --&gt; &lt;form action=&quot;#&quot;&gt; &lt;div class=&quot;mdl-textfield mdl-js-textfield mdl-textfield--floating-label&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample3&quot;&gt; &lt;label for=&quot;sample3&quot; class=&quot;mdl-textfield__label&quot;&gt;Floating&lt;/label&gt; &lt;/div&gt; &lt;/form&gt; &lt;pre&gt;`&amp;lt;!-- Floating Label --&amp;gt; &amp;lt;form action=&quot;#&quot;&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield mdl-textfield--floating-label&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample3&quot;&amp;gt; &amp;lt;label for=&quot;sample3&quot; class=&quot;mdl-textfield__label&quot;&amp;gt;Floating&amp;lt;/label&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/form&amp;gt; `&lt;/pre&gt; ### Multiple Line Textfield &lt;!-- Multiple Line --&gt; &lt;form action=&quot;#&quot;&gt; &lt;div class=&quot;mdl-textfield mdl-js-textfield&quot;&gt; &lt;textarea name=&quot;&quot; id=&quot;sample4&quot; cols=&quot;30&quot; rows=&quot;3&quot; class=&quot;mdl-textfield__input&quot; type=&quot;text&quot;&gt;&lt;/textarea&gt; &lt;label for=&quot;sample4&quot; class=&quot;mdl-textfield__label&quot;&gt;Multiple Line&lt;/label&gt; &lt;/div&gt; &lt;/form&gt; &lt;pre&gt;` &amp;lt;!-- Multiple Line --&amp;gt; &amp;lt;form action=&quot;#&quot;&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield&quot;&amp;gt; &amp;lt;textarea name=&quot;&quot; id=&quot;sample4&quot; cols=&quot;30&quot; rows=&quot;3&quot; class=&quot;mdl-textfield__input&quot; type=&quot;text&quot;&amp;gt;&amp;lt;/textarea&amp;gt; &amp;lt;label for=&quot;sample4&quot; class=&quot;mdl-textfield__label&quot;&amp;gt;Multiple Line&amp;lt;/label&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/form&amp;gt; `&lt;/pre&gt; ### Expandable Textfield &lt;!-- Expandable Textfield --&gt; &lt;form action=&quot;#&quot;&gt; &lt;div class=&quot;mdl-textfield mdl-js-textfield mdl-textfield--expandable&quot;&gt; &lt;label for=&quot;sample5&quot; class=&quot;mdl-button mdl-js-button mdl-button--icon mdl-js-ripple-effect&quot;&gt; _S_ &lt;/label&gt; &lt;div class=&quot;mdl-textfield__expandable-holder&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample5&quot;&gt; &lt;label for=&quot;sample5&quot; class=&quot;mdl-textfield__label&quot;&gt;Expandable Input&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;/form&gt; &lt;pre&gt;` &amp;lt;!-- Expandable Textfield --&amp;gt; &amp;lt;form action=&quot;#&quot;&amp;gt; &amp;lt;div class=&quot;mdl-textfield mdl-js-textfield mdl-textfield--expandable&quot;&amp;gt; &amp;lt;label for=&quot;sample5&quot; class=&quot;mdl-button mdl-js-button mdl-button--icon mdl-js-ripple-effect&quot;&amp;gt; &amp;lt;i class=&quot;material-icons&quot;&amp;gt;S&amp;lt;/i&amp;gt; &amp;lt;/label&amp;gt; &amp;lt;div class=&quot;mdl-textfield__expandable-holder&quot;&amp;gt; &amp;lt;input type=&quot;text&quot; class=&quot;mdl-textfield__input&quot; id=&quot;sample5&quot;&amp;gt; &amp;lt;label for=&quot;sample5&quot; class=&quot;mdl-textfield__label&quot;&amp;gt;Expandable Input&amp;lt;/label&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/form&amp;gt;","link":"/2016/05/27/mdl-textfield/"},{"title":"Mix-Blend-Mode之 Multiply, Screen, Difference","text":"语法 mix-blend-mode: &amp;lt;mode&amp;gt; normal: 默认值, 正常 multiply: 正片叠底 - 查看对应像素的颜色信息, 并将基色和混合色复合, 结果色总是比较暗的颜色, 任何颜色与黑色正片叠底都产生黑色, 任何颜色与白色正片叠底都保持不变. 正片就是常见的幻灯片, 正片叠底的效果就是把基色和混合色的图像都做成幻灯片, 把他们叠放在一起, 凑近亮处显示的效果, 由于两张幻灯片都有内容, 所以重叠起来的图像比单张要暗 screen: 滤色 - 滤色原理和显示器成像原理相同, 将两副幻灯片分别放在不同投影仪上, 打向同一个屏幕, 由于光线的叠加效应, 得到的是一个更明亮的图像. 基色的反相与混合色的反相相乘, 得到的结果除以255后再反相. overlay: 叠加 lighten: 变量 darken: 变暗 color-dodge: 颜色减淡 color-blur: 颜色加深 hard-light: 强光 soft-light: 柔光 difference: 差值 - 混合色与基色相减后取绝对值 exclusion: 排除 hue: 色相 saturation: 饱和度 color: 颜色 luminosity: 亮度","link":"/2016/06/28/mix-blend-mode-e4-b9-8b-multiply-screen-difference/"},{"title":"Middleware","text":"You can include custom middleware functions to the dispatch method of your store. The dispatch function is responsible for sending actions to one or more reducer functions for state changes. The composed specialized functions around the original dispatch method creates the new middleware capable dispatch method. Source code for applyMiddleware(from Redux 1.0.1) export default function applyMiddleware(...middlewares) { return (next) =&amp;gt; (reducer, initialState) =&amp;gt; { var store = next(reducer, initialState); var dispatch = store.dispatch; var chain = []; var middlewareAPI = { getState: store.getState, dispatch: (action) =&amp;gt; dispatch(action) }; chain = middlewares.map(middleware =&amp;gt; middleware(middlewareAPI)); return { ...store, dispatch } } } `&lt;/pre&gt; Composing Functions Functional programming is very literal and very mathematical. In the case of composing functions with math you can express two or more functions like this: &lt;pre&gt;`given: f(x) = x^2 + 3x + 1 g(x) = 2x then: (f · g)(x) = f(g(x)) = f(2x) = 4x^2 + 6x + 1 `&lt;/pre&gt; It is no coincidence that you can compose two or more functions in a similar fashion. Here is a very simple example of a function that composes two functions to return a new specialized function: &lt;pre&gt;`var greet = function(x) { return `Hello, ${x}`} var emote = function(x) { return `${x} :)`} var compose = function(f,g){ return function(x){ return f(g(x)) } } `&lt;/pre&gt; This was just to illustrate the basic concept. We will look at a more generic way to solve that issue by examining the Redux Code. ### Currying Another powerful functional programming concepts is the idea of currying or partially applying argument values to a function. By currying we can create a new specialized function that has partial information supplied to it. Here is the canonical example of currying where we have an add function that curries the first operand parameter to create a specialized add function &lt;pre&gt;`var curriedAdd = function(a){ return function(b){ return a + b; } } var addTen = curriedAdd(10); addTen(10); // 20 `&lt;/pre&gt; By currying and composing your functions you can create powerful new functions that create a pipeline for data processing. ### Redux Dispatch Function A Store in Redux have a dispatch method which is only concerned with the main execution task you are interested in. You dispatch actions to your reducer functions to update state of the application. Redux reducers function takes a state and action parameter and return a new resultant state. &lt;pre&gt;`reducer:: state -&amp;gt; action -&amp;gt; state `&lt;/pre&gt; You might dispatch an action that simply sends a message to remove an item in a list which could look like this: &lt;pre&gt;`{type: types.DELETE_ITEM, id: 10} `&lt;/pre&gt; The store will dispatch this action object to all of it&apos;s reducer functions which could affect state. However the reducer functions are only concerned with executing logic around this deletion. They typically don&apos;t care who did it, how long it took, or logging the before and after effects of the state changes. This is where middleware can help us to address non-core concerns. ### Redux middleware Redux middleware is designed by creating functions that can be composed together before the main dispatch method is invoked. Let&apos;s creating a very simple logger middleware function that can echo the state of your application before and after running your main dispatch function. Redux middleware functions have this signiture: &lt;pre&gt;`middleware:: next -&amp;gt; action -&amp;gt; retVal `&lt;/pre&gt; It might look something like this: &lt;pre&gt;`export default function createLogger({getState}){ return (next) =&amp;gt; (action) =&amp;gt; { const console = window.console; const prevState = getState(); const returnValue = next(action); const nextState = getState(); const actionType = String(action.type); const message = `action ${actionType}`; console.log(`%c prev state`, `color: #9e9e9e`, prevState); console.log(`%c action`, `color: #03A9F4`, action); console.log(`%c next state`, `color:#4CAF50`, nextState) }; } `&lt;/pre&gt; Notice that createLogger accepts the getState method which is injected by applyMiddleware.js and used inside closure to read the current state. This will return a new function with the `next` parameter which is used to compose the next chained middleware function or the main dispatch function. This function returns a curried function that accepts the action object which can be read or modified before sending it to the next middleware function in the chain. Finally the main dispatch function is invoked with the action object. First it captures the previous state The action is dispatched to the next middleware function All downstream middleware functions in the chain are invoked The reducer functions in the store are called with the action payload The logger middleware the gets the resulting next state Dissecting applyMiddleware.js`export default function applyMiddleware(...middlewares){ return (next) =&gt; (reducer, initialState) =&gt; { var store = next(reducer, initialState); var dispatch = store.dispatch; var chain = []; var middlewareAPI = { getState: store.getState, dispatch: (action) =&gt; dispatch(action) }; chain = middlewares.map(middleware =&gt; middleware(middlewareAPI)); dispatch = compose(...chain, store.dispatch); return{ ...store, dispatch }; }; } ` The applyMiddleware function probably could have been named a little better, such as applyMiddlewareToStore. The applyMiddleware function returns a function that takes a mysterious next argument: `return (next) =&gt; (reducer, initialState) =&gt; {...} ` The next argument will be a function that is used to create a store. By default you should look at the implementation for createStore. The final returned function will be like createStore and replace the dispatch function with it’s associated middlewares. Next we assign the store implementation to the function responsible for creating the new store. Then we create a variable to the store’s original dispatch function. Finally we setup an array to hold the middleware chain we will be creating. `var store = next(reducer, initialState) var dispatch = store.dispatch var chain = []; ` This next bit of code injects the getState function and the original dispatch function from the store into each middleware function which you can optionally use in your middleware(the applyMiddleware function pass getState and dispatch to middlewares in it). The resultant middleware is stored in the chain array `var middlewareAPI = { getState: store.getState, dispatch: (action) =&gt; dispatch(action) } chain = middlewares.map(middleware =&gt; middleware({middlewareAPI})) ` Now we create our replacement dispatch function with the information about hte middleware chain: `dispatch = compose(...chain, store.dispatch); ` The magic to composing our middleware chain lies in this utility function supplied by Redux. Here is the implementation `export default function compose(...funcs){ return funcs.reduceRight((compsed,f) =&gt; f(composed)) } ` The composing function will literally express your functions as a composition injecting each middleware as an argument to the next middleware in the chain. Order is important here when assembling your middleware function. Finally, the original store dispatch method is composed. This new looks like: `middlewareI(middlewareJ(middlewareK(store.dispatch)))(action) ` The final thing to do is return the new store object with the overriden function: `return { ...store, dispatch } ` Let’s add our logger middleware we started above into a custom store with the enhanced dispatch function. `import { createStore, applyMiddlware } from 'redux' import loggerMiddleware from 'logger' import rootReducer from './reducers' const createStoreWithMiddleware = applyMiddleware(loggerMiddleware)(createStore) export default function configureStore(initialState){ return createStoreWithMiddleware(rootReducer, initialState); } const store = configureStore() ` Asynchronous MiddlewareOnce you get comfortable with the basics of Redux middleware you will likely want to work with asynchronous actions that involve some sort of asynchronous execution. In particular look at ‘redux-thunk’ for more details. Let’s say you have an action creator that has some async functionality to get stock quote information: `function fetchQuote(symbol){ requestQuote(symbol); return fetch('......') .then(req =&gt; req.json()) .then(json =&gt; showCurrentQuote(symbol, json)); } ` There is no obvious way here to dispatch an action that would be returned from the fetch which is Promise based. Plus we do not have a handle to the dispatch function. Therefore we can use the redux-thunk middleware to defer execution of these operations. By wrapping the execution in a function you can delay this execution: `function fetchQuote(symbol){ return dispatch =&gt; { dispatch(requestQuote(symbol)); return fetch('......').then(req=&gt;req.json).then(json =&gt; dispatch(showCurrentQuote(symbol,json)) } } ` Remember that the applyMiddleware function will inject the dispatch and the getStat function as parameters int o the redux-thunk middleware. Now you can dispatch the resultant action objects to your store which conatains reducers. Here is the middleware function for redux-thunk that does this for you. `export default function thunkMiddleware({dispatch,getState}){ return (next) =&gt; action =&amp;gt; { typeof action === &apos;function&apos;? action(dispatch, getState):next(action) } } If the action is a function it will be called with the dispatch and getState function..","link":"/2016/08/23/middleware/"},{"title":"Mix-Blend-Mode","text":"123456789101112131415161718192021{ mix-blend-mode: normal; mix-blend-mode: multiply; mix-blend-mode: screen; mix-blend-mode: overlay; mix-blend-mode: darken; mix-blend-mode: lighten; mix-blend-mode: color-dodge; mix-blend-mode: color-burn; mix-blend-mode: soft-light; mix-blend-mode: hard-light; mix-blend-mode: difference; mix-blend-mode: exclusion; mix-blend-mode: hue; mix-blend-mode: saturation; mix-blend-mode: color; mix-blend-mode: luminosity; mix-blend-mode: initial; mix-blend-mode: inherit; mix-blend-mode: unset;} mix-blend-mode: screen1234// pug.container - for(var i=0; i&lt;3; i++) .box 123456789101112131415161718192021222324252627282930313233343536$count: 3;$bgcolorlist: #0801fb #1ffe27 #fd1a20;body { background-color: #291f34;}.container { position: absolute; width: 200px; height: 200px; top: 50%; left: 50%; trasnform: translate(-50%, -50%);}.box { position: absolute; top: 0; left: 0; width: 100%; height: 100%; border-radius: 50%; transform-origin: 48% 48%; mix-blend-mode: screen;}@for $i from 1 through $count { .box:nth-child(#{$i}) { background-color: nth($不过colorlist, $\u0006i); animation: turn 3s linear #{1-$i}s infinite; }}@keyframes turn { to { transform: rotate(360deg); }}","link":"/2017/08/28/mix-blend-mode/"},{"title":"New Babel Preset - Env","text":"babel-preset-env is a new preset which let you specify an environment and automatically enables the necessary plugins. At the moment, several presets let you determine what features Babel should support: babel-preset-es2015, babel-preset-es2016, etc: incrementally support various versions of ECMAScript. babel-preset-es2015 transpiles what’s new in ES6 to ES5, babel-preset-es2016 transpiles what’s new in ES7 to ES6. babel-preset-latest: supports all features that are either part of an ECMAScript version or at stage 4. The problem with these presets is that they often do too much. For example, most modern browsers support ES6 generator. Yet if you use babel-preset-es2015, generator functions will always be transpiled to complex ES5 code. babel-preset-env works like babel-preset-latest, but it lets you specify an environment and only transpiles features that are missing in that environment. Note that you need to install and enable plugins and/or presets for experimental features(that are not part of babel-preset-latest) On the plus side, you don’t need es2015 presets anymore. BrowsersFor browsers you have the option to specify either: Browsers via browserslist query syntax Support the last two versions of browsers and IE 7+ 123456789101112\"babel\": { \"presets\": [ [ \"env\", { \"targets\": { \"browsers\": [\"last 2 versions\", \"ie &gt;= 7\"] } } ] ]} Support browsers that have more than 5% market share 123\"targets\": { \"browsers\": \"&gt; 5%\"} Fixed versions of browsers: 123\"targets\": { \"chrome\": 56} Node.jsIf you compile your code for Node.js on the fly via Babel, babel-preset-env is especially useful, because it react to the currently running version of Node.js if you set the target node to current 1234567891011121314\"babel\": { \"presets\": [ [ \"env\", { \"target\": { \"targets\": { \"node\": \"current\" } } } ] ]} Additional Options for babel-preset-envmodules(string, default: ‘commonjs’)This options lets you configure to which module format ES6 modules are transpiled: Transpile to popular module formats: ‘amd’, ‘commonjs’, ‘systemjs’, ‘umd’ Don’t transpile: false include, exclude (Array of strings, default []) include: always enables certain plugins exclude: prevents certain plugins from being enabled useBuiltIns (boolean, default: false)Babel comes with a polyfill for new functionality in standard library. babel-preset-env can optionally import only those parts of the polyfill that are needed on the specified platforms: There are two ways of using the polyfill: core-js polyfills ES5, ES6+ as needed install polyfill: yarn add core-js activate polyfill: import 'core-js' babel-polyfill: polyfills core-js and regenerator runtime(to emulate generators on ES5) install polyfill: yarn add babel-polyfill activate polyfill: import 'babel-polyfill' Either of the two import statements is transpiled to an environment-specific sequence of more fine-grained imports: 12345import \"core-js/modules/es7.string.pad-start\";import \"core-js/modules/es7.string.pad-end\";import \"core-js/modules/web.timers\";import \"core-js/modules/web.immediate\";import \"core-js/modules/web.dom.iterable\"; debug (boolean, default: false)Logs the following information via console.log() Targeted environments Enabled transformers Enabled plugins Enabled polyfills Example1234567891011121314{ \"presets\": [ [\"env\", { \"targets\": { \"safari\": 10 }, \"modules\": false, \"useBuiltIns\": true, \"debug\": true } ] ]}","link":"/2017/05/21/new-babel-preset-env/"},{"title":"Node-Inspector's Crash","text":"I had encountered a problem using node-inspector with info cb(error, NM[0].ref); Cannot read property ‘ref’ of undefined And one method to resolve it is to modify the packagge Same issue with node v6.5.0 can be solved like this : Edit …\\node_modules\\node-inspector\\lib\\InjectorClient.js file at line 111 if(NM.length &gt; 0) cb(error, NM[0].ref); It works which is hack, and another method is without side-effect use the local node-inspector hope it helps","link":"/2017/04/25/node-inspector-s-crash/"},{"title":"Mongodb Simple Guide","text":"yarn add mongoose import mongoose from 'mongoose' const db = mongoose.conenct(MONGODB_URI) 1234567891011import mongoose from 'mongoose'const db = mongoose.connect(MONGODB_URI)db.connection.on('open', () =&gt; { console.log('connected')})db.connection.on('error', (err) =&gt; { console.log(`db error: ${err}`) process.exit}) SchemaSchema defines the skeleton of minimal unit 1234567import mongoose from 'mongoose'const TestSchema = new mongoose.Schema({ name: { type: String }, age: { type: Number, default: 0 }, time: { type: Date, default: Date.now() }, email: { type: String, default: '' },}) Primitive Types: String, Number, Boolean, null, Array, Document, Date ModelInstance of Schema, it has ability to operate db 12const db = mongoose.connect(MONGODB.URI)const testModal = db.model('test1', TestSchema) test1: Name of Collection in the DB EntityInstance of Model, it has ability to operate db 12345678const TestEntity = new TestModel({ name: 'Lenka', age: 35, email: 'lenka@gmail.com',})console.log(TestEntity.name) // Lenkaconsole.log(TestEntity.age) // 35 Collection12345678910111213141516171819202122import mongoose from 'mongoose'const db = mongoose.connect(MONGODB.URI)const TestSchema = new mongoose.Schema({ name: { type: String }, age: { type: Number, default: 0 }, email: { type: String }, time: { type: Date, default: Date.now() },})const TestModel = db.model('test1', TestSchema)const TestEntity = new TestModel({ name: 'hello world', age: 12, email: 'helloworld@gmail.com',})TestEntity.save((err, doc) =&gt; { if (err) =&gt; { console.log('error: ' + err) } else { console.log(doc) }}) Find1obj.find(condition, field, callback) if fields is omited, or null, the docs will return all attributes 12345678Model.find({ 'age': 25 }, (err, docs) =&gt; { if (err) return console.log(err) console.log(docs)})Model.find({}, { name: 1, age: 1, _id: 0 }, (err, docs) =&gt; { // the specific attributes will be returned if corresponding fields are set to positive(here they are name and age), and _id is default to be displayed, if you want to omit it, you should set it to be 0.}) findOneSame as find, except it will return only one matched 123TestModel.findOne(condition, fields, (err, doc) =&gt; { // ...}) findByIdSame as findOne, but it only find by _id 123TestModel.findById('obj._id', (err, doc) =&gt; { // ...}) Create1Model.create({}, callback) 12345678910111213141516171819Model.create({ name: 'test', age: 12,}, (err, doc) =&gt; { if (err) return console.log(err) console.log(doc)})TestModel.create([ { name: 'test1', age: 20 }, { name: 'test2', age: 20 }, { name: 'test3', age: 20 }, { name: 'test4', age: 20 }, { name: 'test5', age: 20 }, { name: 'test6', age: 20 }, { name: 'test7', age: 20 }, { name: 'test8', age: 20 }, { name: 'test9', age: 20 },]) Save1Entity.save({}, callback) 12345678const Entity = new Model({ name: 'entity_save'})Entity.save((err, doc) =&gt; { if (err) return console.log(err) console.log(doc)}) Model.create Entity.save Update1obj.update({}, callback) 12345678const conditions = { name: 'test_upate' }const update = { $set: { age: 16 } }TestModel.update(conditions, update, (err) =&gt; { if (err) return console.log(err) console.log('success')}) Remove1obj.remove({}, callback) 123456const conditions = { name: 'tim' }TestModel.remove(conditions, (err) =&gt; { if (err) return console.log(err) console.log('success')}) Advanced Search $lt: less than $lte: less than or equal to $gt: greater than $gte: greater than or equal to $ne: not equal to $in: belong to $or: or $exists: exist $all 12345678910111213141516171819202122Model.find({ \"age\": { \"$gt\": 18, \"$lt\": 50 } }, (err, docs) =&gt; { // ...})Model.find({ \"age\": { \"$in\": [20, 30] } }, (err, docs) =&gt; { // ...})Model.find({ \"$or\": [ { \"name\": \"yaya\" }, { \"age\": 28 }, ]}, (err, docs) =&gt; { // ...})Model.find({ name: \"$exists\"}, (err, docs) =&gt; { // ...}) Limit123find(condition, { limit: 20 }, function(err, docs) =&gt; { // ...}) 123Model.find({}, null, { limit: 20 }, (err, docs) =&gt; { // ...}) SkipSkim first n docs 123find({}, null, { skip: 4 }, (err, docs) =&gt; { // ...}) if total docs less than 4, it will output nothing Sort-1: descending, 1: ascending 123Model.find({}, null, { sort: { age: -1 } }, (err, docs) =&gt; { // ...}) ObjectIdThe default id _id could be any types in mongodb, and default to be ObjectId ObjectId, is a 12-types BSON String. 4 byte: UNIX TimeStamp 3 byte: Represents the OS where mongodb running on 2 byte: Represents the process where this _id in on 3 byte: Rnadom Number Schema add Attribute1234567import mongoose from 'mongoose'const TestSchema = new mongoose.SchemaTestSchema.add({ name: 'String', email: 'String', age: 'Number',}) Schema add instance method1234567891011import mongoose from 'mongoose'const TextSchema = new mongoose.Schema({ name: 'String',})TestSchema.method('test', () =&gt; { console.log('hah')})const say = mongoose.model('say', TestSchema)var lenka = say()lenka.say() // 'hah' Schema add static method```javascript import mongoose from ‘mongoose’ const db = mongoose.connect(MONGODB.URI) const TestSchema = new mongoose.Schema({ name: { type: String }, age: { type: Number }, }) TestSchema.static(‘findByName’, (name, cb) =&gt; { return this.find({name: name}, cb) }) const TestModel = db.model(‘test’, TestSchema) TestModel.findByName(‘tim’, (err, docs) =&gt; { // … })","link":"/2017/05/30/mongodb-simple-guide/"},{"title":"Node.js 之 Path 模块","text":"path模块用于规范化路径连接和解析路径. path的功能包括不仅限于: 规范化路径 连接路径 路径解析 查找两个绝对路径的相对关系 提取路径的组成部分 规范化路径 path.normalize(p)path 模块中的 normalize(p) 用来规范化路径, 可用于处理路径中的 //, .., .等. var path = require(&apos;path&apos;); path.normalize(&apos;./foo/bar//baz/asfd/que/..&apos;); // 处理后 &apos;foo/bar/baz/asfd&apos; `&lt;/pre&gt; ### 连接路径 path.join([path1][, path2][, ...]) 将任意个路径字符串连接, 同时也会对路径进行规范化 &lt;pre&gt;`var path = require(&apos;path&apos;); //合法的字符串连接 path.join(&apos;./foo&apos;, &apos;bar&apos;, &apos;baz/asdf&apos;, &apos;quux&apos;, &apos;..&apos;) // 连接后 &apos;foo/bar/baz/asfd&apos; // 不合法的字符串将抛出异常 path.join(&apos;foo&apos;,{}, bar) =&amp;gt; TypeError: Arguments to path.join must be strings `&lt;/pre&gt; ### 路径解析 path.resolve([from...], to) path.resolve 方法可以将多个路径解析为一个规范化的绝对路径, 其处理方法类似于对这些路径逐一进行 cd 操作, 与 cd 操作不同的是, 这引起路径可以是文件, 而且可不必实际存在, 仅是字符串操作 &lt;pre&gt;`path.resolve(&apos;foo/bar&apos;,&apos;/tmp/file/&apos;,&apos;..&apos;,&apos;a/../subfile&apos;) `&lt;/pre&gt; 相当于 &lt;pre&gt;`cd foo/bar cd /temp/file/ cd .. cd a/../subfile `&lt;/pre&gt; 如果解析的不是绝对路径, path.resolve() 会将当前工作目录加到解析结果前 &lt;pre&gt;`path.resolve(&apos;wooroot&apos;,&apos;bar&apos;,&apos;./baz&apos;) // 当前工作路径是/home/node, 则输出结果是 &apos;/home/node/wooroot/bar/baz&apos; `&lt;/pre&gt; ### 查找两个绝对路径之间的相对关系 path.relative(from, to) &lt;pre&gt;`path.relative(&apos;/Users/node/demo&apos;, &apos;/Users/node&apos;) =&amp;gt; &apos;..&apos; 提取路径的组成部分 path.dirname(p), path.basename(p[,ext]), path.extname(p)path.dirname =&gt; 文件路径中的目录部分path.basename =&gt; 文件路径中的文件部分path.extname =&gt; 文件路径中的文件扩展名","link":"/2016/08/26/node-js-e4-b9-8b-path-e6-a8-a1-e5-9d-97/"},{"title":"Node.js URL 模块的使用","text":"Node.js 中的 URL 模块, 用于将 URL 字符串解析为对象或将对象格式化为 URL 字符串, 该模块比较简单, 共包括3个方法: URL 各部分说明对于一个 URL 字符串, 其组成部分会有所不同. 其中有些部分只有在 URL 字符串中存在时, 对应字段还才会出现在解析后的对象中. 以下是一个 URL 例子 http://user:pass@host.com:8080/path/to/file?query=string#hash `&lt;/pre&gt; 解析后的字段如下: - `href`: 解析前的完整原始 URL, 协议名和主机名已经转为小写 - `protocol`: 请求协议, 小写, 例如`\u0006\bhttp:` - `slashes`: 协议的`:`后面是否有`\\`, 返回`true`或`false` - `host`: URL 主机名, 包括端口信息, 小写, 例如`host.com:8080` - `auth`: URL 中的认证信息, 例如`user:pass` - `hostname`: 主机名, 小写, 例如`host.com` - `port`: 主机的端口号, 例如`8080` - `pathname`: URL 中的路径, 例如`/path/to/file` - `search`: 查询对象, 即: `queryString`, 包括之前的`?`, 例如`?query=string`; 如果 `parseQueryString = true`, 则返回`{&apos;query&apos;:&apos;string&apos;}` - `query`: 例如`query=string` - `hash`: 锚点部分, 即`#`之后的部分, 例如`#hash` ### 将 URL 字符串转换为对象: url.parse(urlStr[, parseQueryString[, slashesDenoteHost]]) `url.parse()`方法用于解析 URL 对象, 解析后范湖第一个 JSON 对象. 例如: &lt;pre&gt;`&amp;gt; var url = &apos;http://user:pass@host.com:8080/path/to/file?query=string#hash&apos; undefined &amp;gt; url &apos;http://user:pass@host.com:8080/path/to/file?query=string#hash&apos; &amp;gt; var urlModule = require(&apos;url&apos;); undefined &amp;gt; urlModule.parse(url) Url { protocol: &apos;http:&apos;, slashes: true, auth: &apos;user:pass&apos;, host: &apos;host.com:8080&apos;, port: &apos;8080&apos;, hostname: &apos;host.com&apos;, hash: &apos;#hash&apos;, search: &apos;?query=string&apos;, query: &apos;query=string&apos;, pathname: &apos;/path/to/file&apos;, path: &apos;/path/to/file?query=string&apos;, href: &apos;http://user:pass@host.com:8080/path/to/file?query=string#hash&apos; } `&lt;/pre&gt; 第二个可选参数设置为`true`的时候, 会使用`queryString`模块来解析 URL 中的`query` 部分, 默认为`false`. 第三个参数为`true`的时候, 会把诸如`//foo/\u0006bar`这样的 URL 解析为 `{host: &apos;foo&apos;, pathname: &apos;/bar&apos;}`, 而不是 `{pathname: &apos;//foo/bar&apos;}`. 默认为`false` ### 将对象格式化为 URL 字符串: url.format(urlObj) `url.resolve()`用于格式化URL对象, 输入一个 URL 对象, 返回格式化后的 URL 字符串, 例如: &lt;pre&gt;`&amp;gt; var url = require(&apos;url&apos;); undefined &amp;gt; var urlObj = { ... protocol: &apos;http:&apos;, ... slashes: true, ... hostname: &apos;host.com&apos;, ... port: 8080, ... hash: &apos;#hash&apos;, ... search: &apos;?query=string&apos;, ... pathname: &apos;/path/to/file&apos; ... } undefined &amp;gt; var result = url.format(urlObj) undefined &amp;gt; result &apos;http://host.com:8080/path/to/file?query=string#hash&apos; `&lt;/pre&gt; ### URL 路径处理 `url.resolve()`方法用于处理 URL 路径, 也可以用于处理锚点. 例如 &lt;pre&gt;`url.resolve(&apos;/one/two/three&apos;, &apos;four&apos;) // &apos;/one/two/four&apos; url.resolve(&apos;http://example.com/&apos;, &apos;/one&apos;) // &apos;http://example.com/one&apos; url.resolve(&apos;http://example.com/one&apos;, &apos;/two&apos;) // &apos;http://example.com/two&apos; 参数拼接, 如果之间没有/, 则参数二替换参数一末尾的文件名\u0002. 注意区分路径和文件名.","link":"/2016/08/01/node-js-url-e6-a8-a1-e5-9d-97-e7-9a-84-e4-bd-bf-e7-94-a8/"},{"title":"Node","text":"A Node is an interface from which a number of DOM types, and allows these various types to be treated similarly. Properties Node.baseURI: return a DOMStirng representing the base URL Node.childNodes: return a live NodeList containing all the children of this node. NodeList being live means that if the children of the Node change, the NodeList will update automatically. Node.firstChild: return a Node representing the first direct child Node of this Node, or Null if the node has no child. Node.lastChild: Return a Node representing the last direct child Node of this Node, or Null if the node has no child. Node.nextSibling: return a Node representing the next Node in the tree, or null if there is no one. Node.previousSibling Node.nodeName: return a DOMString containing the name of the node. The structure of the name will differ with the name type. E.g. An HTMLElement will contain the name of the corresponding tag, like “audio”, for an HTMLAudioElement, a Text node will have the “#text” string, or a Document node will have the “#document” string. Node.nodeType: return an unsigned short representing the type of the node. Possible values are: Name Value Element_Node 1 Attribute_Node 2 Text_Node 3 … … Document_Node 9 Document_Type_Node 10 Notation_Node 12 Node.nodeValue: return a DOMString representing the value of an object. For most node types, this returns null, and any set operation is ignored.For Nodes of type TEXT_NODE(Text objects), COMMENT_NODE(Comment objects), and PROGRESSING_INSTRUCTION_NODE(ProgressingInstruction objects), the value corresponds to the text data contained in the obejct. Node.parentNode: return a Node that is the parent of this node, if there is no such node, like if this node is the top of the tree or if doesn’t participate in a tree, this property returns Null. Node.parentElement: returns an Element that is the parent of this node. If the node has no parent, or if that parent is not an Element, this property returns Null. Node.rootNode: return a Node representing the topmost Node in this tree or the current node if it’s the topmost node in the tree. Node.textContent: is a DOMString representing the textual content of an element and all its descendants. Methods Node.appendChild() Node.cloneNode(): Clone a Node and optionally all of its contents. By default, it clones the content of the node. Node.hasChildNodes(): return a boolean indicating if the element has any child nodes, or not. Node.insertBefore(newNode, beforeItsChild) Node.isEqualNode(): return a boolean which indicating whether or not two nodes are of the same type and all their defining data points match. Node.isSameNode(): return a boolean value indicating whether or not the two nodes are the same(that is they reference the same object). Node.removeChild() Node.replace(newNode, replaceItsChild) * Note: replaceNode will not generate new one.&lt;/p&gt; E.g. ul&amp;gt;li*3 ul.replace(li[2],li[0]) it will act as:remove li[2], put it li[0], remove li[0], so the result looks like ul–li[2]–li[1]` ExamplesBrowser All Child NodesThe following function recursively cycles all child nodes of a node and executes a callback function upon them(and upon the parent node itself). `function DOMComb(oParent, oCallBack){ if(oParent.hasChildNodes()){ for(var oNode = oParent.firstChild; oNode; oNode = oNode.nextSibling){ DOMComb(oNode, oCallBack); } } oCallBack.call(oParent); } ` Remove all children nested within a node`Element.prototype.removeAll = function(){ while(this.firstChild){ this.removeAll(this.firstChild); } return this;};","link":"/2016/07/18/node/"},{"title":"Note of Sw-Precache","text":"A node module to generate service worker code that will precaches specific resource so they work offline. Serving your local static resources cache-first means that you can get all the crucial scaffolding for your web app – your app shell – on the screen without having to wait for any network responses. Installation1yarn add --dev sw-precache Overview Make sure your site is served using HTTPS. incorporate sw-precache into your node-based build script. Register the service worker JavaScript. Considerations Service worker caching should be considered a prograssive enhancement. If you follow the model of conditionally registering a service worker only if it’s supported(determined by if('serviceWorker' in navigator)), you’ll get offline support on browsers with service workers and on browsers that don’t support service workers, the offline-specific code will never be called. All resources that are precached will be fetched by a service worker runing in a separate thread as soon as the service worker is installed. You should be judicious in what you list in the dynamicUrlsToDependencies and staticFileGlobs options, since listing files that are non-essential(large-images that are not shown on every page, for instance) will result in browsers downloading more data than is strictly necessary. Precaching doesn’t make sense for all types of resource. Other caching strategies can be used in conjunction with sw-precache to provide the best experience for your users. If you do implement additional caching logic, put the code in a separate file and include it using the importScripts() method. sw-precache uses a cache-first strategy, which results in a copy of any cached content being returned without consulting the network. Use with webpack1yarn add --dev sw-precache-webpack-plugin Basic UsageA simple configuration example that will work well in most production environments. 12345678910111213141516171819202122232425262728const path = require('path')const SWPrecachePlugin = require('sw-precache-webpack-plugin')const PUBLIC_PATH = 'https://www.my-project-name.com/'module.exporst = { entry: { main: path.resolve(__dirname, 'src/index') }, output: { path: path.resolve(__dirname, 'src/bundles/'), filename: '[name]-[hash].js', publicPath: PUBLIC_PATH, }, plugins: [ new SWPrecachePlugin({ cacheId: 'my-project-name', dontCacheBustUrlsMatching: /\\.\\w{8}\\./, filename: 'service-worker.js', minify: true, navigateFallback: PUBLIC_PATH + 'index.html', staticFileGlobsIgnorePatterns: [ /\\.map$/, /asset-manifest\\.json$/, ] }) ]} This will generate a new service worker at src/bundles/service-worker.js, then you would register it in your application: 12345(function() { if ('serviceWorker' in navigator) { navigator.serviceWorker.register('./service-worker.js') }})() Configuration filename: string - service worker filename, default is service-worker.js filepath: string - service worker path and name, default is to use webpack.output.path + options.filename. This will override filename. staticFileGlobsIngorePatters: [Regexp] - Define an optional array of regex patterns to filter out of staticFileGlobs. mergeStaticsConfig: [boolean] - Merge provided staticFileGlobs and stripPrefixMulti with webpack’s config, rather than having those take precedence, default is false. minify: [boolean] - Set to true to minify and uglify the generated service-worker, default is false. cacheId: [string] - Not required but you should include this, it will give your service worker cache a unique name, default to sw-precache-webpack-plugin. importScripts: [Array] when importScripts array item is a string, converts to object format: { filename: '&lt;publicPath&gt;/my-scripts.js'} when importScripts array item is an Object look for chunkName property look for filename property replacePrefix: [String] - should only be used in conjunction with stripPrefix staticFileGlobs: [Array] - Omit this to allow the plugin to cache all your bundles’ emitted assets. If mergeStaticsConfig=true: this value will be merged with your bundles’ emitted assets, otherwise this value is just passed to sw-precache and emitted assets won’t be included. stripPrefix: [String] - Same as stripPrefixMulti[stripPrefix] = ‘’ stripPrefixMulti: [Object] - Omit this to use your webpack config’s output.path + /: output.publicPath. Note taht all configuration options are optional. SWPrecacheWebpackPlugin will by default use all your assets emitted by webpack’s compiler for the staticFileGlobs parameter and your webpack config’s {[output.path + '/']: output.publicPath} as the stripPrefixMulti parameter. This behavior is probably what you want, all your webpack assets will be cached by your generated service worker. Just don’t pass any arguments when you initialize this plugin, and let this plugin handle generating your sw-precache configuration. 123plugins: [ new SWPrecacheWebpackPlugin(),]","link":"/2017/09/04/note-of-sw-precache/"},{"title":"Notes in Migrating From React-Router-3 to React-Router-4","text":"HashRouterVersion 4 of React-Router seperate top level router element for the different history type. If you’re using version 4 you should be able to replace &lt;Router hisotry={hashHistory}&gt; with &lt;HashRouter&gt; Multiple Routes at same URL123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import React from 'react'import { BrowserRouter as Router, Route, Link,} from 'react-router-dom'// Each logical 'route' has two components, one for the sidebar and one for the main area. We want to render both of them in different places when the path matches the current URL.const routes = [ { path: '/', exact: true, sidebar: () =&gt; &lt;div&gt;Home&lt;/div&gt;, main: () =&gt; &lt;h2&gt;Home&lt;/h2&gt;, }, { path: '/bubblegum', sidebar: () =&gt; &lt;div&gt;bubblegum&lt;/div&gt;, main: () =&gt; &lt;h2&gt;BubbleGum&lt;/div&gt;, }, { path: '/shoelaces', sidebar: () =&gt; &lt;div&gt;shoelaces&lt;/div&gt;, main: () =&gt; &lt;h2&gt;ShoeLaces&lt;/h2&gt;, },]const sidebarExample = () =&gt; ( &lt;Router&gt; &lt;div style={{ display: 'flex' }}&gt; // sidebar &lt;div style={{ padding: '10px', width: '40%', background: '#f0f0f0', }} &gt; &lt;ul&gt; &lt;li&gt;&lt;Link to='/'&gt;Home&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to='/bubblegum'&gt;Bubblegum&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to='/shoelaces'&gt;ShoeLaces&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; {routes.map((route, index) =&gt; ( // You can render a &lt;Router&gt; in as many places as you want in your app, it will render along with any other &lt;Router&gt;s that also match the URL. // So a sidebar or breadcrumbs or anything else that requires you to render multiple things in multiple places at the same URL is nothing more than multiple &lt;Routes&gt;s &lt;Route key={index} path={route.path} exact={route.exact} component={route.sidebar} /&gt; ))} &lt;/div&gt; // main &lt;div style={{ flex: 1, padding: '30px' }}&gt; {routes.map((route, index) =&gt; ( // Render more &lt;Route&gt;s with the same paths as above, but different components this time. &lt;Route key={index} path={route.path} exact={route.exact} component={route.main} /&gt; ))} &lt;/div&gt; &lt;/div&gt; &lt;/Router&gt;)export default sidebarExample Animated Transitions12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import React from 'react'import ReactCSSTransitionGroup from 'react-addons-css-transition-group'import { BrowserRouter as Router, Route, Link, Redirect,} from 'react-rotuer-dom'// you'll need this CSS somewhere// .fade-enter {// opacity: 0;// z-index: 1;// }// .fade-enter.face-enter-active {// opacity: 1;// transition: opacity 250ms ease-in;// }const AnimationExample = () =&gt; ( &lt;Router&gt; &lt;Route render={({ location }) =&gt; ( &lt;div style={style.fill}&gt; &lt;Route exact path='/' render={() =&gt; ( &lt;Redirect to='/10/20/50' /&gt; )}/&gt; &lt;ul style={style.nav}&gt; &lt;NavLink to='/10/90/50'&gt;Red&lt;/NavLink&gt; &lt;NavLink to='/120/100/40'&gt;Green&lt;/NavLink&gt; &lt;NavLink to='/200/100/40'&gt;Blue&lt;/NavLink&gt; &lt;NavLink to='/310/100/50'&gt;Pink&lt;/NavLink&gt; &lt;/ul&gt; &lt;div style={style.content}&gt; &lt;ReactCSSTransitionGroup transitionName='fade' transitionEnterTimeout={300} transitionLeaveTimeout={300} &gt; // no different than other usage of ReactCSSTransitionGroup, just make sure to pass `location` to `Route` so it can match the old location as it animate out &lt;Route location={loaction} key={location.key} path=\"/:h/:s/:l\" component={HSL} /&gt; &lt;/ReactCSSTransitionGroup&gt; &lt;/div&gt; &lt;/div&gt; )}/&gt; &lt;/Router&gt;)const NavLink = (props) =&gt; ( &lt;li&gt;&lt;Link {...props} style={{color: 'inherit'}} /&gt;&lt;/li&gt;)const HSL = ({ match: { params }}) =&gt; ( &lt;div style={{ ...style.fill, ...style.hsl, background: `hsl(${params.h}%, ${params.s}%, ${params.l}%)` }}&gt; &lt;/div&gt;)export default AnimationExample Route Config1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import React from 'react'import { BrowserRouter as Router, Route, Link,} from 'react-router-dom'// Some folks find value in a centralized route config. A route config is just data. React is great at mapping data into component, and &lt;Route&gt; is a component.// first our route componentconst Main = () =&gt; &lt;h2&gt;Main&lt;/h2&gt;const Sandwiches = () =&gt; &lt;h2&gt;Sandwiches&lt;/h2&gt;const Tacos = ({ routes }) =&gt; ( &lt;div&gt; &lt;h2&gt;Tacos&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;Link to='/tacos/bus'&gt;Bus&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to='/tacos/cart'&gt;Cart&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; {routes.map((route, index) =&gt; ( &lt;RouteWithSubRoutes key={index} {...route}/&gt; ))} &lt;/div&gt;)const Bus = () =&gt; &lt;div&gt;Bus&lt;/div&gt;const Cart = () =&gt; &lt;div&gt;Cart&lt;/div&gt;// then our route configconst routes = [ { path: '/sandwiches', component: sandwiches, }, { path: '/tacos', component: Tacos, routes: [ { path: '/tacos/bus', component: Bus, }, { path: '/tacos/cart', component: Cart, }, ], },]// wrap &lt;Route&gt; and use this everywhere instead, then when sub routes are added to any route it'll workconst RouteWithSubRoutes = (route) =&gt; ( &lt;Route path={route.path} render={props =&gt; ( // pass the sub-routes down to keep nesting &lt;route.component {...props} routes={route.routes} /&gt; )}/&gt;)const RouteConfigExample = () =&gt; ( &lt;Router&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;Link to='/tacos'&gt;Tacos&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to='/sandwiches'&gt;Sandwiches&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; {routes.map((route, index) =&gt; ( &lt;RouteWithSubRoutes key={index} {...route} /&gt; ))} &lt;/div&gt; &lt;/Router&gt;)export default RouteConfigExample Redux IntegrationGenerally, React Router and Redux work just fine together. Occasionally though, an app have a component that doesn’t update when the location changes (child route or active nav links don’t update) This happens if: The component is connected to redux via connect()(Comp) The component is not a “route component”, meaning it is not rendered like so: &lt;Route component={SomeConnectedThing}/&gt; The problem is that Redux implements shouldComponentUpdate and there’s no indication that anything has changed if it isn’t receiving props from the router. This is straightforward to fix. Find where you connect your component and wrap it in withRouter 12import { withRouter } from 'react-router-dom'export default withRouter(connect(mapStateToProps)(Comp)) Code SplittingOne great feature of the web is that we don’t have to make our visitors download the entire app before they can use it. You can think of code spliting as incrementally downloading the app. While there are other tools for the job, react-router use webpack and the bundle loader. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import loadSomething from 'bundle-loader?lazy!./Something'&lt;Bundle load={loadSomething}&gt; {(mod) =&gt; ( // do something w/ the module )}&lt;/Bundle&gt;&lt;Bundle load={loadSomething}&gt; { (Comp) =&gt; Comp ? &lt;Comp/&gt; : &lt;Loading/&gt; }&lt;/Bundle&gt;import React, { Component } from 'react'class Bundle extends Component { state = { // short for 'module' but that's a keyword in js. so 'mod' mod: null, } componentWillMount () { this.load(this.props) } componentWillReceiveProps (nextProps) { if (nextProps.load !== this.props.load) { this.load(nextProps) } } load (props) { this.setState({ mod: null, }) props.load((mod) =&gt; { this.setState({ // handle both es imports and cjs mod: mod.default ? mod.default : mod }) }) } render () { return this.props.children(this.state.mod) }}export default Bundle&lt;Bundle load={() =&gt; import('./something')}&gt; {(mod) =&gt; ()}&lt;/Bundle&gt; 123456789101112131415161718192021222324252627282930313233343536import loadAbout from 'bundle-load?lazy!./loadAbout'import loadDashboard from 'bundle-loader?lazy!./loadDashboard'// components load their module for initial visitconst About = () =&gt; ( &lt;Bundle load={loadAbout}&gt; {(About) =&gt; &lt;About /&gt;} &lt;/Bundle&gt;)const Dashboard = () =&gt; ( &lt;Bundle load={loadDashboard}&gt; {(Dashboard) =&gt; &lt;Dashboard /&gt;} &lt;/Bundle&gt;)class App extends React.Component { componentDidMount () { // preload the rest loadAbout( () =&gt; {} ) loadDashboard( () =&gt; {} ) } render () { return ( &lt;div&gt; &lt;h1&gt;Welcome&lt;/h1&gt; &lt;Route path='/about' component={About} /&gt; &lt;Route path='/dashbaord' component={Dashboard} /&gt; &lt;/div&gt; ) }}ReactDOM.render(&lt;App /&gt;, document.preloadTheRestOfTheApp)","link":"/2017/04/26/notes-in-migrating-from-React-Router-3-to-React-Router-4/"},{"title":"Notes on 'POST' and 'GET' in Form","text":"The ‘method’ attribute in form element specifies how to send form-data(the form-data is sent to the page specified in the ‘action’ attribute). The form-data can be sent as URL variables(with method='get') or as HTTP Post transaction(with method='post'). Notes on GET: Appends form-data into the URL in name-value pairs; The length of a URL is limited(about 3000 characters); Never use GET to send sensitive data cause they will be visible in the URL; Useful for form submissions where a user want to bookmark the result; GET is better than non-secure data, like query string in Google. Notes on POST: Appends form-data inside the body of HTTP request(both in head-line and body); Has no size limitation; Form submissions with POST cannot be bookmarked.","link":"/2016/06/22/notes-on-post-and-get-in-form/"},{"title":"package.json 属性","text":"namepackage.json 中最重要的属性是 name 和 version. 这两个属性是必须要有的, 否则模块无法被安装. 这两个属性一起形成了一个 npm 模块的唯一标识符.模块中内容变化的同时, 模块版本也应该一起变化.name 属性就是你的模块名称, 下面是一些命名规则: name 必须小于等于214字节, 包括前缀名称在内(如../..module) name 不能以’_’或’.’开头 不能有大写字母 name 会成为 url 的一部分, 不能有 url 非法字符 不要使用和 node 核心模块一样的名称 name 中不要有 ‘js’ 和 ‘node’ versionversion 必须可以被 npm 依赖的一个 node-server 模块解析 description一个描述, 方便别人了解你的模块的作用, 搜索的时候也有用 keywords一个字符串数组, 方便别人搜到本模块 homepage项目主页 url注意: 这个项目主页 url 和 url 属性不同, npm 注册工具会认为你把项目发布到其他地方了, 获取模块的时候不是从官方仓库后去, 而是去 url 配置的地址 bugs填写一个提交 bug 的地址或邮箱 { &apos;url&apos;: &apos;https://www.ezcook.de/project/issue&apos;, &apos;email&apos;: &apos;project@ezcook.de&apos; } `&lt;/pre&gt; 如果只填写一个, 可以返回字符串而不是对象 ### license 为模块制定一个协议, 通知用户可以使用的权限, 最常见的是 BSD-3-Clause 或 MIT &lt;pre&gt;`{&apos;license&apos;: &apos;MIT&apos;} `&lt;/pre&gt; ### author, contributors ### files files 属性的值是一个数组, 内容是模块下文件名或文件夹名, 如果是文件夹名, 则文件夹下所有文件也会被包含. 可以在模块根目录下创建一个 &apos;.npmignore&apos; 文件, 写在这个文件里的文件会被排除在 file 属性 ### main main 属性指定程序的主入口文件, 比如这个模块(文件夹)命名为&apos;foo&apos;, package.json中&apos; main&apos; 属性指定为&apos;test.js&apos;, 则通过 require(foo)来使用模块的时候会滴啊用 test.js 脚本. 他应该指向模块根目录下得一个文件, 默认为 index.js ### bin 很多模块有一个或多个需要配置到 PATH 路径下的可执行模块... ### man 制定一个或通过数组指定一些文件夹让 linux 下的 man 指令查找文档地址 ### directories ### repository 指定一个代码存放的地址 &lt;pre&gt;`&apos;repository&apos;: { &apos;type&apos;:&apos;git&apos;, &apos;url&apos;:&apos;https://github.com/...&apos; } 如果是 Github, 可以用缩写完成‘repository’:’gist:…’` scriptsscripts 属性是一个对象, 里面制定了项目的生命周期各个环节需要执行的命令, key 是生命周期中的时间, value 是要执行的命令具体内容有 install, start, stop 等, 详情见npm/scripts config用来设置一些项目不怎么变化的项目配置, 如 port 等 dependenciesdependencies 属性是一个对象, 配置依赖模块的模块列表, key 是模块名称, vlaue 是版本范围, 版本范围是一个字符, 可以被一个或多个空格分隔.比如```‘dependencies’:{ ‘foo’:’1.0.0 - 2.0.0’ ‘foo1’:’&gt;=1.0.0’} devDependencies如果有人想下载并使用你的模块, 也许他们并不希望或需要下载一些你在开发过程中额外的测试或文档框架这种情况下最好把这些依赖添加到 devDependencies 中, 这些模块会在 npm link 或者 npm install 的时候被安装, 也可以像其他 npm 配置一样被管理","link":"/2016/07/20/package-json-e5-b1-9e-e6-80-a7/"},{"title":"Optimize Web App","text":"Optimizing All AssetsOne of the most powerful, but under-utilized ways to significantly improve performance starts with understanding hwo the browser analyzes and serves assets. It turns out that browsers are pretty great at discovering resources while parsing and determing their priority of the fly. Here’s where the critical Request comes in: A request is critical if it contains assets that are necessary to render the content within the users’ viewport. For most sites, it’d be HTML, necessary CSS, a logo, a web font and maybe an image. We can control this behavior by carefully picking critical resources and adjusting theri priority. preloadWith &lt;link red='preload'&gt; we are able to manually force assets’ priority to High ensuring that desired content will be rendered on time. This technique can yield significant improvements in Time to Interactive metric, making optimal user experience possible. Critical requests still seem like a black box for many, and the lack of sharable materials doesn’t help to change that.jj Optimizing ImagesImages often account for most of a web page’s transferred payload. Choosing the right formatThe initial choice falls between vector and raster graphics: Vector: resolution independent, usually significantly smaller in size. Perfect for logos, iconography and simple assets comprising of basic shapes. Raster: offers much more detailed results, ideal for photographs. After making this decision, there are a fair bit of formats to choose from: JPEG, GIF, PNG-8, PNG-24 or newest formats such as WEBP or JPEG-XR, JPEG-2000. JPEG: Imagery with many color(e.g. photos) PNG-8: Imagery with a few color PNG-24: Imagery with partial transparency GIF: Animated imagery Experimenting with new formatsWebP is easily the most popular contender, supporting both lossless and lossy compression, which makes it incredibly versatile. Lossless WebP is 26% smaller than PNGs and 25-34% smaller than JPGs. With 74% browser support it can safely be used with fallback. JPGs and PNGs can be converted to WebP in PS and other image processing app as well as through command line interface(brew install webp). Responsible and responsive ImageryW’re perfectly equipped to do so with picture element and srcset attribute(both have 85% support) The srcset attributesrcset works best in the resolution switching scenario – when we want to display imagery based on user’s screen density and size. Baseed on a set of predefined rules in srcset and size attributes the browser will pick the best image to serve accordingly to the viewport. 123456&lt;img srcset=\"cat-320w.jpg 320w cat-480w.jpg 480w cat-800w.jpg 800w\", sizes=\"(max-width: 320px) 100vw, (max-width: 480px) 80vw, 800px\", src=\"cat-800w.jpg\" alt=\"cat\"/&gt; The picture elementpicture element and the media attribute are designed to make art direction easy. BY providing different sources for varying conditions. Delivery with image CNDsOptimizing Web FontsChoose the right formatThere are four web font formats: EOT, TTF, WOFF and WOFF2. TTF and WOFF are most widely adopted, boasting over 90% browser support. Depending on the support you’re targeting it’s most likely safe to server WOFF2 and fall back to WOFF for older browsers. The advantage of using WOFF2 is a set of custom preprocessing and compression algorithms resulting in approx 30% file-size reduction and impoved parsing capabilities. When defining the sources of web fonts in @font-face use the format() hint to specify which format should be utilized. use Unicode-range subsettingEstablish a font loading strategyFonts are render-blocking – because the browser has to build both the DOM and CSSOM first. Wdb fonts won’t be downloaded before they’re used in a CSS selector that matches an existing node. This behavior significantly delays text rendering, often causing the Flash of Invisible Text(FOIT). Implementing a font strategy prevents users from not being able to access your content. font-display is a new CSS property providing a non-javascript reliant solution. 123456@font-face { font-family: Post Grotesk; src: url('/fonts/Post-Growtest.woff2') format('woff2'), url('/fonts/Post-Growtest.woff' format('woff')), font-display: swap; // show fallback until web font is ready} Optmizing JS","link":"/2017/09/07/optimize-web-app/"},{"title":"Page Scroll With CSS3","text":".st-container{ position: absolute; width: 100%; height: 100%; top: 0; left: 0; } .st-container &amp;gt; input, .st-container &amp;gt; a{ position:fixed; bottom: 0; width: 20%; cursor:pointer; font-size: 16px; height: 34px; line-height: 34px; } .st-container &amp;gt; input{ opacity: 0; z-index: 1000; } .st-container &amp;gt; a{ z-index: 10; font-weight: 700; background: #e23a6e; color:#fff; text-align: center; text-shadow: 1px 1px 1px rgba(151,24,64,.2); } .st-container:before{ content:&quot;&quot;; position: fixed; width: 100%; height: 34px; background-color: #e23a6e; z-index: 9; bottom: 0; } #st-control-1, #st-control-1+a{ left:0; } #st-control-2, #st-control-2+a{ left:20%; } #st-control-3, #st-control-3+a{ left:40%; } #st-control-4, #st-control-4+a{ left:60%; } #st-control-5, #st-control-5+a{ left:80%; } .st-container &amp;gt; input:checked + a, .st-container &amp;gt; input:checked:hover + a{ background-color: #821134; } .st-container &amp;gt; input:checked + a:after, .st-container &amp;gt; input:checked:hover + a:after{ bottom:100%; border:solid transparent; content:&quot;&quot;; height: 0; width: 0; position: absolute; pointer-events: none; border-bottom-color: #821134; border-width: 20px; left:50%; margin-left:-20px; } .st-container &amp;gt; input:hover+a:after{ border-bottom-color: #AD244F; } .st-scroll, .st-panel{ position:relative; width: 100%; height: 100%; } .st-scroll{ top: 0; left: 0; transition:all .6s ease-in-out; } .st-panel{ background-color: #fff; overflow: hidden; } #st-control-1:checked ~ .st-scroll{ //scroll transform:translateY(0%); } #st-control-2:checked ~ .st-scroll{ //scroll transform: translateY(-100%); } #st-control-3:checked ~ .st-scroll{ //scroll transform: translateY(-200%); } #st-control-4:checked ~ .st-scroll{ //scroll transform: translateY(-300%); } #st-control-5:checked ~ .st-scroll{ //scroll transform: translateY(-400%); }","link":"/2016/06/17/page-scroll-with-css3/"},{"title":"Promise 基本点","text":"Promise 基本用法创建 Promise var promise = new Promise(function(resolve, reject){ // do something async if(/* everything ok */){ resolve(&quot;OK&quot;); // it will return Promise.resolve(&quot;OK&quot;), and the downstream will get &quot;OK&quot; as params } else { reject(Error(&quot;Error&quot;)); // it will return Error(&quot;Error&quot;) and the downstream will get Error(&quot;Error&quot;) as params } }) `&lt;/pre&gt; Promise 构造器接受一个函数作为参数, 传入两个回调函数resolve 和 reject, 在这个函数参数中做一些一步操作, 成功后调用 resolve 将 Promise 对象的状态设置为 resolved 并返回一个 Promise 对象用于链式调用, 失败后调用 reject 将 Promise 对象的状态设置为 rejected 并返回一个 Promise 对象用于链式调用 使用时: &lt;pre&gt;`promise.then(function(result){}).catch(function(err){}) Promise API Reference静态方法: Promise.resolve(promise), 返回一个 Promise Promise.resolve(thenable), 从 thenable 对象创建一个新的 Promise, 一个 thenable (类 Promise) 对象是一个带有” then” 方法的对象. Promise.resolve(obj), 创建一个以 obj 为肯定结果的 Promise Promise.reject(obj), 创建一个以 obj 为否定结果的 Promise, 为了一致性和调试方便, obj 应该是一个 Error 实例对象. Promise.all(array), 创建一个 Promise, 当且仅当数组中的所有 Promise 都 resolved 之后才设为 resolved, 若其中存在 rejected, 则设置状态为rejected Promise.race(array), 创建一个 Promise, 当数组首先出现 resovled 或 rejected 的时候设置为同状态","link":"/2016/10/09/promise-e5-9f-ba-e6-9c-ac-e7-82-b9/"},{"title":"Options of Webpack Dll Plugin","text":"The DllPlugin and DllReferencePlugin provide means to split bundles in a way that can drastically improve build time performance. DllPluginThis plugin used in a separate webpack config exclusively to create a dll-only-bundle. It creates a manifest.json file, which is used by the DllReferencePlugin to map dependencies. context: (optional), context of requests in the manifest file(default to the webpack context). name: name of the exposed dll function(TemplatePaths: [hash] &amp; [name]) path: absolute path to the manifest json file(output) 1new webpack.DllPlugin(option) Creates a manifest.json which is written to the given absolute path. It contains mappings from require and import requests, to module ids. It is used by the DllReferencePlugin. Combine this plugin with output.library option to expose(aka, put into the global scope) the dll function output.library expose the name to global scope DllReferencePlugin.name add the name to the mapping file. So it’s important to keep output.library and DllReferencePlugin.name same to set a right mapping. DllReferencePluginThis plugin is used in the primary webpack config, it references the dll-only-bundle to require the pre-built dependencies. context: absolute path, context of the requests in the manifest(or content property) manifest: an object containing content and name or a string to the absolute path of the JSON manifest to be loaded upon compilation. content: (optional), the mappings from request to module id(default to manifest.content) name: (optional), the name where the dll is exposed (default to manifest.name) scope: (optional), prefix which is used for accessing the content of the dll sourceType: (optional), how the dll is exposed. 1new webpack.DllReferencePlugin(options) References a dll manifest file to map dependencies names to module ids, then requires them as needed using the internal __webpack_require__ function. Note: Keep the name consistent with output.library ModesThis plugin can be used in two different modes, scoped and mapped. Scoped ModeThe content of the dll is accessible under a module prefix, i.e. with scope = 'xyz' a file named abc in the dll can be access via require(xyz/abc). Mapped ModeThe content of the dll is mapped to the current directory. If a required file matches a file in the dll(after resolving), then the file from the dll is usd instead. Because this happens after resolving every file in the dll bundle, the same paths must be available for the consumer of the dll bundle, i.e. if the dll contains lodash and the file abc, require('lodash') and require('./abc') will be used from the dll, rather than building them into the main bundle. 123456// webpack.config.dll.jsnew webpack.DllPlugin({ context: __dirname, name: '[name]_[hash]', path: path.join(__dirname', 'manifest.json'),}) 123456// webpack.config.base.jsnew webpack.DllReferencePlugin({ context: __dirname, manifest: require('./manifest.json'), name: './my-dll.js',}) NotesOutput.library and DllPlugin.name1234567891011121314module.exports = { output: { path: path.resolve(__dirname, 'lib'), filename: '[name]_[hash].js', library: '[name]_[hash]', // this set the exposed function name to [name]_[hash] }, plugins: [ new webpack.DllPlugin({ path: path.resolve(__dirname, 'lib', '[name]-manifest.json'), // put the manifest file in lib directory name: '[name]_[hash]', // be consistent with library name to make the map correct context: __dirname, }) ]} Context in Dev ConfigSet the DllReferencePlugin.context same as DllPlugin.context so the manifest will bundle and resolve the dll files from the same root directory. Add dll bundle to htmlAfter bundle the dll, I should insert it betore app.js in the html file to provide the global function. Step 1: Copy the dll files to the dist directory I use the copy-webpack-plugin plugin 1234// webpack.config.jsnew CopyPlugin([ { from './lib/*.js' } // default to output.path, so the dll file will be copied to output.path/lib/*.js]) Generate a manifest of the dll files for html-webpack-plugin to insert to the template I use the webpack-manifest-plugin 12// webpack.config.dll.jsnew ManifestPlugin() It will generate the manifest.json in output.path 123{ \"vendor.js\": \"vendor_0642aa84a6959d661519.js\"} Insert the Manifest into the html 123456789//parse the jsonconst fs = require('fs)const manifest = JSON.parse(fs.readFileSync(require('./lib/manifest.json')))// insertnew HtmlPlugin({ //... dll: `./lib/${manifest['vendor.js']}`, // the dll file locates at ./lib/*.js}) SummaryDll Config123456789101112131415161718192021const webpack = require('webpack')const path = require('path')const ManifestPlugin = require('webpack-manifest-plugin')module.exports = { entry: { vendor: ['./src/vendor'], }, output: { filename: '[name]_[hash].js', path: path.resolve(__dirname, 'lib'), library: '[name]_[hash]', }, plugins: [ new webpack.DllPlugin({ name: '[name]_[hash]', path: path.resolve(__dirname, 'lib', '[name]-manifest.json'), }), new ManifestPlugin(), ],} Dev Config12345678910111213141516171819202122232425262728293031const webpack = require('webpack')const path = require('path')const HtmlPlugin = require('html-webpack-plugin')const CopyPlugin = require('copy-webpack-plugin')const fs = require('fs')const manifest = JSON.parse(fs.readFileSync('./lib/manifest.json'))module.exports = { entry: { app: ['./src/index'], }, output: { filename: 'scripts/[name].bundle.js', path: path.resolve(__dirname, 'dist'), }, plugins: [ new HtmlPlugin({ template: path.resolve(__dirname, 'src', 'templates', 'index.html'), title: 'dev', dll: `./lib/${manifest['vendor.js']}`, }), new webpack.DllReferencePlugin({ context: '.', manifest: require('./lib/vendor-manifest'), }), new CopyPlugin([ { from: './lib/*.js'} ]), ]}","link":"/2017/09/12/options-of-webpack-dll-plugin/"},{"title":"Promise in ES6","text":"在 JavaScript 世界中, 所有代码都是单线程执行的 异步执行可以可以用回调函数实现 function callback() { console.log(&apos;Done&apos;); } console.log(&apos;before setTimeout()&apos;); setTimeout(callback, 1000); console.log(&apos;after setTimeout()&apos;); `&lt;/pre&gt; 先看一个简单的 Promise 例子: 生成0-2之间的随机数, 如果小于1, 则等待一段时间后返回成功, 否则返回失败 &lt;pre&gt;`function test(resolve, reject){ var timeOut = Math.random() * 2; log(&apos;set timeout to: &apos; + timeOut + &apos; seconds.&apos;); setTimeout(function(){ if(timeOut &amp;lt; 1) { log(&apos;call resolve()...&apos;); resolve(&apos;200 ok&apos;); } else { log(&apos;call reject()...&apos;); reject(&apos;timeout in &apos; + timeOut + &apos; seconds&apos;); } }, timeOut * 1000) } `&lt;/pre&gt; 这个`test()`函数有两个参数, 这两个参数都是函数, 如果执行成功, 我们将调用`resolve(&apos;200 ok)&apos;`, 如果执行失败, 我们将调用`reject(&apos;timeout in &apos; + timeOut + &apos; seconds.&apos;)`. 可以看出, `test()`函数只关心自己的逻辑, 并不关心具体的`resolve` 和`reject` 将如何处理. 有了执行函数, 我们就可以用一个 Promise 对象来执行他, 并在将来某个时刻获得成功或失败的结果 &lt;pre&gt;`var p1 = new Promsie(test); var p2 = p1.then(function(result){ console.log(&apos;成功: &apos; + result); }); var p3 = p2.catch(function(err){ console.log(&apos;失败: &apos; + err); }); `&lt;/pre&gt; 变量`p1`是一个 Promise 对象, 他负责执行执行`test`函数, 由于`test`函数在内部是异步执行的, 当`test`函数执行到`resolve(&apos;ok 200&apos;)`时, 告诉 Promsie 对象执行 &lt;pre&gt;`.then(function(result){ // result 是通过 test 传递给 resolve 的参数 console.log(&apos;成功: &apos; + result); }); `&lt;/pre&gt; 当`test`执行到`reject`的时候, 告诉 Promise 对象执行 &lt;pre&gt;`.catch(function(err){ // err 是 test 传递给 reject 的参数 console.log(&apos;失败: &apos;+ err); }); `&lt;/pre&gt; Promise 对象可以串联起来(因为都返回一个 Promise 对象) &lt;pre&gt;`new Promise(test).then(function(result){console.log(result)}).catch(function(err){console.log(err)}); `&lt;/pre&gt; 可见, Promise 最大的好处, 是在异步执行的流程中, 把执行代码和处理结果代码清晰地分离了. Promise 还可以做更多的事情, 比如有若干个异步任务, 需要先做任务1, 如果成功后再做任务2, 任何任务失败则不再继续并执行错误处理函数 要串行执行这样的异步任务, 只需要链式调用 &lt;pre&gt;`job1.then(job2).then(job3).catch(handleError); `&lt;/pre&gt; 其中 job1, job2, job3 都是(或返回) Promise 对象 &lt;pre&gt;`function job2(input){ return new Promise(function(resolve, reject){ .... }) } `&lt;/pre&gt; ### 并行执行异步任务 试想一个页面聊天任务, 我们需要从两个不同的 URL 分别获取用户的个人信息和好友列表, 这两个任务是可以并行执行的, 用`Promise.all()`实现如下: &lt;pre&gt;`var p1 = new Promise(function(resolve, reject){ setTimeout(resolve, 500, &apos;P1&apos;); }); var p2 = new Promise(function(resolve, reject) { setTimeout(resolve, 600, &apos;P2&apos;); }); // 同时执行p1 和 p2, 并在他们都执行完毕后执行 then Promise.all([p1,p2]).then(function(results){ console.log(results); // 获得一个 Array: [&apos;P1&apos;, &apos;P2&apos;] }); `&lt;/pre&gt; 有时多个异步任务是为了容错, 比如同时向两个 URL 读取, 只需要获得先返回的结果, 这种情况下用`Promise.race()`实现: &lt;pre&gt;`var p1 = new Promise(function(resolve, reject){ setTimeout(resolve, 500, &apos;P1&apos;); }); var p2 = new Promise(function(resolve, reject){ setTimeout(resolve, 600, &apos;P2&apos;); }); Promise.race([p1,p2]).then(function(result){ console.log(result); // &apos;P1&apos; });","link":"/2016/07/31/promise-in-es6/"},{"title":"Note-on-Bip-173","text":"wiki AbstractBIP 173 proposed a checksummed base32 format, Bech32 and a standard for native segregated witness output addresses using it to replace BIP 142. This format is not required for using segwit, but is more efficient, flexible and nicer to use. Bech32A Bech32 string is at most 90 characters long and consists of: The human-readable part(hrp), which is intended to convey the type of data, or anything else that is relevant to the reader. The separator which is always “1”. In case “1” is allowed inside the hrp, the last one in the string is the separator. The data part, which is at least 6 characters long and only consists of alphanumeric characters excluding “1”, “b”, “i”, “o”. ChecksumThe last six characters of the data part form a chechsum and contain no information. Segwit address formatA segwit address is a Bech32 encoding of: The human-readable part “bc” for mainnet and the “tb” for testnet. The data-part values: 1 byte: the witness version A convention of the 2-to-40-byte witness program to base32: Start with the bits of the witness program, most significant bit per btye first. Re-arrange those bits into groups of 5, and pad with zeros at the end if needed. Translate those bits to characters.","link":"/2019/04/20/note-on-bip-173/"},{"title":"PropTypes 与 getDefaultProps","text":"组件的属性可以接受任意值. 有时候我们需要一种机制, 验证别人使用组件时, 提供的参数是否符合要求. 组件类的 PropTypes 属性, 就是用来验证组件实例的属性是否符合要求的. var MyTitle = React.createClass({ propTypes: { title: React.PropTypes.string.isRequried, }, render() { return &amp;lt;h1&amp;gt; {this.props.title} &amp;lt;/h1&amp;gt;; } }); `&lt;/pre&gt; 上面的 `MyTitle` 组件有一个 `title` 属性, `PropTypes` 告诉 React, 这个 `title` 属性是必须的, 而且数据类型是字符串. 如果在实例化的时候设置 `title=123`, 控制台会显示一行错误信息 &lt;pre&gt;`Warning: Failed propType: Invalid prop `title` of type `number` supplied to `MyTitle`, expected `string`. `&lt;/pre&gt; 此外, `getDefaultProps` 可以用来设置组件属性的默认值 &lt;pre&gt;`var MyTitle = React.createClass({ getDefaultProps() { return { title: &apos;Hello World&apos; }; }, render(){ return &amp;lt;h1&amp;gt;{this.props.title}&amp;lt;/h1&amp;gt;; } }) ReactDOM.render(&amp;lt;MyTitle /&amp;gt;, document.body); // &apos;Hello World&apos;","link":"/2016/08/02/proptypes-e4-b8-8e-getdefaultprops/"},{"title":"__Proto__与 Prototype","text":"简而言之, x.__proto__ === x.constructor.prototype `&lt;/pre&gt; 在 JS 世界里, 万物皆对象 Function 是对象, Function.prototype 也是对象, 因此他们具有对象的共性: **proto**属性 &lt;pre&gt;`Function.__proto__ === Function.prototype; // Function 的构造函数还是 Function Function.prototype.__proto__ === Object.prototye; Function.prototype 的构造函数是 Object() `&lt;/pre&gt; 而 Object 的构造函数也是 Function, 所以 &lt;pre&gt;`Object.__proto__ === Function.prototype","link":"/2016/07/30/proto-e4-b8-8e-prototype/"},{"title":"React Ajax","text":"组件的数据来源, 通常是通过 AJAX 请求从服务器获取, 可以使用 componentDidMount 方法设置 AJAX 请求, 等到请求成功, 再用this.setState()方法重新渲染 UI. var UserGist = React.createClass({ getInitialState(){ return { userName: &apos;&apos;, lastGistUrl: &apos;&apos; } }, componentDidMounted(){ $.get(this.props.source, function(result){ var lastGist = result[0]; if(this.isMouted()){ this.setState({ userName: lastGist.owner.login, lastGistUrl: lastGist.html_url }); } }.bind(this)); }, render(){ return ( &amp;lt;div&amp;gt; {this.state.userName}&apos;s last Gist is &amp;lt;a href={this.state.lastGistUrl}&amp;gt;here&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; ); } }); React.render( &amp;lt;UserGist source= &apos;....&apos; /&amp;gt;, document.body )","link":"/2016/08/02/react-ajax/"},{"title":"React 性能优化 Tip","text":"慎用 setState, 因为他容易导致重复渲染, 请将数据都交给 redux 管理, 再通过 props 传入. 记得使用 shouldComponentUpdate 比较以确定是否需要重新渲染 请将方法的 bind 一律置于 constructor 中, 可以避免重复绑定, 多个实例的构造函数是共享的. 只传递 component 需要的 props, 传递的太多, 或者传递的太深, 都会加重 shouldComponentUpdate 里面的数据复旦 路由控制与拆包, 当项目变得更大规模与复杂的时候, 我们需要设计成 SPA, 这时路由管理就变得非常重要, 这使得特定 url 参数可以对应特定页面 其他常见:1. 使用 immutable 处理 props, state, store2. 使用 pure-render-decorator 与 immutablejs 搭配使用3. 慎用 setState4. 仅传必要的 props5. 将方法的 bind 置于 constructor","link":"/2016/08/25/react-e6-80-a7-e8-83-bd-e4-bc-98-e5-8c-96-tip/"},{"title":"React 组件生命周期","text":"Mounting/组件初始化相关componentWillMountcomponentDidMount Updating/组件更新相关componentWillReceivePropsshouldComponentUpdatecomponentWillUpdatecomponentDidUpdate Unmounting/组件移除相关componentWillUnmount Initial 相关getDefaultPropsgetInitialState componentWillMount在组件初始化前执行, 但仅执行一次, 即使多次重复渲染该组件,或者改变组件的 state如果希望该回调能执行多次, 可以使用 React.unmountComponentAtNode 移除已有的组件, 然后重新 render componentDidMount在组件初始化完成时触发, 同样只能触发一次 componentWillReceiveProps在组件接收到新的 props 的时间点之前调用, 注意初始化的时候不会触发(此时初始化 props, 而不是获得新的 props), 但是如果组件重复渲染(没有移除), 则会触发此事件 shouldComponentUpdate组件接收到新的 props 或 state 的时候(此时还没进行下一次 render) 会立即调用, 然后通过返回布尔值决定是否要重新渲染当前组件该接口接收两个参数, 第一个参数表示新的props, 第二个表示新的 state shouldComponentUpdate:function(){return true} //重新渲染组件 componentWillUpdateshouldComponentUpdate 返回 true 的时候调用, 此时 props 和 state 都是更新后的值, 而组件尚未重新渲染 componentDidUpdate重新渲染后才会触发 componentWillUnmount组件被移除之前触发, 用于做一些必要的清理, 比如无效的定时器等 getDefaultProps该方法是最先触发的, 可以在该方法中 return 一个对象作为组件的默认 Props(当然如果有从父组件传来的 props, 则以传进来的为主)只在组件初始化的时候执行一次 getInitialState","link":"/2016/07/20/react-e7-bb-84-e4-bb-b6-e7-94-9f-e5-91-bd-e5-91-a8-e6-9c-9f/"},{"title":"Note on Bip32","text":"wiki The specification consists of two parts: a system for deriving a tree of keypairs from a single seed. demostrate how to build a wallet structure on top of such a tree. Specification: Key derivationConventionIn this text we assume the public key cryptography used in Bitcoin, namely elliptic curve cryttography using the field and curve parameters defined by secp256k1. Variables below are either: Integers modulo the order of the curve (referred to as n) Coordinates of points on the curve Byte sequences Addition (+) of two coordinate pair is defined as application of the EC group operation. Concatenation(||) is the operation of appending one byte sequence onto another. Extended KeysWe are going to define a function to derive a number of child keys from a parent key. In order to prevent these from depending solely on the key itself, we extend both private key and public key first with an extra 256 bits of entropy. This extention, called the chain code, is identical for corresponding private key and public keys, and consist of 256 bits, namely 32 bytes. We represent an extended private key as (k, c), with k the normal private key and the c, the chain code. And extended public key is represented as (K, c), with K = point(k) and the c the chain code. Each extended key has 2^31 normal child keys, and 2^31 hardened child keys. Each of these child keys has an index. The normal child keys use indices 0 through 2^31 - 1. The hardened child keys use indices 2^31 - 1 through 2^32 - 1. To ease notation for hardened key indices, a number i_H represents i + 2 ^ 31. Child key derivation (CKB) functionGiven a parent extended key and an index i, it is possible to compute the corresponding child extended key. The algorithm to do so depends on whether the child is a hardened key or not. Private parent key =&gt; private child keyThe function CKDpriv((k_par, c_par), i) =&gt; (k_i, c_i) computes a child extended private key from the parent extended private key. Check whether i &gt;= 2^31(whether the child is a hardened key) if so (hardened child): return failure if not (normal child), let I = HMAC-SHA512(Key = c_par, Data = ser_P(K_par)||ser_32(i)) Split I into two 32-byte sequences, I_L, and I_R. The returned child key k_i is parse_256(I_L) + k_par(mod n) The returned chain code c_i is I_R Private parent key =&gt; public child keyPublic parent key =&gt; private child keyThis is not possible. The key treeThe next step is cascading serveral CKD construction to build a tree. We start with one root, the master extended key m. By evaluating CKBpriv(m, i) for several values of i, we get a number of level-1 derived nodes. As each of these is again an extended key, CKDpriv can be applied to those as well. To shorten notation, we will write CKDpriv(CKDpriv(CKDpriv(m, 3_H), 2), 5) as m/3_H/2/5. Equivalently for public keys, we write CKDpub(CKDpub(CKDpub(M, 3), 2), 5) as M/3/2/5. This results in the following identities: N(m/a/b/c) = N(m/a/b)/c = N(m/a)/b/b = N(m)/a/b/c = M/a/b/c N(m/a_H/b/c) = N(m/a_H/b)/c = N(m/a_H)/b/c However, N(m/a_H) cannot be rewritten as N(m)/a_H, as the latter is not possible. Key identifiersExtended keys can be identified by the Hash160(RIPED160 after SHA256) of the serialized ECDSA public key K, ignoring the chain code. This corresponds exactly to the data used in traditional Bitcoin addresses. It is not advised to represent this data in base58 format though, as it may be interpreted as an address that way. The first 32 bits of the identifier are called key finterprint. Serialization formatExtended public and private keys are serialized as follows: 4 bytes: version bytes (mainnet: 0x0488B21E public, 0x0488ADE4 private; testnet: 0x043587CF public, 0x04358394 private) 1 byte: depth: 0x00 for master nodes, 0x01 for level-1 derived keys. 4 bytes: the fingerprint of the parent’s key (0x00000000 if master key) 4 bytes: child number, 0x00000000 if master key 32 bytes: the chain code 33 bytes: the public key or private key data The 78 bytes structure can be encoded like other Bitcoin data in Base58, by first adding 32 checksum bits(derived from the double SHA256 checksum), and then conventing to the Base58 representation. Master key generationThe total number of possible extended keypairs is almost 2^512, but the produced keys are only 256 bits long, and offer about half of that in terms of security. Therefore the master keys are not generated directly, but instead from a potentially short seed value. Generate a seed byte sequence S of a chosen length(between 128 and 512 bits, 256 bits is advised) from a (P)RNG. Calculate I = HMAC-SHA512(Key = “Bitcoin seed”, Data = S) Split I into two 32-byte sequence, I_L and I_R Use parse_256(I_L) as master secret key and I_R as master chain code. In case I_L is 0 or &gt;= n, the master key is invalid. Specification: Wallet StructureThe default wallet layoutAn HD Wallet is organized as several ‘accounts’. Accounts are numbered, the default account (“”) being numbered 0. Clients are not required to support more than one account, if not, they only use the default account. Each account is composed of two keypair chains: an internal and an external one. The external keychain is used to generate new public addresses, while the internal one is used for all other operations(change addresses, generate addresses, anything that doesn’t need to be communicated).","link":"/2019/03/05/note-on-bip32/"},{"title":"React 表单","text":"用户在表单输入的内容, 属于用户与组件的互动, 要用this.setState()修改 var Input = React.cr而奥特Class({ getInitialState(){ return { value: &apos;Hello&apos; }; }, handleChange(event){ this.setState({ value: event.target.value; }) }, render(){ return( &amp;lt;div&amp;gt;&amp;lt;input type=&apos;text&apos; onChange={this.handleChange} value = {this.state.value} /&amp;gt;&amp;lt;p&amp;gt;{this.state.value}&amp;lt;/p&amp;gt;&amp;lt;/div&amp;gt; ); } }); ReactDOM.render( &amp;lt;Input /&amp;gt;, document.body );","link":"/2016/08/02/react-e8-a1-a8-e5-8d-95/"},{"title":"React-Hot-Loader in Webpack With Ts-Loader","text":"It’s very easy to integrate react-hot-loader into webpack with ts-loader. Config the webpackAdd Hot Module Replacement1234567891011121314// webpack.entryapp: [ 'webpack/hot/only-dev-server', 'webpack-dev-server/client?http://localhost:8080', path.resolve(__dirname, './src'),],plugins: [ new webpack.HotModuleReplacementPlugin()],devServer: { hot: true,} Add React-Hot-Loader into webpack12345678910111213141516171819// add react-hot-loader to entry pointentry: [ 'webpack/hot/only-dev-server', 'webpack-dev-server/client?http://localhost:8080', 'react-hot-loader/patch', path.resolve(__dirname, './src/'),],// add loadermodule: { rules: [ { test: /\\.tsx$/, use: ['react-hot-loader/webpack/', 'ts-loader'], exclude: /node_modules/, include: path.resolve(__dirname, './src'), } ]} Wrap Root Container into module.hot.accept123456if (module.hot) { module.hot.accept('./router', () =&gt; { const Root = require('./router').default render(&lt;Root /&gt;, htmlDOM) })} Note, if you are using ts with babel-preset-es2015, you can set babel to ignore es2015 module transform by 123{ \"presets\": [[\"es2015\", {\"modules\": false}]]} because webpack 3 has built-in support for ES2015 modules. You won’t need to re-require you root module. 12345if (module.hot) { module.hot.accept('./router', () =&gt; { render(&lt;Root /&gt;, htmlDOM) })} Same treatment in ts if your target is es6","link":"/2017/09/29/react-hot-loader-in-with-ts-loader/"},{"title":"React 顶层 API","text":"React.createClass(obj)创建一个 ReactClass(组件类), 参数是一个对象且必须有 render 属性. 该方法必须返回一个封闭的容器或 null/false(表示不渲染) 在该方法中, 所有的 this 都会在最终调用的时候绑定到创建的组件的构造器上. React.createElement(TYPE(string|ReactClass)[, PROPS[, CHILDREN(ReactElement)]])创建一个指定类型的 React 元素(要区分 ReactClass(通性) 和 ReactElement( 个性) 和 Virtual DOM(实例), 通过 ReactClass 创建 ReactElement, 然后实例化成 Virtual DOM: 比如 ButtonComponent 是 Class, 而&lt;ButtonCompoennt /&gt;则是 Element, 最后通过 ReactDOM.render() 生成Virtual DOM)第三个参数 Children 可以是人一个书的 React 元素 React.createElement(&apos;div&apos;, null, React.createElement(&apos;p&apos;, null, React.createElement(Component, {a:1}) ) ) `&lt;/pre&gt; ### React.cloneElement(TYPE(ReactElement)[, PROPS(object)[, CHILDREN(ReactElement)]]) 克隆并返回一个新的 ReactElement(内部子元素也会随之克隆), 新返回的元素会保留就元素的 props, ref, key, 也会集成新的 props( 如果第二个参数不为 null) &lt;pre&gt;`var Hello = React.createClass({ render: function(){ var span = &amp;lt;span a = &apos;1&apos;&amp;gt;Span&amp;lt;/span&amp;gt;; var newSpan = React.cloneElement(span,{b:&apos;2&apos;}, &amp;lt;em&amp;gt;EM&amp;lt;/em&amp;gt;); console.log(newSpan.props); return &amp;lt;div&amp;gt;Hello {span},{newSpan}&amp;lt;/div&amp;gt;; } }); `&lt;/pre&gt; 注意 createElement的第一个参数必须是字符串或者 ReactClass, 而 cloneElement 的第一个参数只能是 ReactClass ### React.createFactory(TYPE(string|ReactElement)) 返回一个某种类型的 ReactElement 工厂函数, 可以利用返回的函数来创建一个 ReactElement( 配置 props 和 children) &lt;pre&gt;`var Component = React.createClass({ render:function(){ return this.props.a == 1? &amp;lt;p&amp;gt;123&amp;lt;/p&amp;gt; : null; } }); var p = React.createFactory(Component), ReactElementP = p{{a:1}}, div = React.createFactory(&apos;div&apos;), ReactElementDiv = div(null, ReactElementP); React.render( ReactElementDiv, document.body ); `&lt;/pre&gt; ### React.render(REACTELEMENT(ReactElement), CONTAINER(DOMElement)[, CALLBACK(function)]) 渲染一个 ReactElement 到 container 指定的 DOM 中, 并返回一个到该组件的引用. 如果提供了可选的回调函数, 则该函数会在组件渲染或更新之后调用 如果我们希望在组件外部可以获得组件内部(能通过 this 访问)的东西, 可以将 React.render 的返回值赋予一个变量, 在后续的调用中访问变量即可. ### React.unmountComponentAtNode(CONTAINER(DOMElement) 从 container 指定的 DOM 中移除已经加载的 ReactElement, 清楚相应的事件处理器和 state, 如果在 container 中没有存在的组件, 则不作处理 如果组件清除成功, 则返回 true ### React.renderToString(REACTELEMENT(ReactElement)) React 为服务端提供的一个方法, 可以直接输出 ReactElement 为 HTML 字符串, 将这些标记发送(比如 res.write(HTMLString))给客户端, 可以获得更快的页面加载速度, 并有利于搜索引擎的抓取 &lt;pre&gt;`var com = &amp;lt;Component /&amp;gt; comHTML = React.renderToString(com) //HTMLString `&lt;/pre&gt; ### React.renderToStaticMarkup 类似于 React.renderToString, 但只生成纯粹的 HTML 标记字符串, 不会包含类似 dta-reactid 之类的 React 属性, 从而节约字节数 ### React.initializeTouchs(ShouldUserTouch(boolean)) 开启或关闭 React 的触摸事件机制, 传入参数 true 使 React 响应 Touch 事件 ### React.Chilren #### React.Children.map(obj children, function[, object context]) 遍历子元素, 映射为一个新的子元素集合 &lt;pre&gt;`var Component = React.createClass({ render: function(){ return ( &amp;lt;ul&amp;gt; {React.Children.map{ this.props.children, function(){ return &amp;lt;li&amp;gt;{child}&amp;lt;/li&amp;gt; } } } &amp;lt;/ul&amp;gt; ) } }) React.Children.forEach(obj children, function[, obj context])遍历子元素, 对每个子元素执行回调, 但不会返回一个新的集合 React.Children.count(obj children)返回子元素总个数","link":"/2016/07/21/react-e9-a1-b6-e5-b1-82-api/"},{"title":"React-Lodable","text":"react-lodable is a higher order component for loading components with dynamicimports. Code-splitting is the process of taking one large bundle containing your entireapp, and splitting them up into multiple smaller bundles which contain seperateparts of your app. This might seem difficult to do, but tools like Webpack have this built in, andReact Loadable is designed to make is super simple. Route-based splitting vs. Component-based splittingA common piece of advice you will see is to break your app into seperate routesand load each one asynchronously. This seems to work well enough for many apps– a a user, clicking a link and waiting for a page to load is a familiarexperience on the web. Namely, a route is simple a component. But in fact there are more places than just routes where you can pretty easilysplit apart your app: Modals, Tabs, and many more UI Components hide contentuntil the user has done something to reveal it. Example: Maybe your app ahs a map buried inside of a tab component. Why wouldyou load a massive mapping library for the parent route every time the usernever to to that tab. React Loadable is a small library that makes component-centric code splittingincredibly easy in React. Loadable is a higher-order component(a function that returns a component)which lets you dynamically load any module before rendering it into your app. We can make it by dynamic import 1234567import Bar from './components/Bar'class Foo extends React.Component { render() { return &lt;Bar /&gt; }} =&gt; 12345678910111213141516class Foo extends React.Component { state = { Bar: null, } componentWillMount() { import('./components/Bar').then(Bar =&gt; this.setState({ Bar })) } render() { let { Bar } = this.state if (!Bar) { return &lt;div&gt;Loading...&lt;/div&gt; } else { return &lt;Bar /&gt; } }} But that’s whole bunch of work, and it doesn’t even handle a bunch of caess.What about when import() fails? What about server-side rendering? react-loadable considers the unexpected cases. 123456789101112import Loadable from 'react-loadable'const LoadableBar = Loadable({ loader: () =&gt; import('./components/Bar'), loading: () =&gt; &lt;div&gt;Loading&lt;/div&gt;,})class Foo extends React.Component { render() { return &lt;LoadableBar /&gt; }} When you use import() with webpack2, it willautomatically code-split foryou with no additional configuration. Define your Loading Component 123function Loading() { return &lt;div&gt;Loading&lt;/div&gt;} When your loader fails, your Loading component will receive an error prop whichwill be true(otherwise it will be false). 123456function Loading(props) { if (props.error) { return &lt;div&gt;Error&lt;/div&gt; } return &lt;div&gt;Loading...&lt;/div&gt;} Sometimes components load really quickly(&lt;200ms) and the loading screen onlyquickly flashes on the screen. Your loading component will get a pastDelay props which will only be trueonce the component has taken longer to load than a set delay. 12345678910function Loading(props) { if (props.error) { return &lt;div&gt;Error&lt;/div&gt; } else if (props.pastDelay) { // only show loading when it takes longer than 200ms return &lt;div&gt;Loading&lt;/div&gt; } else { return null }} This delay defaults to 200ms, but you can customize the delay in Loadable. 12345Loadable({ loader: () =&gt; import('./components/Bar'), loading: () =&gt; Loading, delay: 300,}) Timing out when the loader is taking too long Sometimes network connections suck and never resolve or fail, they just hangthere forever. This sucks for the user because they won’t know if it shouldalways take this long, or if they should try refreshing. The Loading component will receive a timeOut prop which will be set to truewhen the loader has timed out. 1234567891011function Loading(props) { if (props.error) { return &lt;div&gt;Error&lt;/div&gt; } else if (props.timedOut) { return &lt;div&gt;Timed out&lt;/div&gt; } else if (props.pastDelay) { return &lt;div&gt;Loading&lt;/div&gt; } else { return null }} This feature is disabled by default, you can pass a timeout option toLoadable to enable it. By default Loadable will render the default export of the returned module.If you want to customize this behavior you can use the render option. 1234567Loadable({ loader: () =&gt; import('./myComponent'), render(loaded, props) { let Component = loaded.namedExport return &lt;Component {...props} /&gt; },}) You can do whatever you want within loader() as long as it returns a promiseand you are able to render everything You can load multiple resources in parallel with Loadable.Map 1234567891011Loadable.Map({ loader: { Bar: () =&gt; import('./Bar'), i18n: () =&gt; fetch('./i18n/bar.json').then(res =&gt; res.json()), }, render(loaded, props) { let Bar = loaded.Bar.default let i18n = loaded.i18n return &lt;Bar {...props} i18n={i18n} /&gt; },}) As an optimization, you can also decide to preload a component before it getsrendered. 1234567891011121314151617181920212223242526272829const LoadableBar = Loadable({ loader: () =&gt; import('./Bar'), loading: Loading,})class MyComponent extends React.Component { state = { showBar: false, } onClick = () =&gt; { this.setState({ showBar: true }) } onMouseOver = () =&gt; { LoadableBar.preload() } render() { return ( &lt;div&gt; &lt;button onClick={this.onClick} onMouseOver={this.onMouseOver}&gt; showbar &lt;/button&gt; {this.state.showBar &amp;&amp; &lt;LoadableBar /&gt;} &lt;/div&gt; ) }} Server-side rendering to see Github","link":"/2017/11/23/react-lodable/"},{"title":"[WIP]notes of Building Product, Talking to Users and Growing","text":"original notes You need a lot of feedback. Maybe you get a lot of people to your site, but no one sticks around because you didn’t get that initial user feedback. When you have an idea, you should really think about what the idea is really solving. Like what is the actual problem. You should describe your problem in one sentence, and then you should think. When you have a problem and are able to state it, you should think about","link":"/2019/04/17/notes-of-building-product-talking-to-users-and-growing/"},{"title":"React-Native Basic Component","text":"Textimport React, { Component } from &apos;react&apos; import { AppRegistry, Text } from &apos;react-native&apos; const App = () =&amp;gt; &amp;lt;Text&amp;gt;Hello World&amp;lt;/Text&amp;gt; AppRegistry.registerComponent(&quot;Project&quot;, () =&amp;gt; App) 12### Image import React, { Component } from &apos;react&apos; import { AppRegistry, Image } from &apos;react-native&apos; const App = () =&amp;gt; &amp;lt;Image source = {require(&apos;./img/sample.png&apos;)} /&amp;gt; AppRegistry.registerComponent(&quot;Project&quot;, () =&amp;gt; App) 12### View import React, { Component } from &apos;react&apos; import { AppRegistry, Text, View } from &apos;react-native&apos; const App = () =&amp;gt; ( &amp;lt;View style={{alignItems: 'center'}} &amp;gt; &amp;lt;Text&amp;gt;Hello World&amp;lt;/Text&amp;gt; &amp;lt;/View&amp;gt; ) AppRegistry.registerComponent(&quot;Project&quot;, () =&amp;gt; App) `&lt;/pre&gt; ### TextInput &lt;pre&gt;`import React from &apos;react&apos; import { AppRegistry, TextInput, View } from &apos;react-native&apos; const App = () =&amp;gt; ( &amp;lt;View&amp;gt; &amp;lt;TextInput placeholder = &quot;Hello&quot; /&amp;gt; &amp;lt;/View&amp;gt; ) AppRegistry.registerComponent(&apos;Project&apos;, () =&amp;gt; App) `&lt;/pre&gt; ### ListView &lt;pre&gt;`import React, { Component } from &apos;react&apos; import { AppRegistry, Text, View, ListView } from &apos;react-native&apos; class SimpleList extends Component { constructor(){ super(props) var ds = new ListView.DataSource({ rowHasChanged: (r1,r2) =&amp;gt; r1!==r2 }) this.state = { dataSource: ds.cloneWithRows([&apos;john&apos;, &apos;joel&apos;,&apos;james&apos;,&apos;jimmy&apos;,&apos;jackson&apos;]) } } render(){ return ( &amp;lt;View&amp;gt; &amp;lt;ListView dataSource={this.state.dataSource} renderRow={(rowData) =&amp;gt; &amp;lt;Text&amp;gt;{rowData}&amp;lt;/Text&amp;gt;} &amp;lt;/View&amp;gt; ) } } AppRegistry.registerComponent(&quot;Project&quot;, () =&amp;gt; SimpleList)","link":"/2016/09/16/react-native-basic-component/"},{"title":"React-Router 中 Props 的传递","text":"原本写 {children} `&lt;/pre&gt; 的地方改写为 &lt;pre&gt;`{children &amp;amp;&amp;amp; React.cloneElement(children, { prop, // 需要传入的 props })} 即可 官方案例","link":"/2017/02/07/react-router-e4-b8-ad-props-e7-9a-84-e4-bc-a0-e9-80-92/"},{"title":"React-Router Documents","text":"安装 npm install history react-router@latest `&lt;/pre&gt; react-router 依赖 history 模块 &lt;pre&gt;`import {Router, Route, Link} from &apos;react-router&apos; 可以从 lib 目录 require 需要的部分 `&lt;/pre&gt; import { Router } from &apos;react-router/lib/Router&apos; &lt;pre&gt;`import React from &apos;react&apos; import { Router, Route, Link } from &apos;react-router&apos; const App = React.createClass({/*..*/}) const About = React.createClass({/*...*/}) const Users = React.createClass({ render(){ return( &amp;lt;div&amp;gt; &amp;lt;h1&amp;gt;Users&amp;lt;/h1&amp;gt; &amp;lt;div className = &quot;master&quot;&amp;gt; &amp;lt;ul&amp;gt; {/* 在本应用中用 Link 去链接路由*/} {this.state.users.map(user =&amp;gt; ( &amp;lt;li key={user.id}&amp;gt;&amp;lt;Link to={`/user/${user.id}`}&amp;gt;{user.name}&amp;lt;/Link&amp;gt;&amp;lt;/li&amp;gt; ))} &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div className =&quot;detail&quot;&amp;gt; {this.props.children} &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; ) } }) const User = React.createClass({ componentDidMount(){ this.setState({ // 路由应该通过有用的信息来呈现, 比如 URL 的参数 user: findUserById(this.props.params.userId) }) }, render(){ return( &amp;lt;div&amp;gt; &amp;lt;h2&amp;gt;{this.state.user.name}&amp;lt;/h2&amp;gt; {/* 等等 */} &amp;lt;/div&amp;gt; ) } }) /** * 路由配置说明(不用加载整个配置, 只需要加载一个想要的跟路由, 也可以延迟加载这个配置) */ React.render( (&amp;lt;Router&amp;gt; &amp;lt;Route path = &quot;/&quot; component = {App}&amp;gt; &amp;lt;Route path = &quot;about&quot; component = {About}/&amp;gt; &amp;lt;Route path = &quot;users&quot; component = {Users}&amp;gt; &amp;lt;Route path = &quot;/user/:user\u0006Id&quot; component = {User}/&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;Route path = &quot;*&quot; component = {NoMatch}/&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Router&amp;gt;), document.body ) `&lt;/pre&gt; &lt;pre&gt;`import React from &apos;react&apos; import { render } from &apos;react-dom&apos; import { Router, Route, Link } from &apos;react-router&apos; const App = React.createClass({ render(){ return ( &amp;lt;div&amp;gt; &amp;lt;h1&amp;gt;App&amp;lt;/h1&amp;gt; {/* 把 &amp;lt;a&amp;gt; 变成 &amp;lt;Link&amp;gt; */} &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;&amp;lt;Link to=&quot;/about&quot;&amp;gt;&amp;lt;/Link&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;Link to=&quot;/inbox&quot;&amp;gt;&amp;lt;/Link&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; {/* 接着用` this.props.children` 替换`&amp;lt;Child&amp;gt;`, this.props.children 就是 App 的子组件 Inbox 和 About */} {this.props.children} &amp;lt;/div&amp;gt; ) } }) React.render(( &amp;lt;Router&amp;gt; &amp;lt;Route path = &quot;/&quot; component = {App}&amp;gt; &amp;lt;Route path=&quot;about&quot; component = {About} &amp;lt;Route path=&quot;inbox&quot; component = {Inbox} &amp;lt;/Route&amp;gt; &amp;lt;/Router&amp;gt; )) `&lt;/pre&gt; &lt;pre&gt;`const Message = React.createClass({ render(){ return( &amp;lt;h3&amp;gt;Message&amp;lt;/h3&amp;gt; ) } }) const Inbox = React.createClass({ render(){ return( &amp;lt;div&amp;gt; &amp;lt;h2&amp;gt;Inbox&amp;lt;/h2&amp;gt; {this.props.children||&apos;Welcome to your inbox&apos;} &amp;lt;/div&amp;gt; ) } }) React.render(( &amp;lt;Router&amp;gt; &amp;lt;Route path=&quot;/&quot; component = {App}&amp;gt; &amp;lt;Route path =&quot;about&quot; component = {About} /&amp;gt; &amp;lt;Route path =&quot;inbox&quot; component = {Inbox}&amp;gt; &amp;lt;Route path=&quot;message/:id&quot; component={Message}/&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Router&amp;gt; ),document.body) `&lt;/pre&gt; 访问 URL = inbox/message/Jkei 会匹配一个新路由, 其指向 App =&gt; Inbox =&gt; Message &lt;pre&gt;`&amp;lt;App&amp;gt; &amp;lt;Inbox&amp;gt; &amp;lt;Message params = {id: &quot;Jkei&quot;} /&amp;gt; &amp;lt;/Inbox&amp;gt; &amp;lt;/App&amp;gt; `&lt;/pre&gt; ### 获取 URL 参数 为了从服务器获取 message 数据, 我们首先需要知道他的信息, 当渲染组件的时候, React Router 自动向 Route 组件注入一些有用的信息, 尤其是路径中动态部分的参数, 比如上例中的`:id` &lt;pre&gt;`const Message = React.createClass({ componentDidMount(){ const id = this.props.params.id fetchMessgae(id,function(err,message){ this.setState({message:message}) }) } }) `&lt;/pre&gt; ### 路由配置 路由配置是一组指令, 用来告诉 router 如何匹配 URL, 以及匹配后的动作. &lt;pre&gt;`import React from &apos;react&apos; import {Router, Route, Link} from &apos;react-router&apos; const App = React.createClass({ render(){ return( &amp;lt;div&amp;gt; &amp;lt;h1&amp;gt;App&amp;lt;/h1&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;&amp;lt;Link to=&quot;/about&quot;&amp;gt;About&amp;lt;/Link&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;Link to=&quot;/inbox&quot;&amp;gt;Inbox&amp;lt;\u0002/Link&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; {this.props.children} &amp;lt;/div&amp;gt; ) } }) const About = React.createClass({ render(){ return &amp;lt;h3&amp;gt;About&amp;lt;/h3&amp;gt; } }) const Inbox = React.createClass({ render(){ return( &amp;lt;div&amp;gt; &amp;lt;h2&amp;gt;Inbox&amp;lt;/h2&amp;gt; {this.props.children || &apos;Welcome to your Inbox&apos;} &amp;lt;/div&amp;gt; ) } }) const Message = React.createClass({ render(){ return &amp;lt;h3&amp;gt;Message {this.props.params.id}&amp;lt;/h3&amp;gt; } }) React.render(( &amp;lt;Router&amp;gt; &amp;lt;Route path = &quot;/&quot; component = {App}&amp;gt; &amp;lt;Route path = &quot;about&quot; component = {About} /&amp;gt; &amp;lt;Route path = &quot;inbox&quot; component = {Inbox}&amp;gt; &amp;lt;Route path = &quot;message/:id&quot; component = {Message} /&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Router&amp;gt; ),document.body) `&lt;/pre&gt; ### 添加首页 当 URL 为 &quot;/&quot; 的时候, 渲染的 App 组件的 render 中的 this.props.children 还是 undefined, 这种情况我们可以使用`IndexRoute`来设置一个默认页 &lt;pre&gt;`import {IndexRoute} from &apos;react-router&apos; const Dashboard = React.createClass({ render(){ return &amp;lt;div&amp;gt;Welcome to the App!&amp;lt;/div&amp;gt; } }) React.render(( &amp;lt;Router&amp;gt; {/* 当 URL 为 / 的时候渲染 Dashboard*/} &amp;lt;IndexRoute component = {Dashboard} /&amp;gt; &amp;lt;Route path=&quot;about&quot; component = {About} /&amp;gt; &amp;lt;/Router&amp;gt; ),document.body) `&lt;/pre&gt; 现在的 Sitemap 如下: &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;URL&lt;/th&gt; &lt;th&gt;Component&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;/&lt;/td&gt; &lt;td&gt;App =&gt; Dashboard&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/about&lt;/td&gt; &lt;td&gt;App =&gt; About&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; ### 将 UI 于 URL 解耦 如果我们可以将 `/inbox` 从 `/inbox/message:id` 中去除, 并且还能够让 Message 嵌套在 App-&gt;Inbox 中渲染, 那会非常赞, 绝对路径可以做到这一点 &lt;pre&gt;`React.render(( &amp;lt;Router&amp;gt; &amp;lt;Route path = &quot;/&quot; component = {App}&amp;gt; &amp;lt;IndexRoute component = {Dashboard} /&amp;gt; &amp;lt;Route path = &quot;inbox&quot; component = {Inbox} &amp;gt; &amp;lt;Route path = &quot;/message:id&quot; component = {Message} /&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Router&amp;gt; ),document.body) `&lt;/pre&gt; 在多层嵌套路由中使用感觉对路径可以提高逻辑性. Simtemap 如下: &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;URL&lt;/th&gt; &lt;th&gt;Component&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;/&lt;/td&gt; &lt;td&gt;App =&gt; Dashboard&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/message/:id&lt;/td&gt; &lt;td&gt;App =&gt; Inbox =&gt; Message&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; 提醒, 绝对路径可能在动态路由中无法使用 同时, 上述配置存在一个问题, 当用户访问/inbox/message/6的时候回无法访问 使用&amp;lt;Redirect&gt;修正 &lt;pre&gt;`&amp;lt;Route path = &quot;indox&quot; component = {Indox} &amp;gt; &amp;lt;Route path = &quot;/message/:id&quot; component = {Message} /&amp;gt; &amp;lt;Redirect from = &quot;message/:id&quot; to = &quot;/message/:id&quot; /&amp;gt; &amp;lt;/Route&amp;gt; `&lt;/pre&gt; ### 进入和离开的 Hook Route 可以定义 `onEnter` 和 `onLeave` 两个 Hook, 这些 hook 会在页面跳转确认时触发一次, 在路由跳转过程中, `onLeave` hook 会在爱所有将离开的路由中触发, 从最下层的自路由开始直到最外层的父路由结束, 而`onEnter` hook 则从自外层的父路由开始直到最下层的子路由结束 比如从 /message/5 -&gt; /about 依次触发 - /message/:id 的 onLeave - /inbox 的 onLeave - /about 的 onEnter ### 路由匹配原理 路由拥有三个属性来决定是否匹配一个 URL - 嵌套关系 - 路径语法 - 优先级 #### 嵌套关系 当一个给定的 URL 被调用时, 整个集合(命中的部分)都会被渲染, 嵌套路由被描述成一种树形结构, React Router 会深度优化遍历整个路由配置来寻找一个与给定的 URL 匹配的路由 #### 路径语法 路由路径是匹配一个(或一部分) URL 的一个字符串模式, 大部分的路由路径都可以按照字面量理解, 除了一下几个特殊字符: - `:paramName` - 匹配一段位于`/`,`?`, `#`之后的 URL, 命中的部分作为一个参数 - `()` - 内部的内容被认为是可选的 - `*` - 匹配任意字符(非贪婪)直到命中下一个字符或整个 URL 的末尾, 并创建一个 splat 参数 &lt;pre&gt;`&amp;lt;Route path = &apos;/hello/:name&apos; /&amp;gt; // 匹配 /hello/michael 和 /hello/john &amp;lt;Route path = &apos;/hello/(:name)&apos;/&amp;gt; // 匹配 /hello, /hello/michael, /hello/john &amp;lt;Route path = &apos;/files/*.*&apos; /&amp;gt; // 匹配 files/hello.js, files/hello.jpg `&lt;/pre&gt; 使用绝对路径可以使路由忽略嵌套关系 #### 优先级 兄弟路由的前一个优先级高 ### Histories React Router 是建立在 history 之上的, 一个 history 知道如何去监听浏览器地址变化, 并解析这个 URL 转化为 location 对象, 然后 router 使用它匹配到路由. 最后正确渲染组件 常用的 history 有三种形式 - createHashHistory - createBrowserHistory - createMemoryHistory 从 history 库中获取他们 &lt;pre&gt;`import createBrowserHistory from &apos;history/lib/createBrowserHistory&apos; `&lt;/pre&gt; #### createHashHistory 这是一个你会获得的默认 history, 如果不指定某个 history (即&amp;lt;Router&gt;{...}&amp;lt;/Router&gt;) 他用到的是 URL 中的 hash(#) 部分去创建形如 example.com/#/some/path 的路由 HashHistory 是默认的, 可以在服务器中不作任何配置就可以运行, 并且在全部浏览器中都可以使用, 但是不推荐实际生产中使用它, 因为每一个 web 应用都应该有目的地去使用 createBrowserHistory #### 像`?_k=ckuvup` 没用的在 URL 中是什么? 当一个 history 通过应用程序的`pushState`或`replaceState`跳转时, 他可以在新的 location 中存储&quot;lcoation state&quot; 而不现实在 URL 中, 就像在一个 HTML 中 post 的表单数据 在 DOM API 中, 这些 hash history 通过 window.location.hash = newHash 很简单地被用于, 且不用存储他们的 location state, 但是我们希望全部的 history 都能够使用 location state, 因此要为每个 location 添加一个唯一的 key, 并把他们的状态存储在 session storage 中, 当访客点击前进或后退的时候, 可以恢复这些 location state. #### createBrowserHistory 这是 react-router 创建浏览器应用推荐的 History, 使用 History API 在浏览器中被创建用于处理 URL, 新建一个像这样真实的 URL: example.com/some/path ##### 服务器配置 首先服务器应该能够处理 URL 请求, 处理应用启动最初的`/`这样的请求应该没问题,但是当用户来回跳转并在`/ accounts/23`刷新时, 服务器会受到来自`/account/23`的请求, 这时你就需要处理这个 URL 并在响应中包含 JS 程序代码 一个 express 的应用看起来可能是这样的: &lt;pre&gt;`const express = require(&apos;express&apos;) const path = require(&apos;path&apos;) const port = process.env.PORT || 8080 const app = express() // 通常用于加载静态资源 app.use(express.static(__dirname + &apos;/public&apos;)) // 在你应用 JS 文件中包含一个 script 标签的 index.html 中处理任何一个 route app.get(&apos;*&apos;,function(request, response){ response.sendFile(path.resolve(__dirname, &apos;public&apos;, &apos;index.html&apos;) }) app.listen(port) console.log(&apos;server started on port&apos; + port) `&lt;/pre&gt; 当服务器找不到其他文件的时候, 服务器生成静态文件和操作 index.html 文件. ### 实例展示 &lt;pre&gt;`import React from &apos;react&apos; import createBrowserHistory from &apos;history/createBrowserHistory&apos; import { Router, Route, IndexRoute } from &apos;react-router&apos; import App from &apos;../componnents/App&apos; import Home from &apos;../componnents/Home&apos; import About from &apos;../componnents/About&apos; import Features from &apos;../componnents/Features&apos; React.render( &amp;lt;Router history = {createBrowserHistory()} &amp;gt; &amp;lt;Route path = &apos;/&apos; component = {App} &amp;gt; &amp;lt;IndexRoute component = {Home} /&amp;gt; &amp;lt;Route path = &apos;about&apos; component = {About} /&amp;gt; &amp;lt;Route path = &apos;features&apos; component = {Features} /&amp;gt; &amp;lt;/Route&amp;gt; &amp;lt;/Router&amp;gt;, document.body ) `&lt;/pre&gt; ### 默认路由(IndexRoute)与 IndexLink 如果设置了 IndexRoute =&gt; Home, 就要设置跳转到 Home 的路由&apos;/&apos;, 即`&amp;lt;Link to=&apos;/&apos;&amp;gt;Home&amp;lt;/Link&amp;gt;`, 他会一直处于激活状态(因为所有子路由都经过&apos;/&apos;), 我们仅希望在 Home 被渲染后激活并连接到他, 即需要在 Home 路由被渲染后才激活指向&apos;/&apos; 的链接, 请使用`&amp;lt;IndexLink to=&apos;/&apos;&amp;gt;Home&amp;lt;/IndexLink&amp;gt;` ### 动态路由 React Router 适用于小型网站, 也可以支持大型网站 对于大型应用而言, 一个首当其冲的问题就是所需要加载的 JS 的大小, 程序应当只加载当前渲染页需要的的 JS, 有些开发者称之为&quot;代码拆分&quot;, 在用户浏览过程中按需加载 对于底层细节的修改不应该需要他上面每一层级都进行修改, 举个例子, 为一个照片浏览页添加一个路径不应该影响到首页加载的 JS 大小, 也不能因为多个团队共用一个大型路由配置文件二造成合并时的冲突. 路由是个非常适合做代码拆分的地方: 他的责任就是配置好每个 view React Routerzhogn 的路径匹配及组件加载都是异步完成的, 不仅允许你延迟加载组件, **并且可以延迟加载路由配置**. 在首次加载包中你只需要有一个路径定义, 路由会自动解析剩下的路径 Route 可以定义`getChildRoutes`, `getIndexRoute`, 和`getComponents` 这几个函数, 他们都是异步执行的, 并且只有需要时被调用, 这种方式成为&quot;逐渐匹配&quot; React Router 会逐渐地匹配 URL 并且只加载该 URL 对应页面所需要路径配置和组件 如果配合 webpack 代码拆分工具使用的话, 一个原本繁琐的架构就会变得简明 &lt;pre&gt;`const CourseRoute = { path: &apos;course/:courseId&apos;, /* 当 get routes/indexRoute/Component 的时候 require 相应的资源 getChildRoutes(location, callback){ require.ensure([],function(require){ callback(null, [ require(&apos;./routes/Announcements&apos;), require(&apos;./routes/Assignments&apos;), require(&apos;./routes/Grades&apos;) ]) }) }, getIndexRoute(location, callback){ require.ensure([], function(require){ callback(null, require(&apos;./components/Index&apos;)) }) }, getComponents(location, callback){ require.ensure([],function(require){ callback(null, requrie(&apos;./components/Course&apos;)) }) } } `&lt;/pre&gt; ### 跳转前确认 React Router 提供一个`routerWillLeave` 生命周期钩子, 这使得 React 可以拦截正在发生的跳转, 或者在离开 Route 前提示用户 `routerWillLeave` 返回值有一下两种: 1\\. `return false` 取消此次跳转 2\\. `return` 返回提示信息, 在离开 route 前提示用户进行确认 在 Route 组件中引入`Lifecycle` mixin 来安装这个钩子 &lt;pre&gt;`import { Lifecycle } from &apos;react-router&apos; const Home = React.createClass({ mixins: [Lifecycle], routerWillLeave(nextLocation){ if(!this.state.isSaved){ return &apos;Your work is not saved!&apos; } } }) `&lt;/pre&gt; ### 服务端渲染 服务端渲染与客户端渲染有些许不同, 需要 - 发生错误的时候发送一个`500`响应 - 需要重定向时发送一个`30x`响应 - 需要在渲染之前获得数据(用 router 完成) ### 组件生命周期 路由配置如下: &lt;pre&gt;`&amp;lt;Route path = &apos;/&apos; component = {App} &amp;gt; &amp;lt;IndexRoute component = {Home} /&amp;gt; &amp;lt;Route path = &apos;invoices/:invoiceId&apos; component = {Invoice}/&amp;gt; &amp;lt;Route path = &apos;accounts/:accountId&apos; component = {Account}/&amp;gt; &amp;lt;/Route&amp;gt; `&lt;/pre&gt; #### 路由切换时, 组件生命周期的变化 当用户打开’/‘ 页面 Component LifeCycle App componentDidMount Home componentDidMount Invoice N/A Account N/A 当用户从’/‘ 跳转到 ‘/invoices/123’ Component LifeCycle App componentWillReceiveProps, componentDidUpdate Home componentWillUnmount Invoice componentDidMount Account N/A 获取数据最简单的通过 router 获取数据的方法是通过组件生命周期 Hook 来实现. 在 Invoice 中添加一个简单的数据获取功能 `let Invoice = React.createClass({ getInitialState(){ return{ invoice: null } }, componentDidMount(){ this.setState({ this.fetchInvoice() }) }, componentDidUpdate(prevProps){ let oldId = prevProps.params.invoiceId let newId= this.props.params.invoiceId if(newId !== oldId){ this.fetchInvoice() } }, componentWillUnmount(){ this.ignorelastFetch = true }, fetchInvoice(){ let url = `/api/invoices/${this.props.params.invoiceId}` this.request = fetch(url, (err, data) =&amp;gt; { if(!this.ingoreFetch){ this.setState({invoice: data.invoice}) } }) }, render(){ return &amp;lt;InvoiceView invoice = {this.state.invoice} /&amp;gt; }})","link":"/2016/08/26/react-router-documents/"},{"title":"Redux APIs","text":"Compose(…funcs)/** * compose(f,h,g)(...args) =&amp;gt; f(g(h(...args))) * 使用了 reduceRight, 从右开始执行 * @param {多个函数, 逗号隔开} * @return {函数} */ export default function compose(...funcs){ if(funcs.length === 0){ return arg =&amp;gt; arg } if(funcs.length === 1){ return funcs[0] } const last = funcs[funcs.length - 1] const rest = funcs.slice(0,-1) return (...args) =&amp;gt; rest.reduceRight((composed, f) =&amp;gt; f(composed), last(...args)) } `&lt;/pre&gt; 关键在于 reduceRight 可以传入初值 ### createStore(reducer, [initialState]) &lt;pre&gt;`import isPlainObject from &apos;lodash/isPlainObject&apos; import $$observable from &apos;symbol-observable&apos; export var ActionTypes = { INIT: &apos;@@redux/INIT&apos; } export default function createStore(reducer, preloadState, enhancer){ var currentReducer = reducer var currentState = preloadState var currentListeners = [] var nextListeners = currentListeners var isDispatching = false } function ensureCanMutateNextListeners(){ if(nextListeners === currentListeners){ nextListeners = currentListeners.slice() } } function getState(){ return currentState } function subscribe(listener){ if(typeof listener !== &apos;function&apos;){ throw new Error(&apos;Expected listener to be a function&apos;) } var isSubscribed = true ensureCanmutateNextListener() nextListeners.push(listener) return function ubsubscribe(){ if(!isSubscribe){ return } isSubscribe = false ensureCanMutateNextListeners() var index = nextListeners.indexOf(listener) nextListeners.splice(index,1) } } function dispatch(action){ if(isPlainObecjt(action)){ throw new Error(&apos;Action must be plain objects &apos; + &apos;Use custom middleware for async action&apos;) } if(typeof action.type === &apos;undefined&apos;){ throw new Error(&apos;Actions may not have an undefined &quot;type&quot; property. &apos; + &apos;Have you misspelled a constant?&apos;) } if(isDispatching){ throw new Error(&apos;Reducers may not dispatch actions.&apos;) } try{ isDispatching = true currentState = currentReducer(currentState, action) } finally { isDispatching = false } var listeners = currentListeners = nextListeners for(var i = 0; i&amp;lt; listeners.length, i++){ listeners[i]() } return action } function replaceReducer(nextReducer){ if(typeof nextReducer !== &apos;function&apos;){ throw new Error(&apos;Expected the nextReducer to be a function&apos;) } currentReducer = nextReducer dispatch({type:ActionTYpes.INIT}) } ### combineReudcers(reducers) `&lt;/pre&gt; import { combineReducers } from &apos;redux&apos; import counterReducer from &apos;./counterReducer&apos; import todosReducer from &apos;./todosReducer&apos; const rootReducer = combineReducers({ counter: counterReducer, // &amp;lt;--- 键名是 state 中的属性, 键值是对应 reducer 函数名 todos: todosReducer }) export default rootReducer &lt;pre&gt;` 如果提高需求 `&lt;/pre&gt; state ├── counter: 0 ├── todo ├── optTime: [] ├── todoList: [] # 这其实就是原来的 todos！ &lt;pre&gt;` 对应的 reducers 是: `&lt;/pre&gt; reducers/ ├── index.js &amp;lt;-------------- combineReducers (生成 rootReducer) ├── counterReducer.js ├── todoReducers/ &amp;lt;--------- combineReducers ├── index.js ├── optTimeReducer.js ├── todoListReducer.js &lt;pre&gt;` `&lt;/pre&gt; /* reducers/index.js */ import { combineReducers } from &apos;redux&apos; import counterReducer from &apos;./counterReducer&apos; import todosReducers from &apos;./todosReducer&apos; const rootReducer = combineReducers({ counter: counterReducer, todos: todosReducers }) export default rootReducer ================================================= /* reducers/todosReducers/index.js */ import { combineReducers } from &apos;redux&apos; import optTimeReducer from &apos;./optTimeReducer&apos; import todoListReducer from &apos;./todoListReducer&apos; const todosReducers = combineReducers({ optTime: optTimeReducer, todoList: todoListReducer }) export default todosReducers &lt;pre&gt;` 无论 dispatch 哪个 action 都会流通**所有** reducer, 但是由于 reducer 是纯函数, 效率还是会提高. ### BindActionCreator ### applyMiddlware(...middlewares) 先要理解 Middleware, enhancer Redux 引入中间件机制是为了在 dispatch 前后进行处理 `&lt;/pre&gt; const printStateMiddleware = ({getState}) =&gt; next =&gt; action =&gt; { console.log(&apos;...&apos;) let returnValue = next(action) console.log(&apos;...&apos;) return returnValue } &lt;pre&gt;` 实际上最内层 `&lt;/pre&gt; function printStateMiddleware(middlewareAPI){ //中间件内可以使用的 API, 如 getState 与 dispatch return function(dispatch){ // 传入原 dispatch 的引用 return function(action){ console.log(...) var returnValue = dispatch(action) // 执行 dispatch 行为, dispatch(action) 返回的还是 action console.log(...) return returnValue // 传给下一个中间件的 action } } } &lt;pre&gt;` ### Store Enhancer 说白了 Store Enhancer 是对生成 store 的 API 的改造, 与 middleware 的最大区别是 middlewere 不修改 store 的 API 改造 store 的 API 就要从 createStore 入口 Redux 的 applyMiddleware 就是一个 Enhancer `&lt;/pre&gt; import compose from &apos;./compose&apos; // 作用就是层层包裹 // 传入中间件 export default function applyMiddleware(...middlewares){ // 传入 createStore return function(createStore){ // 返回一个函数签名和 createStore 一样的函数, 即返回一个增强版的 createStore return function(reducer, preloadState, enhancer){ // 用原 createStore 先生成一个 store, 包含 getState, dispatch, subscribe, replaceReducer 四个 API var store = creataStore(reducer, preloadState, enhancer) &lt;pre&gt;` var dispatch = store.dispatch // 生成指向原 dispatch的引用 var chain = [] // 存储中间件的数组 //提供给中间件的 API 其实就是 store 的 API var middlewareAPI = { getState: store.getStore, dispatch: (action) =&amp;gt; dispatch(action) } // 给中间件添加 API chain = middlewares.map(middleware =&amp;gt; middleware(middlewareAPI)) // 串联中间件, 添加中间件的起点 store.dispatch, 返回经过修饰的 dispatch dispatch = compose(...middlewares)(store.dispatch) return{ ...store, // store 中保留的原 API dispatch // 用新的 dispatch 覆盖原 dispatch } } }}```参考","link":"/2016/08/24/redux-apis/"},{"title":"Redux 搭配 React","text":"第一步是初始化 react 组件 getInitialState(){ return{ item: store.getState() } } `&lt;/pre&gt; 第二步是在组件 render 后调用 subscribe 函数, 每次 redux 发生 dispatch 的时候都要调用 react 的 setState &lt;pre&gt;`componentDidMount(){ var unsubscribe = store.subscribe(this.onChange) } onChange(){ this.setState({ item: store.getState() }) } React 会根据 State 的变化重新 render 组件this.state.item.todos.map()","link":"/2016/08/16/redux-e6-90-ad-e9-85-8d-react/"},{"title":"Redux-Form 的深坑...慢慢积累","text":"如果 Field 无法输入, 注意 state 是否是 immutable 的, 如果是, 则需要 import { Field, reduxForm } from &apos;redux-form/immutable&apos;","link":"/2016/09/06/redux-form-e7-9a-84-e6-b7-b1-e5-9d-91-e6-85-a2-e6-85-a2-e7-a7-af-e7-b4-af/"},{"title":"Redux-Promise","text":"npm install --save redux-promise `&lt;/pre&gt; &lt;pre&gt;`import promiseMiddleWare from &apos;redux-promise&apos; `&lt;/pre&gt; The default export is a middleware function. If it receives a promise, it will dispatch the resolved value of the promise. It will not dispatch anything if the promise rejects. If it receives an Flux Standard Action whose `payload` is a promise, it will either: dispatch a copy of the action with the resolved value of the promise, and set status to success dispatch a copy of the action with the rejected value of the promise and set the status to error The middleware returns a promise to the caller so that it can wait for the operation to finish before continuing. This is especially useful for server-side rendering. If you find that a promise is not being returned, ensure that all middleware before it in the chain is also returning its next() call to the caller. Using in combination with redux-actions Because it supports FSA actions, you can use redux-promise in combination with redux-actions createAction(FETCH_DATA`, async id =&gt; { const result = await somePromise; return result.someValue});","link":"/2016/09/04/redux-promise/"},{"title":"Refs to Components","text":"The DOM returned from render() is virtual, so called Virtual DOM, and we can get any factual input(value) from a virtual object, such as access to value from a component. The ref returned from ReactDOM.renderReactDOM.render() will return a reference to your component’s backing instance(or null for stateless components) var myComponent = ReactDOM.render(&amp;lt;MyComponent /&amp;gt;, myContainer) However, that the JSX doesn’t return a component. It’s just a ReactElement: a lightweight representation that tells React what the mounted component should look like. var myComponentElement = &amp;lt;MyComponent title = &apos;title&apos;/&amp;gt;; //This is just a ReactElement `&lt;/pre&gt; &lt;pre&gt;`var myComponentInstance = ReactDOM.render(myComponent, myContainer); //a Virtual DOM `&lt;/pre&gt; ### The ref Callback Attribute React supports a special attribute that you can attach to any component. The &apos;ref&apos; attribute ca be a callback function, and this callback will be executed **immediately after the component is mounted**. The referenced component will be passed in as a parameter, and the callback function may use the component immediately, or save the reference for future use. It&apos;s as simple as adding a `ref` attribute to anything returned from render: &lt;pre&gt;`render: function(){ return ( &amp;lt;TextInput ref={function(input){ if(input != nill){ input.focus(); } }} /&amp;gt; ); }, `&lt;/pre&gt; or use ES6 arrow funciton: &lt;pre&gt;`render: function(){ return &amp;lt;TextInput ref={(c) =&amp;gt; this._input = c} /&amp;gt;; }, componentDidMount: function{ this._input.focus(); } `&lt;/pre&gt; ### The ref String Attribute React also supports using a string as a ref prop on any component. Add `ref` attribute to component so you can access to them via `this.refs` Assign a ref attribute to anything returned from render such as: `&lt;input ref='myInput'&gt; ` In some other code, access the backing instance via this.refs as in `var input = this.refs.myInput; var inputValue = input.value; ` A Complete Example`var MyComponent = React.createClass({ handleClick: function(){ if(this.myTextInput != null){ this.myTextInput.focus() } }, render: function(){ return( &amp;lt;div&amp;gt; &amp;lt;input type=&apos;text&apos; ref={(ref) =&amp;gt; this.myTextInput = ref} /&amp;gt; &amp;lt;input type=&apos;button&apos; value=&apos;Focus the text input&apos; onClick = {this.handleClick} /&amp;gt; &amp;lt;/div&amp;gt; ); }}); ReactDOM.render(&lt;MyComponent /&gt;, document.getElementById(‘example’)); Note: ref will be destroyed as component unmounted.","link":"/2016/07/21/refs-to-components/"},{"title":"RegExp in JS","text":"Literal/patter/attributes new RegExpnew RegExp(pattern, attribtues) patternRegExp Attribtues g: global i: ignoreCase m: multi-lines source: literal text lastIndex: mark the index where to start next match Examplevar re = new RegExp(&apos;^[0-9]+$&apos;,&apos;g&apos;); console.log(re.source); //^[0-9]+$ `&lt;/pre&gt; &lt;pre&gt;`var re = new RegExp(&apos;\\\\d{3}&apos;,&apos;g&apos;); var str = &apos;123a456b&apos;; console.log(re.lastIndex); // 0 re.exec(str); //return [&apos;123&apos;] console.log(re.lastIndex); // 3 re.exec(str); // [&apos;456&apos;] console.log(re.lastIndex); //7 re.exec(str); console.log(re.lastIndex) // 0, reset to 0 if exceed. re.lastIndex = 3; //Set Start Index re.exec(str); // [&apos;456&apos;] RegExp Methodsre.compile(re) //execute RegExp in scriptsre.exec(str) //return an Array including String, or null.re.test(str) =&gt; true/false String Methodsstr.search(re,subStr)str.match(re) =&gt; Array including Stringstr.replace(re,str) =&gt; new Stringstr.split(re)","link":"/2016/07/19/regexp-in-js/"},{"title":"Service-Worker With Webpack","text":"1yarn add --dev sw-precache-webpack-plugin 12345678910111213// webpacknew SWPrecachePlugin({ cacheId: 'demo', filename: 'service-worker.js', dontCacheBustUrlsMatching: false, staticFileGlobsIgnorePatterns: [ /index\\.html$/, /\\.map$/, /\\.css$/, /\\.svg$/, /\\.eot$/, ]}) This will generate service-worker.js in dist. Add Router1app.use('/service-worker.js', serve('./dist/service-worker.js')) Note: [name].[ext]?[hash] will not be found by sw-precache(hash will be ignored), so filename should be specified like [name].[hash].[ext] or so. Cache files who are not bundled by webpack.123456789101112131415161718new SWPrecachePlugin({ cacheId: 'demo', filename: 'service-worker.js', minify: true, // add two lines mergeStaticConfig: true, staticFileBlogs: [ path.join(__dirname, '../dist/static/*.*'), ], dontCacheBustUrlsMatching: false, staticFileGlobsIgnorePatterns: [ /\\.index\\.html$/, /\\.map$/, /\\.css$/, /\\.svg$/, /\\.eot$/, ]}) About the Request URLThe images are cached in /dist/static/*, while the request url is /static/*. In dev it can be proxied by webpack. In prod it can be delegated by nginx. But the plugin can fix it by itself: 1234567891011121314151617181920new SWPrecachePlugin({ cacheId: 'demo', filename: 'service-worker.js', minify: true, mergeStaticConfig: true, staticFileGlobs: [ path.join(__dirname, '../dist/static/*.*') ], stripPrefixMulti: { [path.join(__dirname, '../dist/static')]: '/static' }, dontCacheBustUrlsMatching: false, staticFileGlobsIgnorePatterns: [ /\\.index\\.html$/, /\\.map$/, /\\.css$/, /\\.svg$/, /\\.eot$/, ]}) Note: dontCacheBustUrlsMatching: false will set cached key as http://domain/path/to/filename?hash, whose hash will change if the bundled file changed.","link":"/2017/09/03/service-worker-with-webpack/"},{"title":"Shell 指令","text":"Shell 在计算机科学中是指”提供用户使用界面”的软件, 通常指的是命令行界面的解析器, 一般来说, 这个词指的是操作系统中提供访问内核所提供服务的程序. Shell 也用于泛指为所有用户提供操作界面的程序, 也就是程序和用户交互的层面. 因此与之相对的是程序内核(Core), 内核不提供和用户的交互功能. bash (Bourne Again Shell) 是 Linux 标准的默认 shell, 支持 POSIX 标准, 完全兼容 sh.进入 shell: 一般 Linux 系统中, 桌面(GUI)状态下使用快捷键 Ctrl+Alt+T 能打开一个虚拟终端, 输入 shell 命令并执行.退出 shell: 在 shell 中输入 exit 然后回车默认提示符: 普通用户$, 根用户#查看 shell 版本: echo $SHELL查看命令的辅助信息:--help, --version 目录文件指令pwd: 查看当前目录echo $HOME 或者 echo ~: 查看主目录 ls: 列出文件或目录下的文件名 -a(all): 显示所有文件, 包括隐藏文件 -l(long): 显示详细信息(long 表示长格式显示) -d(detail): 显示目录属性 -h(human): 人性化显示文件大小 -i(inode): 显示 inode -ll(ls -l): 显示目录下文件的长信息 cd: 改变目录 ~ 进入当前用户的根目录 同上 -进入上次目录 .. 进入上一级目录 . 进入当前目录 mkdir: 创建目录(文件夹) -p 递归创建e.g. mkdir b/a =&gt;fail, mkdir不能创建多级目录mkdir -p b/a 同时创建 b 和 a rmdir: 删除空目录 rm: 删除目录及文件 -r强制删除目录 -f强制 一般用 rm -rf .. touch: 修改文件时间或者创建文件 chmod: 设置目录或文件的访问权限 chmod[选项][操作对象][操作符][权限][文件名] 操作符号 添加某个权限 -取消某个权限 =赋予给定权限并取消其他权限 数字设定法 chmod abc 文件名 其中 abc 各为一个数字, 分别表示 user, group, other 的权限 r为4, w为2, x为1, -为0(二进制位) rwx = 7; rw- = 6; r-x = 5 访问权限组(每一个文件或目录的访问权限都有三组)在 Linux 中是按照用户和组来设定权限的 所有者权限: 就是文件或者目录的创建者, 一般来说和 root 用户权限相当. 文件被创建时, 文件所有者自动拥有对该文件的读写和可执行权限. 同组权限: 就是所有者所在的用户组的其他成员的权限 其他用户权限 访问权限(读取, 写入, 执行) r: 读取文件内容的权限, 或者浏览目录的权限 w: 新增,修改文件内容的权限, 或者删除, 移动目录内文件的权限 x: 执行文件的权限, 或者进入目录的权限 用 -ll 也就是 -ls l显示文件或目录的详细信息, 最左的一列为文件的访问权限, 例如:-rw-r--r-- 1 root root 483997 Jul 15 18:31 sobsrc.tgz这里有10个位置, 第一个制定文件的类型, 通常意义上, 一个目录也是一个文件, 如果第一个字符是-, 表示是一个非目录文件, 如果是 d, 表示是一个目录 - rw- r– r– 非目录的文件 所有者权限 组用户 其他用户 普通文件 可读写 只读 只读 chown: 改变目录的所有者cp: 复制目录或文件 -r 复制目录 -p 连带文件属性复制 -d 若源文件是链接文件, 则复制链接属性 -a 相当于 -pdr cp[现象][原文件或目录][目标目录] mv: 剪切或改名(move) mv a ../a 将当前目录下的 a 复制剪切到上一级的 a 目录中 mv abc.txt de.txt 如果原文件和目标文件在同一目录下, 则为改名, 否则是剪切 文件内容命令diff: 比较两个文件的差异patch: 修补文件(给文件打补丁)cat: 输出文件内容more: 逐屏显示文件内容less: 逐页显示文件内容head: 显示文件开头若干行内容tail: 显示文件最后若干行内容od: 查看特殊格式的文件内容 常见目录/ 根目录/bin 存放必要的命令/boot 存放内核以及启动所需要的文件/dev 存放设备文件/etc 存放系统的配置文件/home 用户文件的主目录/lib 存放必要的运行库/mnt 存放临时的映射文件系统/proc 存放存储进程和系统信息/root 超级用户的主目录/sbin 存放系统管理程序/tmp 存放临时文件/usr 包含了一般不需要修改的应用程序, 命令程序文件, 程序库,手册等/usr/bin 系统命令(普通用户 home)/usr/sbin 系统命令(超级用户 root)/var 包含系统产生的经常变化的文件","link":"/2016/07/19/shell-e6-8c-87-e4-bb-a4/"},{"title":"<Script> 小知识","text":"&lt;script&gt; 按照出现顺序被执行 后加载的脚本可以依赖先加载的脚本, 但是先加载的脚本堵塞, 整个网页的加载会堵塞. 当一个脚本被执行时, 可以访问前面的 HTML 元素, 但不能访问后面的元素. 页面元素在他之前的所有脚本都加载完之前是不会执行渲染的. async 和 deferHTML5 添加了两个工具用于控制脚本的执行 async 表示”不用马上执行”. 定义一个页面需要的变量或函数在async中是不行的, 因为你没法知道什么时候async代码会执行 defer 表示”等待页面解析完成之后执行”, 大致等价于把脚本绑定到window.onload事件. 当这个代码被执行, DOM 中的一切元素都可以访问, 不同于async, 所有加了defer的脚本会按照他们出现在 HTML 中的顺序执行, 只是推迟到页面解析后按顺序执行. type 属性设定解释器若要修改 type 的默认属性(默认为 javascript), 可以通过一个标记实现:&amp;lt;meta http-equiv = &quot;Content-Script-Type&quot; content = &quot;text/vbscript&quot; integrity 属性integrity属性是子资源完整性新规范的一部分, 他允许你为脚本文件将包含的内容提供一个 hash, 这意味着可以防止在传输的时候内容丢失或被恶意修改. 就算使用了 SSL, 这个规范也是有意义的, 因为有时候你要加载的资源是你无法控制的站外资源.如果你选择使用他, 就要在&lt;script&gt;标记里添加一个 hash 类型以及 hash 值, 将他们以连字符分隔&amp;lt;script src=&quot;...&quot; integrity = &quot;hash-value&quot;&amp;gt;&amp;lt;/script&amp;gt; document.currentScriptIE 不支持的一个新东西叫 document.currentScript, 他指向当前正在执行的脚本, 如果你要从你嵌入的&lt;script&gt;中拿一些属性用 &lt;script&gt;和 innerHTML通过 DOM 动态添加到页面上的 &lt;script&gt; 会被浏览器执行 var myScript = document.createElement(&quot;script&quot;); myScript.textContent = &quot;alert(&apos;hello&apos;)&quot;; document.head.appendChild(myScript); 然而, 通过innerHTML动态添加到到 HTML 的 &lt;script&gt; 则不会被执行document.head.innerHTML += &quot;&amp;lt;script&amp;gt;alert('Hello')&amp;lt;/script&amp;gt;&quot;Note: 但是他会显示在 HTML 里(尽管不会执行)","link":"/2016/07/18/script-e5-b0-8f-e7-9f-a5-e8-af-86/"},{"title":"Simple CheetSheet of Flex","text":"FlexParent display: flex flex-direction: row | row-reverse | column | column-reverse flex-wrap: nowrap | wrap | wrap-reverse flex-flow: &lt;flex-direction&gt; || &lt;flex-wrap&gt; justify-content: flex-start | flex-end | center | space-between | space-around align-items: flex-start | flex-end | center | stretch | baseline (single row) align-content: flex-start | flex-end | center | stretch | space-between | space-around (multi-row) Children(flex-item) order: &lt;integer&gt; flex-grow: &lt;number&gt;(0 default) flex-shrink: &lt;number&gt;(0 default) flex-basis: &lt;length&gt; | auto (auto default) flex: none || &lt;flex-grow&gt;&lt;flex-shrink&gt;&lt;flex-basis&gt; align-self: auto | flex-start | flex-end | center | stretch | baseline notice: float, clear, vertical-align are unavailable in flex item","link":"/2016/12/07/simple-cheetsheet-of-flex/"},{"title":"Snippets of Nginx","text":"nginx.confOne server{} for a site service. Use location to specify router of requests. proxy_pass target to delegate inverse . root dir to specify static files directory. server_name to set domains whose requests will be handled. 123456789101112// a node server listening to 3000// handle requests from example.comserver { listen: 80; server_name: example.com; location / { index index.html; root: /public/; proxy_pass http://location:3000 }} Gzip12345gzip on;gzip_proxied any;gzip_min_length 1024;gzip_buffers 4 8k;gzip_types text/css application/javascript application/atom+xml application/rss+xml text/plain image/svg+xml application/json text/javascript; CORS123456789101112server { listen: 80; server_name: example.com; location / { add_header Access-Control-Allow-Origin: *; add_header Access-Control_Allow_Credentials true; add_header Access-Control-AllowMethods GET,POST,OPTIONS; index index.html; root: /public/ }} API delegate12345678server { listen: 80; server_name: example.com; location /api { proxy_pass: https://localhost:3000; }} HTTP to HTTPS12345678910111213141516171819server { listen: 80; server_name: example.com, *.example.com; location / { return 301 https://$host$request_uri; }}server { listen: 443 ssl; server_name example.com; ssl_certificate /crts/crt.pem; // add the certificate ssl_certificate_key /crts/key.pem location / { index index.html; root: /public/ }}","link":"/2017/09/03/snippets-of-Nginx/"},{"title":"Simple Usage of flatMap","text":"Original Both map() and flatMap() take a function f as a parameter that controls how an input Array is translated to an output Array: With map(), each input Array element is translated to exactly one output element, aka, f returns a single value With flatMap(), each input Array element is translated to zero or more output elements, aka, f returns an Array of values. An smiple implementation of flatMap: 123456789101112function flatMap (arr, mapFunc) { const result = [] for (const [index, value] of arr.entries()) { const x = mapFunc(value, index, arr) if (Array.isArray(x)) { result.push(...x) } else { result.push(x) } } return result} flatMap is simpler if mapFunc is only allowed to return Arrays, but we don’t impose this restriction here, because non-Array values are occasionally useful. Filtering and mapping at the same time1234567891011121314function processArray (arr, processFunc) { return arr.map(x =&gt; { try { return { value: processFunc(x) } } catch (e) { return { error: e } } })}const results = processArray(myArray, myFunc)const values = flatMap(results, result =&gt; result.value ? [result.value] : []) // here we use [result.value] to avoid destructing value if it is an array.const errors = flapMap(results, result =&gt; result.error ? result.error : []) Mapping to multiple valuesThe Array method map() maps each input Array element to one output. But if we want to map it to multiple output elements? That becomes necessary in the following example: The React component TagList is invoked with two attributes 1&lt;TagList tags={['foo', 'bar', 'baz']} handleClick={x =&gt; console.log(x)} /&gt; The attributes are: An Array of tags, each tag being a string A callback for handling clicks on tags TagList is rendered as a series of links seperated by commas: 1234567891011class TagList extends React.Component { render () { const { tags, handleClick } = this.props return flatMap(tags, (tag, index) =&gt; [ ...(index &gt; 0 ? [', '] : []), &lt;a key={index} href=\"\" onClick={e =&gt; handleClick(tag, e)}&gt; {tag} &lt;/a&gt; ]) }} Here each tag (except the first) provide two elements in the rendered Array Arbitrary IterablesflatMap can be generalized to work with arbitrary iterables 1234567function* flatMapIter(iterable, mapFunc) { let index = 0 for (const x of iterable) { yield* mapFunc(x, index) index++ }} flatMapIter function works with Arrays: 1234function fillArray () { return new Array(x).fill(x)}console.log([...flatMapIter([1,2,3], fillArray)]) Implementing flatMap via reduceYou can use the Array method reduce to implement a simple version of flatMap 123456function flatMap (arr, mapFunc) { return arr.reduce( (prev, x) =&gt; prev.concat(mapFunc(x)), [], )} Related to flatMap: flattenflatten is an operation that concatenates all the elements of an Array 12&gt; flatten(['a', ['b', 'c'], ['d']])['a', 'b', 'c', 'd'] It can be implemented as follows: 1const flatten = (arr) =&gt; [].concat(...arr) So the following expressions are equivalent 12flatten(arr.map(func))flatMap(arr, x =&gt; x)","link":"/2017/05/26/simple-usage-of-flatMap/"},{"title":"Simple Usage of Scp","text":"Original Basic Syntax of SCP1scp source_file_name username@destination_host:destination_folder Provider the detail information of SCP process using -v parameterBaisc SCP command without parameter will copy the files in background. User will see nothing unless the process is done or something error appears. You can use -v parameter to print debug information into screen. 12# verbosescp -v source_file_name username@destination_host:destination_folder Provider modification times, access times, and modes from original filesThe -p (lowercase) parameter will help you on this. An estimated time and the connection speed will apear on the screen. 12# processscp -p source_file_name username@destination_host:destination_folder Make file transfer faster using -C parameterOne of parameter that can faster your file transfer is -C parameter. The -C parameter will compress your file on the go. The unique thing is the compression is only happen in the network. When the file is arrived to the destination server, it will returning into the original size as before the compression happen. 12# Compressionscp -Cpv source_file_name username@destination_host:destination_folder Specify specific port to use with SCPUsually SCP is using port 22 as a default port. But for security reason, you may change the port into another port. Use -P (uppercase) to specify the port. `bash scp -P 2212 source_file_name username@destination_host:destination_folder","link":"/2017/05/17/simple-usage-of-scp/"},{"title":"Source Code of Koa-Static","text":"Source Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576'use strict'/** * Module Dependencies */const debug = require('debug')('koa-static')const { resolve } = require('path')const assert = require('assert')const send = require('koa-send')/** * Expose `serve()` */module.exports = serve/** * Serve static files from `root` * * @param {String} root * @param {Object} [opts] * @return {Function} * @api public */function serve (root, opts) { opts = opts || {} // ensure `root` assert(root, 'root directory is required to serve files') // options debug('static %s %j', root, opts) // set opts.root to absolute one opts.root = resolve(root) // set default static file if (opts.index !== false) opts.index = opts.index || 'index.html' // if defer is supported if (!opts.defer) { return async function serve (ctx, next) { let done = false if (ctx.method === 'HEAD' || ctx.method === 'GET') { try { done = await send(ctx, ctx.path, opts) } catch (err) { if (err.status !== 404) { throw err } } } if (!done) { await next() } } } retrun async function serve (ctx, next) { await next() if(ctx.method !== 'HEAD' &amp;&amp; ctx.method !== 'GET') return // response is already handled if (ctx.body != null || ctx.status !== 404) return try { await send(ctx, ctx.path, opts) } catch (err) { if (err.status !== 404) { throw err } } }} Usage123const Koa = require('koa')const app = new Koa()app.use(require('koa-static')(root, opts)) Options maxage: default to 0. hidden: Allow transfer of hidden files, detault to false. index: Default file name, detault to ‘index.html’. defer: If true, serves after return next(). gzip: default to true. extensions: default to false.","link":"/2017/09/30/source-code-of-koa-static/"},{"title":"Snippets of Koa Middlewares","text":"koa-compressCompress middleware for Koa Example123456789const compress = require('koa-compress')const Koa = require('koa')const app = new Koa()app.use(compress({ filter: (content_type) =&gt; /text/i.test(content_type), threshold: 2048, flush: require('zlib').Z_SYNC_FLUSH,})) OptionsThe options are passed to zlib filter: An optional function that checks the response content type to decide whether to compress. By default, it uses compressible threshold: Minimum response size in bytes to compress. Default 1024 byte or 1kb. koa-morganHTTP Request logger middleware for node.js 1const morgan = require('morgan') morgan(format, options)Create a new morgan logger middleware function using the given format and options. The format argument amay be a string of a predefined name, a string fo a format string, or a function that will produce a log entry. The format function will be called with three arguments tokens, req and res, where tokens is object with all tokens, req is the HTTP request and res is the HTTP response. The function is expected to return a string that will be the log line, or undefined/null to skip logging. predefined format string combined: Standard Apache combined log output 1:remote-addr - :remote-user [:date[clf]] \":method :url HTTP/:http-version\" :status :res[content-length] \":referrer\" \":user-agent\" common: Standard Apache common log output dev short tiny 1:method :url :status :res[content-length] - :response-time ms write logs to a fileSingle file Simple app that will log all request in the Apache combined format to the file access.log 1234567891011121314151617const fs = require('fs')const Koa = require('koa')const morgan = require('koa-morgan')const accessLogStream = fs.createWriteStream(__dirname + '/access.log', { flags: 'a' })const app = new Koa()// setup the loggerapp.use(morgan('combined', { stream: accessLogStream }))app.use((ctx) =&gt; { ctx.body = 'hello world'})app.listen(3000) koa-sessionSimple session middleware for koa. Default is cookie-based session and support external store. Require Node 7.6 or greater for asycn/await support 1234567891011121314151617181920212223242526const session = require('koa-session')const Koa = require('koa')const app = new Koa()app.keys = ['some secret hurr']const CONFIG = { key: 'koa:sess', // (string) cookie key, default is koa:sess maxAge: 86400000, // (number) in ms, default is 1 day, overWrite: true, // (boolean) can overwrite or not, default true httpOnly: true, // (boolean) httpOnly or not, default true signed: true, // (boolean) signed or not, default true rolling: false, // (boolean) Force a session identifier cookie to be set on every response. The expiration is reset to the original maxAge.}app.use(session(CONFIG, app)) // or if you prefer to default config, you can use =&gt; app.use(session(app))app.use(ctx =&gt; { if (ctx.path === '/favicon.ico') return let n = ctx.session.views || 0 ctx.session.views = ++n ctx.body = n + ' views'})app.listen(3000)console.log('listening on port 3000') OptionsThe cookie name is controlled by the key option, which default to ‘koa:sess’. All other options are passed to ctx.cookies.get() and ctx.cookies.set() allowing you to control security, domain, path and signing among other setting.","link":"/2017/06/29/snippets-of-koa-middlewares/"},{"title":"TypeScript With Node","text":"Configuring TypeScript CompilationTypeScript uses the file tsconfig.json to adjust project compile options 123456789101112131415\"compilerOptions\": { \"module\": \"commonjs\", \"target\": \"es6\", \"noImplicityAny\": true, \"moduleResolution\": \"node\", \"sourceMap\": true, \"outDir\": \"dist\", \"baseUrl\": \".\", \"paths\": { \"*\": [ \"node_modules/*\", \"src/types/*\" ] }} compilerOptions Description “module”: “commonjs” The output module type (in your .js files). Node uses commonjs “target”: “es6” The output language level. Node supports ES6 “noImplicityAny”: true Enables a stricter setting which throws errors when something has a default any value “moduleResolution”: “node” TypeScript attempts to mimic Node’s module resolution strategy “sourceMap”: true “ourDir”: “dist” Location to output .js files after compilation “baseUrl”: “.” Part of configuring module resolution “paths”: {…} Part of configuring module resolution The rest of the file define the TypeScript project context. The project context is basically a set of options that determine which files are compiled when the compiler is invoked with a specific tsconfig.json. 123\"include\": [ \"src/**/*\"] include takes an array of glob pattern of files to include in the compilation. Type Definition (.d.ts) FilesTypeScript uses .d.ts files to provide types for JavaScript libraries that were not written in TypeScript. This is great because once you have a .d.ts file, TypeScript can type check that library and provide you better help in your editor. The TypeScript community actively shares all the most up-to-date .d.ts files for popular libraries on a Github repository called DefinitelyTyped. Because the &quot;noImplicityAny&quot;: true, we are required to have a .d.ts file for every library used. You could set noImplicityAny to false to silence errors about missing .d.ts files. It’s a best practice to have a .d.ts file for every library(Even the .d.ts file is basically empty) Installing .d.ts files from DefinitelyTypedFor the most part, you’ll find d.ts files for the libraries you are using on DefinitelyTyped. These .d.ts files can be easily installed into your project by using npm scope @types. For example, if we want the .d.ts file for jQuery, we can do so with npm install --save-dev @types/jquery. Once .d.ts files have been installed using npm, you should see them in your node_modules/@types folder. The compiler will always look in this folder for .d.ts files when resolving JavaScript libraries. What if a library isn’t on DefinitelyTyped?Setting up TypeScript to look for .d.ts files in another folder The Compiler knows to look in node_modules/@types by default, but to help the compiler find our own .d.ts files we have to configure path mapping in our tsconfig.json. Path mapping can get pretty confusing, but the basic idea is that the TypeScript compiler will look in specific places, in a specific order when resolving modules, and we have the ability to tell the compiler exactly how to do it. In the tsconfig.json for this project you’ll see the following: 123456\"baseUrl\": \".\",\"paths\": { \"*\": [ \"src/types/*\" ]} This tells the TypeScript compiler that in addition to looking in node_module/@types for every import (*) also look in our own .d.ts file location &lt;baseUrl&gt; + src/types/* First the compiler will look for a .d.ts file in node_modules/@types and then src/types Summary of .d.ts managementIn general if you stick to the following steps you should have minimal .d.ts issues: After installing any npm package as a dependency or dev dependency, immediately try to install the .d.ts file via @types If the library has a .d.ts file on DefinitelyTyped, the install wil succeed and you are done, if the install fails because the package doesn’t exist, generate .d.ts by yourself Source MapIn the tsconfig.json 123\"compilerOptiosn\": { \"sourceMaps\": true} With this option enabled, next to every .js file that the TypeScript compiler outputs there will be a .map.js file as well. This .map.js file provides the information necessary to map back to the source .ts file while debugging. Using Debugger in VS CodeWhen debugging in VS Code, it looks for a top level .vscode folder with a launch.json file. In this file, you can tell VS Code exactly what you want to do: 1234567891011{ \"type\": \"node\", \"request\": \"launch\", \"name\": \"Debug\", \"program\": \"${workspaceRoot}/dist/server.js\", \"smartStep\": true, \"outFiles\": [ \"../dist/**/*.js\" ], \"protocal\": \"inspector\"} This is mostly identical to the “Node.js: Launch Program” template with a couple minor changes: launch.json Options Description “program”: “${workspaceRoot}/dist/server.js” Modified to point to our entry point in dist “smartStep”: true Won’t step into code that doesn’t have a source map “outFiles”: […] Specify where output files a dropped. Use with source map “protocal”: “inspector” Use the new Node Debug Protocal because we’re on the latest node","link":"/2017/05/30/start-in-typescript/"},{"title":"Start Up With Ts, React, Router, Redux, Rxjs","text":"The Repo Dependencies12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849\"devDependencies\": { \"@types/react\": \"^16.0.5\", \"@types/react-dom\": \"^15.5.4\", \"@types/react-redux\": \"^5.0.6\", \"@types/redux-actions\": \"^1.2.8\", \"@types/webpack\": \"^3.0.10\", \"@types/webpack-dev-server\": \"^2.4.1\", \"autoprefixer\": \"^7.1.3\", \"babel-core\": \"^6.26.0\", \"babel-loader\": \"^7.1.2\", \"babel-preset-env\": \"^1.6.0\", \"babel-preset-react\": \"^6.24.1\", \"bundle-loader\": \"^0.5.5\", \"eslint\": \"^4.6.1\", \"eslint-config-airbnb\": \"^15.1.0\", \"eslint-plugin-import\": \"^2.7.0\", \"eslint-plugin-jsx-a11y\": \"^6.0.2\", \"eslint-plugin-react\": \"^7.3.0\", \"html-webpack-plugin\": \"^2.30.1\", \"node-sass\": \"^4.5.3\", \"precss\": \"^2.0.0\", \"redux-devtools\": \"^3.4.0\", \"redux-devtools-dock-monitor\": \"^1.1.2\", \"redux-devtools-log-monitor\": \"^1.3.0\", \"rimraf\": \"^2.6.1\", \"sass-loader\": \"^6.0.6\", \"ts-loader\": \"^2.3.4\", \"typescript\": \"next\", \"uglifyjs-webpack-plugin\": \"^0.4.6\", \"webpack\": \"^3.5.5\", \"webpack-dashboard\": \"^1.0.0-5\", \"webpack-dev-server\": \"^2.7.1\", \"webpack-merge\": \"^4.1.0\"},\"dependencies\": { \"@types/node\": \"^8.0.26\", \"@types/react-router-dom\": \"^4.0.7\", \"babel-plugin-transform-runtime\": \"^6.23.0\", \"extract-text-webpack-plugin\": \"^3.0.0\", \"react\": \"^15.6.1\", \"react-dom\": \"^15.6.1\", \"react-redux\": \"^5.0.6\", \"react-router\": \"^4.2.0\", \"react-router-dom\": \"^4.2.2\", \"redux\": \"^3.7.2\", \"redux-actions\": \"^2.2.1\", \"redux-observable\": \"^0.16.0\", \"rxjs\": \"^5.4.3\"} Project Structure123456789101112131415161718192021222324252627282930313233343536373839404142.├── config│ ├── webpack.config.base.js│ ├── webpack.config.dev.js│ ├── webpack.config.prod.js├── src│ ├── actions│ │ ├── index.tsx│ │ ├── hello.tsx│ ├── components│ │ ├── AsyncRoute.tsx│ ├── containers│ │ ├── App.tsx│ │ ├── Header.tsx│ │ ├── Body.jsx│ │ ├── Footer.tsx│ │ ├── Index.tsx│ │ ├── Page2.tsx│ │ ├── DevTools.tsx│ ├── epics│ │ ├── index.tsx│ │ ├── hello.tsx│ ├── reducers│ │ ├── index.tsx│ │ ├── hello.tsx│ ├── store│ │ ├── index.tsx│ │ ├── configureStore.dev.tsx│ │ ├── configureStore.prod.tsx│ ├── templates│ │ ├── index.html│ ├── utils│ │ ├── connect.tsx│ │ ├── nav.tsx│ ├── app.tsx├── package.json├── tsconfig.json├── postcss.config.js├── .babelrc├── .eslintrc.js├── .gitignore├── yarn.lock Step 1: Create Project12# init projectyarn init -y 1234# add eslintyarn add --dev eslint eslint-config-airbnb eslint-plugin-import eslint-plugin-jsx-a11y eslint-plugin-reacteslint --init 12# add webpackyarn add --dev webpack webpack-dev-server webpack-dashboard webpack-merge @types/webpack @types/webpack-dev-server 1234567891011121314151617181920212223242526# add loader for jsxyarn add --dev babel-core babel-loader babel-preset-env babel-preset-react# add loader for tsxyarn add --dev ts-loader typescript@next# add loader for cssyarn add --dev style-loader css-loader resolve-url-loader postcss-loader node-sass sass-loader# add loader for fileyarn add --dev url-loader file-loader# add plugin for jsyarn add babel-plugin-transform-runtime# add plugin for postcssyarn add --dev autoprefixer precss# add plugin for htmlyarn add --dev html-webpack-plugin# add plugin for uglifyjsyarn add --dev uglifyjs-webpack-plugin# add plugin for extract cssyarn add --dev extract-text-webpack-plugin set gitignore12345678# Logs*.log# dependenciesnode_modules# builddist set typescript config123456789101112131415161718192021222324252627{ \"compilerOptions\": { \"outDir\": \"dist\", \"module\": \"commonjs\", \"target\": \"es5\", \"lib\": [\"es6\", \"dom\"], \"sourceMap\": true, \"allowJs\": true, \"jsx\": \"react\", \"moduleResolution\": \"node\", \"rootDir\": \"src\", \"noImplicitReturns\": true, \"noImplicitThis\": false, \"noImplicitAny\": false, \"strictNullChecks\": true }, \"exclude\": [ \"config\", \"node_modules\", \"dist\", \"webpack\", \"jest\" ], \"types\": [ \"typePatches\" ]} Set basic webpack config123456789101112131415161718192021222324252627282930313233// /config/webpack.config.base.jsconst path = require('path')module.exports = { output: { path: path.resolve(__dirname, '../dist'), filename: 'scripts/[name]-[hash].js', chunkFilename: 'scripts/[name]-[chunkhash].js', }, module: { rules: [ { test: /\\.tsx?$/, loader: 'ts-loader', exclude: /node_modules/ }, { test: /\\.jsx?$/, loader: 'babel-laoder', exclude: /node_modules/, }, { test: /\\.(png|jpg)$/, loader: 'url-loader', options: { limit: 8192, name: '[name]-[hash].[ext]', } } ] }, resolve: { extensions: ['.tsx', '.ts', '.jsx', '.js', '.scss', '.css', '.json'] }} Set dev webpack config12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// /config/webpack.config.dev.jsconst path = require('path')const webpack = require('webpack')const merge = require('webpack-merge')const HtmlPlugin = require('html-webpack-plugin')const DashboardPlugin = require('webpack-dashboard/plugin')const baseConfig = require('./webpack.config.base')const devConfig = { entry: { app: [ 'webpack/hot/only-dev-server', 'webpack-dev-server/client?http://localhost:8080', path.resolve(__dirname, '../src/app.tsx'), ], }, module: { rules: [ { test: /\\.scss$/, use: [ 'style-loader', { loader: 'css-loader', options: { modules: true, name: '[local]-[name]-[hash]' }, }, ], 'resolve-url-loader', 'sass-loader', }, ], }, devtool: 'source-map', plugins: [ new webpack.HotModuleReplacementPlugin(), new webpack.NamedModulesPlugin(), new webpack.DefinePluing({ 'process.env': { NODE_ENV: 'development', }, }), new DashboardPlugin(), new HtmlPlugin({ title: '开发', template: path.resolve(__dirname, '../src/temlates/index.html'), }), ], devServer: { hot: true, compress: true, historyApiFallback: true, }}module.exports = merge(baseConfig, devConfig) Set prod webpack config1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// /config/webpack.config.prod.jsconst path = require('path')const webpack = require('webpack')const merge = require('webpack-merge')const ExtractTextPlugin = require('extract-text-webpack-plugin')const UglifyJSPlugin = require('uglifyjs-webpack-plugin')const HtmlPlugin = require('html-webpack-plugin')const baseConfig = require('./webpack.config.base.js')const prodConfig = { entry: { app: path.resolve(__dirname, '../src/app.tsx'), }, module: { rules: [ test: /\\.scss$/, use: ExtractTextPlugin.extract({ fallback: 'style-loader', use: [ { loader: 'css-loader', options: { modules: true, name: '[local]-[name]-[hash]', importLoaders: 3, }, }, ], exclude: /node_modules/, }), { loader: 'postcss-loader', options: { config: path.resolve(__dirname, './config/postcss.config.json') } }, 'resolve-url-loader', 'sass-loader', ], }, devtool: 'inline-source-map', plugins: [ new webpack.DefinePluing({ 'process.env.NODE_ENV': 'production', }), new webpack.optimize.CommonsChunkPlugin({ name: 'app', filename: 'scripts/vendor-[hash].min.js', }), new HtmlPlugin({ title: '生产', template: path.resolve(__dirnaem, '../src/templates/index.html'), minify: { collapseBooleanAttributes: true, collapseInlineTagWhitespace: true, collapseWhitespace: true, minifyCSS: true, minifyJS: true, removeAttributeQuotes: true, removeComments: true, removeEmptyAttributes: true, removeRedundantAttributes: true, removeTagWhitespace: true, }, }), new ExtractTextPlugin({ filename: 'styles/[name]-[contenthash].css', }), new UglifyJSPlugin(), ],} Set config refered by webpack(babelrc, postcss, index.html)12345678910111213141516171819// /.babelrc{ \"presets\": [ [ \"env\", { \"targets\": { \"browsers\": [\"last 2 versions\", \"safari &gt;= 9\"], } } ], \"react\", ], \"plugins\": [ [\"transform-runtime\", { \"polyfill\": false, \"regenerator\": true }], ]} 123456789const precss = require('precss')const autoprefixer = require('autoprefixer')module.exports = { plugins: [ precss, autoprefixer, ],} 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt; &lt;title&gt;&lt;%= htmlWebpackPlugin.options.title %&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Step 2: Skeleton of React App(React + Router)123yarn add --dev bundle-laoder @types/react @types/react-dom @types/node @types/react-router-domyarn add react react-dom react-router-dom In src/app.tsx render the App to html 1234567891011121314151617import * as React from 'react'import { render } from 'react-dom'import App from './containers/App'render( &lt;App /&gt;, document.getElementById('app') as HTMLElement)if (module.hot) { module.hot.accept('./containers/App', () =&gt; { const App = require('./containers/App').default render ( &lt;App /&gt;, document.getElementById('app') ) })} Create App Represental Component123456789101112131415161718192021222324252627// `./src/containers/App.tsx`import * as React from 'react'import { BrowserRouter as Router, Route,} from 'react-router-dom'import Header from './Header'import Body from './Body'import Footer from './Footer'export default class extends React.Component { constructor () { super () } render () { return ( &lt;Router&gt; &lt;div&gt; &lt;Route path=\"/\" component={Header} /&gt; &lt;Route path=\"/\" component={Body} /&gt; &lt;Route path=\"/\" component={Footer} /&gt; &lt;/div&gt; &lt;/Router&gt; ) }} Create Header, Body, Footer Containers123456789101112131415161718192021222324252627282930313233// ./src/containers/Header.tsximport * as React from 'react'import { goTo } from '..utils/nav'class Header extends React.Component { protected goTo = goTo.bind(this) constructor () { super() this.state = { navs: [ { label: '首页', url: 'index' }, { label: '第二页', url: 'page2' }, { label: '第三页', url: 'page3' }, ] } } render () { const { navs } = this.state return ( &lt;div&gt; { navs.map( (nav: {label: string, url: string}) =&gt; &lt;span key={nav.url} onClick={this.goTo(nav.url)}&gt;{nav.label}&lt;/span&gt; ) } &lt;/div&gt; ) }}export default Header 1234567// ./src/utils/nav.tsxexport function goTo(url: string) { retrn () =&gt; { this.props.history.push(url) }} Same structure in Body and Footer. Add AsyncRoute12345678910111213141516171819202122232425262728293031323334353637383940import * as React from 'react'interface PassedProps extends React.Props&lt;any&gt; { load: any; children: any;}class Bundle extends React.Component&lt;PassedProps, any&gt; { constructor () { super() this.state = { mod: null, } } componentWillMount () { this.load(this.props) } componentWillReceiveProps (nextProps) { if (nextProps.load !== this.props.load) { this.load(nextProps) } } load (props) { this.setState({ mod: null, }) props.load((mod) =&gt; { this.setState({ mod: mod.default || mod, }) }) } render () { return this.state.mod ? this.props.children(this.state.mod) : null }}export default module =&gt; routerProps =&gt; (&lt;Bundle load={module}&gt; { Comp =&gt; Comp ? &lt;Comp {...routerProps} /&gt; : null}) And use it in body container 1234567891011import * as React from 'react'import { Route } from 'react-router'import Index from 'bundle-loader?lazy!./Index'import AsyncRoute from '../components/AsyncRoute'export default () =&gt; ( &lt;div&gt; &lt;Route path=\"/index\" component={AsyncRoute(Index)} &lt;/div&gt;) Add Redux123yarn add --dev redux-devtools redux-devtools-dock-monitor redux-devtools-log-monitoryarn add redux redux-actions react-redux Create Actions1234567891011// ./src/actions/hello.tsximport { createActions } from 'redux-actions'export default createActions({ SAY_HELLO: text =&gt; ({ text })})// export// {// sayHello: (text: string) =&gt; ({ text: string })// } 12345// ./src/actions/index.tsximport helloActions from './hello'export default { ...helloActions} Create Reducers1234567891011// ./src/reducers/hello.tsximport { handleActions } from 'redux-actions'import actions from '../actions'export default handleActions({ [actions.sayHello.toString()]: (state, action) =&gt; { return { ...state, ...action.payload } },}, { text: '',}) 1234567// ./src/reducers/index.tsximport { combineReducers } from 'redux'import helloReducer from './hello'export default combineReducers({ hello: helloReducer,}) Create Store12345678910111213141516171819202122// ./src/store/configureStore.dev.tsximport { createStore, applyMiddleware, compose, GenericStoreEnhancer } from 'redux'import reducer from '../reducers'const enhancer = compose( // applyMiddleware(...middlewares) window.devToolsExtension ? window.devToolsExtension() : f =&gt; f,)function configureStoreDev(initState: any): any { const store = createStore(reducer, initState, enhancer) if (module.hot) { module.hot.accpet('../reducers', () =&gt; { store.replaceReducer(require('../reducers').default) }) } return store}module.exports = configureStoreDev 12345678910// ./src/store/configureStoreProdimport { createStore, applyMiddleware } from 'redux'import reducer from '../reducers'function configureStoreProd (initState: any) { return createStore(reducer, initState)}module.exports = configureStoreProd 1234567// ./src/store/index.jsxif (process.env.NODE_ENV == 'development') { module.exports = require('./configureStore.dev')} else { module.exports = require('./configureStore.prod')} Add Provider to Main Container12345678910111213141516171819202122232425262728293031// ./container/App.tsximport * as React from 'react'import { BrowserRouter as Router, Route,} from 'react-router-dom'import { Provider } from 'react-redux'import Header from './Header'import Body from './Body'import Footer from './Footer'const configureStore = require('../store')const store = configureStore({})export default class extends React.Component { constructor () { super() } render () { returun ( &lt;Router&gt; &lt;Provider store={store}&gt; &lt;Route path=\"/\" component={Header} /&gt; &lt;Route path=\"/\" component={Body} /&gt; &lt;Route path=\"/\" component={Body} /&gt; &lt;/Provider&gt; &lt;/Router&gt; ) }} custom connect to cache mapStateToProps and mapDispatchToProps12345678import { connect } from 'react-redux'import { bindActionCreators } from 'redux'import actions from '../actions'const mapStateToProps = (state: any) =&gt; stateconst mapDispatchToProps = (dispatch: any) =&gt; (bindActionCreators(actions, dispatch))export default (Comp: any) =&gt; connect(mapStateToProps, mapDispatchToProps)(Comp) Connect the Presentational Container12345678910111213141516171819202122232425262728293031323334353637import * as React from 'react'import connect from '../utils/connect'import { goTo } from '../utils/nav'interface PassedProps extends React.Props&lt;any&gt; { sayHello: any;}class Header extends React.Component&lt;PassedProps, any&gt; { protected goTo = goTo.bind(this) constructor () { super() this.state = { navs: [ { label: '首页', url: 'index' }, { label: '第二页', url: 'page2' }, { label: '第三页', url: 'page3' }, ] } } componentDidMount () { this.props.sayHello('world') } render () { const { navs } = this.state return ( &lt;div&gt; {navs.map((nav: { label: string, url: string}) =&gt; &lt;span key={nav.url} onClick={this.goTo(nav.url)} &gt;{nav.label}&lt;/span&gt;)} &lt;/div&gt; ) }}export default connect(Header) Add Rxjs1yarn add rxjs redux-observable Create Epics1234567891011// ./src/epics/hello.tsximport 'rxjs'export const sayHello = (action$, store) =&gt; .action$.ofType('SAY_HELLO') .delay(1000) .map(() =&gt; ({ type: 'SAY_HELLO', payload: { text: 'got hello' } })) 12345678// ./src/epcis/index.tsximport { combineEpics } from 'redux-observable'import { sayHello } from './hello'export default combineEpics( sayHello,) Add Epic to Enhancer1234567891011121314151617181920212223import { createStore, applyMiddleware, compose, GenericStoreEnhancer } from 'redux'import { createEpicMiddleware } from 'redux-observable'import reducer from '../reducers'import epics from '../epics'const epicMiddleware = createEpicMiddleware(epics)const enhancer = compose( applyMiddleware(epicMiddleware), window.devToolsExtension ? window.devToolsExtension() : f =&gt; f)function configureStoreDev (initState: any) { const store = createStore(reducer, initState, enhancer) if (module.hot) { module.hot.accept('../reducers', () =&gt; { store.replaceReducer(require('../reducers').default) }) } return store}module.exports = configureStoreDev Add Service Worker1yarn add sw-precache-webpack-plugin Add the Plugin in webpack.config.prod.js1234const SWPrecachePluing = require('sw-precache-webpack-plugin')plugins: [ new SWPrecachePluing()] Add Bundle Analyzer1yarn add --dev webpack-bundle-anaylzer Add the Plugin in webpack.config.dev.js12345const BundleAnalyzer = require('webpack-bundle-analyzer').BundleAnalyzerPluginplugins: [ new BundleAnalyzer()] Add DllAdd webpack.config.dll.js12345678910111213141516171819202122// webpack.config.dll.jsconst path = require('path')const webpack = require('webpack')const ManifestPlugin = require('webpack-manifest-plugin')module.exports = { entry: { vendor: [/* ... */], }, output: { path: path.resolve(__dirname, '../lib'), filename: '[name]_[hash:5].js', library: '[name]_[hash:5]', }, plugins: [ new webpack.DllPlugin({ name: '[name]_[hash:5]', path: path.resolve(__dirname, '../lib', '[name]-manifest.json'), }), new ManifestPlugin(), ],} Copy dll to dist and refer12345678910// webpack.config.base.jsconst vendorManifest = require('../lib/vendor-manifest.json')plugins: [ new CopyPlugin([ { from: path.resolve(__dirname, '../lib/*.js') }, ]), new webpack.DllReference({ manifest: vendorManifest, }),] Insert Dll files in html12345678910111213// webpack.config.dev.jsconst fs = require('fs')const manifest = JSON.parse(fs.readFileSync(path.resolve(__dirname, '../lib/manifest.json')))module.exports = { // ... plugins: [ new HtmlPlugin({ // ... dll: `./lib/${manifest['vendor.js']}`, }), ],}","link":"/2017/09/05/start-up-with-ts-react-router-redux-rxjs/"},{"title":"Stacking Context 成因及特性","text":"会形成Stacking Context 的元素 root 元素( html ) position 不是 static 且 z-index 不是 auto 的元素 flex item 且 z-index 不是 auto 的元素 opacity 小于 1 的元素 transform 不是 none 的元素 mix-blend-mode 不是 normal 的元素 filter 不是 none 的元素 isolation 为 isolate 的元素 mobile webkit 和 chrome 22+ 上的 fixed 元素 在 will-change 属性上指定值为上述任意属性的元素 指定 -webkit-overflow-scrolling 为 touch 的元素 Stacking Context 的特性 stacking context 可以嵌套 每个 Stacking context 相对于兄弟元素都是完全独立的, 其内部规则不会影响到外部 每个 stacking context 元素都会被父级 stacking context 视为一个 stacking 规则 为已经定位的元素( absolute 或 relative) 指定 z-index 可以改变其 parent stacking context 中 z 的偏移量 一个值得注意的坑: 如果一个元素不是通过absolute 或 relative 实现 stacking context, 那么他的 z-index 为 0 , 仅高于 auto, 且无法改变.","link":"/2017/01/18/stacking-context-e6-88-90-e5-9b-a0-e5-8f-8a-e7-89-b9-e6-80-a7/"},{"title":"Tag Picture in Html","text":"The picture element is a markup pattern that allows developers to declare multiple sources for an image. This markup is a container used to specify multiple &lt;source&gt; elements for a specific &lt;img&gt; contained in it. 1234567&lt;picture&gt; &lt;source media=\"(min-width: 40em)\" srcset=\"big.jpg 1x, big-hd.jgp 2x\"&gt; &lt;source srcset=\"small.jpg 1x, small-hd.jpg 2x\"&gt; &lt;img src=\"fallback.jpg\"&gt;&lt;/picture&gt; Use the media attributeThe media attribute lets you specify a media query that the user agent will evaluates to select a &lt;source&gt; element. If the media query evaluates to false, the &lt;source&gt; element is skipped. 1234&lt;picture&gt; &lt;source srcset=\"logo-wide.jpg\" media=\"(min-width: 600px)\"&gt; &lt;img src=\"logo-narrow.jpg\"&gt;&lt;/picture&gt; The srcset and sizes attributes extend the img and source elements to provide a list of available image sources and their sizes. Browsers can then use this information to pick the best image source. 1234567&lt;img srcset=\"elva-fairy-320w.jpg 320w, elva-fairy-480w.jpg 480w, elva-fairy-800w.jpg 800w\" sizes=\"(max-width: 320px) 280px, (max-width: 480px) 440px, 800px\" src=\"elva-fairy-800w.jpg\" alt=\"Elva dressed as a fairy\"&gt; srcset defines the set of images we will allow the browser to choose between, and what size each image is. Before each comma, we write: An Image filename (elva-fair-320w.jpg) A space The image’s inherit width in pixels(480w) – note that this issue the w unit, not px as you might expect. sizes defines a set of media conditions(e.g. screen widths) and indicates what image size would be best to choose, when certain media conditions are true. Before each comma, we write: A media condition(max-width: 480px) – when the viewport width is 480 px or less A space The width of the slot the image will fill when the media condition is true(440px) Resolution switching1234567&lt;img srcset=\"elva-fairy-320w,jpg, elva-fairy-480w.jpg 1.5x, elva-fairy-640w.jpg 2x\" src=\"elva-fairy-640w.jpg\" alt=\"elva-fairy\"&gt;","link":"/2017/09/15/tag-picture-in-html/"},{"title":"Text Gradient","text":".background{ background:#04161f; font-family:”Lato”, sans-serif; margin:3em auto; max-width:50em;}.grad1{ display:inline-block; font-size: 96px; margin:0; opacity:0.9; background:#fff; color:black; position:relative; text-shadow:1px 1px 0px #04161f, 1px 1px 0px #04161f, -1px -1px 0px #04161f;}.grad1:before, .grad1:after{ position:absolute; top:0; right:0; bottom:0; left:0; pointer-events:none;}.grad1:before{ background: -webkit-linear-gradient(left, #23966c, #faaa54, #e23b4a, #db0768, #350670); content:””; display:block; mix-blend-mode:screen;}.grad1:after{ content:”CSS Gradient”; background:#04161f; color:#fff; mix-blend-mode:multiply;}.grad2{ font-size:72px; background:-webkit-linear-gradient(left, #23966c, #faaa54, #e23b4a, #db0768, #350670); -webkit-background-clip:text; -webkit-text-fill-color:transparent;} Mix-Blend-Mode CSS Gradient body{ background:#04161f; font-family:”Lato”, sans-serif; margin:3em auto; max-width:50em;}.grad1{ display:inline-block; font-size: 96px; margin:0; opacity:0.9; background:#fff; color:black; position:relative; text-shadow:1px 1px 0px #04161f, 1px 1px 0px #04161f, -1px -1px 0px #04161f;}.grad1:before, .grad1:after{ position:absolute; top:0; right:0; bottom:0; left:0; pointer-events:none;}.grad1:before{ background: -webkit-linear-gradient(left, #23966c, #faaa54, #e23b4a, #db0768, #350670); content:””; display:block; mix-blend-mode:screen;}.grad1:after{ content:”CSS Gradient”; background:#04161f; color:#fff; mix-blend-mode:multiply;}` -webkit-background-clip + -webkit-text-fill-modeCSS Gradient`.grad2{ font-size:72px; background:-webkit-linear-gradient(left, #23966c, #faaa54, #e23b4a, #db0768, #350670); -webkit-background-clip:text; -webkit-text-fill-color:transparent;}","link":"/2016/06/16/text-gradient/"},{"title":"Throttle 函数","text":"function throttle (fn, threshold, scope) { threshold || threshold = 250 var last, timer return function () { var ctx = scope || this var now = +new Date() var args = arguments if (last &amp;amp;&amp;amp; now - last - threshold &amp;lt; 0) { // hold on it clearTimeout(timer) timer = setTimeout(function () { last = now fn.apply(ctx, args) }, threshold) } else { last = now fn.apply(ctx, args) } } } `&lt;/pre&gt; &lt;pre&gt;`Elm.addEventListener(&apos;click&apos;, throttle(function(event){ // ... }, 1000)) 假设第一次执行 throttle(fn0), fn0会立即执行, 并记录 throttle 开启的时间last 第二次执行, 假设为 throttle(fn1), 如果距离 now 未超出时限 threshold, 则开启定时器, threshold 后执行 fn1, 并设置 last 如果在开启定时器后, threshold 时限内执行 throttle(fn2) 则用于执行 fn1 的定时器会被清空, 开启 fn2 的定时器, 并设置 last 简而言之, 执行 throttle 的时候, 如果上一次的定时器未被执行, 则会被清除, 并重新开始计时","link":"/2017/02/22/throttle-e5-87-bd-e6-95-b0/"},{"title":"Usage of Nock","text":"Installnpm install ncck `&lt;/pre&gt; ### Use Setup Mocking Obejct like this: &lt;pre&gt;`var nock = require(&apos;nock&apos;) var couchdb = nock(&apos;http://myapp.iriscouch.com&apos;) .get(&apos;/user/1&apos;) .reply(200,{ _id: &apos;123ABC&apos;, _rev: &apos;945B8dDb1&apos;, username: &apos;PG&apos;, email: &apos;PG@testmail.com&apos; }); `&lt;/pre&gt; This setup says that we will intercept every HTTP call to `http://myapp.iriscouch.com` It will intercept an HTTP GET request to `&apos;users/1&apos;` and reply with a status 200 and the body will contain a user representation in JSON Then the test can call the module, and the module will do the HTTP requests. #### Specifying hostname The request hostname can be a string or a RegExp &lt;pre&gt;`var scope = nock(&apos;http://www.example.com&apos;) .get(&apos;/resource&apos;) .reply(200, &apos;domain matched&apos;); var scope = nock(/example\\.com/) .get(&apos;/resource&apos;) .reply(200, &apos;domain regex matched&apos;); `&lt;/pre&gt; #### Specifying path The request path can be a string, a RegExp or a filter function and you can use any HTTP verb &lt;pre&gt;`var scope = nock(&apos;http://www.example.com&apos;) .get(&apos;/resource&apos;) .replay(200, &apos;path matched&apos;); var scope = nock(&apos;http://www.example.com&apos;) .get(/resource$/) .reply(200, &apos;path using regex matched&apos;); var scope = nock(&apos;http://www.example.com&apos;) .get(function(uri){ return uri.indexOf(&apos;cats&apos;) &amp;gt;= 0; }) .reply(200, &apos;path using function matched&apos;); `&lt;/pre&gt; #### Specifying Request Body argument to the `get`, `post`, `put` or `delete` specifications like this: &lt;pre&gt;`var scope = nock(&apos;http://www.example.com&apos;) .post(&apos;/users&apos;, { username: &apos;PG&apos;, email: &apos;example@mail.com&apos; }) .reply(201, { ok: true, id: &apos;123ABC&apos;, rev: &apos;946B7D1C&apos; }); `&lt;/pre&gt; The request body can be a string, a regexp, a jSON object or a function &lt;pre&gt;`var scope = nock(&apos;http://www.example.com&apos;) .post(&apos;/users&apos;, /email=.?@gmail.com/gi) .reply(201, { ok: true, id: &apos;123ABC&apos;, rev: &apos;946B7D1C&apos; }); var scope = nock(&apos;http://www.example.com&apos;) .post(&apos;/users&apos;, { username: &apos;PG&apos;, password: &apos;/a.+&apos;/, email: &apos;preasfd@gmail.com&apos; }) .reply(201, { ok: true, id: &apos;123ABC&apos;, rev: &apos;946B7D1C&apos; }) `&lt;/pre&gt; #### Specifying Replies You can specify the return status code for a path on the first argument of reply like this: &lt;pre&gt;`.reply(404) `&lt;/pre&gt; Or specify the reply body as a string: &lt;pre&gt;`.reply(200, &apos;Hello from google&apos;) `&lt;/pre&gt; or as a JSON-encoded object: &lt;pre&gt;`.reply(200, { username: &apos;PG&apos;, email: &apos;asdf@gmail.com&apos;, _id: &apos;awefrf&apos; }) `&lt;/pre&gt; or even as a file: &lt;pre&gt;`.replyWithFile(200, __dirname+&apos;/replies/user.json&apos;) `&lt;/pre&gt; An asynchronous function that gets an error-first callback as last argument also works: &lt;pre&gt;`.reply(201, function(uri, requestBody, cb){ fs.readFile(&apos;cat-poem.txt&apos;, cb); // Error-first callback });","link":"/2016/08/29/usage-of-nock/"},{"title":"Usage of Redux-Action","text":"UsagecreateAction(type, payloadCreator = Identity, ?metaCreator) import { createAction } from &apos;redux-action&apos; `&lt;/pre&gt; Wraps an action creator so that its return value is the payload of a Flux Standard Action. If no payload creator is passed, or if it&apos;s not a function, the identity function is used. ### Example &lt;pre&gt;`let increment = createAction(&apos;INCREMENT&apos;, amount =&amp;gt; amount); // same as increment = createAction(&apos;INCREMENT&apos;); expect(increment(42)).to.deep.equal({ type:&apos;INCREMENT&apos;, payload: 42, }); `&lt;/pre&gt; If the payload is an instance of an Error Object, redux-actions will automatically set `action.error` to true. ### Example &lt;pre&gt;`const increment = createAction(&apos;INCREMENT&apos;); const error = new TypeError(&apos;not a number&apos;); expect(increment(error)).to.deep.equal({ type: &apos;INCREMENT&apos;, payload: error, error: true, }) `&lt;/pre&gt; `createAction` also return its `type` when used as type in `handleAction` or `handleActions` ### Example &lt;pre&gt;`const increment = createAction(&apos;INCREMENT&apos;) // as parameter in handleAction: handleAction(increment, { next(state, action){...}, throw(state, action) {...}, }); const reducer = handleActions({ [increment]: (state, action) =&amp;gt; ({ counter: state.counter + action.payload }) }) `&lt;/pre&gt; ### createActions(?actionsMap, ?...identityActions) &lt;pre&gt;`import { createActions } from from &apos;redux-actions&apos; `&lt;/pre&gt; Returns an object mapping action types to action creator. The keys of this object are camel-cased from the keys in `actionsMap` and the string literals of `identityActions` the values are the action creators. ### combineActions(...actionTypes) Combine any number of action types or action creators, `actionTypes` is a list of positional arguments which can be action type strings, symbols, or action creators. This allows you to reduce multiple distinct actions with the same reducers. &lt;pre&gt;`const { increment, decrement } = createActions({ INCREMENT: amount =&amp;gt; ({amount}), DECREMENT: amount =&amp;gt; ({amount: -amount}), }) const reducer = handleAction(combineActions(increment, decrement), { next: (state, { payload: { amount }}) =&amp;gt; ({ ...state, counter: state.counter + amount}), throw: state =&amp;gt; ({ ...state, counter: 0}), }, { counter: 10 }) expect(reducer(undefined, increment(1)).to.deep.equal({ counter: 11 })) expect(reducer(undefined, decrement(1)).to.deep.equal({ counter: 9 })) expect(reducer(undefined, increment(new Error)).to.deep.equal({ counter: 0 })) expect(reducer(undefined, decrement(new Error)).to.deep.equal({ counter: 0 }))","link":"/2016/11/06/usage-of-redux-action-2/"},{"title":"Updating With React.render","text":"What does React.render do First, validate the inputs If there was no previous component, render as a new component Otherwise, compare the next component to the previous component using “shouldCUpdateComponent” If “shouldUpdateComponent” is true, update the component using ReactComponent.updateComponent. Otherwise, unmount and continue to render as a new component React.render gives you a declarative way to use React’s update flow at the top level, similar to how re-rendering works inside a component. Many times, however, you can create a wrapper component so that you only have a single React.render call. This allows you to keep the logic inside components, which may be cleaner.","link":"/2016/07/20/updating-with-react-render/"},{"title":"Utils in Axios","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// global toStringvar toString = Object.prototype.toString// isArrayfunction isArray (val) { return toString.call(val) === '[object Array]'}// isArrayBufferfunction isArrayBuffer (val) { return toString.call(val) === '[object arrayBuffer]'}// isFormDatafunction isFormData (val) { return (typeof FormData !== 'undefined' &amp;&amp; (val instanceof FormData))}// isStringfunction isString (val) { return typeof val === 'string'}// isNumberfunction isNumber (val) { return typeof val === 'number'}// isUndefindedfunction isUndefined (val) { return typeof val === 'undefined'}// isObjectfunction isObject (val) { return val !== null &amp;&amp; typeof val === 'object'}// isDatefunction isDate (val) { return toString.call(val) === '[object Date]'}// isFilefunction isFile (val) { return toString.call(val) === '[object File]'}// isBlobfunction isBlob (val) { return toString.call(val) === '[object Blob]'}// isFunctionfunction isFunction (val) { return toString.call(val) === '[object Function]'}// isStreamfunction isStream (val) { return isObject(val) &amp;&amp; isFunction(val.pipe)}// isURLSearchParamsfunction isURLSearchParams (val) { return typeof URLSearchParams !== 'undefined' &amp;&amp; val instanceof URLSearchParams}// trimfunction trim (val) { return str.replace(/^\\s*/, '').replace(/\\s*$/, '')}// isStandardBrowserEnvfunction isStandardBrowserEnv () { if (typeof navigator !== 'undefined' &amp;&amp; navigator.product === 'ReactNative') { return false } return { typeof window !== 'undefined' &amp;&amp; typeof document !== 'undefined' }}/** * Iterate over an Array or an Object invoking a function for each item */function forEach (obj, fn) { if (obj === null || typeof obj === 'undefined') { return } if (typeof obj !== 'object' &amp;&amp; !isArray(obj)) { obj = [obj] } if (isArray(obj)) { for (let i = 0, l = obj.length; i &lt; l; i++) { fn.call(null, obj[i], i, obj) } } else { for (let key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { fn.call(null, obj[key], key, obj) } } }}","link":"/2017/06/05/utils-in-axios/"},{"title":"Web 坐标整理","text":"坐标分类 文档坐标 窗口坐标 scrollElement.scrollTop: 设置或获得一个元素距离他容器顶部的像素距离, 当一个元素的容器没有产生垂直方向的滚动条, 则他的 scrollTop 的值默认为0 获得滚动距离var intElementScrollTop = someElement.scrollTop; scrollTop可以被设置为任何整数, 但是一下情况会报错:1. 如果一个元素不能被滚动(没有溢出容器或本身不可滚动)的时候设置其 scrollTop 为 0; 设置 scrollTop 的值小于 0, scrollTop 被设为 0 如果设置了超出这个容器可以滚动的值, scrollTop 会被设为最大值 其实就是溢出距离 Element.scrollHeight: 计量元素内容高度的只读属性, 包括 overflow 样式属性导致的视图中不可见内容 没有垂直滚动条的情况下, scrollHeight 值与元素视图填充所有内容所需要的最小值 clientHeight 相同, 包括元素的 padding, 但不包括 margin 其实就是溢出元素的本身高度 !()[https://developer.mozilla.org/@api/deki/files/840/=ScrollHeight.png] 判断元素是否滚动到底部element.scrollHeight - element.scrollTop === element.clientHeight clientTopElement.clientTop: 一个元素顶部边框的宽度, 不包括顶部外边距或内边距, 只读属性 clientHeight 可以通过 CSS height + CSS padding - 水平滚动条高度 来计算 其实就是可视区域高度 mouseEvent.clientX: 只读属性, 事件发生时应用客户端区域的水平坐标, 与页面无关 mouseEvent.x 是 mouseEvent.clientX 的别名 windowwindow.innerHeight: 浏览器窗口的视口( viewport ) 高度, 如果存在滚动条, 则要包括在内, 只读属性 window.outerHeight: 整个浏览器窗口的高度 offsetmouseEvent.offsetX: read-only property provides the offset in the X coordinate of the mouse pointer between that event and the padding edge of the target node pageevent.PageX: read-only property returns the horizontal coordinate of the event relative to the whole document 文档坐标 screenmouseEvent.screenX: read-only property provides the horizontal coordinate of the mouse pointer in the global(screen) coordinate.","link":"/2016/12/08/web-e5-9d-90-e6-a0-87-e6-95-b4-e7-90-86/"},{"title":"Usage of Grid in Css","text":"Original IntroductionCSS Grid Layout (aka ‘Grid’), is a two-dimensional grid-based layout system that aims to do nothing less than completely change the way we design grid-based user interfaces. TerminologyGrid ContainerThe element on which display: grid is applied. It’s the direct parent of all the grid items. In this example container is the grid container. 12345&lt;div class=\"container\"&gt; &lt;div class=\"item item-1\"&gt;&lt;/div&gt; &lt;div class=\"item item-2\"&gt;&lt;/div&gt; &lt;div class=\"item item-3\"&gt;&lt;/div&gt;&lt;/div&gt; Grid ItemThe children (e.g. direct descendants) of the grid container. Here the item elements are grid items, but sub-item isn’t. 1234567&lt;div class=\"container\"&gt; &lt;div class=\"item\"&gt;&lt;/div&gt; &lt;div class=\"item\"&gt; &lt;p class=\"sub-item\"&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=\"item\"&gt;&lt;/div&gt;&lt;/div&gt; Grid LineThe dividing lines that make up the structure of the grid. They can be either vertical(column grid line) or horizontal(row grid line) and reside on either side of a row or column. Here the yellow line is an example of a column grid line. Grid TrackThe space between two adjacent grid lines. You can think of them like the columns or rows of the grid. Here’s the grid track between second and third row grid lines. Grid CellThe space between two adjacent row and two adjacent column lines. It’s a single ‘unit’ of the grid. Here’s the grid cell between row grid lines 1 and line2, and column grid lines 2 and 3. Grid AreaThe total space surrounded by four grid lines. A grid area may be comprised of any number of grid cells. Here’s the grid area between row and grid lines 1 and 3, and column grid lines 1 and 3. PropertiesContainer display grid: generates a block-level grid inline-grid: generates an inline level grid subgrid: if your grid container is itself a grid item(i.e. nested grids), you can use this property to indicate that you want the sizes of its rows/columns to be taken from its parent rather than specifying its own. 123.container { display: grid | inline-grid | subgrid;} column, float, clear and vertical-align have no effect on a grid container grid-template-rows &amp; grid-template-columns : can be a length, a percentage, or a function of the free space in the grid(using the fr unit) : an arbitrary name of your choosing 1234.container { grid-template-columns: &lt;track-size&gt; | [&lt;line-name&gt;] &lt;track-size&gt;; grid-template-rows: &lt;track-size&gt; | &lt;line-name&gt; &lt;track-size&gt;;} A line can have more than one name, seperated by spcae. You can use repeat() notation to streamline things: 123.container { grid-template-columns: repeat(3, 20px [col-start]) 5%;} The fr unit allows you to set the size of a track as a fraction of the free space of the grid container. The free space is calculated after any non-flexible items. grid-template-areas: : the name of a grid area specified with grid-area .: a period signifies an empty grid cell. none: no grid areas are defined. 123.container { grid-template-areas: &lt;grid-area-name&gt; | . | none;} 123456789101112131415161718192021.item-a { grid-area: header;}.item-b { grid-area: main;}.item-c { grid-area: sidebar;}.item-d { grid-area: footer;}.container { grid-template-columns: repeat(4, 50px); grid-template-rows: auto; grid-template-areas: 'header header header header' 'main main . sidebar' 'footer footer footer footer'} grid-template: a shorthand for setting grid-template-rows, grid-template-columns and grid-template-areas in a single decalration. none: sets all three properties to their initial values subgrid: sets grid-template-rows, grid-template-columns to subgrid, and grid-template-areas to its initial value. /: sets grid-template-rows and grid-template-columns to the specified values, respectively, and sets grid-template-areas to none grid-column-gap &amp; grid-column-gap: Specifies the size of the grid lines. You can think of it like setting the width of the gutters between the columns/rows. : a length value grid-gap: a shorthand for grid-row-gap and grid-column-gap justify-items: Aligns the content inside a grid item along with the row axis start: aligns the content to the left end of the grid area end: aligns the content to the right end of the grid area center: aligns the content in the center of the grid area stretch: fills the whole width of the grid area(this is the default) This behavior can also be set on individual grid items via the justify-self property align-items: aligns the content inside a grid item along the column axis. This value applies to all grid items inside the container. start: aligns the content to the top of the grid area end: aligns the content to the bottom of the grid area center: aligns the content in the center of the grid area stretch: fills the whole height of the grid area(this is the default) This behavior can also be set on individual grid items via the align-self properties. justify-content: Sometimes the total size of your grid might be less than the size of its grid container. This could happen if all of your grid items are sized with non-flexible units like px. In this case you can set the alignment of the grid within the grid container. This property aligns the grid along the row axis. start: aligns the grid to the left end of the grid container end center stretch: resize the grid items to allow the grid to fill the full width of the grid container. space-around: places an even amount of space between each grid item, with half-sized spaces on the far ends. space-between: places an event amount of space between each grid item, with no space at the far ends. space-evenly: places an even amount of space between each grid item, including the far ends align-content: start end center stretch space-around space-between space-evenly grid-auto-columns &amp; grid-auto-rows: : can be a length, a percentage, or a fraction of the free space in the grid(using the fr unit) To illustrate how implicit grid tracks get created, think about this: 1234.container { grid-template-columns: 60px 60px; grid-template-rows: 90px 90px;} This creates a 2 x 2 grid 12345678.item-a { grid-row: 2/3; grid-column: 1/2;}.item-b { grid-row: 2/3; grid-column: 5/6;} We told .item-b to start on column line 5 and end at column line 6, but we never defined a column 5 or 6. Because we referenced lines that don’t exist, implicit track with widths of 0 are created to fill in the gap. We can use grid-auto-column and grid-auto-row to specify the widths of these implicit tracks: 123.container { grid-auto-columns: 60px;} grid-auto-flow: If you have grid items that you don’t explicitly place on the grid, the auto-placement algorithm kicks in to automatically place the items. This properties controls how the auto-placement algorithm works. row: tells the auto-placement algorithm to fill in each row in turn. adding new rows as necessary. column: tells the auto-placement algorithm to fill in each column in turn, adding new columns as necessary. dense: tells the auto-placement algorithm to attempt to fill in holes earlier in the grid if smaller items come up later. dense might cause your items to appear out of order grid: a shorthand for setting all of the following properties in a single declaration: grid-template-rows, grid-template-columns, grid-template-areas, grid-auto-rows, grid-auto-columns, grid-auto-flow Items grid-column-start &amp; grid-column-end &amp; grid-row-start &amp; grid-row-end determines a grid item’s location within the grid by referring to specific grid line. : can be number to refer to a numbered grid line, or a name to refer to a named grid line span : the item will span across the provided number of grid tracks span : the item will span across until it hits the next line with the provided name auto grid-column &amp; grid-row: shorthand for grid-column-start + grid-column-end and grid-row-start + grid-row-end, respectively. / grid-area: gives an item a name so that it can be referenced by a template created with the grid-template-areas property. Alternatively, this property can be used as an even shorter shorthand for grid-row-start + grid-column-start + grid-row-end + grid-column-end. : a name of your choosing / / / justify-self: aligns the content inside a grid item along the row axis. This value applies to the content inside a single item. start end center stretch align-self: aligns the content inside a grid item along the column axis. This value applies to the content inside a single grid item. start end center stretch","link":"/2017/05/18/usage-of-grid-in-css/"},{"title":"Usage of Redux-Action","text":"createAction(type, payloadCreator = Identity, ?metaCreator): actionCreator with specified type and it will accept a payload The more correct name for this function is probably createActionCreator(), but it’s too redundant. createAction(&apos;ADD_TODO&apos;)(&apos;Use the Reudx&apos;); `&lt;/pre&gt; &lt;pre&gt;`import { createAction } from &apos;redux-action&apos; `&lt;/pre&gt; &lt;pre&gt;`const increment = createAction(&apos;INCREMENT&apos;); expect(increment(42)).to.deep.equal({ type: &apos;INCREMENT&apos;, payload: 42 }); `&lt;/pre&gt; Wraps an action creator so that its return value is the payload of a Flux Standard Action. If no payload creator is passed, or if it&apos;s not a function, the identity function is used. **If the payload is an instance of an Error Object, redux-actions will automatically set `action.error` to true.** &lt;pre&gt;`const increment = createAction(&apos;INCREMENT&apos;); const error = new TypeError(&apos;not a number&apos;); expect(increment(error)).to.deep.equal({ type: &apos;INCREMENT&apos;, payload: error, error: true }) `&lt;/pre&gt; `createAction` also return its `type` when used as type in `handleAction` or `handleActions` &lt;pre&gt;`const increment = createAction(&apos;INCREMENT&apos;) // as param in handleAction handleAction(increment, { next(state, action) {...}, throw(state, action) {...} }); // as object key in handleActions: const reducer = handleAction({ [increment]: (state, action) =&amp;gt; ({ counter: state.counter + action.payload }) }, {counter: 0}) `&lt;/pre&gt; **increment 是 createActions() 创建的一个 actionCreator, 接受 payload 作为参数, 返回一个 action 对象, 该对象传递到 store 中, 并由 store 直接 dispatch 给 handleAction 返回的 reducer** handleAction(type, reducer | reduceMap, ?defaultState) `import { handleAction } from 'redux-action' ` Wraps a reducer so that it only handles Flux Standard Actions of a certain type. If a single reducer is passed, it is used to handle both normal actions and failed actions(A failed action is analogous to a rejected promise). You can use this form if you know a certain type of action will never fail, like the increment example. Otherwise, you can specify separate reducers for next() and throw(). This API is inspired by the ES6 generator interface. `handleAction('FETCH_DATA', { next(state, action) {...}, throw(state, action) {...} }); ` handleAction返回的是指定action类型的reducer, 该 reducer 接收到的 action 如果 error=null, 则执行 next 方法, 如果接收到的 action.error=true, 则执行 throw 方法 createAction(type, payload)返回 action 后, 会自动将 action 传递给 handleAction, 并在 handleAction 内部根据 actionType 执行对应代码块, handleAction 会返回 new State, 通过 combineReducers, 返回给State if either next() or throw() are undefined or null, then the identity function is used for that reducer. combineActions(…actionTypes) Combine any number of action types or action creators. actionTypes is a list of positional arguments which can be action type string, symbols, or action creators. This allows you to reduce multiple distinct actions with the same reducer. `const {increment, decrement} = createAction({ INCREMENT: amount =&gt; ({ amount }), DECREMENT: amount =&gt; ({ amount: -amount}) }) const reducer = handleAction(combineActions(increment, decrement), { next:(state, {payload: { amount }}) =&gt; ({...state, counter: state.counter + amount}), throw: state =&gt; ({...state, counter: 0}), },{counter: 10}) expect(reducer(undefined, increment(1)).to.deep.equal({counter: 1})) expect(reducer(undefined, decrement(1)).to.deep.equal({counter: 0})) expect(reducer(undefined, increment(new Error)).to.deep.equal({counter: 0})) expect(reducer(undefined, decrement(new Error)).to.deep.equal({counter: 0})) ` Usage with middleware Redux-actions is handy all by itself, however its real power comes when you combine it with middleware The identity form createAction is a great way to create a single action creator that handles multiple payload types. For example, using redux-promise and redux-rx `const addTodo = createAction(‘ADD_TODO’) // a single reducerhandleAction(‘ADD_TODO’, (state = {todos: []}, action) =&gt; ({ …state, todos: […state.todos, action.payload]})); // …that works with all of these forms:// (Don’t forget to use bindActionCreators() or equivalent.// I’ve left that bit out)addTodo(‘Use Redux’)addTodo(Promise.resolve(‘Weep with joy’))addTodo(Observable.of( ‘Learn about middleware’, ‘Learn about higher-order stores’)).subscribe()","link":"/2016/09/04/usage-of-redux-action/"},{"title":"Webpack 2 起步","text":"虽然和 webpack1 一样, 还是过一遍 创建一个 bundlemkdir webpack-demo &amp;amp;&amp;amp; webpack-demo npm init -y yarn add --dev webpack@beta yarn add lodash `&lt;/pre&gt; #### 创建 app/index.js &lt;pre&gt;`// app/index.js import _ from &apos;lodash&apos; function component () { let element = document.createElement(&apos;div&apos;); // use lodash element.innerHtml = _.join([&apos;Hello&apos;, &apos;webpack&apos;], &apos; &apos;) return element } document.body.appendChild(component()) `&lt;/pre&gt; #### 创建 index.html &lt;pre&gt;`&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;webpack 2 demo&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;script src=&quot;public/bundle.js&quot;&amp;gt;&amp;gt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; `&lt;/pre&gt; #### 创建打包后文件 &lt;pre&gt;`./node_modules/.bin/webpack app/index.js public/bundle.js `&lt;/pre&gt; webpack 会自动处理包的依赖关系 ### 添加配置文件 &lt;pre&gt;`var path = require(&apos;path&apos;) module.exports = { entry: &apos;./app/index.js&apos;, output: { path: path.resolve(__dirname, &apos;public&apos;), filename: &apos;bundle.js&apos; } } `&lt;/pre&gt; 通过 webpack 命令行进行打包 &lt;pre&gt;`webpack --config webpack.config.js `&lt;/pre&gt; `webpack` 会默认执行名为 `webpack.config.js` 的配置文件, 因此仅输入`webpack` 即可进行打包 ### 通过 yarn 执行打包 在 `yarn init` 生成的 `package.json` 中添加 &lt;pre&gt;`{ ... &quot;scripts&quot;: { &quot;build&quot;: &quot;webpack&quot; } ... } 即可将webpack指令添加进 yarn 的快捷方式, 此时执行 yarn build 即可打包","link":"/2017/01/29/webpack-2-e8-b5-b7-e6-ad-a5/"},{"title":"Webpack.config.js","text":"entryThe entry point for the bundle. If you pass a string: The string is resolved to a module which is loaded upon startup. If you pass an array: All modules are loaded upon startup. The last one is exported. entry:[&apos;./entry1&apos;,&apos;./entry2&apos;] `&lt;/pre&gt; If you pass an object: Multiple entry bundles are created. The key is the chunk name. The value can be a string or an array &lt;pre&gt;`{ entry:{ page1: &apos;./pages1&apos;, page2: [&apos;./entry1&apos;,&apos;./entry2&apos;] }, output: { // Make sure to use [name] or [id] in output.filename // when using multiple entry points filename: &apos;[name].bundle.js&apos;, chunkFilename: &apos;[id].bundle.js&apos; } } `&lt;/pre&gt; ### Output `output` options tell webpack how to write the compiled files to disk. Note, that while there can be multiple &apos;entry&apos; points, only &apos;output&apos; configuration is specified. If you use hashing(`[hash]` or `[chunkhash]`) make sure to have a consistent ordering of modules. Use the `OccurenceOrderPlugin` or `recordsPath` #### output.filename Specifies the name of each output file on disk. You must **not** specify an absolute path here! The `output.path` option determines the location on disk the files are written to, `filename` is used solely for naming the individual files. ##### single entry &lt;pre&gt;`{ entry: &apos;./src/app.js&apos;, output: { filename: &apos;bundle.js&apos;, path: &apos;./build&apos; } } `&lt;/pre&gt; ##### multiple entries If you configuration creates more than a single &quot;chunk&quot;(as with multiple entry points or when using plugins like CommonsChunkPlugin), you should use substitutions below to ensure that each file has a unique name. `[name]` is replaced by the name of the chunk `[hash]` is replaced by the hash of the compilation. `[chunkhash]` is replaced by the hash of the chunk. &lt;pre&gt;`{ entry:{ app: &apos;./src/app.js&apos;, search: &apos;./src/search.js&apos; }, output:{ filename: [name].js, path: __dirname + &apos;/built&apos; } } output.pathThe output directory as absolute path(required). Module.loadersAn array of automatically applied loaders. Each item can have there properties: test: A condition that must be met exclude: A condition that must not be met include: A condition that must be met loader: A string of ‘!’ separated loaders ‘loaders’: An array of loaders as string resolve","link":"/2016/07/21/webpack-config-js/"},{"title":"Webpack","text":"Use webpack in a projectIt’s best to have webpack as a dependency in your project, through this you can choose a local webpack version and will not be forced to use the single global one.Add a package.json configuration file or npm with: $ npm init `&lt;/pre&gt; The answers to the question are not so important if you don&apos;t want to publish your project to npm. Install and add `webpack` to the `package.json` with: &lt;pre&gt;`$ npm install --save-dev webpack `&lt;/pre&gt; ### Create a modular JavaScript Project Let&apos;s create some modules in JavaScript, using the CommonJS syntax: #### cat.js &lt;pre&gt;`var cats = [&apos;dave&apos;,&apos;henry&apos;,&apos;martha&apos;]; module.exports = cats; `&lt;/pre&gt; #### app.js(Entry Point) &lt;pre&gt;`var cats = require(&apos;cats.js&apos;); console.log(cats); `&lt;/pre&gt; The **Entry Point** is where your application will start, and where webpack will start tracking dependencies between modules. Give webpack the entry point(app.js) and specify an output file(app.bundle.js): &lt;pre&gt;`webpack ./app.js app.bundle.js `&lt;/pre&gt; webpack will read and analyze the entry point and its dependencies(including transitive dependencies). Then it will bundle them into `app.bundle.js`. Now your bundle is ready to run. Run `node app.bundle.js` and marvel in your abundance of cats. To gain full access to webpack&apos;s flexibility, we need to create a &quot;configuration file&quot; ### Project Structure We will put the source files in **src**, and bundled files in **dist**. The final project structure will look like this: ![](https://raw.githubusercontent.com/dtinth/webpack-docs-images/2459637650502958669ea6b11bf49dc0b3b083ae/usage/project-structure.png) Create webpack.config.js `module.exports = { entry: './src/app.js', output: { path: './dist', filename: '[name].bundle.js' } }; ` A webpack configuration file is a CommonJS-Style module. So you can run any kind of code here, as long as a configuration object is exported out of its module. Using loadersWebpack only supports JavaScript modules natively, but most people will be using a transpiler for ES2015, CoffeeScript, TypeScript, etc. They can be used in webpack by using loaders.Loaders are special modules webpack uses to ‘load’ other modules(written in another language) into JavaScript(that webpack understands). using babel-loader1. Install Babel and the presets: `npm install --save-dev babel-loader ` Configure Babel to use there presets by add .babelrc `{'presets':['es2015']} ` Modify webpack.config.js to process all .js files using babel-loader. `module.exports = { entry: './src/app.js', output: { path: './dist', filename: '[name].bundle.js' }, module: { loaders: [ {test: /\\.js$/,exclude: /node_modules/, loader: 'babel-loader',} ] } } ` We are excluding node_modules here because otherwise all external libraries will also go through Babel, slowing down compilation.4. Install the libraries you want to use `npm install --save jquery babel-polyfill ` We are using --save instead of --save-dev this time, as there libraries will be used in runtime. -dev means the libraries only used during development. Edit src/app.js `import ‘babel-polyfill’; import cats from ‘./cats’; import $ from ‘jquery’; $(‘&lt;h1&gt;Cats&lt;/h1&gt;’).appendTo(‘body’); const ul = $(‘&lt;ul&gt;&lt;/ul&gt;’).appendTo(‘body’); for (const cat of cats) { $(&apos;&amp;lt;li&amp;gt;&amp;lt;/li&amp;gt;&apos;).text(cat).appendTo(ul); } 123456789101112131415161718192021222324252627 6\\. Using Plugins An example would be minifying your file so that the client can load if faster. This can be done with **plugins**. We&apos;ll add the uglify plugin to our configuration:const webwebpack = require(&apos;webpack&apos;);module.exports = { entry: &apos;./src/app.js&apos;, output: { path: &apos;./dist&apos;, filename: &apos;[name].bundle.js&apos; }, module: { loaders: [ {test: /&amp;#46;jsx?$/, exclude: /node_modules/,loader: &apos;babel-loader&apos;} ] },plugins: [ new webpack.optimize.UglifyJsPlugin({ compress: { warning:false, }, output: { comments: false, }, }), ]} The Uglify plugin is included with webpack so you don’t need to add additional modules, but this may not always be the case.","link":"/2016/07/21/webpack-2/"},{"title":"Webpack 2 Config 文件入门","text":"webpack 2 config 文件入门 webpack.config.js 的基本结构var path = require(&apos;path&apos;) module.exports = { entry: { home: &apos;./home.js&apos;, about: &apos;./about.js&apos;, contact: &apos;./contact.js&apos;, }, // 入口文件 // string | [string] | object {&amp;lt;key&amp;gt;: string | [string] } // 一个页面搭配一个入口文件 output: { // output 包含一系列关于打包后文件的配置 // output.chunkFilename: string, 这个参数确定了加载 chunk 的名称 // output.crossOriginLoading: boolean | string, 只在 target 参数指定为 web 的时候使用, 因为此时通过 jsonp 加载模块 // crossOriginLoading: false(default) , 禁止跨域加载 // crossOriginLoading: &apos;anonymous&apos;, 允许无 credential 的跨域加载 // crossOriginLoading: &apos;use-credentials&apos;, 允许有 credential 的跨域加载 // // output.devtoolFallbackModuleFilenameTemplate: string | function(info) // output.hotUpdateChunkFilename: string, 指定热刷新的 chunk 的名称, 仅支持 id 和 hash 占位符 // hotUpdateChunkFilename: &apos;[id].[hash].hot-update.js&apos; // output.sourceMapFilename: string, 仅当 devtool 使用 source map 时生效, 默认为[ file].map, 可选占位符有[name], [id], [hash], [chunkhash] path: path.resolve(__dirname, &apos;dist&apos;), // 打包后文件存储路径, 必须是绝对路径, 可以用 path 模块生成 publicPath: /assert/, // 解析文件中相对路径时依赖的根目录 // 该字段设定了输出文件的 public Url // // 默认的, 相对路径会基于 html 文件位置或&amp;lt;base&amp;gt;标签进行解析, 添加 publicPath 后, 各个 loaders 会在每个相对路径前添加 publicPath, 即相对路径基于 publicPath 进行解析 // 该值一般以&apos;/&apos;结尾 // 默认值为&apos;&apos; // simple rule: 该参数的值为html 页面到 output.path 的相对值 // path: path.resolve(__dirname, &apos;public/assets&apos;), // publicPath: &apos;https://cdn.example.com/assets/&apos;, // publicPath 也会对 webpack-dev-server 生效 // publicPath: &apos;https://cdn.example.com/assets/&apos; cdn, 并且应该使用 https // publicPath: &apos;//cdn.example.com/assets/&apos;, cdn, 使用相同协议 // publicPath: &apos;/assets/&apos;, 相对于服务器根路径 // publicPath: &apos;assets/&apos;, 相对于 html 页面 // publicPath: &apos;../assets/&apos;, 相对于 html 页面 // publicPath: &apos;&apos;, 相对于 html 页面(同一路径) filename: &apos;bundle.js&apos;, // 打包后的文件名称 // 对于单一入口文件, filename 可以为静态名称&apos;bundle.js&apos; // 对于多入口文件, 可以使用参数生成特定名称 // [name], [id], [hash], [chunkhash] // 可以为文件添加路径: &apos;js/[name]/bundle.js&apos; library: &apos;MyLibrary&apos;, // 输出库的名称 libraryTarget: &apos;umd&apos;, // 输出库的类型 }, module: { // module.noParse: RegExp | [RegExp], 符合正则的字段被 import, require, define 后不会被处理, 可以提高打包速度 // noParse: /jquery|lodash/ // rules: [ // 模块应用规则(loaders, parser 的设定等) // module.rules: array // 一条 Rule 可以分为三部分, Conditions, Results, Nested Rules // Conditions, 有两个输入值, // 1\\. The resource: 文件引用的绝对路径经过 resolve 规则解析后的结果 // 2\\. The issuer: 引用 resource 的模块到文件的绝对路径 // 比如, &apos;app.js&apos; 中 &apos;import ./style.css&apos;, resource 是 &apos;/path/to/style.css&apos;, issuer 是 &apos;/path/to/app.js&apos; // 在 rule 中, test, include, exclude 和 resource 作用于resource, 而 issuer 族谱用于 issuer // Results // Rule Results 仅在 Rule Conditions 满足时起作用 // Rule Results 有二种输出值 // Applied Loaders: 一个数组, 其元素是应用于 resource 的 loaders // Parser options: 一个 options 对象, 作为当前 module 的 parser // loader, options, use 用于 loaders, // query, loaders 用于提高兼容性 // enforce 属性指定 loader 类型, 可选值有: normal, pre, post // parser 属性影响 parser options // Nested Rules // 在 rules 和 oneOf 属性中可以指定 nested rules // Rule.enforce: &apos;pre&apos; | &apos;post&apos;, 指定 loader 的类型, 默认为 normal // 还有一种 inline loader 应用于 inline import/require, // 所有 loaders 按照 post, inline, normal, pre 排序并依次执行 // 所有 normal loaders 可以通过在 request 中添加前缀 &apos;!&apos; 进行忽略 // 所有 normal 和 pre loaders 可以通过在 request 中添加前缀 &apos;-!&apos; 进行忽略 // 所有 normal, post 和 pre loaders 可以通过在 request 前添加 &apos;!!&apos; 进行忽略 // Rule.exclude // Rule.exclude 是 Rule.resource.exclude 的缩写 // // Rule.include // Rule.include 是 Rule.resource.include 的缩写 // // Rule.issuer // // Rule.loader // Rule.loader 是 Rule.use: [{loader}] 的别名 // // Rule.loaders // Rule.loaders 是 Rule.use 的别名, 他的存在仅为了兼容 webpack1, 应使用 Rule.use // // Rule.oneOf // 一个数组, 其元素为一系列 rules, 仅第一个符合条件的 rule 会起作用 // // Rule.options/ Rule.query // Rule.options 和 Rule.query 都是 Rule.use: [{options}] 的缩写 // Rule.query 的存在仅为了兼容 webpack1, 应使用 Rule.options // // Rule.parser // 一个 parser options 的对象, 所有要使用的 parser options 都集中在此 // 每个不同的 parser options 都会创建对应 parser, 并且 plugins 可以根据 parser options 应用. 当 parser options 中没有设置或设置为 true 时, 大部分 plugins 默认只应用他们自己的 parser plugins // parser: { // amd: false, // disable AMD // commonjs: false, // disable CommonJS // harmony: false, // disable ES6 Harmony import/exports // requireInclude: false, // disable require.include // requreEnsure: false, // disable require.ensure // } // Rule.resource // Rule.rules, 一个 Rules 组成 的数组 // Rule.test, Rule.resource.test 的缩写 // Rule.use, 一系列应用于 modules 的 UseEntries, 每一个 entry 指定一个 loader // use: [&apos;style-loader&apos;] 是 use: [{loader: &apos;style-loader&apos;}] 的缩写 // 可以链式传入多个 loaders, 从右向左依次执行 // use: [ // {loader: &apos;style-loader&apos;}, // {loader: &apos;css-loader&apos;, options: { importLoader: 1}}, // {loader: &apos;less-loader&apos;, options: { noIeCompat: true}}, // ] // Condition // Condition 可以为以下之一: // String: 比如 exclude: &apos;node_modules&apos; // RegExp: 比如 test: /\\.js$/, exclude: /node_modules/ // function: 返回 true 或 false // Condition Array: 至少有一个满足时刻认为满足 condition // Object: 所有属性都满足时可认为满足 // // {test: Condition}, {include: Condition}, {exclude: Condition}, {and: [Condition]}, {or: [Condition]}, {not: Condition} // // UseEntry: object // 该属性必须有一个字符串 loader. // 该属性相对 context 的值解析 loader // 该属性拥有 options 属性, 该属性为 string 或 object, 该属性会作为 loader options 被传给 loader // 考虑到兼容性, 目前仍支持 query 作为 options 的别名 // { test: /\\.jsx?$/, // 通过正则表达式选择要处理的文件 include: [ // 限定文件范围 path.resolve(__dirname, &apos;app&apos;) ], exclude: [ // 排除文件范围 path.resolve(__dirname, &apos;demo&apos;) ] // 最佳实践 // test 中使用正则表达式 // include 和 exclude 中使用绝对路径 // 优先使用 include 而不是 exclude issuer: { test, include, exclude }, // issuer 的应用范围 enforce: &apos;pre&apos;, enforce: &apos;post&apos;, loader: &apos;babel-loader&apos;, // 使用 babel-loader 处理符合条件的文件 // webpack2 中 -loader 不再可以省略 options: { presets: [&apos;es2015&apos;] } // babel-loader 的配置 }, { test: /\\.html$/, use: [ // 应用多个 loader 及相关配置 &apos;htmllint-loader&apos;, { loader: &apos;html-loader&apos;, options: { // ... } } ] }, { oneOf: [ /* rules */ ], // 仅应用 rules 数组中的一条规则 }, { rules: [ /* rules */ ], // 应用所有 rules }, { resource: { and: [ /* conditions */ ]} // 当所有 conditions 都满足时才认为符合条件 }, { resource: { or: [ /* conditions */ ]}, }, { resource: [ /* conditions */] }, // 当某一 condition 满足时即可认为符合条件 { resource: { not: /* condition */ } // 当某一 condition 不满足时可认为符合条件 } ], // rules 结束 }, resolve: { // 解析模块 request 时的配置 // (不会应用于解析 loader ) modules: [ &apos;node_modules&apos;, path.resolve(__dirname, &apos;app&apos;) ], // 解析 modules 时的路径 extensions: [&apos;.js&apos;, &apos;.json&apos;, &apos;.jsx&apos;, &apos;.css&apos;], // 可以省略的扩展名 alias: { // 模块别名 // 为 import 或 require 创建别名 // Utilities: path.resolve(__dirname, &apos;src/utilities&apos;) // import Utility from &apos;../../utilities/utility&apos; 可以缩写为 // import Utility from &apos;Utilities/utility&apos; // 末尾添加$可以进行精确匹配, 类似正则 // &apos;module&apos;: &apos;new-module&apos;, // 别名 module 可以表示 new-module, 包括文件与路径, 比如 module/path/file 会被解析为 new-module/path/file &apos;only-module$&apos;: &apos;new-module&apos;, // 别名 only-module(处于尾部) 会被解析成 new-module, 因此 module/path/file 不会被解析 }, // aliasFields: string // 指定一个 field, 比如 browser, 来执行特定的 alias // aliasFields: [&apos;browser&apos;] // // resolve.descriptionFiles: array // 用于描述的 JSON 文件, 默认为 // descriptionFiles: [&apos;package.json&apos;] // // resolve.enforceExtension: boolean // 如果为 true, webpack 不会处理没有扩展名的文件, 默认为 false, 及允许 require(&apos;./foo&apos;) 这种写法 // //resolve.enforceModuleExtension: boolean //默认为 false, 是否允许 modules(loaders) 省略扩展名 // //resolve.extensions: array, 自动解析指定的扩展名 //默认为 // extensions: [&apos;.js&apos;, &apos;.json&apos;] // 因此可以使用 import File from (&apos;../path/to/file&apos;) 这种写法 // // resolve.mainFields: array // 当 import 一个包时, 比如 import * as D3 from &apos;d3&apos;, 这个设置决定package.json中的哪个 field 对应的包的会被检索, 默认值基于 target 的值 // 当 target 指定为 webworker, web 或不指定 // mainFields: [&apos;browser&apos;, &apos;module&apos;, &apos;main&apos;] // 对于其他 target, // mainFields [&apos;module&apos;, &apos;main&apos;] // 例如, D3的 package 包括这些 fields // { // ... // main: &apos;build/d3.Node.js&apos;, // browser: &apos;build/d3.js&apos;, // module: &apos;index&apos; // ... // } // // resolve.mainFiles: array // 这里的 filename 会在解析路径的时候用到, 默认为 // mainFiles: [&apos;index&apos;] // // resolve.modules: array // 限定 webpack 搜索与解析的范围 // 可以使用绝对路径偶相对路径, 但是他们的行为有少许不同. // 相对路径的检索方式与 Node 检索 module 相近, 首先检索当前路径及父路径 // 绝对路径则只会检索给定路径 // 默认值为 modules: [&apos;node_modules&apos;] // // 如果要添加路径, 应当添加在 node_modules 前面 // modules: [path.resolve(__dirname, &apos;src&apos;), &apos;node_modules&apos;] // // resolve.unsafeCache: regex | array | boolean // 默认为 true, 即允许模块缓存, 即使这种行为是不安全的 // }, performance: { // 此配置决定 webpack 的通知功能 // 主要用于对文件尺寸的控制 hints: &apos;warning&apos;, // enum // hints: boolean | &apos;error&apos; | &apos;warning&apos; // 设定 webpack 何时显示通知 // 默认为 warning maxAssetSize: 200000, // int (in bytes) // maxAssetSize: int, 这个选项限制了单个 asset 的尺寸, 默认为250000 maxEntrypointSize: 400000, // int (in bytes) // maxEntrypointSize: int, 限制初始加载时单个 entry 的最大请求数, 默认为250000 assetFilter: function (assetFilename) { return assetFilename.endsWith(&apos;.css&apos;) || assetFilename.endsWith(&apos;.js&apos;) } // assetFilter: function, 这个属性允许 webpack 控制使用哪些文件来计算 performance hint, 默认为 // function (assertFilename) { // return !(/\\.map$/.test(assetFilename)) // } // // 可以自己设定 filter function // assetFilter: function(assetFilename) { // return assetFilename.endsWith(&apos;.js&apos;) // } }, devtool: &apos;source-map&apos;, // enum, string | false // 可以提高 debug 的便利性, 但是会影响打包速度 // 面向开发有: eval, inline-source-map, eval-source-map, cheap-module-eval-source-map // 面向生产有: source-map, hidden-source-map, cheap-source-map, nosources-source-map context: __dirname, // 使用绝对路径 // webpack 的根路径, loaders 的配置文件(.babelrc, postcss.config.js)和 entry 都是基于 context 来解析的 // 该属性值默认为当前目录, 但是强烈建议书写这一字段, 可以使你的配置文件独立于当前工作目录 target: &apos;web&apos;, // enum // 打包文件运行环境 // webpack 可以针对多个 environment 或 target 编译 // target: string, (async-node|electron|electron-renderer|node|node-webkit|web|webworker) externals: [&apos;react&apos;, /^@angular\\//], // 不必打包的内容 // externals: string| RegExp | function | array | object // 例如要使用 jquery 的 cdn, 则可以这样配置 // externals: { // jquery: &apos;jQuery&apos; // } // import $ from &apos;jquery&apos; // // externals: { // substract: [&apos;./math&apos;, &apos;substract&apos;] // } // 会形成一个负责结构, ./math 是父模块, 而你的 bundle 仅请求其子模块 substract // // externals: { // react: &apos;react&apos;, // lodash: { // commonjs: &apos;lodash&apos;, // amd: &apos;lodash&apos;, // root: &apos;_&apos; // } // } // watch: boolean // webpack 可以监控文件并在他们变化时进行重新编译 // 默认为 false watchOptions: object, // 配置 watch 的模式 // { // aggregateTimeout: number, 从第一次检测到文件变化到进行重新编译的延迟时间, 这个段时间内的其他变化会被整合进此次编译 // ignored: string | RegExp, 忽视某些文件的变化, 减轻 CPU 负担 // poll: boolean | number, 每隔1000ms 进行一次检测 // } stats: { // 待补充 }, devServer: { // 这一部分的设置会被 webpack-dev-server 采用 contentBase: path.resolve(__dirname, &apos;dist&apos;), // 指定 serve 目录为 dist compress: true, // 开启 gzip 压缩 port: 9000, // 指定端口 // 当 devServer 启动时, 控制台会打印 // http://localhost:9000 // webpack result is served from /build/ // content is served from dist/ // 这几行指出了 server 的位置和 served 内容 // 如果你使用了 Node.js API, 那么这部分会被忽略 // // devServer.filename: string, 这个选项可以减少 lazy mode 下的编译次数 // 默认的, 在 lazy mode 下, 每一个请求会进行一次新的编译 // 添加 filename 后, devServer 仅在请求 filename 时进行编译, 比如 // lazy: true, // filename: bundle.js // 此时, devServer 仅在请求/ bundle.js 时进行编译 // filename 仅在 lazy mode 中起作用 // devServer.headers: object, 在所有 request 中添加请求头 // headers: { // &apos;X-Custom-Foo&apos;: &apos;bar&apos; // } // // devServer.historyApiFallback: boolean, object // 当使用 Html5 History Api 时, index.html 可能得到404响应 // // devServer.hot: boolean, 开启 webpack 模块热替换 // // devServer.host - CLI only // 指定 host // // devServer.https: boolean | object, devServer 默认false, 即使用 http // // devServer.inline - CLI only // 切换 devServer 的模式, 默认使用 inline 模式, 即脚本会直接注入到你的 bundle 以实现重载, 设置 devServer.inline: false 可以启用 iframe 模式 // // }, plugins: [ // 待补充 ] }","link":"/2017/01/29/webpack-2-config-e6-96-87-e4-bb-b6-e5-85-a5-e9-97-a8/"},{"title":"Webpack Dev Server","text":"The webpack-dev-server is a little node.js Express server, which uses the webpack-dev-middleware to serve a webpack bundle. It also has a little runtime which is connected to the server via Socket.IO. Let’s say you have the following config file(webpack.config.js) var path = require(&apos;path&apos;); module.exports = { entry:{ app:[&apos;./app/main.js&apos;] }, output:{ path: path.resolve(__dirname, &apos;build&apos;), publicPath:&apos;/assets/&apos;, filename: &apos;bundle.js&apos; }, } `&lt;/pre&gt; You have an `app` folder with your initial entry point that webpack will bundle into a `bundle.js` file in the `build` folder. ### Content Base The webpack-dev-server will serve the files in the **current directory**, unless you configure a specific content base. &lt;pre&gt;`webpack-dev-server --content-base build/ `&lt;/pre&gt; it will serve you `build` folder. This modified bundle is served from memory at the relative path specified in `publicPath`. Namely your bundle will be available as `localhost:8080/assets/bundle.js` ### Automatic Refresh The webpack-dev-server supports multiple modes to automatic refresh pages: Iframe mode(page is embedded in an iframe and reload on change) Inline mode(as a small webpack-dev-server client entry is added to the bundle which refresh the page on change) Inline ModeTo use the inline mode, specify --inline on the command line(you cannot specify it in configuration). 配置 webpack-dev-server 自动刷新`// webpack.config.js entry: [ 'webpack/hot/dev-server', 'webpack-dev-server/client?http://localhost:8080', path.resolve(__dirname, 'app/main.js') ], devServer:{ historyApiFallback: true, hot:true, inline:true, progress: true } ` `//package.json “dev”: “webpack-dev-server –progress –colors –inline –hot –content-base build/“, “build”: “webpack”``` 此时访问 localhost:8080 相当于访问 build/, 所以可以省略 index.html","link":"/2016/08/15/webpack-dev-server/"},{"title":"Webpack 发布配置","text":"单文件模式// 新建 webpack.production.config.js // in package.json &quot;deploy&quot;:&quot;NODE_EVN=production webpack -p -config webpack.production.config.js&quot; // in web.production.config.js // 和开发环境不同之处在于入口和出口. 相应的在 HTML 和 JS 源也要进行修改 var path = require(&apos;path&apos;) var node_modules_dir = path.resolve(__dirname, &apos;node_modules&apos;) module.exports = { entry:[ &apos;babel-polyfill&apos;, path.resolve(__dirname, &apos;app/main.js&apos;) ], output:{ path: path.resolve(__dirname, &apos;build&apos;), filename: &apos;app.js&apos; }, module:{ loaders:[ { ... } ] } } `&lt;/pre&gt; ### 多文件模式 库最好不要打包, 因为一般库都不会改动, 所以 load 一次就够了. 对库进行分离 &lt;pre&gt;`// in webpack.production.config.js var path = require(&apos;path&apos;) var webpack = require(&apos;webpack&apos;) var node_modules_dir = path.resolve(__dirname, &apos;node_modules&apos;) module.exports = { entry:{ app: [path.resolve(__dirname, &apos;app/main.js&apos;)], react: [&apos;babel-polyfill&apos;,&apos;react&apos;,&apos;react-dom&apos;] }, output:{ path: path.resolve(__dirname, &apos;build&apos;), filename: &apos;app.js&apos; }, module:{ loaders:[ ... ] }, plugins:[ new webpack.optimize.CommonsChunkPlugin(&apos;react&apos;,&apos;react.js&apos;) ] }","link":"/2016/08/16/webpack-e5-8f-91-e5-b8-83-e9-85-8d-e7-bd-ae/"},{"title":"Webpack Code Splitting - Async","text":"Currently a ‘function-like’ import() module loading syntax proposal is on the way into ECMAScript. The ES6 Defines import() as method to load ES6 modules dynamically onruntime. Webpack treats import() as a split-point and puts the requested module in a seperate chunk. import() takes the module name as argument and returns a Promise: import(name) =&gt; Promise 1234567function determineDate () { import('moment').then((moment) =&gt; { console.log(moment().format()) }).catch(e =&gt; console.log('failed'))}determineDate() Note that the fully dynamic statement, such as import(foo) will fail because webpack requries at least some file location information. This is because foo could potentially be any path to any file in your system or project. The import() must contain at least some information about where the module is located. so bundling can be limited to a specific directory or set of files. Chunk NameSince webpack 2.4.0, chunk names for dynamic imports can be specified using a “magic comment” 1import(/* webpackChunkName: 'my-chunk-name' */ 'module') Since webpack 2.6.0, the placeholder [request], [index] are supported: 12345// will generate files like `i18n/namespace-i18n-bundle-en.json`import(/* webpackChunkName: 'i18n/[request]' */ `i18n/${namespace}-i18n-bundle-${language}.json`)// will generate files `i18n-0`, `i18n-1`import(/* webpackChunkName: 'i18n-[index]' */ '`i18n/${namespace}-i18n-bundle-${language}.json`') import modeSince webpack 2.6.0, different modes for resolving dynamic imports can be specified: 1import(/* webpackMode: lazy */ `i18n/${namespace}-i18n-${language}.json`) lazy: The default behavior. Lazy generates a chunk per request. So everything is lazy loaded. lazy-once: Only available for imports with expression. Generate a single chunk for all possible requests. So the first request causes a network request for all modules, all following requests are already fulfilled. eager: Eager generates no chunk. All files are included in the current chunk. No network request is required to load the files. It still returns a Promise, but it’s already resolved. You can combine both options ( webpackChunkName and webpackMode ), it’s parsed a JSON5 object without curly brackets: 1import(/* webpackMode: 'lazy-once', webpackChunkName: 'all-i18n-data' */ `i18n/${namespace}-i18n-${lanaguage}.json`) Usage with BabelIf you want to use import with Babel, you’ll need to install the syntax-dynamic-import plugin while it’s still Stage 3 to get around the parser error. 1yarn add --dev babel-core babel-loader babel-plugin-syntax-dynamic-import babel-preset-es2015 1234function determineDate () { import('moment').then(moment =&gt; moment().format()).then(str =&gt; console.log(str)).catch(e =&gt; console.log(e))}determineDate() 123456789101112131415module.exports = { entry: './index', output: { filename: 'app.js' }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: 'babel-loader' } ] }} 1234{ \"presets\": [[\"es2015\", { \"modules\": false }]], \"plugins\": [\"syntax-dynamic-import\"]} Diabled default import in es6. Not using the syntax-dynamic-import plugin will fail the build with 1Module build failed: SyntaxError: 'import' and 'export' may only appear at the top level or 1Module build failed: SyntaxError: Unexpected token, expected \\{ Usage with Babel and async / awaitTo use es7 async/await with import() 1yarn add --dev babel-plugin-transform-async-to-generator babel-plugin-trasnform-regenerator babel-plugin-transform-runtime babel-plugin-syntax-async-functions 123456async function determineDate () { const moment = await import('moment') return moment().format()}determineDate().then(str =&gt; console.log(str)) 12345678910{ \"presets\": [[\"es2015\", { \"modules\": false }]], \"plugins\": [ \"syntax-async-functions\", \"syntax-dynamic-import\", \"transform-async-to-generator\", \"trasnform-regenerator\", \"transform-runtime\" ]} import() imports the entire module namespaceNote that the promise is resolved with the module namespace. Consider the following two examples: 12345// Example 1: top-level importimport * as Component from './component'// Example 2: Code Splitting With Import()import('./component').then(Component =&gt; /* ... */) Component in both of the cases resolves to the same thing, meaning in the case of using import() with ES2015 moduels you have to explicitly access default and named exports: 123456async function main () { // Destructing Example const { default: Component } = await import ('./component') // Inline example render((await import('./component')).default)}","link":"/2017/05/30/webpack-code-splitting-async/"},{"title":"Webpack 常用 Plugin 和 Loader","text":"常用Loaderhtml 相关 html-loader `&lt;/pre&gt; css 相关 &lt;pre&gt;`style-loader css-loader autoprefixer-loader sass-loader `&lt;/pre&gt; js 相关 &lt;pre&gt;`babel-loader babel-core babel-preset-es2015 babel-preset-react babel-preset-stage3 eslint-loader `&lt;/pre&gt; ### 常用插件Plugin #### config 类 &lt;pre&gt;`NormalModuleReplacementPlugin ContextReplacementPlugin IgnorePlugin PrefetchPlugin `&lt;/pre&gt; #### Optimize &lt;pre&gt;`DedupePlugin LimitChunkCountPlugin OccurenceOrderPlugin UglifyJsPlugin CommonsChunkPlugin `&lt;/pre&gt; #### 其他 &lt;pre&gt;`HotModuleReplacementPlugin NoErrorPlugin ProgressPlugin HtmlWebpackPlugin","link":"/2016/08/19/webpack-e5-b8-b8-e7-94-a8-plugin-e5-92-8c-loader/"},{"title":"Webpack 杂","text":"loaders在 React 里会用到 JSX, ES6, js, 统一使用 .js 作为后缀, 便于 babel 配置 npm install --save babel-loader // { test: /\\.js?$/, exclude: /node_modules/, loader: &apos;babel&apos;, query:{ presets: [&apos;es2015&apos;, &apos;react&apos;] } } `&lt;/pre&gt; CSS, SCSS, ICONFONT 字体文件 &lt;pre&gt;`npm install --save style-loader css-loader sass-loader node-sass url-loader, file-loader // { test: /\\.scss$/, loader: &apos;style!css!sass&apos; }, { test: /\\.(png|jpg)$/, loader: &apos;url?limit-8192&apos; } pluginshtml-webpack-plugin 会由 entry 得配置将入口文件所属的 html 文件作为模板, 重新生成一个 html 文件, 其中的静态资源都已经根据配置打包好使用 webpack 后, 对文件的版本 hash 会变得非常简单, 在出口文件 filename 中添加[hash]即可; 就目前而言, 清楚资源缓存的最好方法是文件名 hash, 由于每次改动后生成的文件名都不一样, 上线并不会覆盖之前的版本, 只是多了一个版本的文件, 页面即使同步有时间差, 要么访问旧版页面, 要么访问新版页面, 不会存在冲突. 这样服务器就可以放心的对静态资源开启永久强缓存, 并且有利于回滚, 至于静态资源产生的积压, 可以交由运维处理.","link":"/2016/07/25/webpack-e6-9d-82/"},{"title":"Webpack 配置 React/babel","text":"安装 reactnpm install --save react react-dom `&lt;/pre&gt; ### 安装 babel-loader &lt;pre&gt;`npm install --save-dev babel-loader babel-core babel-preset-es2015 babel-preset-react babel-preset-stage-2 // 支持 ES2015, JSX, ES7 `&lt;/pre&gt; &lt;pre&gt;`npm install --save polyfill `&lt;/pre&gt; &lt;pre&gt;`npm install --save babel-runtime npm install --save-dev babel-plugin-transform-runtime // 减少打包时候的重复代码 `&lt;/pre&gt; ### 配置 babel &lt;pre&gt;`// 在入口添加 polyfill entry:[ &apos;babel-polyfill&apos;, &apos;webpack/hot/dev-server&apos;, &apos;webpack-dev-server/client?http://localhost:8080&apos; ] `&lt;/pre&gt; 添加`.babalrc` &lt;pre&gt;`{ &quot;presets&quot;:[ &quot;es2015&quot;, &quot;react&quot;, &quot;stage-2&quot; ], &quot;plugins&quot;:[ &quot;transform-runtime&quot; ] }","link":"/2016/08/16/webpack-e9-85-8d-e7-bd-ae-reactbabel/"},{"title":"Webpack 开发和部署","text":"Thanks to Webpack 傻瓜指南 启用 Source Map在 webpack.config.js 中添加字段 devtool: &apos;eval-source-map&apos;, `&lt;/pre&gt; 这样出错后会采用 sourceMap 直接显示出错位置 ### 配置 webpack-dev-server 在 webpack.config.js 中添加字段 &lt;pre&gt;`devServer: { historyApiFallback: true, hot: true, inline: true, progress: true, } `&lt;/pre&gt; ### 使用 preLoaders 和 postLoaders preLoaders 在 loaders 之前执行, 总体顺序是 preLoader -&gt; loaders -&gt; postLoaders #### 安装 jshint &lt;pre&gt;`npm install --save-dev jshint-loader `&lt;/pre&gt; 在 config 中配置 &lt;pre&gt;`module:{ preloaders:[ { test: /\\.jsx$/, loader:&apos;jshint-loader&apos; } ] } jshint:{ &apos;esnext&apos;:true } `&lt;/pre&gt; ### 部署上线 项目开发完成后需要部署上线, 此时应该创建一个新的 config, 因为部署上线使用的 webpack 不需要 dev-tools, dev-server, jshint 等 复制现有的 config 文件, 命名为 webpack.production.config.js, 将里面与开发有关的东西删除, 在 package.json 中添加 &lt;pre&gt;`&quot;scripts&quot;:{ &quot;build&quot;: &quot;webpack --progress --profile --colors --config webpack.production.config.js&quot; }, `&lt;/pre&gt; 上线的时候运行 &lt;pre&gt;`npm run build `&lt;/pre&gt; ### 分离第三方库 如果第三方库很多, 会导致最后 bundle 文件很大, 减慢加载速度, 因此需要把第三方库和 app 本身的代码分开 #### 修改 entry 入口文件 &lt;pre&gt;`entry:{ app: path.resolve(APP_PATH, &apos;index.js&apos;), //添加要打包在 vendors 里面的库 vendors: [&apos;jquery&apos;, [moment]] }, `&lt;/pre&gt; #### 添加 CommonsChunkPlugin &lt;pre&gt;`plugins: [ //使用 uglifyJs 压缩 js 代码 new webpack.optimize.UglifyJsPlugin({minimize: true}), //把入口文件里的数组打包成 vendors.js new webpack.optimize.CommonsChunkPlugin(&apos;vendors&apos;,&apos;vendors.js&apos;), new HtmlWebpackPlugin({title: &apos;Welcome&apos;}) ] `&lt;/pre&gt; 运行 build 后会生成 vendor.js ### 生成多页面 假设需求是生成两个页面, 一个叫 index.html, 需要引用 app.js 和 vendors.js 两个文件; 另一个是 mobile.html, 需要应用 mobie.js 和 vendor.js 这两个文件 首先新建一个叫 mobile.js 的文件入口, 比 app.js 简单一些 &lt;pre&gt;`import &apos;./main.scss&apos;; import $ from &apos;jquery&apos;; import &apos;imports?jQuery=jQuery!./plugin.js&apos;; $(document).ready(function(){ let app = document.createElement(&apos;div&apos;); app.innerHTML = &apos;&amp;lt;h1&amp;gt;Hello World&amp;lt;/h1&amp;gt;&apos;; document.body.appendChild(app); $(&apos;h1&apos;).greenify(); }); `&lt;/pre&gt; 在 config 修改入口文件和输出配置 &lt;pre&gt;`entry:{ // 三个入口文件: app, mobile, vendors app: path.resolve(APP_PATH, &apos;index.js&apos;), mobile: path.resolve(APP_PATH, &apos;mobile.js&apos;), vendors: [&apos;jquery&apos;,&apos;moment&apos;] }, output:{ path: DIST_PATH, filename: &apos;[name].js&apos; }, `&lt;/pre&gt; 为 html-webpack-plugin 设置模板, 并保存于 templates &lt;pre&gt;`// index.html &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;{%= o.htmlWebpackPlugin.options.title %}&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h3&amp;gt;Welcome to Index&amp;lt;/h3&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; //mobile.html &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;{%= o.HtmlWebpackPlugin.options.title %}&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h3&amp;gt;Welcome to Mobile&amp;lt;/h3&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; `&lt;/pre&gt; 继续配置 config.js, 让 HtmlWebpackPlugin 可以生成多个文件 &lt;pre&gt;`//Templates 的文件夹路径 var TEM_PATH = path.resolve(ROOT_PATE, &apos;templates&apos;); ... plugins:[ //创建两个 HtmlWebpackPlugin 的实例, 生成两个页面 new HtmlWebpackPlugin({ title: &apos;Hello World App&apos;, template: path.resolve(TEM_PATH, &apos;index.html&apos;), filename: &apos;index.html&apos; //chunks 这个参数告诉插件要引用 chunks 中的那几个入口 chunks: [&apos;app&apos;,&apos;vendors&apos;], //scripts 要插入的位置 inject: &apos;body&apos; }), new HtmlWebpackPlugin({ title: &apos;Hello Mobile App&apos;, template: path.resolve(TEM_PATH, &apos;mobile.html&apos;), filename: &apos;mobile.html&apos;, chunks: [&apos;mobile&apos;,&apos;vendors&apos;], inject: &apos;body&apos; }) ] 生成 hash 名称的 script 来防止缓存webpack 基于 md5 可以生成 hash 名称```output:{ path: DIST_Path, filename: ‘[name].[hash].js’},","link":"/2016/07/22/webpack-e5-bc-80-e5-8f-91-e5-92-8c-e9-83-a8-e7-bd-b2/"},{"title":"用 Javascript 实现选中粘贴","text":"为了对付单位愚蠢的每日工作总结的要求, 写了一个小脚本来导出任务管理器里的内容到剪贴板, 于是接触了一下纯 javascript 实现复制到剪贴板功能 代码先行贴出 123456789101112131415161718192021222324252627282930313233343536(function() { 'use strict'; if ('your_url'){ var issueList = document.querySelectorAll('.issue-list li'); var taskList = []; for(var i = 0, len = issueList.length; i &lt; len; i++){ var key = issueList[i].getAttribute('data-key'); var title = issueList[i].getAttribute('title'); var task = '已完成: '+key+'-'+title; taskList.push(task); } var text = taskList.join('\\n'); var clipboard = document.createElement('textarea'); clipboard.style.width = '100%'; clipboard.style.height = '300px'; clipboard.value = text; var listPanel = document.getElementsByClassName('list-panel')[0]; listPanel.appendChild(clipboard); var today = document.createElement('button'); today.style.width = '100%'; today.innerText = 'Today'; listPanel.appendChild(today); today.addEventListener('click', function () { window.location.href = 'url_to_today'; }); var button = document.createElement('button'); button.style.width = '100%'; button.innerText = 'copy to clipboard'; listPanel.appendChild(button); button.addEventListener('click', function() { clipboard.select(); document.execCommand('copy'); clipboard.blur(); }); }})()","link":"/2017/04/17/用-javascript-实现选中粘贴/"},{"title":"Webpack","text":"Webpack 是一款模块加载兼打包工具, 能把各种资源, 例如 JS(X), coffee, css(sass/less), 图片等都作为模块来使用和处理 可以直接使用 require 的形式来引入各模块, 即时他们可能需要经过编译, webpack 上有各种健全的加载器(loader)会处理这些事情. Webpack 优势 webpack 是一 commonJS 的形式来书写脚本的, 但对 AMD/CMD 的支持也很全面, 方便就项目进行代码迁移 能被模块化的不仅是 JS 了 开发便捷, 能替代部分 grunt/gulp 工作, 比如打包, 压缩混淆, 图片转 base64等 扩展性强, 插件机制完善, 特别支持 React 热拔插(react-hot-loader). 安装与配置常规使用 npm 安装$npm install -g webpack如果是常规项目, 还是把依赖写入 package.json 更好 $npm init $npm install --save-dev webpack `&lt;/pre&gt; ### 配置 每个项目下都必须配置一个 webpack.config.js, 他的作用如同常规的 gulpfile.js, 就是一个配置项, 告诉 webpack 需要做什么 比如: &lt;pre&gt;`var webpack = require(&apos;webpack&apos;); var commonsPlugin = new webpack.optimize.CommonsChunkPlugin(&apos;common.js&apos;); module.exports = { //插件项 plugins: [commonsPlugin], //页面入口文件配置 entry:{ index: &apos;./src/js/page/entry1.js&apos; }, //文件输出配置 output:{ path: &apos;dist/js/page&apos;, filename: &apos;[name].js&apos; }, module:{ //加载器配置 loaders:[ {test: /\\.css$/, loader: &apos;style-loader!css-loader&apos;}, {test: /\\.js$/, loader: &apos;jsx-loader?harmony&apos;}, {test: /\\.scss$/, loader: &apos;style!css!sass?sourceMap&apos;}, {test: /\\.(png|jpg)$/, loader: &apos;url-loader?limit-8192&apos;} ] }, }; `&lt;/pre&gt; #### plugins 插件项 这里使用了一个 CommonsChunkPlugin 的插件, 用于提取多个入口文件的公共部分, 然后生成一个 common.js 来访方便多页面之间的复用 #### entry 是页面入口文件配置, output 是输出配置 决定入口文件要生成什么名字的文件, 存放到哪里 &lt;pre&gt;`{ entry: { page1: &apos;./page1&apos;, //支持数组, 将加载数组中的所有模块, 但一最后一个模块为输出 page2: [&apos;./entry1&apos;,&apos;./entry2&apos;] }, output:{ path:&apos;dist/js/page&apos;, filename: &apos;[name].bundle.js&apos; } } `&lt;/pre&gt; 这段代码最终会生成一个page1.bundle.js, 和一个page2.bundle.js, 并存放到./dist/page下 #### module.loaders 是最关键的配置 告诉 webpack 每一种文件都要用什么加载器来处理 多个 loader 之间用&apos;!&apos;连接 所有加载器都要通过 npm 来加载 配置信息的参数&apos;?limit=8192&apos;表示将所有小于8kb的图片都转为 base64格式, 超过8kb 的图片用 url-loader 来处理 ### 运行 webpack `$webpack --display-error-details` 后面的参数&apos;--display-error-details&apos; 是推荐加上的, 方便出错的时候能查阅更详细的信息 其他主要参数有 &lt;pre&gt;`$webpack --config XXX.js //使用另一份配置文件 $webpack --watch //监听变动并自动打包 $webpack -p //压缩混淆脚本, 这个很重要 $webpack -d //生成 map 隐射文件, 告知哪些模块被最终打包到哪里 `&lt;/pre&gt; ### 模块引入 #### HTML 直接在页面&amp;lt;body&amp;gt;中引入 webpack 最终生成的页面脚本即可 &lt;pre&gt;`&amp;lt;body&amp;gt; &amp;lt;script scr = &apos;dist/js/page/common.js&apos;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script scr = &apos;dist/js/page/index.js&apos;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; `&lt;/pre&gt; 可以看到连样式都不需要, 脚本执行的时候会动态生成&amp;lt;style&amp;gt;并注入 head #### JS 各脚本模块可以直接用 commonJS 来书写, 并可以直接引入未经编译的模块, 比如 JSX, Sass, coffee 等(只要在 webpack.config.js 中配置好加载器) 看一下编译前的页面入口文件(index.js) &lt;pre&gt;`require(&apos;../../css/reset.scss&apos;); //加载 Reset 模块 require(&apos;../../css/allComponent.scss&apos;); //加载组件模块 var React = require(&apos;react&apos;); var AppWrap = require(&apos;redux&apos;).createRedux; var Provider = require(&apos;redux/react&apos;).Provider; var stores = require(&apos;AppStore&apos;); var redux = createRedux(stores); var App = React.createClass({ render: function(){ return ( &amp;lt;Provider redux = {redux}&amp;gt; {function() {return &amp;lt;AppWrap /&amp;gt;;}} &amp;lt;/Provider&amp;gt; ); } }); ReactDOM.render( &amp;lt;App /&amp;gt;,document.body ); 后续的都由 webpack 处理","link":"/2016/07/20/webpack/"},{"title":"智能合约编写注意事项","text":"原文连接 Overflow 与 UnderflowSolidity 可以处理 256 位数字, 最高为 2256 - 1, 所以对 (2 256 - 1) 加 1 会导致归 0. 同理, 对 unsigned 类型 0 做减 1 运算会得到 (2**256 - 1) 测试代码如下 123456789101112131415pragma solidity 0.4.18;contract OverflowUnderflow { uint public zero = 0; uint public max = 2**256 - 1; // zero will end up at 2 ** 256 - 1 function underflow() public { zero -= 1; } function overflow() public { max += 1; }} 尽管他们同样危险, 但是在智能合约中, underflow 造成的影响更大. 比如, 账号 A 持有 X tokens, 如果他发起一笔 X + 1 tokens 的交易, 如果代码不进行校验, 则账号 A 的余额可能发生 underflow 导致余额变多. 可以引入 SafeMath Library 解决 123456789101112131415161718192021222324252627282930313233343536373839404142pragma solidity 0.4.18;library SafeMath { function mul(uint256 a, uint256 b) internal pure returns (uint256) { if (a==0) { return 0; } uint c = a * b; assert(c / a == b); return c; } function div(uint256 a, uint256 b) internal pure returns (uint256) { uint256 c = a / b; return c; } function sub(uint256 a, uint256 b) internal pure returns (uint256) { assert(b &lt;= a); return a - b; } function add(uint256 a, uint256 b) internal pure returns (uint256) { uint256 c = a + b; assert(c &gt;= a); return c; }}contract OverflowUnderflow { using SafeMath for uint; uint public zero = 0; uint public max = 2 ** 256 - 1; function underflow() public { zero = zero.sub(1); } function overflow() public { max = max.add(1); }} Visibility 与 Delegatecall Public functions 可以被任意地址调用 External functions 只能从合约外部调用 Private functions 只能从合约内部调用 Internal functions 允许从合约及其子合约调用 External functions 消耗的 gas 比 public 少, 因为其使用 calldata 而 Public 需要复制所有参数到 memory. Delegatecall引自 Solidity Docs Delegatecall is identical to a message call apart from the fact that the code at the target address is executed in the context of the calling contract and msg.sender and msg.value do not change their values. This means that a contract can dynamically load code from a different address at runtime. Storage, current address and balance still refer to the calling contract, only the code is taken from the called address. 这个特性可以用于构建 Library 和模块化代码. 但是与此同时, 这也有可能造成别人对你的代码进行操作. 下例中, 攻击者调用 pwn 方法获得了合约的拥有权. 123456789101112131415161718192021222324252627282930pragma solidity 0.4.18;contract Delegate { address public owner; function Delegate(address _owner) public { owner = _owner; } function pwn() public { owner = msg.sender; }}contract Deletagion { address public owner; Delegate delegate; function Delegation(address _delegateAddreses) public { delegate = Delegate(_delegateAddreses); owner = msg.sender; } // an attacker can call Delegate.pwn() in the context of Delegation, this means that pwn() will modify the state of **Delegation** and not Delegate, the result is that the attacker takes unauthorized ownership of the contract. function () public { if(delegate.delegatecall(msg.data)) { this; } }} Reentrancy(TheDAO hack)Solidity 中 call 函数被调用时, 如果带有 value 参数, 则会转发所有他所收到的 gas. 在一下代码片段中, call 函数在 sender 的余额实际减少前被调用. 这里有一个漏洞曾导致 TheDAO 攻击. 12345678function withdraw(uint _amount) public { if(balances[msg.sender] &gt;= _amount) { if(msg.sender.call.value(_amount)()) { _amount; } balances[msg.sender] -= amount; }} 引自 Reddit 的解释 In simple words, it’s like the bank teller doesn’t change your balance until she has given you all the money you requested. “Can I withdraw $500? Wait, before that , can I withdraw $500?” And so on. The smart contracts as designed only check you have $500 at beginning once, and allow themselves to be interrupted.","link":"/2018/01/29/智能合约编写注意事项/"},{"title":"webpackDevServer Proxy","text":"devServer.proxy: object Proxying some URLs can be useful when you have a separate API backend development server and you want to send API requests on the same domain. The dev-server makes use of the powerful http-proxy-middleware package. With a backend on localhost:3000, you can use this to enable proxying: 123proxy: { &apos;/api&apos;: &apos;http://localhost:3000&apos;} A request to /api/users will now proxy to the request to http://localhost:3000/api/users If you don’t want /api to be passed along, we need to rewrite the path 12345678proxy: { &apos;/api&apos;: { target: &apos;http://localhost:3000&apos;, pathRewrite: { &apos;^/api&apos;: &apos;&apos;, } }} A backend server running on HTTPS with an invalid certificate will not be accepted by default. If you want to, modify config like this: 123456proxy: { &apos;/api&apos;: { target: &apos;https://other-server.example.com&apos;, secure: false, }}","link":"/2017/04/27/webpackDevServer-Proxy/"},{"title":"Webpack简明指南","text":"Thanks to Webpack 傻瓜式指南 安装npm install -g webpack `&lt;/pre&gt; ### 建立项目 &lt;pre&gt;`mkdir webpack cd webpack npm init touch .gitignore `&lt;/pre&gt; #### 项目结构 &lt;pre&gt;`project | |---app | | | |---index.js | |---sub.js | |---package.json | |---webpack.config.js `&lt;/pre&gt; &lt;pre&gt;`//sub.js function generateText(){ var element = document.createElement(&apos;h2&apos;); element.innerHTML = &quot;Hello, I&apos;m h2&quot;; return element; } module.exports = generateText; `&lt;/pre&gt; &lt;pre&gt;`//index.js var sub = require(&apos;./sub&apos;); var app = document.createElement(&apos;div&apos;); app.innerHTML = &quot;&amp;lt;h1&amp;gt;Hello, I&apos;m h1&quot;; app.appendChild(sub()) `&lt;/pre&gt; ### 配置 Webpack 目的是将两个 js 根据依赖关系合并, 然后在 dist 目录创建一个 index.html 并引用合并后的 js. 这里安装一个 plugin, 可以快速生成 HTML &lt;pre&gt;`npm install --save-dev html-webpack-plugin `&lt;/pre&gt; 修改 webpack.config.js &lt;pre&gt;`var path = require(&apos;path&apos;); var HtmlWebpackPlugin = require(&apos;html-webpack-plugin&apos;); //定义文件夹路径 var ROOT_PATH = path.resolve(__dirname); var APP_PATH = path.resolve(ROOT_PATH, &apos;app&apos;); var DIST_PATH = path.resolve(ROOT_PATH, &apos;dist&apos;); module.exports = { //项目文件夹, 可以直接用文件夹名, 默认寻找 index.js entry: APP_PATH, output: { path: DIST_PATH, filename: &apos;bundle.js&apos; }, //添加插件, 自动生成 html plugins: [ new HtmlWebpackPlugin({title: &apos;Hello World App&apos;}) ] }; `&lt;/pre&gt; 然后在项目目录运行 &lt;pre&gt;`webpack `&lt;/pre&gt; 可以看到 html 已经引用了 bundle.js ### 配置 webpack-dev-server 用于自动刷新浏览器 安装webpack-dev-server &lt;pre&gt;`npm install -g webpack-dev-server `&lt;/pre&gt; 修改 webpack.config.js &lt;pre&gt;`module.exports = { ... devServer: { historyApiFallback: true, hot: true, inline: true, progress: true, }, ... } `&lt;/pre&gt; 修改 package.json &lt;pre&gt;`... &quot;scripts&quot;: { &quot;start&quot;: &quot;webpack-dev-server --hot --inline&quot; }, ... `&lt;/pre&gt; 在项目目录执行 &lt;pre&gt;`npm start `&lt;/pre&gt; 登录 http://localhost:8080 ### 添加 CSS 样式 css-loader 会遍历 css 文件, style-loader 会把样式插入到&amp;lt;style&amp;gt; &lt;pre&gt;`npm install -save-dev css-loader style-laoder `&lt;/pre&gt; 修改 webpack.config.js &lt;pre&gt;`... module:{ loaders: [ { test: /\\.css$/, loaders: [&apos;style&apos;,&apos;css&apos;], include: APP_PATH } ] } ... `&lt;/pre&gt; 注意 loaders 的书写方式, 从右向左执行 添加样式文件 app/main.css &lt;pre&gt;`h1 { color: red; } `&lt;/pre&gt; 在入口文件&quot;index.js&quot; 中引用 &lt;pre&gt;`require(&apos;./main.css&apos;) `&lt;/pre&gt; ### 使用 sass 这里需要 sass-loader 和 node-sass 一起解析文件 &lt;pre&gt;`npm install --save-dev sass-loader node-sass `&lt;/pre&gt; 修改 webpack.config.js &lt;pre&gt;`//先删除 css 规则 { test: /\\.scss$/, loaders: [&apos;style&apos;,&apos;css&apos;,&apos;sass&apos;], include: APP_PATH }, `&lt;/pre&gt; 添加两个 sass 文件 app/variables.scss 和 app/main.scss &lt;pre&gt;`//variables.scss $red: red; `&lt;/pre&gt; &lt;pre&gt;`//main.scss @import &apos;./variables.scss&apos;; h1{ color: $red; } `&lt;/pre&gt; 在入口文件 index.js 中引用 &lt;pre&gt;`require(&apos;./main.scss&apos;); `&lt;/pre&gt; ### 处理图片 &lt;pre&gt;`npm install --save-dev url-loader `&lt;/pre&gt; 配置webpack.config.js &lt;pre&gt;`{ test: /\\.(png|jpg)$/, loader: &apos;url?limit=8192&apos; } `&lt;/pre&gt; 注意, Limit参数制定了小于 8M 的图片会被转为 base64 编码, 可以减轻网络请求. &lt;pre&gt;`@import &apos;./variabels.scss&apos; h1 { color: $red; background-image: url(&apos;./imgs/avatar.jpg&apos;); } `&lt;/pre&gt; ### 添加第三方库 &lt;pre&gt;`npm install --save-dev jquery moment `&lt;/pre&gt; 修改 index.js &lt;pre&gt;`var sub = require(&apos;./sub&apos;); require(&apos;./main.scss&apos;); var $ = require(&apos;jquery&apos;); var moment = require(&apos;moment&apos;); var app = document.createElement(&apos;div&apos;); app.innerHTML = &apos;&amp;lt;h1&amp;gt;Hello, h1&apos;; document.body.append(app); app.appendChild(sub()); $(&apos;body&apos;).append(&apos;&amp;lt;p&amp;gt;Inserted By Jquery. Now is &apos; + moment().format() + &apos;&amp;lt;/p&amp;gt;&apos;); `&lt;/pre&gt; ### 添加 ES6 支持 安装 loader &lt;pre&gt;`npm install -save-dev babel-loader babel-preset-es2015 `&lt;/pre&gt; 配置 webpack.config.js &lt;pre&gt;`... { test: /\\.jsx$/, loaders: babel, include: APP_PATH, query:{ presets: [&apos;es2015&apos;] } } ... `&lt;/pre&gt; es2015 这个参数是 babel 的 plugin, 可以支持最新的 ES6 的特性 现在可以 js 文件改为 ES6 风格 &lt;pre&gt;`//sub.js export default function(){ var element = document.createElement(&apos;h2&apos;); element.innerHTML = &apos;This is h2&apos;; return element; } `&lt;/pre&gt; &lt;pre&gt;`//index.js import &apos;./main.scss&apos;; import generateText from &apos;./sub&apos;; import $ from &apos;jquery&apos;; import moment from &apos;moment&apos;; let app = document.createElement(&apos;div&apos;); const myPromise = Promise.resolve(42); myPromise.then((number) =&amp;gt; { $(&apos;body&apos;).append(&apos;&amp;lt;p&amp;gt;Promise result is &apos; + number + &apos;now is &apos; + moment().format() + &apos;&amp;lt;/p&amp;gt;&apos;); }); app.innerHTML = &apos;&amp;lt;h1&amp;gt;This is h1&apos;; document.body.appendChild(app); app.appendChild(generateText());","link":"/2016/07/21/webpack-e7-ae-80-e6-98-8e-e6-8c-87-e5-8d-97/"},{"title":"XTemplate 模板语法","text":"变量变量会从当前模板的上下文查找值, 如果要输出一个变量的值, 可以使用 {{ variable }} `&lt;/pre&gt; 这样模板引擎会从上下文寻找变量`variable`并打印出来. 变量可以使用`.`访问其属性, 和 js 一样也可以通过`[]`访问属性 &lt;pre&gt;`{{ user.name }} {{ user['name'] }} `&lt;/pre&gt; 如果一个变量的值是`undefined`或`null`, 那么什么也不会输出, 也不会报错. ### 支持的数据类型 XTemplate 支持 js 中所有基本数据类型 - Boolean - Number - String - Null - Undefined - Object - Array ### 输出 使用`{{ foo }}`来输出`escape`之后的数据, `{{{ foo }}}`来输出`unescape`的原始数据 &lt;pre&gt;`escaped: {{ foo }} unescaped: {{{ foo }}} `&lt;/pre&gt; 如果希望输出最原始数据(包括`{{}}`), 那么需要使用`{{% %}}`语法 &lt;pre&gt;`{{% {{ x }} %}} `&lt;/pre&gt; 渲染这个模板, 会输出 &lt;pre&gt;`{{ x }} `&lt;/pre&gt; #### 添加注释 &lt;pre&gt;`{{! comment }} `&lt;/pre&gt; #### 添加空格 `{{~`删除空格前缀 `~}}`删除空格后缀 ### 作用域 每一个模板都有一个独立的作用于, 在字幕版中可以访问父模板的上下文, 但是字幕版中定义或者修改变量不会影响到父模板的变量 &lt;pre&gt;`// parent.xtpl {{ set (a=1,b=2) }} {{ include ('sub.xtpl') }} in parent: a = {{ a }} b = {{ b }} `&lt;/pre&gt; &lt;pre&gt;`// sub.xtpl in sub: {{ set b = 3 }} a = {{ a }} b = {{ b }} `&lt;/pre&gt; 渲染 parent.xtpl 得到 &lt;pre&gt;`in sub: a: 1 b: 3 in parent: a: 1 b: 2 `&lt;/pre&gt; ### 根数据 通过`root.foo` 可以访问到渲染的根数据, 即调用`render`方法时传入的数据 用数据`{ name: &apos;foo&apos;, array: [{name:&apos;bar&apos;}] }`渲染下面模板: &lt;pre&gt;`{{ #each(arr) }} {{root.name}} {{name}} {{/each}} `&lt;/pre&gt; 得到 &lt;pre&gt;`foo bar `&lt;/pre&gt; ## 方法和逻辑 可以使用变量上 js 提供的方法: &lt;pre&gt;`var x = [1,2,3] `&lt;/pre&gt; &lt;pre&gt;`{{#each(x.slice(1))}}{{this}} {{/each}} // =&amp;gt; 2 3 `&lt;/pre&gt; ### 操作符 XTemplate 支持在数据上使用一些操作符: &lt;pre&gt;`+, -, *, /, % `&lt;/pre&gt; &lt;pre&gt;`===, !==, &amp;gt;, &amp;gt;=, &amp;lt;, &amp;lt;= `&lt;/pre&gt; &lt;pre&gt;`||, &amp;amp;&amp;amp;, ! `&lt;/pre&gt; &lt;pre&gt;`?: `&lt;/pre&gt; ### 函数调用 如果你传递 js 的方法到模板中, 那么可以使用它 &lt;pre&gt;`{{foo(1,2,3)}} `&lt;/pre&gt; ### 内置函数 &lt;pre&gt;`range(start, end, [step]) `&lt;/pre&gt; 不包括 end &lt;pre&gt;`set(key = value, [key = value]) `&lt;/pre&gt; `set` 用于定义或修改一个变量 &lt;pre&gt;`{{ set(x=1) }} {{ set(y=3,z=2) }} {{x}} {{y+z}} `&lt;/pre&gt; 渲染得到 &lt;pre&gt;`1 5 `&lt;/pre&gt; `void`, 允许忽略模板渲染 &lt;pre&gt;`{{ set(x=1) }} {{ void(x) }} `&lt;/pre&gt; 将渲染空 ## 命令 命令是一些特殊的区块, 对于这些特殊的区块, XTemplate 会做特殊处理. XTemplate 自带了一些内置的命令, 也可以自定义命令 `if` &lt;pre&gt;`{{# if(variable) }} It is true {{/ if}} `&lt;/pre&gt; 如果 vairable 为 true, 则渲染命令块 &lt;pre&gt;`{{# if(variable) }} {{ elseif (vairable)}} {{ else }} {{/ if }} `with` 和 js 中的`with`类似 `&lt;/pre&gt; var a = { b:1 } ``` &lt;pre&gt;`{{{#with(a)}}} {{b}} // 1 {{/with}} `&lt;/pre&gt; `each` `each`可以对 array 和 dictionary 进行迭代 &lt;pre&gt;`// array {{ set (array = [{ name: 'foo' }, { name: 'bar' }])}} {{#each(array)}} {{xindex}} {{this.name}} {{/each}} `&lt;/pre&gt; 渲染得到 &lt;pre&gt;`0 foo 1 bar `&lt;/pre&gt; &lt;pre&gt;`// dictionary {{ set (dictionary = { foo:'bar', hello:'world' })}} {{#each(dictionary,'value','key')}} {{key}}{{value}} {{/each}} `&lt;/pre&gt; 渲染得到 &lt;pre&gt;`foo bar hello world `&lt;/pre&gt; ### 访问上层变量 在`with`和`each`中, 可以通过`../`访问外层的同名变量 &lt;pre&gt;`// {a: 1, b:[{a:2}]} {{#with(x)}} {{#each(b)}} {{../a}}{{a}} // 12 {{/with}} {{/with}} `&lt;/pre&gt; ### 宏 宏允许你定义一个可复用的代码片段 &lt;pre&gt;`{{#macro(\"test\",\"param\",default=1)}} param is {{param}} {{default}} {{/macro}} `&lt;/pre&gt; 现在可以调用该宏 &lt;pre&gt;`{{macro(\"test\", \"2\")}} {{macro(\"test\",\"2\",default=2)}} `&lt;/pre&gt; 渲染结果 &lt;pre&gt;`param is 2 1 param is 2 2 `&lt;/pre&gt; ### include `include` 引入其他的模板, 在共享组件的时候十分有效 &lt;pre&gt;`{{ include ('item.html') }} `&lt;/pre&gt; 如果下网引入子模板的时候可以在子模板的上下文设置其他值, 可以通过`include`后面的参数传入 &lt;pre&gt;`// parent.html {{ set(x='x',y='y') }} {{ include ('sub.html', xx=x,yy=x) }} `&lt;/pre&gt; &lt;pre&gt;`// sub.html x:{{x}} y:{{y}} xx:{{xx}} yy:{{yy}} `&lt;/pre&gt; parent.html渲染结果 &lt;pre&gt;`x: x // from parent.html y: y // from parent.html xx: x // from sub.html yy: x // from sub.html `&lt;/pre&gt; ### includeOnce 功能和`include`一样, 区别在于对于同一个模板, 只在第一次调用的时候起作用. ### parse 如果希望能够让子模板拥有一个完全独立的上下文, 不需要父级作用于, 则可以使用`parse` &lt;pre&gt;`// parent.html {{ set(x = 'x', y = 'y') }} {{ parse('sub.html', xx = x, yy = x) }} `&lt;/pre&gt; &lt;pre&gt;`// sub.html x: {{x}} y: {{y}} xx: {{xx}} yy: {{yy}} `&lt;/pre&gt; parent.html渲染结果 &lt;pre&gt;`x: y: xx:x yy:x `&lt;/pre&gt; ## 模板继承 当编写一个 template 的时候, 可以定义`blocks`, 这样在字幕版中可以重写这些 block &lt;pre&gt;`// parent.xtpl &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;....&amp;gt; {{{block ('head')}}} &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; {{{block ('body')}}} &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; `&lt;/pre&gt; &lt;pre&gt;`// child.xtpl {{ extend ('./parent.xtpl')}} {{#block ('head')}} // overwrite head block &amp;lt;....&amp;gt; {{/block}} {{#block ('body')}} // overwrite body block &amp;lt;...&amp;gt; {{/block}} 渲染 child.xtpl 可以获得新的模板下的实例","link":"/2016/09/18/xtemplate-e6-a8-a1-e6-9d-bf-e8-af-ad-e6-b3-95/"}],"tags":[{"name":"CSS3","slug":"CSS3","link":"/tags/CSS3/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"jQuery","slug":"jQuery","link":"/tags/jQuery/"},{"name":"Trick","slug":"Trick","link":"/tags/Trick/"},{"name":"Material Design","slug":"Material-Design","link":"/tags/Material-Design/"},{"name":"GraphQL, Apollo, TypeScript","slug":"GraphQL-Apollo-TypeScript","link":"/tags/GraphQL-Apollo-TypeScript/"},{"name":"Phoenix, Elixir, Ecto","slug":"Phoenix-Elixir-Ecto","link":"/tags/Phoenix-Elixir-Ecto/"},{"name":"Node, CLI","slug":"Node-CLI","link":"/tags/Node-CLI/"},{"name":"Int8Array","slug":"Int8Array","link":"/tags/Int8Array/"},{"name":"ETH, Wallet","slug":"ETH-Wallet","link":"/tags/ETH-Wallet/"},{"name":"Contract, Solidity","slug":"Contract-Solidity","link":"/tags/Contract-Solidity/"},{"name":"Solidity","slug":"Solidity","link":"/tags/Solidity/"},{"name":"BlockChain","slug":"BlockChain","link":"/tags/BlockChain/"},{"name":"Node.js, Nest.js","slug":"Node-js-Nest-js","link":"/tags/Node-js-Nest-js/"},{"name":"Ruby, Rails, RoR, Mina","slug":"Ruby-Rails-RoR-Mina","link":"/tags/Ruby-Rails-RoR-Mina/"},{"name":"Contract, Ethereum, Web3","slug":"Contract-Ethereum-Web3","link":"/tags/Contract-Ethereum-Web3/"},{"name":"Ethereum, IPFS","slug":"Ethereum-IPFS","link":"/tags/Ethereum-IPFS/"},{"name":"Node, Fastify","slug":"Node-Fastify","link":"/tags/Node-Fastify/"},{"name":"Smart Contract, Web3","slug":"Smart-Contract-Web3","link":"/tags/Smart-Contract-Web3/"},{"name":"Solidity, Error Handling","slug":"Solidity-Error-Handling","link":"/tags/Solidity-Error-Handling/"},{"name":"Solidity, Public, External","slug":"Solidity-Public-External","link":"/tags/Solidity-Public-External/"},{"name":"React, Docker","slug":"React-Docker","link":"/tags/React-Docker/"},{"name":"Ethereum","slug":"Ethereum","link":"/tags/Ethereum/"},{"name":"HTTP2, Node","slug":"HTTP2-Node","link":"/tags/HTTP2-Node/"},{"name":"Go, Http, Web","slug":"Go-Http-Web","link":"/tags/Go-Http-Web/"},{"name":"Erlang, Elixir, GenServer","slug":"Erlang-Elixir-GenServer","link":"/tags/Erlang-Elixir-GenServer/"},{"name":"Webpack","slug":"Webpack","link":"/tags/Webpack/"},{"name":"Economics","slug":"Economics","link":"/tags/Economics/"},{"name":"JSON-RPC","slug":"JSON-RPC","link":"/tags/JSON-RPC/"},{"name":"Ruby, Rails","slug":"Ruby-Rails","link":"/tags/Ruby-Rails/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"Rust, Rocket","slug":"Rust-Rocket","link":"/tags/Rust-Rocket/"},{"name":"DAPP, Solidity","slug":"DAPP-Solidity","link":"/tags/DAPP-Solidity/"},{"name":"D3, Example","slug":"D3-Example","link":"/tags/D3-Example/"},{"name":"GitHub, Workflow","slug":"GitHub-Workflow","link":"/tags/GitHub-Workflow/"},{"name":"Protobuf","slug":"Protobuf","link":"/tags/Protobuf/"},{"name":"Pug, HTML","slug":"Pug-HTML","link":"/tags/Pug-HTML/"},{"name":"Drizzle, Ethereum, BlockChain","slug":"Drizzle-Ethereum-BlockChain","link":"/tags/Drizzle-Ethereum-BlockChain/"},{"name":"Mock, JavaScript","slug":"Mock-JavaScript","link":"/tags/Mock-JavaScript/"},{"name":"Blockchain","slug":"Blockchain","link":"/tags/Blockchain/"},{"name":"Redux","slug":"Redux","link":"/tags/Redux/"},{"name":"DApp, Solidity","slug":"DApp-Solidity","link":"/tags/DApp-Solidity/"},{"name":"Javascript","slug":"Javascript","link":"/tags/Javascript/"},{"name":"babel","slug":"babel","link":"/tags/babel/"},{"name":"babel-polyfill","slug":"babel-polyfill","link":"/tags/babel-polyfill/"},{"name":"RxJS","slug":"RxJS","link":"/tags/RxJS/"},{"name":"BOOTSTRAP","slug":"BOOTSTRAP","link":"/tags/BOOTSTRAP/"},{"name":"HTML5","slug":"HTML5","link":"/tags/HTML5/"},{"name":"commandline","slug":"commandline","link":"/tags/commandline/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"webpack","slug":"webpack","link":"/tags/webpack/"},{"name":"CommonJS","slug":"CommonJS","link":"/tags/CommonJS/"},{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"ESLint","slug":"ESLint","link":"/tags/ESLint/"},{"name":"React-Redux","slug":"React-Redux","link":"/tags/React-Redux/"},{"name":"Chrome, Extensions","slug":"Chrome-Extensions","link":"/tags/Chrome-Extensions/"},{"name":"DOM","slug":"DOM","link":"/tags/DOM/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"},{"name":"Gulp","slug":"Gulp","link":"/tags/Gulp/"},{"name":"NPM","slug":"NPM","link":"/tags/NPM/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"ES6","slug":"ES6","link":"/tags/ES6/"},{"name":"Thunk","slug":"Thunk","link":"/tags/Thunk/"},{"name":"测试","slug":"测试","link":"/tags/测试/"},{"name":"Koa","slug":"Koa","link":"/tags/Koa/"},{"name":"NODE","slug":"NODE","link":"/tags/NODE/"},{"name":"AJAX","slug":"AJAX","link":"/tags/AJAX/"},{"name":"CORS","slug":"CORS","link":"/tags/CORS/"},{"name":"Elixir, Phoenix, SCSS","slug":"Elixir-Phoenix-SCSS","link":"/tags/Elixir-Phoenix-SCSS/"},{"name":"webpack2","slug":"webpack2","link":"/tags/webpack2/"},{"name":"FP","slug":"FP","link":"/tags/FP/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Node, Graphql, Koa","slug":"Node-Graphql-Koa","link":"/tags/Node-Graphql-Koa/"},{"name":"automatic","slug":"automatic","link":"/tags/automatic/"},{"name":"Immutable","slug":"Immutable","link":"/tags/Immutable/"},{"name":"Closure","slug":"Closure","link":"/tags/Closure/"},{"name":"DevTools","slug":"DevTools","link":"/tags/DevTools/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"MDL","slug":"MDL","link":"/tags/MDL/"},{"name":"precache","slug":"precache","link":"/tags/precache/"},{"name":"Promise","slug":"Promise","link":"/tags/Promise/"},{"name":"Webpack, DLL","slug":"Webpack-DLL","link":"/tags/Webpack-DLL/"},{"name":"blockchain, bitcoin, bip","slug":"blockchain-bitcoin-bip","link":"/tags/blockchain-bitcoin-bip/"},{"name":"React, Router, Code-splitting","slug":"React-Router-Code-splitting","link":"/tags/React-Router-Code-splitting/"},{"name":"lecture, yc","slug":"lecture-yc","link":"/tags/lecture-yc/"},{"name":"React-Native","slug":"React-Native","link":"/tags/React-Native/"},{"name":"React-Router","slug":"React-Router","link":"/tags/React-Router/"},{"name":"RegExp","slug":"RegExp","link":"/tags/RegExp/"},{"name":"Koa, NPM, Package","slug":"Koa-NPM-Package","link":"/tags/Koa-NPM-Package/"},{"name":"Html, Picture","slug":"Html-Picture","link":"/tags/Html-Picture/"},{"name":"Nock","slug":"Nock","link":"/tags/Nock/"},{"name":"Solidity, Smart Contract","slug":"Solidity-Smart-Contract","link":"/tags/Solidity-Smart-Contract/"}],"categories":[{"name":"note","slug":"note","link":"/categories/note/"},{"name":"Uncategorized","slug":"Uncategorized","link":"/categories/Uncategorized/"},{"name":"workNote","slug":"note/workNote","link":"/categories/note/workNote/"},{"name":"Soup","slug":"Soup","link":"/categories/Soup/"},{"name":"github","slug":"github","link":"/categories/github/"},{"name":"workNote","slug":"workNote","link":"/categories/workNote/"},{"name":"note","slug":"github/note","link":"/categories/github/note/"}]}